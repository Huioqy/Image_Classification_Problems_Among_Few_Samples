{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Pyramid\n",
    "# def batch_pyramid(images):\n",
    "#     pyramid_list = []\n",
    "#     for i in tqdm(range(len(images))):\n",
    "#         img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#         G = img.copy()\n",
    "#         gp = [G]\n",
    "#         for i in range(4):\n",
    "#             G = cv2.pyrDown(G)\n",
    "#             gp.append(G)\n",
    "#         lp = [gp[4]]\n",
    "#         for i in range(4,0,-1):\n",
    "#             GE = cv2.pyrUp(gp[i])\n",
    "#             (x,y) = gp[i-1].shape\n",
    "#             L = cv2.subtract(gp[i-1],GE[:x,:y])\n",
    "#             lp.append(L)\n",
    "#         lp_1 = cv2.normalize(lp[1], lp[1],0,255,cv2.NORM_MINMAX)\n",
    "#         lp_2 = cv2.normalize(lp[2], lp[2],0,255,cv2.NORM_MINMAX)\n",
    "#         lp_out = [cv2.resize(lp_1, (128,128)),cv2.resize(lp_2, (128,128))]\n",
    "#         pyramid_list.append((np.array(lp_out)).astype(np.uint8))\n",
    "#     pyramid_list=np.array(pyramid_list,dtype = float32).reshape(\n",
    "#         [images.shape[0],images.shape[1],images.shape[2],2])/255.0\n",
    "    \n",
    "#     print (pyramid_list.shape)\n",
    "#     return pyramid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "# def load_flower_data():\n",
    "#     # grab the list of images that we'll be describing\n",
    "#     print(\"[INFO] handling images...\")\n",
    "#     TRAIN_ORIGINAL_DIR = '../train/'\n",
    "#     TRAIN_SUB_DIR = '../subsample/'\n",
    "#     TRAIN_GAN = '../../image_gan/'\n",
    "#     TEST_DIR = '../../test/'\n",
    "\n",
    "#     # use this for full dataset\n",
    "#     train_images_gan = [TRAIN_GAN + i for i in os.listdir(TRAIN_GAN)]\n",
    "#     test_images = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "    \n",
    "#     train_images = train_images_gan\n",
    "    \n",
    "#     train_images.sort(key=natural_keys)\n",
    "#     test_images.sort(key=natural_keys)\n",
    "\n",
    "#     # initialize the features matrix and labels list\n",
    "#     trainImage = []\n",
    "#     trainLabels = []\n",
    "#     testImage = []\n",
    "#     testLabels = []\n",
    "\n",
    "#     # loop over the input images\n",
    "#     for (i, imagePath) in enumerate(train_images):\n",
    "#         # extract the class label\n",
    "#         # get the labels from the name of the images by extract the string before \"_\"\n",
    "#         label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "#         # read and resize image\n",
    "#         img = cv2.imread(imagePath)\n",
    "#         img = cv2.resize(img, (128,128))\n",
    "\n",
    "#         # add the messages we got to features and labels matricies\n",
    "#         trainImage.append(img)\n",
    "#         trainLabels.append(label)\n",
    "\n",
    "#         # show an update every 100 images until the last image\n",
    "#         if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "#             print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "            \n",
    "#       # loop over the input images\n",
    "#     for (i, imagePath) in enumerate(test_images):\n",
    "#         # extract the class label\n",
    "#         # our images were named as labels.image_number.format\n",
    "#         # get the labels from the name of the images by extract the string before \".\"\n",
    "#         label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "#         # extract CNN features in the image\n",
    "#         img = cv2.imread(imagePath)\n",
    "#         img = cv2.resize(img, (128,128))\n",
    "\n",
    "#         # add the messages we got to features and labels matricies\n",
    "#         testImage.append(img)\n",
    "#         testLabels.append(label)\n",
    "\n",
    "#         # show an update every 100 images until the last image\n",
    "#         if i > 0 and ((i + 1) % 1000 == 0 or i == len(test_images) - 1):\n",
    "#             print(\"[INFO] processed {}/{}\".format(i + 1, len(test_images)))\n",
    "\n",
    "\n",
    "#     trainImage = np.array(trainImage,dtype = float32)\n",
    "#     trainLabels = np.array(trainLabels)\n",
    "#     testImage = np.array(testImage,dtype = float32)\n",
    "#     testLabels = np.array(testLabels)\n",
    "#     print (trainImage.shape)\n",
    "    \n",
    "#     trainImage = trainImage.astype(np.float32) / 255\n",
    "#     testImage = testImage.astype(np.float32) / 255\n",
    "    \n",
    "#     le = preprocessing.LabelEncoder()\n",
    "#     le.fit(trainLabels)\n",
    "#     list(le.classes_)\n",
    "#     trainLabels = le.transform(trainLabels) \n",
    "#     testLabels = le.transform(testLabels) \n",
    "    \n",
    "#     return trainImage, trainLabels, testImage, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "[INFO] processed 1000/4000\n",
      "[INFO] processed 2000/4000\n",
      "[INFO] processed 3000/4000\n",
      "[INFO] processed 4000/4000\n",
      "[INFO] processed 156/156\n",
      "(4000, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [53:39<00:00,  1.24it/s]\n",
      "  3%|▎         | 5/156 [00:00<00:03, 44.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 128, 128, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:03<00:00, 49.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 128, 128, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(156, 2)\n",
      "[INFO] trainImage matrix: 768.00MB\n",
      "[INFO] trainLabels matrix: 0.0625MB\n",
      "[INFO] testImage matrix: 29.95MB\n",
      "[INFO] testLabels matrix: 0.0024MB\n",
      "[INFO] trainImage_pyramid matrix: 512.00MB\n",
      "[INFO] testImage_pyramid matrix: 19.9680MB\n"
     ]
    }
   ],
   "source": [
    "trainImage, trainLabels, testImage, testLabels = load_flower_data()\n",
    "\n",
    "trainImage_pyramid = batch_pyramid(trainImage)\n",
    "testImage_pyramid = batch_pyramid(testImage)\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "print (trainLabels)\n",
    "testLabels = keras.utils.to_categorical(testLabels, nb_classes)\n",
    "print (testLabels)\n",
    "print (testLabels.shape)\n",
    "\n",
    "np.save('../trainImage.npy', trainImage)\n",
    "np.save('../trainLabels.npy', trainLabels)\n",
    "np.save('../testImage.npy', testImage)\n",
    "np.save('../testLabels.npy', testLabels)\n",
    "np.save('../trainImage_pyramid_L.npy', trainImage_pyramid)\n",
    "np.save('../testImage_pyramid_L.npy', testImage_pyramid)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage matrix: {:.2f}MB\".format(\n",
    "    (testImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testLabels matrix: {:.4f}MB\".format(\n",
    "    (testLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainImage_pyramid matrix: {:.2f}MB\".format(\n",
    "    (trainImage_pyramid.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_pyramid matrix: {:.4f}MB\".format(\n",
    "    (testImage_pyramid.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, log_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.pyramid_dim = 2  # color dimension\n",
    "        self.nb_class = 2\n",
    "        \n",
    "        # number of convolutional filters to use  \n",
    "        self.nb_CNN = [32, 64, 64, 64, 128]  \n",
    "        # number of dense filters to use  \n",
    "        self.nb_Dense = [256] \n",
    "        # size of pooling area for max pooling  \n",
    "        self.pool_size = (2, 2)  \n",
    "        # convolution kernel size  \n",
    "        self.kernel_size = (3, 3)\n",
    "        self.batch_normalization_control = True\n",
    "        \n",
    "        # name for checkpoint\n",
    "        self.model_name = 'CNN_Pyramid_L_C%d_D%d_Kernel(%d,%d)_%d_lrdecay' % (len(self.nb_CNN), len(self.nb_Dense),\n",
    "                                                          self.kernel_size[0], self.kernel_size[1], max(self.nb_CNN))\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(0.001, \n",
    "                                             global_step=self.global_step, \n",
    "                                             decay_steps=10, \n",
    "                                             decay_rate=0.9, \n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "        \n",
    "        # test\n",
    "\n",
    "        #load_flower_data\n",
    "        self.train_x = np.load('../trainImage.npy')\n",
    "        self.train_y = np.load('../trainLabels.npy')\n",
    "        self.test_x = np.load('../testImage.npy')\n",
    "        self.test_y = np.load('../testLabels.npy')\n",
    "        self.train_x_pyramid = np.load('../trainImage_pyramid_L.npy')\n",
    "        self.test_x_pyramid = np.load('../testImage_pyramid_L.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['losses'] = []\n",
    "        self.train_hist['accuracy'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches_train = len(self.train_x) // self.batch_size\n",
    "        self.num_batches_test= len(self.test_x) // self.batch_size\n",
    "\n",
    "    def cnn_model(self, x, x_pyramid, keep_prob, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"cnn\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            B = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"CNN:x\",x.get_shape()) # 128, 128, 3 \n",
    "            print(\"CNN:x_pyramid\",x_pyramid.get_shape()) # 128, 128, 3 \n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(inputs = x,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_1'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_1.get_shape())\n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_2 = tf.layers.conv2d(inputs = x_pyramid,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_2'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_2.get_shape())\n",
    "\n",
    "            #把数据和边缘进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)\n",
    "            net = tf.nn.relu(net, name = 'relu_conv_1')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_1'\n",
    "                                             )\n",
    "            \n",
    "            for i in range(2,len(self.nb_CNN)+1):\n",
    "                net = tf.layers.conv2d(inputs = net,                 # 输入,\n",
    "                                       filters = self.nb_CNN[i-1],      # 卷积核个数,\n",
    "                                       kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                       strides = (1, 1),\n",
    "                                       padding = 'same',              # padding方法\n",
    "                                       kernel_initializer = W,\n",
    "                                       bias_initializer = B,\n",
    "                                       kernel_regularizer = None,\n",
    "                                       bias_regularizer = None,\n",
    "                                       activity_regularizer = None,\n",
    "                                       name = 'conv_'+ str(i)        # 命名用于获取变量\n",
    "                                       )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "                if self.batch_normalization_control:\n",
    "                    net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_conv_' + str(i))\n",
    "                net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_' + str(i)\n",
    "                                             )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #flatten\n",
    "            net = tf.reshape(net, [-1, int(net.get_shape()[1]*net.get_shape()[2]*net.get_shape()[3])],name='flatten')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #dense layer\n",
    "            for i in range(1,len(self.nb_Dense)+1):\n",
    "                net = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_Dense[i-1],\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_' + str(i)\n",
    "                                    )\n",
    "#                 net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_dense_' + str(i))\n",
    "                net = tf.layers.dropout(inputs = net,\n",
    "                                        rate=keep_prob,\n",
    "                                        noise_shape=None,\n",
    "                                        seed=None,\n",
    "                                        training = is_training,\n",
    "                                        name= 'dropout_dense_' + str(i)\n",
    "                                        )\n",
    "            #output\n",
    "            logit = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_class,\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_output'\n",
    "                                    )\n",
    "            out_logit = tf.nn.softmax(logit, name=\"softmax\")\n",
    "            print(\"CNN:out_logit\",out_logit.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out_logit, logit\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.c_dim], \n",
    "                                name='x_image')\n",
    "        \n",
    "        self.x_pyramid = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.pyramid_dim], \n",
    "                                name='x_pyramid')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[self.batch_size, self.nb_class], name='y_label')\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of cnn_model\n",
    "        self.out_logit, self.logit = self.cnn_model(self.x, self.x_pyramid, self.keep_prob, is_training=True, reuse=False)\n",
    "        \n",
    "        self.loss_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,\n",
    "                                                                                         logits =self.logit))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # trainable variables into a group\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        cnn_vars = [var for var in tf_vars if var.name.startswith('cnn')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.cnn_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.loss_cross_entropy,\n",
    "                                                                                        var_list=cnn_vars)\n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        # output of cnn_model\n",
    "        self.out_logit_test, self.logit_test = self.cnn_model(self.x, self.x_pyramid, self.keep_prob, is_training=False, reuse=True)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logit_test, 1), tf.argmax(self.y, 1))\n",
    "        self.predict = tf.argmax(self.logit_test, 1)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        self.loss_sum = tf.summary.scalar(\"loss\", self.loss_cross_entropy)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep = self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name+'.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            CNN_losses = []\n",
    "  \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.train_x.shape[0]), self.train_x.shape[0])\n",
    "            shuffled_set = self.train_x[shuffle_idxs]\n",
    "            shuffled_set_pyramid = self.train_x_pyramid[shuffle_idxs]\n",
    "            shuffled_label = self.train_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches_train):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_pyramid= shuffled_set_pyramid[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, cnn_loss = self.sess.run([self.cnn_optim, self.loss_sum, self.loss_cross_entropy],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.x_pyramid: batch_x_pyramid,\n",
    "                                                          self.y: batch_y,\n",
    "                                                          self.keep_prob: 0.5}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                CNN_losses.append(cnn_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" % (epoch_loop, idx, self.num_batches_train, \n",
    "                                                                          time.time() - start_time, cnn_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            # Evaluates accuracy on test set\n",
    "            test_accuracy_list = []\n",
    "            for idx_test in range(self.num_batches_test):\n",
    "                batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_pyramid_test =self.test_x_pyramid[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                    self.x_pyramid: batch_x_pyramid_test,\n",
    "                                                                    self.y: batch_y_tes,\n",
    "                                                                    self.keep_prob: 1.0})\n",
    "                test_accuracy_list.append(accuracy)\n",
    "            test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        \n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss: %.8f acc: %.5f lr: %.8f'% (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                    np.mean(CNN_losses), test_accuracy, rate))\n",
    "            \n",
    "            self.train_hist['losses'].append(np.mean(CNN_losses))\n",
    "            self.train_hist['accuracy'].append( test_accuracy)\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "            \n",
    "            # save trainhist for train\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name + '.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' \n",
    "                                 + self.model_name + '.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "        \"\"\"test after train\"\"\"\n",
    "        best_acc = max(self.train_hist['accuracy'])\n",
    "        beat_epoch = self.train_hist['accuracy'].index(best_acc) + 1\n",
    "        print (\" [*] Best Epoch: \", beat_epoch, \", Accuracy: \", best_acc)\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(beat_epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_pyramid_test =self.test_x_pyramid[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_pyramid: batch_x_pyramid_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Best Epoch:\", beat_epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "\n",
    "    def test(self, epoch):\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_pyramidtest =self.test_x_pyramid[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_pyramid: batch_x_pyramid_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Epoch:\", epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True) \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['losses'])+1)\n",
    "\n",
    "        y1 = hist['losses']\n",
    "        y2 = hist['accuracy']\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "                            \n",
    "        ax2 = ax1.twinx()  \n",
    "\n",
    "        ax1.plot(x, y1, 'b')\n",
    "        ax2.plot(x, y2, 'r')\n",
    "                            \n",
    "        ax1.set_xlabel('Epoch')\n",
    "                            \n",
    "        ax1.set_ylabel('CNN_loss')    \n",
    "        ax2.set_ylabel('accuracy')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_pyramid (100, 128, 128, 2)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 64)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_pyramid (100, 128, 128, 2)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 64)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "cnn/conv_1_1/kernel:0 (float32_ref 3x3x3x32) [864, bytes: 3456]\n",
      "cnn/conv_1_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_2/kernel:0 (float32_ref 3x3x2x32) [576, bytes: 2304]\n",
      "cnn/conv_1_2/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_2/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_3/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_3/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_4/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_5/kernel:0 (float32_ref 3x3x64x128) [73728, bytes: 294912]\n",
      "cnn/conv_5/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_1/kernel:0 (float32_ref 2048x256) [524288, bytes: 2097152]\n",
      "cnn/dense_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "cnn/dense_output/kernel:0 (float32_ref 256x2) [512, bytes: 2048]\n",
      "cnn/dense_output/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 711970\n",
      "Total bytes of variables: 2847880\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 1] [   0/  40] time: 3.9415, loss: 0.72748423\n",
      "Epoch: [ 1] [   1/  40] time: 4.1916, loss: 1.77451169\n",
      "Epoch: [ 1] [   2/  40] time: 4.4464, loss: 0.64063239\n",
      "Epoch: [ 1] [   3/  40] time: 4.6957, loss: 0.44035247\n",
      "Epoch: [ 1] [   4/  40] time: 4.9421, loss: 0.33514467\n",
      "Epoch: [ 1] [   5/  40] time: 5.1984, loss: 0.26929021\n",
      "Epoch: [ 1] [   6/  40] time: 5.4469, loss: 0.22619008\n",
      "Epoch: [ 1] [   7/  40] time: 5.6929, loss: 0.13048439\n",
      "Epoch: [ 1] [   8/  40] time: 5.9427, loss: 0.19762586\n",
      "Epoch: [ 1] [   9/  40] time: 6.1980, loss: 0.17145529\n",
      "Epoch: [ 1] [  10/  40] time: 6.4538, loss: 0.10859808\n",
      "Epoch: [ 1] [  11/  40] time: 6.7026, loss: 0.09583066\n",
      "Epoch: [ 1] [  12/  40] time: 6.9497, loss: 0.08076564\n",
      "Epoch: [ 1] [  13/  40] time: 7.2042, loss: 0.07668161\n",
      "Epoch: [ 1] [  14/  40] time: 7.4577, loss: 0.08369073\n",
      "Epoch: [ 1] [  15/  40] time: 7.7043, loss: 0.11295565\n",
      "Epoch: [ 1] [  16/  40] time: 7.9558, loss: 0.06146160\n",
      "Epoch: [ 1] [  17/  40] time: 8.2125, loss: 0.13295528\n",
      "Epoch: [ 1] [  18/  40] time: 8.4669, loss: 0.09205182\n",
      "Epoch: [ 1] [  19/  40] time: 8.7119, loss: 0.08595683\n",
      "Epoch: [ 1] [  20/  40] time: 8.9596, loss: 0.06281184\n",
      "Epoch: [ 1] [  21/  40] time: 9.2194, loss: 0.08603361\n",
      "Epoch: [ 1] [  22/  40] time: 9.4752, loss: 0.05391844\n",
      "Epoch: [ 1] [  23/  40] time: 9.7249, loss: 0.10979013\n",
      "Epoch: [ 1] [  24/  40] time: 9.9748, loss: 0.15896276\n",
      "Epoch: [ 1] [  25/  40] time: 10.2433, loss: 0.10488611\n",
      "Epoch: [ 1] [  26/  40] time: 10.4985, loss: 0.10075418\n",
      "Epoch: [ 1] [  27/  40] time: 10.7442, loss: 0.08946729\n",
      "Epoch: [ 1] [  28/  40] time: 10.9914, loss: 0.04021162\n",
      "Epoch: [ 1] [  29/  40] time: 11.2569, loss: 0.07229513\n",
      "Epoch: [ 1] [  30/  40] time: 11.5169, loss: 0.10012932\n",
      "Epoch: [ 1] [  31/  40] time: 11.7759, loss: 0.04159909\n",
      "Epoch: [ 1] [  32/  40] time: 12.0378, loss: 0.15156448\n",
      "Epoch: [ 1] [  33/  40] time: 12.2935, loss: 0.04739937\n",
      "Epoch: [ 1] [  34/  40] time: 12.5553, loss: 0.10973675\n",
      "Epoch: [ 1] [  35/  40] time: 12.8070, loss: 0.04847199\n",
      "Epoch: [ 1] [  36/  40] time: 13.0530, loss: 0.04425062\n",
      "Epoch: [ 1] [  37/  40] time: 13.3121, loss: 0.01755257\n",
      "Epoch: [ 1] [  38/  40] time: 13.5696, loss: 0.09919440\n",
      "Epoch: [ 1] [  39/  40] time: 13.8170, loss: 0.11309528\n",
      "[1/50] - ptime: 13.9804 loss: 0.18740609 acc: 0.23000 lr: 0.00100000\n",
      "Epoch: [ 2] [   0/  40] time: 15.9727, loss: 0.07994734\n",
      "Epoch: [ 2] [   1/  40] time: 16.2247, loss: 0.06582420\n",
      "Epoch: [ 2] [   2/  40] time: 16.4728, loss: 0.04508602\n",
      "Epoch: [ 2] [   3/  40] time: 16.7187, loss: 0.05821933\n",
      "Epoch: [ 2] [   4/  40] time: 16.9613, loss: 0.02160467\n",
      "Epoch: [ 2] [   5/  40] time: 17.2159, loss: 0.09680558\n",
      "Epoch: [ 2] [   6/  40] time: 17.4694, loss: 0.03166287\n",
      "Epoch: [ 2] [   7/  40] time: 17.7184, loss: 0.09259546\n",
      "Epoch: [ 2] [   8/  40] time: 17.9660, loss: 0.07402866\n",
      "Epoch: [ 2] [   9/  40] time: 18.2201, loss: 0.06909032\n",
      "Epoch: [ 2] [  10/  40] time: 18.4701, loss: 0.05435524\n",
      "Epoch: [ 2] [  11/  40] time: 18.7162, loss: 0.06202210\n",
      "Epoch: [ 2] [  12/  40] time: 18.9645, loss: 0.06571700\n",
      "Epoch: [ 2] [  13/  40] time: 19.2176, loss: 0.05155654\n",
      "Epoch: [ 2] [  14/  40] time: 19.4764, loss: 0.04033387\n",
      "Epoch: [ 2] [  15/  40] time: 19.7228, loss: 0.04821631\n",
      "Epoch: [ 2] [  16/  40] time: 19.9701, loss: 0.02111108\n",
      "Epoch: [ 2] [  17/  40] time: 20.2190, loss: 0.07089063\n",
      "Epoch: [ 2] [  18/  40] time: 20.4739, loss: 0.02412026\n",
      "Epoch: [ 2] [  19/  40] time: 20.7201, loss: 0.00725204\n",
      "Epoch: [ 2] [  20/  40] time: 20.9769, loss: 0.02014504\n",
      "Epoch: [ 2] [  21/  40] time: 21.2296, loss: 0.01874320\n",
      "Epoch: [ 2] [  22/  40] time: 21.4879, loss: 0.12918077\n",
      "Epoch: [ 2] [  23/  40] time: 21.7336, loss: 0.15544134\n",
      "Epoch: [ 2] [  24/  40] time: 21.9799, loss: 0.03342620\n",
      "Epoch: [ 2] [  25/  40] time: 22.2351, loss: 0.09280305\n",
      "Epoch: [ 2] [  26/  40] time: 22.4894, loss: 0.09026740\n",
      "Epoch: [ 2] [  27/  40] time: 22.7354, loss: 0.06770365\n",
      "Epoch: [ 2] [  28/  40] time: 22.9847, loss: 0.12127090\n",
      "Epoch: [ 2] [  29/  40] time: 23.2431, loss: 0.02083069\n",
      "Epoch: [ 2] [  30/  40] time: 23.4963, loss: 0.03983432\n",
      "Epoch: [ 2] [  31/  40] time: 23.7420, loss: 0.03533986\n",
      "Epoch: [ 2] [  32/  40] time: 23.9921, loss: 0.01394864\n",
      "Epoch: [ 2] [  33/  40] time: 24.2523, loss: 0.03737878\n",
      "Epoch: [ 2] [  34/  40] time: 24.5061, loss: 0.03645631\n",
      "Epoch: [ 2] [  35/  40] time: 24.7555, loss: 0.02613223\n",
      "Epoch: [ 2] [  36/  40] time: 25.0016, loss: 0.01604360\n",
      "Epoch: [ 2] [  37/  40] time: 25.2625, loss: 0.05693855\n",
      "Epoch: [ 2] [  38/  40] time: 25.5151, loss: 0.16739835\n",
      "Epoch: [ 2] [  39/  40] time: 25.7611, loss: 0.17444433\n",
      "[2/50] - ptime: 11.0291 loss: 0.06085417 acc: 0.25000 lr: 0.00100000\n",
      "Epoch: [ 3] [   0/  40] time: 27.6088, loss: 0.09605908\n",
      "Epoch: [ 3] [   1/  40] time: 27.8535, loss: 0.01600850\n",
      "Epoch: [ 3] [   2/  40] time: 28.1018, loss: 0.11223991\n",
      "Epoch: [ 3] [   3/  40] time: 28.3674, loss: 0.04424378\n",
      "Epoch: [ 3] [   4/  40] time: 28.6151, loss: 0.05768158\n",
      "Epoch: [ 3] [   5/  40] time: 28.8662, loss: 0.07714503\n",
      "Epoch: [ 3] [   6/  40] time: 29.1186, loss: 0.04855934\n",
      "Epoch: [ 3] [   7/  40] time: 29.3649, loss: 0.08328477\n",
      "Epoch: [ 3] [   8/  40] time: 29.6181, loss: 0.07872394\n",
      "Epoch: [ 3] [   9/  40] time: 29.8650, loss: 0.07893492\n",
      "Epoch: [ 3] [  10/  40] time: 30.1170, loss: 0.03913961\n",
      "Epoch: [ 3] [  11/  40] time: 30.3710, loss: 0.04759204\n",
      "Epoch: [ 3] [  12/  40] time: 30.6195, loss: 0.00988388\n",
      "Epoch: [ 3] [  13/  40] time: 30.8696, loss: 0.02581942\n",
      "Epoch: [ 3] [  14/  40] time: 31.1184, loss: 0.12873803\n",
      "Epoch: [ 3] [  15/  40] time: 31.3681, loss: 0.04622544\n",
      "Epoch: [ 3] [  16/  40] time: 31.6184, loss: 0.00783457\n",
      "Epoch: [ 3] [  17/  40] time: 31.8633, loss: 0.03751153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 3] [  18/  40] time: 32.1126, loss: 0.06197466\n",
      "Epoch: [ 3] [  19/  40] time: 32.3788, loss: 0.03287204\n",
      "Epoch: [ 3] [  20/  40] time: 32.6282, loss: 0.04513976\n",
      "Epoch: [ 3] [  21/  40] time: 32.8853, loss: 0.05670438\n",
      "Epoch: [ 3] [  22/  40] time: 33.1390, loss: 0.03479360\n",
      "Epoch: [ 3] [  23/  40] time: 33.3936, loss: 0.01997443\n",
      "Epoch: [ 3] [  24/  40] time: 33.6438, loss: 0.05966530\n",
      "Epoch: [ 3] [  25/  40] time: 33.8930, loss: 0.04162209\n",
      "Epoch: [ 3] [  26/  40] time: 34.1483, loss: 0.10198610\n",
      "Epoch: [ 3] [  27/  40] time: 34.3977, loss: 0.07680871\n",
      "Epoch: [ 3] [  28/  40] time: 34.6455, loss: 0.03881118\n",
      "Epoch: [ 3] [  29/  40] time: 34.8939, loss: 0.03795028\n",
      "Epoch: [ 3] [  30/  40] time: 35.1514, loss: 0.02760784\n",
      "Epoch: [ 3] [  31/  40] time: 35.4040, loss: 0.02328650\n",
      "Epoch: [ 3] [  32/  40] time: 35.6450, loss: 0.02760923\n",
      "Epoch: [ 3] [  33/  40] time: 35.8923, loss: 0.05791844\n",
      "Epoch: [ 3] [  34/  40] time: 36.1504, loss: 0.01300879\n",
      "Epoch: [ 3] [  35/  40] time: 36.3998, loss: 0.05625969\n",
      "Epoch: [ 3] [  36/  40] time: 36.6492, loss: 0.05756174\n",
      "Epoch: [ 3] [  37/  40] time: 36.9018, loss: 0.08218247\n",
      "Epoch: [ 3] [  38/  40] time: 37.1613, loss: 0.02967041\n",
      "Epoch: [ 3] [  39/  40] time: 37.4096, loss: 0.12025084\n",
      "[3/50] - ptime: 11.0564 loss: 0.05348210 acc: 0.22000 lr: 0.00100000\n",
      "Epoch: [ 4] [   0/  40] time: 39.2661, loss: 0.05454611\n",
      "Epoch: [ 4] [   1/  40] time: 39.5167, loss: 0.01985715\n",
      "Epoch: [ 4] [   2/  40] time: 39.7665, loss: 0.04826060\n",
      "Epoch: [ 4] [   3/  40] time: 40.0185, loss: 0.03462873\n",
      "Epoch: [ 4] [   4/  40] time: 40.2711, loss: 0.04463674\n",
      "Epoch: [ 4] [   5/  40] time: 40.5175, loss: 0.02735979\n",
      "Epoch: [ 4] [   6/  40] time: 40.7642, loss: 0.01443568\n",
      "Epoch: [ 4] [   7/  40] time: 41.0160, loss: 0.02396669\n",
      "Epoch: [ 4] [   8/  40] time: 41.2728, loss: 0.02127752\n",
      "Epoch: [ 4] [   9/  40] time: 41.5218, loss: 0.05081826\n",
      "Epoch: [ 4] [  10/  40] time: 41.7706, loss: 0.00742165\n",
      "Epoch: [ 4] [  11/  40] time: 42.0227, loss: 0.02562182\n",
      "Epoch: [ 4] [  12/  40] time: 42.2767, loss: 0.00896316\n",
      "Epoch: [ 4] [  13/  40] time: 42.5251, loss: 0.00703603\n",
      "Epoch: [ 4] [  14/  40] time: 42.7719, loss: 0.01239311\n",
      "Epoch: [ 4] [  15/  40] time: 43.0252, loss: 0.04774555\n",
      "Epoch: [ 4] [  16/  40] time: 43.2837, loss: 0.03862067\n",
      "Epoch: [ 4] [  17/  40] time: 43.5326, loss: 0.06789993\n",
      "Epoch: [ 4] [  18/  40] time: 43.7862, loss: 0.02001317\n",
      "Epoch: [ 4] [  19/  40] time: 44.0385, loss: 0.02219404\n",
      "Epoch: [ 4] [  20/  40] time: 44.2873, loss: 0.02789628\n",
      "Epoch: [ 4] [  21/  40] time: 44.5333, loss: 0.01300856\n",
      "Epoch: [ 4] [  22/  40] time: 44.7809, loss: 0.00359150\n",
      "Epoch: [ 4] [  23/  40] time: 45.0366, loss: 0.04303316\n",
      "Epoch: [ 4] [  24/  40] time: 45.2845, loss: 0.11626072\n",
      "Epoch: [ 4] [  25/  40] time: 45.5346, loss: 0.06384061\n",
      "Epoch: [ 4] [  26/  40] time: 45.7853, loss: 0.13144708\n",
      "Epoch: [ 4] [  27/  40] time: 46.0365, loss: 0.02278471\n",
      "Epoch: [ 4] [  28/  40] time: 46.2858, loss: 0.01619187\n",
      "Epoch: [ 4] [  29/  40] time: 46.5366, loss: 0.06670413\n",
      "Epoch: [ 4] [  30/  40] time: 46.7845, loss: 0.04579008\n",
      "Epoch: [ 4] [  31/  40] time: 47.0365, loss: 0.03292498\n",
      "Epoch: [ 4] [  32/  40] time: 47.2856, loss: 0.03616979\n",
      "Epoch: [ 4] [  33/  40] time: 47.5452, loss: 0.02571109\n",
      "Epoch: [ 4] [  34/  40] time: 47.7959, loss: 0.05457886\n",
      "Epoch: [ 4] [  35/  40] time: 48.0547, loss: 0.03100360\n",
      "Epoch: [ 4] [  36/  40] time: 48.3129, loss: 0.01569806\n",
      "Epoch: [ 4] [  37/  40] time: 48.5591, loss: 0.00990149\n",
      "Epoch: [ 4] [  38/  40] time: 48.8074, loss: 0.00558149\n",
      "Epoch: [ 4] [  39/  40] time: 49.0680, loss: 0.04437043\n",
      "[4/50] - ptime: 11.1008 loss: 0.03510462 acc: 0.41000 lr: 0.00100000\n",
      "Epoch: [ 5] [   0/  40] time: 50.8086, loss: 0.01198364\n",
      "Epoch: [ 5] [   1/  40] time: 51.0528, loss: 0.00952318\n",
      "Epoch: [ 5] [   2/  40] time: 51.3135, loss: 0.01727749\n",
      "Epoch: [ 5] [   3/  40] time: 51.5627, loss: 0.01454806\n",
      "Epoch: [ 5] [   4/  40] time: 51.8123, loss: 0.03112215\n",
      "Epoch: [ 5] [   5/  40] time: 52.0687, loss: 0.00341370\n",
      "Epoch: [ 5] [   6/  40] time: 52.3218, loss: 0.01496275\n",
      "Epoch: [ 5] [   7/  40] time: 52.5706, loss: 0.00687833\n",
      "Epoch: [ 5] [   8/  40] time: 52.8178, loss: 0.01272963\n",
      "Epoch: [ 5] [   9/  40] time: 53.0706, loss: 0.00385908\n",
      "Epoch: [ 5] [  10/  40] time: 53.3255, loss: 0.00835309\n",
      "Epoch: [ 5] [  11/  40] time: 53.5729, loss: 0.03813843\n",
      "Epoch: [ 5] [  12/  40] time: 53.8249, loss: 0.00121254\n",
      "Epoch: [ 5] [  13/  40] time: 54.0825, loss: 0.01747247\n",
      "Epoch: [ 5] [  14/  40] time: 54.3376, loss: 0.02927634\n",
      "Epoch: [ 5] [  15/  40] time: 54.5839, loss: 0.00357412\n",
      "Epoch: [ 5] [  16/  40] time: 54.8379, loss: 0.01325252\n",
      "Epoch: [ 5] [  17/  40] time: 55.0940, loss: 0.08703993\n",
      "Epoch: [ 5] [  18/  40] time: 55.3436, loss: 0.02967130\n",
      "Epoch: [ 5] [  19/  40] time: 55.5898, loss: 0.00688282\n",
      "Epoch: [ 5] [  20/  40] time: 55.8423, loss: 0.03324445\n",
      "Epoch: [ 5] [  21/  40] time: 56.1039, loss: 0.01133356\n",
      "Epoch: [ 5] [  22/  40] time: 56.3460, loss: 0.01607205\n",
      "Epoch: [ 5] [  23/  40] time: 56.5945, loss: 0.06207247\n",
      "Epoch: [ 5] [  24/  40] time: 56.8454, loss: 0.02057851\n",
      "Epoch: [ 5] [  25/  40] time: 57.1010, loss: 0.00364429\n",
      "Epoch: [ 5] [  26/  40] time: 57.3492, loss: 0.02422448\n",
      "Epoch: [ 5] [  27/  40] time: 57.5968, loss: 0.00852978\n",
      "Epoch: [ 5] [  28/  40] time: 57.8485, loss: 0.00197481\n",
      "Epoch: [ 5] [  29/  40] time: 58.1043, loss: 0.02871233\n",
      "Epoch: [ 5] [  30/  40] time: 58.3533, loss: 0.01107202\n",
      "Epoch: [ 5] [  31/  40] time: 58.6029, loss: 0.01562461\n",
      "Epoch: [ 5] [  32/  40] time: 58.8526, loss: 0.01020551\n",
      "Epoch: [ 5] [  33/  40] time: 59.1063, loss: 0.01291190\n",
      "Epoch: [ 5] [  34/  40] time: 59.3543, loss: 0.00332664\n",
      "Epoch: [ 5] [  35/  40] time: 59.6051, loss: 0.01335581\n",
      "Epoch: [ 5] [  36/  40] time: 59.8573, loss: 0.03848734\n",
      "Epoch: [ 5] [  37/  40] time: 60.1058, loss: 0.00559040\n",
      "Epoch: [ 5] [  38/  40] time: 60.3563, loss: 0.05128002\n",
      "Epoch: [ 5] [  39/  40] time: 60.6083, loss: 0.00584390\n",
      "[5/50] - ptime: 11.0115 loss: 0.01848141 acc: 0.23000 lr: 0.00100000\n",
      "Epoch: [ 6] [   0/  40] time: 62.4944, loss: 0.08841906\n",
      "Epoch: [ 6] [   1/  40] time: 62.7404, loss: 0.02939784\n",
      "Epoch: [ 6] [   2/  40] time: 62.9980, loss: 0.01693010\n",
      "Epoch: [ 6] [   3/  40] time: 63.2584, loss: 0.05055068\n",
      "Epoch: [ 6] [   4/  40] time: 63.5076, loss: 0.00600263\n",
      "Epoch: [ 6] [   5/  40] time: 63.7568, loss: 0.01917834\n",
      "Epoch: [ 6] [   6/  40] time: 64.0156, loss: 0.02920015\n",
      "Epoch: [ 6] [   7/  40] time: 64.2683, loss: 0.00881128\n",
      "Epoch: [ 6] [   8/  40] time: 64.5183, loss: 0.00871668\n",
      "Epoch: [ 6] [   9/  40] time: 64.7642, loss: 0.01787425\n",
      "Epoch: [ 6] [  10/  40] time: 65.0248, loss: 0.00311445\n",
      "Epoch: [ 6] [  11/  40] time: 65.2783, loss: 0.00619609\n",
      "Epoch: [ 6] [  12/  40] time: 65.5289, loss: 0.03646511\n",
      "Epoch: [ 6] [  13/  40] time: 65.7795, loss: 0.11815158\n",
      "Epoch: [ 6] [  14/  40] time: 66.0415, loss: 0.08113358\n",
      "Epoch: [ 6] [  15/  40] time: 66.2902, loss: 0.00895103\n",
      "Epoch: [ 6] [  16/  40] time: 66.5464, loss: 0.00796452\n",
      "Epoch: [ 6] [  17/  40] time: 66.7959, loss: 0.03336045\n",
      "Epoch: [ 6] [  18/  40] time: 67.0568, loss: 0.01301720\n",
      "Epoch: [ 6] [  19/  40] time: 67.3081, loss: 0.02716038\n",
      "Epoch: [ 6] [  20/  40] time: 67.5585, loss: 0.01742422\n",
      "Epoch: [ 6] [  21/  40] time: 67.8110, loss: 0.02735298\n",
      "Epoch: [ 6] [  22/  40] time: 68.0722, loss: 0.02109711\n",
      "Epoch: [ 6] [  23/  40] time: 68.3198, loss: 0.05900227\n",
      "Epoch: [ 6] [  24/  40] time: 68.5704, loss: 0.01301639\n",
      "Epoch: [ 6] [  25/  40] time: 68.8208, loss: 0.08113104\n",
      "Epoch: [ 6] [  26/  40] time: 69.0843, loss: 0.01573468\n",
      "Epoch: [ 6] [  27/  40] time: 69.3332, loss: 0.01072946\n",
      "Epoch: [ 6] [  28/  40] time: 69.5824, loss: 0.01696440\n",
      "Epoch: [ 6] [  29/  40] time: 69.8329, loss: 0.00348908\n",
      "Epoch: [ 6] [  30/  40] time: 70.0906, loss: 0.02011376\n",
      "Epoch: [ 6] [  31/  40] time: 70.3416, loss: 0.06144930\n",
      "Epoch: [ 6] [  32/  40] time: 70.5931, loss: 0.02305653\n",
      "Epoch: [ 6] [  33/  40] time: 70.8451, loss: 0.00703916\n",
      "Epoch: [ 6] [  34/  40] time: 71.0932, loss: 0.01532881\n",
      "Epoch: [ 6] [  35/  40] time: 71.3456, loss: 0.05219586\n",
      "Epoch: [ 6] [  36/  40] time: 71.5928, loss: 0.00293990\n",
      "Epoch: [ 6] [  37/  40] time: 71.8421, loss: 0.00923238\n",
      "Epoch: [ 6] [  38/  40] time: 72.0905, loss: 0.00360024\n",
      "Epoch: [ 6] [  39/  40] time: 72.3374, loss: 0.00758371\n",
      "[6/50] - ptime: 11.1219 loss: 0.02697692 acc: 0.27000 lr: 0.00100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 7] [   0/  40] time: 74.1856, loss: 0.01155573\n",
      "Epoch: [ 7] [   1/  40] time: 74.4353, loss: 0.00348218\n",
      "Epoch: [ 7] [   2/  40] time: 74.6858, loss: 0.00359596\n",
      "Epoch: [ 7] [   3/  40] time: 74.9422, loss: 0.01398062\n",
      "Epoch: [ 7] [   4/  40] time: 75.1948, loss: 0.00705005\n",
      "Epoch: [ 7] [   5/  40] time: 75.4501, loss: 0.00322538\n",
      "Epoch: [ 7] [   6/  40] time: 75.6985, loss: 0.02328734\n",
      "Epoch: [ 7] [   7/  40] time: 75.9527, loss: 0.00132199\n",
      "Epoch: [ 7] [   8/  40] time: 76.2046, loss: 0.00747291\n",
      "Epoch: [ 7] [   9/  40] time: 76.4558, loss: 0.00261334\n",
      "Epoch: [ 7] [  10/  40] time: 76.7062, loss: 0.00362312\n",
      "Epoch: [ 7] [  11/  40] time: 76.9634, loss: 0.00092502\n",
      "Epoch: [ 7] [  12/  40] time: 77.2154, loss: 0.00284757\n",
      "Epoch: [ 7] [  13/  40] time: 77.4648, loss: 0.00254669\n",
      "Epoch: [ 7] [  14/  40] time: 77.7246, loss: 0.01097309\n",
      "Epoch: [ 7] [  15/  40] time: 77.9817, loss: 0.00797208\n",
      "Epoch: [ 7] [  16/  40] time: 78.2316, loss: 0.00505298\n",
      "Epoch: [ 7] [  17/  40] time: 78.4828, loss: 0.01297475\n",
      "Epoch: [ 7] [  18/  40] time: 78.7284, loss: 0.00132377\n",
      "Epoch: [ 7] [  19/  40] time: 78.9858, loss: 0.02035777\n",
      "Epoch: [ 7] [  20/  40] time: 79.2414, loss: 0.07743556\n",
      "Epoch: [ 7] [  21/  40] time: 79.4904, loss: 0.00638559\n",
      "Epoch: [ 7] [  22/  40] time: 79.7504, loss: 0.00680193\n",
      "Epoch: [ 7] [  23/  40] time: 80.0113, loss: 0.00777260\n",
      "Epoch: [ 7] [  24/  40] time: 80.2683, loss: 0.00538809\n",
      "Epoch: [ 7] [  25/  40] time: 80.5189, loss: 0.00184728\n",
      "Epoch: [ 7] [  26/  40] time: 80.7685, loss: 0.00876120\n",
      "Epoch: [ 7] [  27/  40] time: 81.0269, loss: 0.01893634\n",
      "Epoch: [ 7] [  28/  40] time: 81.2774, loss: 0.00236444\n",
      "Epoch: [ 7] [  29/  40] time: 81.5307, loss: 0.00698287\n",
      "Epoch: [ 7] [  30/  40] time: 81.7766, loss: 0.02074958\n",
      "Epoch: [ 7] [  31/  40] time: 82.0428, loss: 0.02692096\n",
      "Epoch: [ 7] [  32/  40] time: 82.2905, loss: 0.00267385\n",
      "Epoch: [ 7] [  33/  40] time: 82.5427, loss: 0.00570830\n",
      "Epoch: [ 7] [  34/  40] time: 82.7942, loss: 0.00169089\n",
      "Epoch: [ 7] [  35/  40] time: 83.0458, loss: 0.03586748\n",
      "Epoch: [ 7] [  36/  40] time: 83.2993, loss: 0.07682081\n",
      "Epoch: [ 7] [  37/  40] time: 83.5491, loss: 0.01416748\n",
      "Epoch: [ 7] [  38/  40] time: 83.7921, loss: 0.16048527\n",
      "Epoch: [ 7] [  39/  40] time: 84.0488, loss: 0.04577482\n",
      "[7/50] - ptime: 11.1312 loss: 0.01699294 acc: 0.31000 lr: 0.00100000\n",
      "Epoch: [ 8] [   0/  40] time: 85.7570, loss: 0.02200868\n",
      "Epoch: [ 8] [   1/  40] time: 86.0076, loss: 0.03306251\n",
      "Epoch: [ 8] [   2/  40] time: 86.2578, loss: 0.06079680\n",
      "Epoch: [ 8] [   3/  40] time: 86.5133, loss: 0.00543303\n",
      "Epoch: [ 8] [   4/  40] time: 86.7640, loss: 0.03239011\n",
      "Epoch: [ 8] [   5/  40] time: 87.0224, loss: 0.01856622\n",
      "Epoch: [ 8] [   6/  40] time: 87.2734, loss: 0.00821365\n",
      "Epoch: [ 8] [   7/  40] time: 87.5204, loss: 0.00637726\n",
      "Epoch: [ 8] [   8/  40] time: 87.7765, loss: 0.00193835\n",
      "Epoch: [ 8] [   9/  40] time: 88.0429, loss: 0.00847024\n",
      "Epoch: [ 8] [  10/  40] time: 88.2925, loss: 0.00746477\n",
      "Epoch: [ 8] [  11/  40] time: 88.5436, loss: 0.02510489\n",
      "Epoch: [ 8] [  12/  40] time: 88.7968, loss: 0.05185310\n",
      "Epoch: [ 8] [  13/  40] time: 89.0599, loss: 0.01122195\n",
      "Epoch: [ 8] [  14/  40] time: 89.3078, loss: 0.00640820\n",
      "Epoch: [ 8] [  15/  40] time: 89.5596, loss: 0.05059082\n",
      "Epoch: [ 8] [  16/  40] time: 89.8123, loss: 0.01787912\n",
      "Epoch: [ 8] [  17/  40] time: 90.0743, loss: 0.02738173\n",
      "Epoch: [ 8] [  18/  40] time: 90.3222, loss: 0.02034832\n",
      "Epoch: [ 8] [  19/  40] time: 90.5753, loss: 0.00368390\n",
      "Epoch: [ 8] [  20/  40] time: 90.8281, loss: 0.00868717\n",
      "Epoch: [ 8] [  21/  40] time: 91.0877, loss: 0.02887429\n",
      "Epoch: [ 8] [  22/  40] time: 91.3393, loss: 0.00050511\n",
      "Epoch: [ 8] [  23/  40] time: 91.5898, loss: 0.01267008\n",
      "Epoch: [ 8] [  24/  40] time: 91.8477, loss: 0.01634385\n",
      "Epoch: [ 8] [  25/  40] time: 92.1056, loss: 0.00349628\n",
      "Epoch: [ 8] [  26/  40] time: 92.3525, loss: 0.00681752\n",
      "Epoch: [ 8] [  27/  40] time: 92.6052, loss: 0.04320217\n",
      "Epoch: [ 8] [  28/  40] time: 92.8589, loss: 0.00305775\n",
      "Epoch: [ 8] [  29/  40] time: 93.1158, loss: 0.00444130\n",
      "Epoch: [ 8] [  30/  40] time: 93.3683, loss: 0.02755427\n",
      "Epoch: [ 8] [  31/  40] time: 93.6188, loss: 0.00576346\n",
      "Epoch: [ 8] [  32/  40] time: 93.8752, loss: 0.04110163\n",
      "Epoch: [ 8] [  33/  40] time: 94.1279, loss: 0.01462626\n",
      "Epoch: [ 8] [  34/  40] time: 94.3747, loss: 0.03812399\n",
      "Epoch: [ 8] [  35/  40] time: 94.6279, loss: 0.03167970\n",
      "Epoch: [ 8] [  36/  40] time: 94.8829, loss: 0.01499286\n",
      "Epoch: [ 8] [  37/  40] time: 95.1346, loss: 0.02591002\n",
      "Epoch: [ 8] [  38/  40] time: 95.3866, loss: 0.03460056\n",
      "Epoch: [ 8] [  39/  40] time: 95.6421, loss: 0.00600520\n",
      "[8/50] - ptime: 11.0616 loss: 0.01969118 acc: 0.42000 lr: 0.00100000\n",
      "Epoch: [ 9] [   0/  40] time: 97.5565, loss: 0.00181857\n",
      "Epoch: [ 9] [   1/  40] time: 97.8084, loss: 0.00601033\n",
      "Epoch: [ 9] [   2/  40] time: 98.0631, loss: 0.02748249\n",
      "Epoch: [ 9] [   3/  40] time: 98.3121, loss: 0.00138601\n",
      "Epoch: [ 9] [   4/  40] time: 98.5618, loss: 0.00344831\n",
      "Epoch: [ 9] [   5/  40] time: 98.8127, loss: 0.00901967\n",
      "Epoch: [ 9] [   6/  40] time: 99.0707, loss: 0.01142650\n",
      "Epoch: [ 9] [   7/  40] time: 99.3180, loss: 0.00350263\n",
      "Epoch: [ 9] [   8/  40] time: 99.5668, loss: 0.00171031\n",
      "Epoch: [ 9] [   9/  40] time: 99.8195, loss: 0.00825192\n",
      "Epoch: [ 9] [  10/  40] time: 100.0745, loss: 0.00793835\n",
      "Epoch: [ 9] [  11/  40] time: 100.3204, loss: 0.00048291\n",
      "Epoch: [ 9] [  12/  40] time: 100.5721, loss: 0.00083804\n",
      "Epoch: [ 9] [  13/  40] time: 100.8246, loss: 0.01772409\n",
      "Epoch: [ 9] [  14/  40] time: 101.0736, loss: 0.02712640\n",
      "Epoch: [ 9] [  15/  40] time: 101.3246, loss: 0.03674962\n",
      "Epoch: [ 9] [  16/  40] time: 101.5745, loss: 0.05833282\n",
      "Epoch: [ 9] [  17/  40] time: 101.8278, loss: 0.00648136\n",
      "Epoch: [ 9] [  18/  40] time: 102.0849, loss: 0.00039043\n",
      "Epoch: [ 9] [  19/  40] time: 102.3324, loss: 0.00644624\n",
      "Epoch: [ 9] [  20/  40] time: 102.5851, loss: 0.04169372\n",
      "Epoch: [ 9] [  21/  40] time: 102.8428, loss: 0.00399423\n",
      "Epoch: [ 9] [  22/  40] time: 103.0967, loss: 0.02029967\n",
      "Epoch: [ 9] [  23/  40] time: 103.3458, loss: 0.01704584\n",
      "Epoch: [ 9] [  24/  40] time: 103.5985, loss: 0.01901332\n",
      "Epoch: [ 9] [  25/  40] time: 103.8549, loss: 0.03998681\n",
      "Epoch: [ 9] [  26/  40] time: 104.1094, loss: 0.03480166\n",
      "Epoch: [ 9] [  27/  40] time: 104.3551, loss: 0.03086491\n",
      "Epoch: [ 9] [  28/  40] time: 104.6070, loss: 0.02503282\n",
      "Epoch: [ 9] [  29/  40] time: 104.8656, loss: 0.01023352\n",
      "Epoch: [ 9] [  30/  40] time: 105.1205, loss: 0.01109235\n",
      "Epoch: [ 9] [  31/  40] time: 105.3692, loss: 0.00697128\n",
      "Epoch: [ 9] [  32/  40] time: 105.6267, loss: 0.01490645\n",
      "Epoch: [ 9] [  33/  40] time: 105.8902, loss: 0.00267894\n",
      "Epoch: [ 9] [  34/  40] time: 106.1418, loss: 0.01158512\n",
      "Epoch: [ 9] [  35/  40] time: 106.3896, loss: 0.00750116\n",
      "Epoch: [ 9] [  36/  40] time: 106.6467, loss: 0.00097173\n",
      "Epoch: [ 9] [  37/  40] time: 106.9050, loss: 0.00214072\n",
      "Epoch: [ 9] [  38/  40] time: 107.1544, loss: 0.00339844\n",
      "Epoch: [ 9] [  39/  40] time: 107.4066, loss: 0.00628995\n",
      "[9/50] - ptime: 11.1388 loss: 0.01367674 acc: 0.34000 lr: 0.00100000\n",
      "Epoch: [10] [   0/  40] time: 109.2296, loss: 0.00966460\n",
      "Epoch: [10] [   1/  40] time: 109.4841, loss: 0.00049622\n",
      "Epoch: [10] [   2/  40] time: 109.7368, loss: 0.00657114\n",
      "Epoch: [10] [   3/  40] time: 109.9928, loss: 0.01055225\n",
      "Epoch: [10] [   4/  40] time: 110.2419, loss: 0.01170025\n",
      "Epoch: [10] [   5/  40] time: 110.4919, loss: 0.00525734\n",
      "Epoch: [10] [   6/  40] time: 110.7409, loss: 0.00012561\n",
      "Epoch: [10] [   7/  40] time: 111.0018, loss: 0.00819131\n",
      "Epoch: [10] [   8/  40] time: 111.2480, loss: 0.00053749\n",
      "Epoch: [10] [   9/  40] time: 111.5021, loss: 0.00168097\n",
      "Epoch: [10] [  10/  40] time: 111.7515, loss: 0.00031348\n",
      "Epoch: [10] [  11/  40] time: 112.0079, loss: 0.00278510\n",
      "Epoch: [10] [  12/  40] time: 112.2577, loss: 0.00471477\n",
      "Epoch: [10] [  13/  40] time: 112.5085, loss: 0.00029901\n",
      "Epoch: [10] [  14/  40] time: 112.7602, loss: 0.00092891\n",
      "Epoch: [10] [  15/  40] time: 113.0160, loss: 0.00050549\n",
      "Epoch: [10] [  16/  40] time: 113.2646, loss: 0.00175121\n",
      "Epoch: [10] [  17/  40] time: 113.5173, loss: 0.00053015\n",
      "Epoch: [10] [  18/  40] time: 113.7726, loss: 0.00192659\n",
      "Epoch: [10] [  19/  40] time: 114.0214, loss: 0.00029379\n",
      "Epoch: [10] [  20/  40] time: 114.2732, loss: 0.00135104\n",
      "Epoch: [10] [  21/  40] time: 114.5217, loss: 0.00230155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10] [  22/  40] time: 114.7765, loss: 0.00332963\n",
      "Epoch: [10] [  23/  40] time: 115.0261, loss: 0.00164649\n",
      "Epoch: [10] [  24/  40] time: 115.2751, loss: 0.00034310\n",
      "Epoch: [10] [  25/  40] time: 115.5333, loss: 0.01460745\n",
      "Epoch: [10] [  26/  40] time: 115.7848, loss: 0.03537609\n",
      "Epoch: [10] [  27/  40] time: 116.0331, loss: 0.00764632\n",
      "Epoch: [10] [  28/  40] time: 116.2790, loss: 0.00049362\n",
      "Epoch: [10] [  29/  40] time: 116.5296, loss: 0.00052990\n",
      "Epoch: [10] [  30/  40] time: 116.7827, loss: 0.00128544\n",
      "Epoch: [10] [  31/  40] time: 117.0315, loss: 0.06424870\n",
      "Epoch: [10] [  32/  40] time: 117.2814, loss: 0.00099299\n",
      "Epoch: [10] [  33/  40] time: 117.5336, loss: 0.00612686\n",
      "Epoch: [10] [  34/  40] time: 117.7874, loss: 0.00402764\n",
      "Epoch: [10] [  35/  40] time: 118.0394, loss: 0.00398076\n",
      "Epoch: [10] [  36/  40] time: 118.2852, loss: 0.00223228\n",
      "Epoch: [10] [  37/  40] time: 118.5374, loss: 0.00361915\n",
      "Epoch: [10] [  38/  40] time: 118.7907, loss: 0.00036112\n",
      "Epoch: [10] [  39/  40] time: 119.0421, loss: 0.00214341\n",
      "[10/50] - ptime: 11.0377 loss: 0.00563673 acc: 0.75000 lr: 0.00090000\n",
      "Epoch: [11] [   0/  40] time: 120.8056, loss: 0.01608338\n",
      "Epoch: [11] [   1/  40] time: 121.0568, loss: 0.00860128\n",
      "Epoch: [11] [   2/  40] time: 121.3045, loss: 0.00118116\n",
      "Epoch: [11] [   3/  40] time: 121.5565, loss: 0.01472544\n",
      "Epoch: [11] [   4/  40] time: 121.8087, loss: 0.00282940\n",
      "Epoch: [11] [   5/  40] time: 122.0615, loss: 0.00111594\n",
      "Epoch: [11] [   6/  40] time: 122.3097, loss: 0.00148833\n",
      "Epoch: [11] [   7/  40] time: 122.5609, loss: 0.00021023\n",
      "Epoch: [11] [   8/  40] time: 122.8183, loss: 0.00272952\n",
      "Epoch: [11] [   9/  40] time: 123.0695, loss: 0.00052570\n",
      "Epoch: [11] [  10/  40] time: 123.3198, loss: 0.05359314\n",
      "Epoch: [11] [  11/  40] time: 123.5746, loss: 0.00811510\n",
      "Epoch: [11] [  12/  40] time: 123.8334, loss: 0.06212179\n",
      "Epoch: [11] [  13/  40] time: 124.0882, loss: 0.02603948\n",
      "Epoch: [11] [  14/  40] time: 124.3349, loss: 0.02745349\n",
      "Epoch: [11] [  15/  40] time: 124.5902, loss: 0.05661564\n",
      "Epoch: [11] [  16/  40] time: 124.8493, loss: 0.03716160\n",
      "Epoch: [11] [  17/  40] time: 125.0977, loss: 0.01408694\n",
      "Epoch: [11] [  18/  40] time: 125.3463, loss: 0.01143455\n",
      "Epoch: [11] [  19/  40] time: 125.6017, loss: 0.00911306\n",
      "Epoch: [11] [  20/  40] time: 125.8602, loss: 0.00061245\n",
      "Epoch: [11] [  21/  40] time: 126.1085, loss: 0.01113940\n",
      "Epoch: [11] [  22/  40] time: 126.3558, loss: 0.01255158\n",
      "Epoch: [11] [  23/  40] time: 126.6079, loss: 0.02756674\n",
      "Epoch: [11] [  24/  40] time: 126.8639, loss: 0.00505920\n",
      "Epoch: [11] [  25/  40] time: 127.1125, loss: 0.00802534\n",
      "Epoch: [11] [  26/  40] time: 127.3616, loss: 0.00129352\n",
      "Epoch: [11] [  27/  40] time: 127.6149, loss: 0.00524193\n",
      "Epoch: [11] [  28/  40] time: 127.8659, loss: 0.00599080\n",
      "Epoch: [11] [  29/  40] time: 128.1155, loss: 0.00877671\n",
      "Epoch: [11] [  30/  40] time: 128.3639, loss: 0.00188423\n",
      "Epoch: [11] [  31/  40] time: 128.6195, loss: 0.00824842\n",
      "Epoch: [11] [  32/  40] time: 128.8791, loss: 0.01423347\n",
      "Epoch: [11] [  33/  40] time: 129.1272, loss: 0.00575516\n",
      "Epoch: [11] [  34/  40] time: 129.3773, loss: 0.00169724\n",
      "Epoch: [11] [  35/  40] time: 129.6374, loss: 0.00784188\n",
      "Epoch: [11] [  36/  40] time: 129.8917, loss: 0.00518792\n",
      "Epoch: [11] [  37/  40] time: 130.1416, loss: 0.02543735\n",
      "Epoch: [11] [  38/  40] time: 130.3905, loss: 0.00063865\n",
      "Epoch: [11] [  39/  40] time: 130.6488, loss: 0.00040375\n",
      "[11/50] - ptime: 11.0603 loss: 0.01282027 acc: 0.63000 lr: 0.00090000\n",
      "Epoch: [12] [   0/  40] time: 132.3622, loss: 0.00096213\n",
      "Epoch: [12] [   1/  40] time: 132.6184, loss: 0.00913524\n",
      "Epoch: [12] [   2/  40] time: 132.8806, loss: 0.01083650\n",
      "Epoch: [12] [   3/  40] time: 133.1277, loss: 0.01618826\n",
      "Epoch: [12] [   4/  40] time: 133.3764, loss: 0.00050156\n",
      "Epoch: [12] [   5/  40] time: 133.6315, loss: 0.00249490\n",
      "Epoch: [12] [   6/  40] time: 133.8813, loss: 0.00184483\n",
      "Epoch: [12] [   7/  40] time: 134.1339, loss: 0.00095534\n",
      "Epoch: [12] [   8/  40] time: 134.3825, loss: 0.00025405\n",
      "Epoch: [12] [   9/  40] time: 134.6393, loss: 0.00025521\n",
      "Epoch: [12] [  10/  40] time: 134.8913, loss: 0.00191074\n",
      "Epoch: [12] [  11/  40] time: 135.1389, loss: 0.00277466\n",
      "Epoch: [12] [  12/  40] time: 135.3900, loss: 0.01701271\n",
      "Epoch: [12] [  13/  40] time: 135.6473, loss: 0.00047863\n",
      "Epoch: [12] [  14/  40] time: 135.9004, loss: 0.00739633\n",
      "Epoch: [12] [  15/  40] time: 136.1528, loss: 0.00071038\n",
      "Epoch: [12] [  16/  40] time: 136.4007, loss: 0.00020867\n",
      "Epoch: [12] [  17/  40] time: 136.6597, loss: 0.00134131\n",
      "Epoch: [12] [  18/  40] time: 136.9105, loss: 0.00578759\n",
      "Epoch: [12] [  19/  40] time: 137.1526, loss: 0.00051446\n",
      "Epoch: [12] [  20/  40] time: 137.4055, loss: 0.00020347\n",
      "Epoch: [12] [  21/  40] time: 137.6656, loss: 0.02077653\n",
      "Epoch: [12] [  22/  40] time: 137.9185, loss: 0.00032330\n",
      "Epoch: [12] [  23/  40] time: 138.1693, loss: 0.00301870\n",
      "Epoch: [12] [  24/  40] time: 138.4195, loss: 0.00048916\n",
      "Epoch: [12] [  25/  40] time: 138.6849, loss: 0.02760473\n",
      "Epoch: [12] [  26/  40] time: 138.9359, loss: 0.00337009\n",
      "Epoch: [12] [  27/  40] time: 139.1848, loss: 0.01847011\n",
      "Epoch: [12] [  28/  40] time: 139.4390, loss: 0.00785362\n",
      "Epoch: [12] [  29/  40] time: 139.6999, loss: 0.00596941\n",
      "Epoch: [12] [  30/  40] time: 139.9501, loss: 0.00179974\n",
      "Epoch: [12] [  31/  40] time: 140.2006, loss: 0.00653727\n",
      "Epoch: [12] [  32/  40] time: 140.4530, loss: 0.00833377\n",
      "Epoch: [12] [  33/  40] time: 140.7155, loss: 0.00282720\n",
      "Epoch: [12] [  34/  40] time: 140.9623, loss: 0.00241322\n",
      "Epoch: [12] [  35/  40] time: 141.2097, loss: 0.00070808\n",
      "Epoch: [12] [  36/  40] time: 141.4615, loss: 0.00053887\n",
      "Epoch: [12] [  37/  40] time: 141.7230, loss: 0.00228341\n",
      "Epoch: [12] [  38/  40] time: 141.9724, loss: 0.00061911\n",
      "Epoch: [12] [  39/  40] time: 142.2211, loss: 0.01040881\n",
      "[12/50] - ptime: 11.1067 loss: 0.00515280 acc: 0.45000 lr: 0.00090000\n",
      "Epoch: [13] [   0/  40] time: 144.1612, loss: 0.01229812\n",
      "Epoch: [13] [   1/  40] time: 144.4078, loss: 0.00100081\n",
      "Epoch: [13] [   2/  40] time: 144.6587, loss: 0.00112540\n",
      "Epoch: [13] [   3/  40] time: 144.9103, loss: 0.00033979\n",
      "Epoch: [13] [   4/  40] time: 145.1591, loss: 0.00006889\n",
      "Epoch: [13] [   5/  40] time: 145.4111, loss: 0.00080441\n",
      "Epoch: [13] [   6/  40] time: 145.6670, loss: 0.00134561\n",
      "Epoch: [13] [   7/  40] time: 145.9225, loss: 0.00129016\n",
      "Epoch: [13] [   8/  40] time: 146.1740, loss: 0.00021192\n",
      "Epoch: [13] [   9/  40] time: 146.4237, loss: 0.00385916\n",
      "Epoch: [13] [  10/  40] time: 146.6800, loss: 0.00012737\n",
      "Epoch: [13] [  11/  40] time: 146.9302, loss: 0.00015672\n",
      "Epoch: [13] [  12/  40] time: 147.1765, loss: 0.00094707\n",
      "Epoch: [13] [  13/  40] time: 147.4273, loss: 0.00450122\n",
      "Epoch: [13] [  14/  40] time: 147.6884, loss: 0.00071074\n",
      "Epoch: [13] [  15/  40] time: 147.9432, loss: 0.00017384\n",
      "Epoch: [13] [  16/  40] time: 148.1932, loss: 0.00002036\n",
      "Epoch: [13] [  17/  40] time: 148.4475, loss: 0.00779703\n",
      "Epoch: [13] [  18/  40] time: 148.7103, loss: 0.00116122\n",
      "Epoch: [13] [  19/  40] time: 148.9552, loss: 0.00473598\n",
      "Epoch: [13] [  20/  40] time: 149.2040, loss: 0.00003623\n",
      "Epoch: [13] [  21/  40] time: 149.4564, loss: 0.00056146\n",
      "Epoch: [13] [  22/  40] time: 149.7164, loss: 0.00261416\n",
      "Epoch: [13] [  23/  40] time: 149.9647, loss: 0.00054845\n",
      "Epoch: [13] [  24/  40] time: 150.2152, loss: 0.00235631\n",
      "Epoch: [13] [  25/  40] time: 150.4688, loss: 0.00153784\n",
      "Epoch: [13] [  26/  40] time: 150.7294, loss: 0.00279102\n",
      "Epoch: [13] [  27/  40] time: 150.9785, loss: 0.00075088\n",
      "Epoch: [13] [  28/  40] time: 151.2253, loss: 0.00457622\n",
      "Epoch: [13] [  29/  40] time: 151.4817, loss: 0.00031009\n",
      "Epoch: [13] [  30/  40] time: 151.7423, loss: 0.00048786\n",
      "Epoch: [13] [  31/  40] time: 151.9882, loss: 0.00036396\n",
      "Epoch: [13] [  32/  40] time: 152.2393, loss: 0.00023809\n",
      "Epoch: [13] [  33/  40] time: 152.4943, loss: 0.00012885\n",
      "Epoch: [13] [  34/  40] time: 152.7478, loss: 0.00052671\n",
      "Epoch: [13] [  35/  40] time: 152.9960, loss: 0.00052967\n",
      "Epoch: [13] [  36/  40] time: 153.2441, loss: 0.00020908\n",
      "Epoch: [13] [  37/  40] time: 153.5003, loss: 0.00018446\n",
      "Epoch: [13] [  38/  40] time: 153.7506, loss: 0.00047139\n",
      "Epoch: [13] [  39/  40] time: 153.9990, loss: 0.00003974\n",
      "[13/50] - ptime: 11.0929 loss: 0.00154846 acc: 0.55000 lr: 0.00090000\n",
      "Epoch: [14] [   0/  40] time: 155.8267, loss: 0.00061410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14] [   1/  40] time: 156.0721, loss: 0.00063327\n",
      "Epoch: [14] [   2/  40] time: 156.3217, loss: 0.00001337\n",
      "Epoch: [14] [   3/  40] time: 156.5753, loss: 0.00002368\n",
      "Epoch: [14] [   4/  40] time: 156.8264, loss: 0.00067068\n",
      "Epoch: [14] [   5/  40] time: 157.0739, loss: 0.00077422\n",
      "Epoch: [14] [   6/  40] time: 157.3212, loss: 0.00002346\n",
      "Epoch: [14] [   7/  40] time: 157.5784, loss: 0.00028840\n",
      "Epoch: [14] [   8/  40] time: 157.8265, loss: 0.00123743\n",
      "Epoch: [14] [   9/  40] time: 158.0764, loss: 0.00020181\n",
      "Epoch: [14] [  10/  40] time: 158.3267, loss: 0.00019133\n",
      "Epoch: [14] [  11/  40] time: 158.5830, loss: 0.00027273\n",
      "Epoch: [14] [  12/  40] time: 158.8347, loss: 0.00020946\n",
      "Epoch: [14] [  13/  40] time: 159.0820, loss: 0.00001589\n",
      "Epoch: [14] [  14/  40] time: 159.3310, loss: 0.00005079\n",
      "Epoch: [14] [  15/  40] time: 159.5895, loss: 0.00004020\n",
      "Epoch: [14] [  16/  40] time: 159.8376, loss: 0.00275783\n",
      "Epoch: [14] [  17/  40] time: 160.0837, loss: 0.00030005\n",
      "Epoch: [14] [  18/  40] time: 160.3308, loss: 0.00516684\n",
      "Epoch: [14] [  19/  40] time: 160.5885, loss: 0.00006719\n",
      "Epoch: [14] [  20/  40] time: 160.8434, loss: 0.00032118\n",
      "Epoch: [14] [  21/  40] time: 161.0910, loss: 0.00064129\n",
      "Epoch: [14] [  22/  40] time: 161.3399, loss: 0.00005253\n",
      "Epoch: [14] [  23/  40] time: 161.6004, loss: 0.00017452\n",
      "Epoch: [14] [  24/  40] time: 161.8513, loss: 0.00075544\n",
      "Epoch: [14] [  25/  40] time: 162.1007, loss: 0.00003949\n",
      "Epoch: [14] [  26/  40] time: 162.3520, loss: 0.00098355\n",
      "Epoch: [14] [  27/  40] time: 162.6179, loss: 0.00000552\n",
      "Epoch: [14] [  28/  40] time: 162.8676, loss: 0.00005919\n",
      "Epoch: [14] [  29/  40] time: 163.1158, loss: 0.00211895\n",
      "Epoch: [14] [  30/  40] time: 163.3684, loss: 0.00010569\n",
      "Epoch: [14] [  31/  40] time: 163.6314, loss: 0.00036512\n",
      "Epoch: [14] [  32/  40] time: 163.8791, loss: 0.00016913\n",
      "Epoch: [14] [  33/  40] time: 164.1276, loss: 0.00004154\n",
      "Epoch: [14] [  34/  40] time: 164.3769, loss: 0.00025850\n",
      "Epoch: [14] [  35/  40] time: 164.6336, loss: 0.00020026\n",
      "Epoch: [14] [  36/  40] time: 164.8860, loss: 0.00003327\n",
      "Epoch: [14] [  37/  40] time: 165.1342, loss: 0.00006652\n",
      "Epoch: [14] [  38/  40] time: 165.3866, loss: 0.00013736\n",
      "Epoch: [14] [  39/  40] time: 165.6531, loss: 0.00011919\n",
      "[14/50] - ptime: 11.1259 loss: 0.00050502 acc: 0.58000 lr: 0.00090000\n",
      "Epoch: [15] [   0/  40] time: 167.5075, loss: 0.00008880\n",
      "Epoch: [15] [   1/  40] time: 167.7622, loss: 0.00032312\n",
      "Epoch: [15] [   2/  40] time: 168.0106, loss: 0.00010444\n",
      "Epoch: [15] [   3/  40] time: 168.2606, loss: 0.00002405\n",
      "Epoch: [15] [   4/  40] time: 168.5113, loss: 0.00019736\n",
      "Epoch: [15] [   5/  40] time: 168.7641, loss: 0.00011165\n",
      "Epoch: [15] [   6/  40] time: 169.0126, loss: 0.00003819\n",
      "Epoch: [15] [   7/  40] time: 169.2647, loss: 0.00006756\n",
      "Epoch: [15] [   8/  40] time: 169.5259, loss: 0.00019672\n",
      "Epoch: [15] [   9/  40] time: 169.7748, loss: 0.00010025\n",
      "Epoch: [15] [  10/  40] time: 170.0239, loss: 0.00155103\n",
      "Epoch: [15] [  11/  40] time: 170.2740, loss: 0.00467485\n",
      "Epoch: [15] [  12/  40] time: 170.5291, loss: 0.00011353\n",
      "Epoch: [15] [  13/  40] time: 170.7803, loss: 0.00007511\n",
      "Epoch: [15] [  14/  40] time: 171.0318, loss: 0.00697191\n",
      "Epoch: [15] [  15/  40] time: 171.2843, loss: 0.00021976\n",
      "Epoch: [15] [  16/  40] time: 171.5402, loss: 0.00018035\n",
      "Epoch: [15] [  17/  40] time: 171.7942, loss: 0.00163819\n",
      "Epoch: [15] [  18/  40] time: 172.0409, loss: 0.00014521\n",
      "Epoch: [15] [  19/  40] time: 172.2957, loss: 0.00036997\n",
      "Epoch: [15] [  20/  40] time: 172.5544, loss: 0.00062224\n",
      "Epoch: [15] [  21/  40] time: 172.8076, loss: 0.00003854\n",
      "Epoch: [15] [  22/  40] time: 173.0554, loss: 0.00949873\n",
      "Epoch: [15] [  23/  40] time: 173.3056, loss: 0.00007879\n",
      "Epoch: [15] [  24/  40] time: 173.5669, loss: 0.00043308\n",
      "Epoch: [15] [  25/  40] time: 173.8215, loss: 0.00165849\n",
      "Epoch: [15] [  26/  40] time: 174.0650, loss: 0.00071638\n",
      "Epoch: [15] [  27/  40] time: 174.3131, loss: 0.00021082\n",
      "Epoch: [15] [  28/  40] time: 174.5745, loss: 0.00026005\n",
      "Epoch: [15] [  29/  40] time: 174.8247, loss: 0.00006892\n",
      "Epoch: [15] [  30/  40] time: 175.0710, loss: 0.01441627\n",
      "Epoch: [15] [  31/  40] time: 175.3244, loss: 0.00034109\n",
      "Epoch: [15] [  32/  40] time: 175.5834, loss: 0.00044283\n",
      "Epoch: [15] [  33/  40] time: 175.8368, loss: 0.00047627\n",
      "Epoch: [15] [  34/  40] time: 176.0876, loss: 0.00154567\n",
      "Epoch: [15] [  35/  40] time: 176.3380, loss: 0.00011487\n",
      "Epoch: [15] [  36/  40] time: 176.5964, loss: 0.00113390\n",
      "Epoch: [15] [  37/  40] time: 176.8415, loss: 0.00904595\n",
      "Epoch: [15] [  38/  40] time: 177.0908, loss: 0.00011329\n",
      "Epoch: [15] [  39/  40] time: 177.3425, loss: 0.00016816\n",
      "[15/50] - ptime: 11.0730 loss: 0.00146441 acc: 0.63000 lr: 0.00090000\n",
      "Epoch: [16] [   0/  40] time: 179.1043, loss: 0.00442947\n",
      "Epoch: [16] [   1/  40] time: 179.3557, loss: 0.00000935\n",
      "Epoch: [16] [   2/  40] time: 179.6153, loss: 0.00013138\n",
      "Epoch: [16] [   3/  40] time: 179.8720, loss: 0.00384736\n",
      "Epoch: [16] [   4/  40] time: 180.1235, loss: 0.00110077\n",
      "Epoch: [16] [   5/  40] time: 180.3780, loss: 0.00011742\n",
      "Epoch: [16] [   6/  40] time: 180.6454, loss: 0.00012943\n",
      "Epoch: [16] [   7/  40] time: 180.8940, loss: 0.00001164\n",
      "Epoch: [16] [   8/  40] time: 181.1419, loss: 0.00060785\n",
      "Epoch: [16] [   9/  40] time: 181.3923, loss: 0.00007417\n",
      "Epoch: [16] [  10/  40] time: 181.6580, loss: 0.00116103\n",
      "Epoch: [16] [  11/  40] time: 181.9064, loss: 0.00032641\n",
      "Epoch: [16] [  12/  40] time: 182.1544, loss: 0.00023886\n",
      "Epoch: [16] [  13/  40] time: 182.4057, loss: 0.00026000\n",
      "Epoch: [16] [  14/  40] time: 182.6580, loss: 0.00005806\n",
      "Epoch: [16] [  15/  40] time: 182.9110, loss: 0.00035658\n",
      "Epoch: [16] [  16/  40] time: 183.1610, loss: 0.00334757\n",
      "Epoch: [16] [  17/  40] time: 183.4178, loss: 0.00029385\n",
      "Epoch: [16] [  18/  40] time: 183.6753, loss: 0.00006061\n",
      "Epoch: [16] [  19/  40] time: 183.9236, loss: 0.02698724\n",
      "Epoch: [16] [  20/  40] time: 184.1663, loss: 0.02160559\n",
      "Epoch: [16] [  21/  40] time: 184.4175, loss: 0.02560313\n",
      "Epoch: [16] [  22/  40] time: 184.6731, loss: 0.08274142\n",
      "Epoch: [16] [  23/  40] time: 184.9236, loss: 0.04853369\n",
      "Epoch: [16] [  24/  40] time: 185.1722, loss: 0.00408200\n",
      "Epoch: [16] [  25/  40] time: 185.4305, loss: 0.00703154\n",
      "Epoch: [16] [  26/  40] time: 185.6885, loss: 0.00816948\n",
      "Epoch: [16] [  27/  40] time: 185.9373, loss: 0.01754503\n",
      "Epoch: [16] [  28/  40] time: 186.1891, loss: 0.00096652\n",
      "Epoch: [16] [  29/  40] time: 186.4444, loss: 0.02135421\n",
      "Epoch: [16] [  30/  40] time: 186.7008, loss: 0.00043506\n",
      "Epoch: [16] [  31/  40] time: 186.9510, loss: 0.00266732\n",
      "Epoch: [16] [  32/  40] time: 187.2018, loss: 0.00057549\n",
      "Epoch: [16] [  33/  40] time: 187.4650, loss: 0.01508018\n",
      "Epoch: [16] [  34/  40] time: 187.7195, loss: 0.04272340\n",
      "Epoch: [16] [  35/  40] time: 187.9676, loss: 0.02381194\n",
      "Epoch: [16] [  36/  40] time: 188.2202, loss: 0.02143290\n",
      "Epoch: [16] [  37/  40] time: 188.4791, loss: 0.03601384\n",
      "Epoch: [16] [  38/  40] time: 188.7269, loss: 0.16594088\n",
      "Epoch: [16] [  39/  40] time: 188.9782, loss: 0.15296751\n",
      "[16/50] - ptime: 11.1645 loss: 0.01857075 acc: 0.73000 lr: 0.00090000\n",
      "Epoch: [17] [   0/  40] time: 190.7378, loss: 0.01888304\n",
      "Epoch: [17] [   1/  40] time: 190.9881, loss: 0.02333325\n",
      "Epoch: [17] [   2/  40] time: 191.2382, loss: 0.02057405\n",
      "Epoch: [17] [   3/  40] time: 191.4984, loss: 0.01627688\n",
      "Epoch: [17] [   4/  40] time: 191.7575, loss: 0.01024454\n",
      "Epoch: [17] [   5/  40] time: 192.0071, loss: 0.01105992\n",
      "Epoch: [17] [   6/  40] time: 192.2578, loss: 0.04912614\n",
      "Epoch: [17] [   7/  40] time: 192.5213, loss: 0.00116120\n",
      "Epoch: [17] [   8/  40] time: 192.7757, loss: 0.02645175\n",
      "Epoch: [17] [   9/  40] time: 193.0284, loss: 0.01372373\n",
      "Epoch: [17] [  10/  40] time: 193.2796, loss: 0.09184563\n",
      "Epoch: [17] [  11/  40] time: 193.5342, loss: 0.05749682\n",
      "Epoch: [17] [  12/  40] time: 193.7870, loss: 0.00190112\n",
      "Epoch: [17] [  13/  40] time: 194.0358, loss: 0.00200221\n",
      "Epoch: [17] [  14/  40] time: 194.2863, loss: 0.00586169\n",
      "Epoch: [17] [  15/  40] time: 194.5513, loss: 0.01554783\n",
      "Epoch: [17] [  16/  40] time: 194.8023, loss: 0.00897445\n",
      "Epoch: [17] [  17/  40] time: 195.0546, loss: 0.00986160\n",
      "Epoch: [17] [  18/  40] time: 195.3052, loss: 0.00538600\n",
      "Epoch: [17] [  19/  40] time: 195.5640, loss: 0.03330887\n",
      "Epoch: [17] [  20/  40] time: 195.8171, loss: 0.02666405\n",
      "Epoch: [17] [  21/  40] time: 196.0655, loss: 0.01632017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17] [  22/  40] time: 196.3182, loss: 0.00435257\n",
      "Epoch: [17] [  23/  40] time: 196.5788, loss: 0.02627864\n",
      "Epoch: [17] [  24/  40] time: 196.8286, loss: 0.06596846\n",
      "Epoch: [17] [  25/  40] time: 197.0811, loss: 0.00187123\n",
      "Epoch: [17] [  26/  40] time: 197.3319, loss: 0.00042858\n",
      "Epoch: [17] [  27/  40] time: 197.5882, loss: 0.00249695\n",
      "Epoch: [17] [  28/  40] time: 197.8441, loss: 0.01845443\n",
      "Epoch: [17] [  29/  40] time: 198.0935, loss: 0.00471767\n",
      "Epoch: [17] [  30/  40] time: 198.3456, loss: 0.00094495\n",
      "Epoch: [17] [  31/  40] time: 198.5991, loss: 0.00279429\n",
      "Epoch: [17] [  32/  40] time: 198.8474, loss: 0.00775020\n",
      "Epoch: [17] [  33/  40] time: 199.0990, loss: 0.00529734\n",
      "Epoch: [17] [  34/  40] time: 199.3483, loss: 0.00804730\n",
      "Epoch: [17] [  35/  40] time: 199.6149, loss: 0.00393565\n",
      "Epoch: [17] [  36/  40] time: 199.8648, loss: 0.00532077\n",
      "Epoch: [17] [  37/  40] time: 200.1120, loss: 0.00406451\n",
      "Epoch: [17] [  38/  40] time: 200.3653, loss: 0.00475560\n",
      "Epoch: [17] [  39/  40] time: 200.6178, loss: 0.00685639\n",
      "[17/50] - ptime: 11.1112 loss: 0.01600851 acc: 0.75000 lr: 0.00090000\n",
      "Epoch: [18] [   0/  40] time: 202.3430, loss: 0.00276052\n",
      "Epoch: [18] [   1/  40] time: 202.6051, loss: 0.00474030\n",
      "Epoch: [18] [   2/  40] time: 202.8596, loss: 0.00044052\n",
      "Epoch: [18] [   3/  40] time: 203.1105, loss: 0.00030591\n",
      "Epoch: [18] [   4/  40] time: 203.3631, loss: 0.00170768\n",
      "Epoch: [18] [   5/  40] time: 203.6291, loss: 0.00051487\n",
      "Epoch: [18] [   6/  40] time: 203.8829, loss: 0.00049571\n",
      "Epoch: [18] [   7/  40] time: 204.1309, loss: 0.00121203\n",
      "Epoch: [18] [   8/  40] time: 204.3851, loss: 0.00135257\n",
      "Epoch: [18] [   9/  40] time: 204.6465, loss: 0.00031262\n",
      "Epoch: [18] [  10/  40] time: 204.8967, loss: 0.01714396\n",
      "Epoch: [18] [  11/  40] time: 205.1500, loss: 0.00065159\n",
      "Epoch: [18] [  12/  40] time: 205.4054, loss: 0.00166322\n",
      "Epoch: [18] [  13/  40] time: 205.6655, loss: 0.03056883\n",
      "Epoch: [18] [  14/  40] time: 205.9092, loss: 0.00105257\n",
      "Epoch: [18] [  15/  40] time: 206.1585, loss: 0.00974500\n",
      "Epoch: [18] [  16/  40] time: 206.4152, loss: 0.00272902\n",
      "Epoch: [18] [  17/  40] time: 206.6683, loss: 0.00030445\n",
      "Epoch: [18] [  18/  40] time: 206.9168, loss: 0.00375074\n",
      "Epoch: [18] [  19/  40] time: 207.1708, loss: 0.00020237\n",
      "Epoch: [18] [  20/  40] time: 207.4186, loss: 0.00981194\n",
      "Epoch: [18] [  21/  40] time: 207.6739, loss: 0.00104991\n",
      "Epoch: [18] [  22/  40] time: 207.9264, loss: 0.01060388\n",
      "Epoch: [18] [  23/  40] time: 208.1757, loss: 0.01347443\n",
      "Epoch: [18] [  24/  40] time: 208.4308, loss: 0.00237584\n",
      "Epoch: [18] [  25/  40] time: 208.6908, loss: 0.00412489\n",
      "Epoch: [18] [  26/  40] time: 208.9388, loss: 0.06708013\n",
      "Epoch: [18] [  27/  40] time: 209.1848, loss: 0.00578362\n",
      "Epoch: [18] [  28/  40] time: 209.4382, loss: 0.00408703\n",
      "Epoch: [18] [  29/  40] time: 209.6900, loss: 0.01362894\n",
      "Epoch: [18] [  30/  40] time: 209.9382, loss: 0.02079109\n",
      "Epoch: [18] [  31/  40] time: 210.1887, loss: 0.02780473\n",
      "Epoch: [18] [  32/  40] time: 210.4480, loss: 0.00111564\n",
      "Epoch: [18] [  33/  40] time: 210.6978, loss: 0.01095777\n",
      "Epoch: [18] [  34/  40] time: 210.9467, loss: 0.00411345\n",
      "Epoch: [18] [  35/  40] time: 211.1936, loss: 0.00419519\n",
      "Epoch: [18] [  36/  40] time: 211.4470, loss: 0.00178883\n",
      "Epoch: [18] [  37/  40] time: 211.7074, loss: 0.00251750\n",
      "Epoch: [18] [  38/  40] time: 211.9551, loss: 0.01547850\n",
      "Epoch: [18] [  39/  40] time: 212.2048, loss: 0.00959077\n",
      "[18/50] - ptime: 11.0335 loss: 0.00780071 acc: 0.55000 lr: 0.00090000\n",
      "Epoch: [19] [   0/  40] time: 213.9735, loss: 0.00753300\n",
      "Epoch: [19] [   1/  40] time: 214.2223, loss: 0.00029171\n",
      "Epoch: [19] [   2/  40] time: 214.4762, loss: 0.00015166\n",
      "Epoch: [19] [   3/  40] time: 214.7370, loss: 0.00063946\n",
      "Epoch: [19] [   4/  40] time: 214.9863, loss: 0.00012955\n",
      "Epoch: [19] [   5/  40] time: 215.2373, loss: 0.00033192\n",
      "Epoch: [19] [   6/  40] time: 215.4911, loss: 0.00192912\n",
      "Epoch: [19] [   7/  40] time: 215.7435, loss: 0.00138205\n",
      "Epoch: [19] [   8/  40] time: 215.9913, loss: 0.00317004\n",
      "Epoch: [19] [   9/  40] time: 216.2409, loss: 0.00005869\n",
      "Epoch: [19] [  10/  40] time: 216.5000, loss: 0.00251667\n",
      "Epoch: [19] [  11/  40] time: 216.7501, loss: 0.00164881\n",
      "Epoch: [19] [  12/  40] time: 216.9995, loss: 0.00604013\n",
      "Epoch: [19] [  13/  40] time: 217.2448, loss: 0.00085812\n",
      "Epoch: [19] [  14/  40] time: 217.4982, loss: 0.00030777\n",
      "Epoch: [19] [  15/  40] time: 217.7507, loss: 0.00196217\n",
      "Epoch: [19] [  16/  40] time: 217.9990, loss: 0.00272328\n",
      "Epoch: [19] [  17/  40] time: 218.2469, loss: 0.00019220\n",
      "Epoch: [19] [  18/  40] time: 218.5035, loss: 0.00105501\n",
      "Epoch: [19] [  19/  40] time: 218.7548, loss: 0.01064815\n",
      "Epoch: [19] [  20/  40] time: 219.0045, loss: 0.00003768\n",
      "Epoch: [19] [  21/  40] time: 219.2519, loss: 0.00015663\n",
      "Epoch: [19] [  22/  40] time: 219.5090, loss: 0.02241884\n",
      "Epoch: [19] [  23/  40] time: 219.7696, loss: 0.00379965\n",
      "Epoch: [19] [  24/  40] time: 220.0174, loss: 0.00041369\n",
      "Epoch: [19] [  25/  40] time: 220.2673, loss: 0.00015373\n",
      "Epoch: [19] [  26/  40] time: 220.5239, loss: 0.00004619\n",
      "Epoch: [19] [  27/  40] time: 220.7795, loss: 0.00017828\n",
      "Epoch: [19] [  28/  40] time: 221.0306, loss: 0.00067343\n",
      "Epoch: [19] [  29/  40] time: 221.2773, loss: 0.03880198\n",
      "Epoch: [19] [  30/  40] time: 221.5363, loss: 0.00012940\n",
      "Epoch: [19] [  31/  40] time: 221.7956, loss: 0.00107292\n",
      "Epoch: [19] [  32/  40] time: 222.0386, loss: 0.01161148\n",
      "Epoch: [19] [  33/  40] time: 222.2896, loss: 0.01528583\n",
      "Epoch: [19] [  34/  40] time: 222.5502, loss: 0.00072526\n",
      "Epoch: [19] [  35/  40] time: 222.8033, loss: 0.00079969\n",
      "Epoch: [19] [  36/  40] time: 223.0568, loss: 0.00432460\n",
      "Epoch: [19] [  37/  40] time: 223.3071, loss: 0.00076462\n",
      "Epoch: [19] [  38/  40] time: 223.5839, loss: 0.00035811\n",
      "Epoch: [19] [  39/  40] time: 223.8388, loss: 0.00034427\n",
      "[19/50] - ptime: 11.1326 loss: 0.00364164 acc: 0.70000 lr: 0.00090000\n",
      "Epoch: [20] [   0/  40] time: 225.6500, loss: 0.00022130\n",
      "Epoch: [20] [   1/  40] time: 225.9048, loss: 0.00125910\n",
      "Epoch: [20] [   2/  40] time: 226.1530, loss: 0.00007795\n",
      "Epoch: [20] [   3/  40] time: 226.4074, loss: 0.00314006\n",
      "Epoch: [20] [   4/  40] time: 226.6678, loss: 0.01611894\n",
      "Epoch: [20] [   5/  40] time: 226.9206, loss: 0.00177224\n",
      "Epoch: [20] [   6/  40] time: 227.1724, loss: 0.04781402\n",
      "Epoch: [20] [   7/  40] time: 227.4237, loss: 0.08762001\n",
      "Epoch: [20] [   8/  40] time: 227.6817, loss: 0.00029465\n",
      "Epoch: [20] [   9/  40] time: 227.9350, loss: 0.01642993\n",
      "Epoch: [20] [  10/  40] time: 228.1829, loss: 0.01161270\n",
      "Epoch: [20] [  11/  40] time: 228.4363, loss: 0.01068553\n",
      "Epoch: [20] [  12/  40] time: 228.6950, loss: 0.02082942\n",
      "Epoch: [20] [  13/  40] time: 228.9470, loss: 0.00012819\n",
      "Epoch: [20] [  14/  40] time: 229.1984, loss: 0.04464995\n",
      "Epoch: [20] [  15/  40] time: 229.4510, loss: 0.00056422\n",
      "Epoch: [20] [  16/  40] time: 229.7089, loss: 0.00940287\n",
      "Epoch: [20] [  17/  40] time: 229.9594, loss: 0.00197585\n",
      "Epoch: [20] [  18/  40] time: 230.2082, loss: 0.12937459\n",
      "Epoch: [20] [  19/  40] time: 230.4625, loss: 0.00867120\n",
      "Epoch: [20] [  20/  40] time: 230.7210, loss: 0.00110013\n",
      "Epoch: [20] [  21/  40] time: 230.9696, loss: 0.00181069\n",
      "Epoch: [20] [  22/  40] time: 231.2226, loss: 0.00802946\n",
      "Epoch: [20] [  23/  40] time: 231.4765, loss: 0.00546387\n",
      "Epoch: [20] [  24/  40] time: 231.7209, loss: 0.01250863\n",
      "Epoch: [20] [  25/  40] time: 231.9680, loss: 0.02414093\n",
      "Epoch: [20] [  26/  40] time: 232.2148, loss: 0.00240906\n",
      "Epoch: [20] [  27/  40] time: 232.4689, loss: 0.00800956\n",
      "Epoch: [20] [  28/  40] time: 232.7320, loss: 0.00290545\n",
      "Epoch: [20] [  29/  40] time: 232.9829, loss: 0.00169372\n",
      "Epoch: [20] [  30/  40] time: 233.2335, loss: 0.00063052\n",
      "Epoch: [20] [  31/  40] time: 233.4905, loss: 0.00263758\n",
      "Epoch: [20] [  32/  40] time: 233.7479, loss: 0.02095811\n",
      "Epoch: [20] [  33/  40] time: 233.9933, loss: 0.00032839\n",
      "Epoch: [20] [  34/  40] time: 234.2371, loss: 0.00078988\n",
      "Epoch: [20] [  35/  40] time: 234.4876, loss: 0.00106086\n",
      "Epoch: [20] [  36/  40] time: 234.7371, loss: 0.00032983\n",
      "Epoch: [20] [  37/  40] time: 234.9846, loss: 0.00914890\n",
      "Epoch: [20] [  38/  40] time: 235.2349, loss: 0.00071891\n",
      "Epoch: [20] [  39/  40] time: 235.4900, loss: 0.00902953\n",
      "[20/50] - ptime: 11.0927 loss: 0.01315867 acc: 0.66000 lr: 0.00081000\n",
      "Epoch: [21] [   0/  40] time: 237.2451, loss: 0.00181850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21] [   1/  40] time: 237.4967, loss: 0.00277041\n",
      "Epoch: [21] [   2/  40] time: 237.7568, loss: 0.00744647\n",
      "Epoch: [21] [   3/  40] time: 238.0025, loss: 0.00293924\n",
      "Epoch: [21] [   4/  40] time: 238.2513, loss: 0.00104067\n",
      "Epoch: [21] [   5/  40] time: 238.5070, loss: 0.00104931\n",
      "Epoch: [21] [   6/  40] time: 238.7612, loss: 0.00012488\n",
      "Epoch: [21] [   7/  40] time: 239.0094, loss: 0.00035087\n",
      "Epoch: [21] [   8/  40] time: 239.2602, loss: 0.00012586\n",
      "Epoch: [21] [   9/  40] time: 239.5127, loss: 0.00003260\n",
      "Epoch: [21] [  10/  40] time: 239.7661, loss: 0.01541924\n",
      "Epoch: [21] [  11/  40] time: 240.0105, loss: 0.00092948\n",
      "Epoch: [21] [  12/  40] time: 240.2579, loss: 0.00244695\n",
      "Epoch: [21] [  13/  40] time: 240.5119, loss: 0.01374571\n",
      "Epoch: [21] [  14/  40] time: 240.7642, loss: 0.00031671\n",
      "Epoch: [21] [  15/  40] time: 241.0137, loss: 0.00216351\n",
      "Epoch: [21] [  16/  40] time: 241.2647, loss: 0.00012686\n",
      "Epoch: [21] [  17/  40] time: 241.5157, loss: 0.00060324\n",
      "Epoch: [21] [  18/  40] time: 241.7742, loss: 0.00270275\n",
      "Epoch: [21] [  19/  40] time: 242.0234, loss: 0.00011240\n",
      "Epoch: [21] [  20/  40] time: 242.2718, loss: 0.00122336\n",
      "Epoch: [21] [  21/  40] time: 242.5285, loss: 0.00057363\n",
      "Epoch: [21] [  22/  40] time: 242.7859, loss: 0.00016369\n",
      "Epoch: [21] [  23/  40] time: 243.0355, loss: 0.00497879\n",
      "Epoch: [21] [  24/  40] time: 243.2809, loss: 0.00041674\n",
      "Epoch: [21] [  25/  40] time: 243.5368, loss: 0.00030190\n",
      "Epoch: [21] [  26/  40] time: 243.7891, loss: 0.00055602\n",
      "Epoch: [21] [  27/  40] time: 244.0382, loss: 0.00053225\n",
      "Epoch: [21] [  28/  40] time: 244.2862, loss: 0.00057347\n",
      "Epoch: [21] [  29/  40] time: 244.5436, loss: 0.00038689\n",
      "Epoch: [21] [  30/  40] time: 244.7918, loss: 0.00008231\n",
      "Epoch: [21] [  31/  40] time: 245.0410, loss: 0.01370751\n",
      "Epoch: [21] [  32/  40] time: 245.2872, loss: 0.00038656\n",
      "Epoch: [21] [  33/  40] time: 245.5454, loss: 0.00091387\n",
      "Epoch: [21] [  34/  40] time: 245.8029, loss: 0.00042727\n",
      "Epoch: [21] [  35/  40] time: 246.0507, loss: 0.00089105\n",
      "Epoch: [21] [  36/  40] time: 246.3002, loss: 0.00074471\n",
      "Epoch: [21] [  37/  40] time: 246.5568, loss: 0.00080587\n",
      "Epoch: [21] [  38/  40] time: 246.8103, loss: 0.00373854\n",
      "Epoch: [21] [  39/  40] time: 247.0527, loss: 0.00034793\n",
      "[21/50] - ptime: 11.0565 loss: 0.00220045 acc: 0.63000 lr: 0.00081000\n",
      "Epoch: [22] [   0/  40] time: 248.8548, loss: 0.00020621\n",
      "Epoch: [22] [   1/  40] time: 249.1032, loss: 0.00004565\n",
      "Epoch: [22] [   2/  40] time: 249.3554, loss: 0.00229550\n",
      "Epoch: [22] [   3/  40] time: 249.6156, loss: 0.00012654\n",
      "Epoch: [22] [   4/  40] time: 249.8733, loss: 0.00029360\n",
      "Epoch: [22] [   5/  40] time: 250.1200, loss: 0.00009250\n",
      "Epoch: [22] [   6/  40] time: 250.3713, loss: 0.00009005\n",
      "Epoch: [22] [   7/  40] time: 250.6344, loss: 0.00028833\n",
      "Epoch: [22] [   8/  40] time: 250.8863, loss: 0.00372568\n",
      "Epoch: [22] [   9/  40] time: 251.1346, loss: 0.00007848\n",
      "Epoch: [22] [  10/  40] time: 251.3838, loss: 0.00591385\n",
      "Epoch: [22] [  11/  40] time: 251.6454, loss: 0.00016208\n",
      "Epoch: [22] [  12/  40] time: 251.8991, loss: 0.00006204\n",
      "Epoch: [22] [  13/  40] time: 252.1457, loss: 0.00005076\n",
      "Epoch: [22] [  14/  40] time: 252.4002, loss: 0.00054285\n",
      "Epoch: [22] [  15/  40] time: 252.6678, loss: 0.00032788\n",
      "Epoch: [22] [  16/  40] time: 252.9202, loss: 0.00013244\n",
      "Epoch: [22] [  17/  40] time: 253.1758, loss: 0.00016695\n",
      "Epoch: [22] [  18/  40] time: 253.4286, loss: 0.00017310\n",
      "Epoch: [22] [  19/  40] time: 253.6778, loss: 0.00064652\n",
      "Epoch: [22] [  20/  40] time: 253.9312, loss: 0.00017975\n",
      "Epoch: [22] [  21/  40] time: 254.1803, loss: 0.00019709\n",
      "Epoch: [22] [  22/  40] time: 254.4305, loss: 0.00006454\n",
      "Epoch: [22] [  23/  40] time: 254.6957, loss: 0.00006148\n",
      "Epoch: [22] [  24/  40] time: 254.9464, loss: 0.00061634\n",
      "Epoch: [22] [  25/  40] time: 255.1963, loss: 0.00015208\n",
      "Epoch: [22] [  26/  40] time: 255.4514, loss: 0.00796439\n",
      "Epoch: [22] [  27/  40] time: 255.7011, loss: 0.00008300\n",
      "Epoch: [22] [  28/  40] time: 255.9535, loss: 0.00457353\n",
      "Epoch: [22] [  29/  40] time: 256.2023, loss: 0.00006890\n",
      "Epoch: [22] [  30/  40] time: 256.4553, loss: 0.00052688\n",
      "Epoch: [22] [  31/  40] time: 256.7046, loss: 0.00052998\n",
      "Epoch: [22] [  32/  40] time: 256.9544, loss: 0.00026596\n",
      "Epoch: [22] [  33/  40] time: 257.2058, loss: 0.00369302\n",
      "Epoch: [22] [  34/  40] time: 257.4598, loss: 0.00058196\n",
      "Epoch: [22] [  35/  40] time: 257.7146, loss: 0.00147220\n",
      "Epoch: [22] [  36/  40] time: 257.9709, loss: 0.00014608\n",
      "Epoch: [22] [  37/  40] time: 258.2192, loss: 0.00052149\n",
      "Epoch: [22] [  38/  40] time: 258.4807, loss: 0.00108017\n",
      "Epoch: [22] [  39/  40] time: 258.7336, loss: 0.00074344\n",
      "[22/50] - ptime: 11.1211 loss: 0.00097358 acc: 0.69000 lr: 0.00081000\n",
      "Epoch: [23] [   0/  40] time: 260.5247, loss: 0.00005876\n",
      "Epoch: [23] [   1/  40] time: 260.7717, loss: 0.00025478\n",
      "Epoch: [23] [   2/  40] time: 261.0222, loss: 0.00088120\n",
      "Epoch: [23] [   3/  40] time: 261.2718, loss: 0.00000787\n",
      "Epoch: [23] [   4/  40] time: 261.5318, loss: 0.00021009\n",
      "Epoch: [23] [   5/  40] time: 261.7875, loss: 0.00009122\n",
      "Epoch: [23] [   6/  40] time: 262.0410, loss: 0.00017649\n",
      "Epoch: [23] [   7/  40] time: 262.2916, loss: 0.00002911\n",
      "Epoch: [23] [   8/  40] time: 262.5522, loss: 0.00060177\n",
      "Epoch: [23] [   9/  40] time: 262.8079, loss: 0.00004949\n",
      "Epoch: [23] [  10/  40] time: 263.0572, loss: 0.00003774\n",
      "Epoch: [23] [  11/  40] time: 263.3110, loss: 0.00082428\n",
      "Epoch: [23] [  12/  40] time: 263.5736, loss: 0.00019184\n",
      "Epoch: [23] [  13/  40] time: 263.8223, loss: 0.00002599\n",
      "Epoch: [23] [  14/  40] time: 264.0671, loss: 0.00040784\n",
      "Epoch: [23] [  15/  40] time: 264.3191, loss: 0.00016640\n",
      "Epoch: [23] [  16/  40] time: 264.5833, loss: 0.00017451\n",
      "Epoch: [23] [  17/  40] time: 264.8336, loss: 0.00003447\n",
      "Epoch: [23] [  18/  40] time: 265.0842, loss: 0.00002280\n",
      "Epoch: [23] [  19/  40] time: 265.3371, loss: 0.00077039\n",
      "Epoch: [23] [  20/  40] time: 265.5966, loss: 0.00013807\n",
      "Epoch: [23] [  21/  40] time: 265.8461, loss: 0.00019871\n",
      "Epoch: [23] [  22/  40] time: 266.0968, loss: 0.00025009\n",
      "Epoch: [23] [  23/  40] time: 266.3481, loss: 0.00088879\n",
      "Epoch: [23] [  24/  40] time: 266.6040, loss: 0.00066659\n",
      "Epoch: [23] [  25/  40] time: 266.8510, loss: 0.00018348\n",
      "Epoch: [23] [  26/  40] time: 267.0982, loss: 0.00009828\n",
      "Epoch: [23] [  27/  40] time: 267.3514, loss: 0.00022569\n",
      "Epoch: [23] [  28/  40] time: 267.6037, loss: 0.00003890\n",
      "Epoch: [23] [  29/  40] time: 267.8548, loss: 0.00004281\n",
      "Epoch: [23] [  30/  40] time: 268.1019, loss: 0.00003093\n",
      "Epoch: [23] [  31/  40] time: 268.3541, loss: 0.00000525\n",
      "Epoch: [23] [  32/  40] time: 268.6159, loss: 0.00021702\n",
      "Epoch: [23] [  33/  40] time: 268.8675, loss: 0.00016034\n",
      "Epoch: [23] [  34/  40] time: 269.1161, loss: 0.00015320\n",
      "Epoch: [23] [  35/  40] time: 269.3722, loss: 0.00009017\n",
      "Epoch: [23] [  36/  40] time: 269.6281, loss: 0.00058819\n",
      "Epoch: [23] [  37/  40] time: 269.8807, loss: 0.00024584\n",
      "Epoch: [23] [  38/  40] time: 270.1291, loss: 0.00001667\n",
      "Epoch: [23] [  39/  40] time: 270.3892, loss: 0.00166570\n",
      "[23/50] - ptime: 11.0968 loss: 0.00027304 acc: 0.70000 lr: 0.00081000\n",
      "Epoch: [24] [   0/  40] time: 272.1191, loss: 0.00007691\n",
      "Epoch: [24] [   1/  40] time: 272.3689, loss: 0.00001320\n",
      "Epoch: [24] [   2/  40] time: 272.6357, loss: 0.00008814\n",
      "Epoch: [24] [   3/  40] time: 272.8844, loss: 0.00001943\n",
      "Epoch: [24] [   4/  40] time: 273.1336, loss: 0.00033245\n",
      "Epoch: [24] [   5/  40] time: 273.3891, loss: 0.00002737\n",
      "Epoch: [24] [   6/  40] time: 273.6416, loss: 0.00008330\n",
      "Epoch: [24] [   7/  40] time: 273.8911, loss: 0.00170654\n",
      "Epoch: [24] [   8/  40] time: 274.1397, loss: 0.00006225\n",
      "Epoch: [24] [   9/  40] time: 274.3917, loss: 0.00003238\n",
      "Epoch: [24] [  10/  40] time: 274.6486, loss: 0.00032089\n",
      "Epoch: [24] [  11/  40] time: 274.8969, loss: 0.00035711\n",
      "Epoch: [24] [  12/  40] time: 275.1455, loss: 0.00002936\n",
      "Epoch: [24] [  13/  40] time: 275.4023, loss: 0.00001270\n",
      "Epoch: [24] [  14/  40] time: 275.6508, loss: 0.00001798\n",
      "Epoch: [24] [  15/  40] time: 275.9040, loss: 0.00007466\n",
      "Epoch: [24] [  16/  40] time: 276.1538, loss: 0.00033743\n",
      "Epoch: [24] [  17/  40] time: 276.4105, loss: 0.00021878\n",
      "Epoch: [24] [  18/  40] time: 276.6690, loss: 0.00002637\n",
      "Epoch: [24] [  19/  40] time: 276.9184, loss: 0.00003696\n",
      "Epoch: [24] [  20/  40] time: 277.1677, loss: 0.00043196\n",
      "Epoch: [24] [  21/  40] time: 277.4192, loss: 0.00057062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24] [  22/  40] time: 277.6746, loss: 0.00004658\n",
      "Epoch: [24] [  23/  40] time: 277.9302, loss: 0.00029818\n",
      "Epoch: [24] [  24/  40] time: 278.1783, loss: 0.00007302\n",
      "Epoch: [24] [  25/  40] time: 278.4366, loss: 0.00021736\n",
      "Epoch: [24] [  26/  40] time: 278.6917, loss: 0.00006851\n",
      "Epoch: [24] [  27/  40] time: 278.9413, loss: 0.00001500\n",
      "Epoch: [24] [  28/  40] time: 279.1936, loss: 0.00004264\n",
      "Epoch: [24] [  29/  40] time: 279.4498, loss: 0.00001454\n",
      "Epoch: [24] [  30/  40] time: 279.7028, loss: 0.00025730\n",
      "Epoch: [24] [  31/  40] time: 279.9546, loss: 0.00000724\n",
      "Epoch: [24] [  32/  40] time: 280.2090, loss: 0.00002764\n",
      "Epoch: [24] [  33/  40] time: 280.4697, loss: 0.00243053\n",
      "Epoch: [24] [  34/  40] time: 280.7211, loss: 0.00005835\n",
      "Epoch: [24] [  35/  40] time: 280.9702, loss: 0.00001147\n",
      "Epoch: [24] [  36/  40] time: 281.2252, loss: 0.00000832\n",
      "Epoch: [24] [  37/  40] time: 281.4836, loss: 0.00001175\n",
      "Epoch: [24] [  38/  40] time: 281.7324, loss: 0.00004369\n",
      "Epoch: [24] [  39/  40] time: 281.9842, loss: 0.00077172\n",
      "[24/50] - ptime: 11.1197 loss: 0.00023202 acc: 0.70000 lr: 0.00081000\n",
      "Epoch: [25] [   0/  40] time: 283.7432, loss: 0.00070552\n",
      "Epoch: [25] [   1/  40] time: 283.9973, loss: 0.00059973\n",
      "Epoch: [25] [   2/  40] time: 284.2536, loss: 0.00013762\n",
      "Epoch: [25] [   3/  40] time: 284.5123, loss: 0.00002327\n",
      "Epoch: [25] [   4/  40] time: 284.7638, loss: 0.00002693\n",
      "Epoch: [25] [   5/  40] time: 285.0144, loss: 0.00001964\n",
      "Epoch: [25] [   6/  40] time: 285.2692, loss: 0.00000411\n",
      "Epoch: [25] [   7/  40] time: 285.5298, loss: 0.00000199\n",
      "Epoch: [25] [   8/  40] time: 285.7799, loss: 0.00001299\n",
      "Epoch: [25] [   9/  40] time: 286.0328, loss: 0.00007270\n",
      "Epoch: [25] [  10/  40] time: 286.2839, loss: 0.00149512\n",
      "Epoch: [25] [  11/  40] time: 286.5480, loss: 0.00010682\n",
      "Epoch: [25] [  12/  40] time: 286.8019, loss: 0.00014184\n",
      "Epoch: [25] [  13/  40] time: 287.0539, loss: 0.00022121\n",
      "Epoch: [25] [  14/  40] time: 287.3215, loss: 0.00007609\n",
      "Epoch: [25] [  15/  40] time: 287.5782, loss: 0.00003219\n",
      "Epoch: [25] [  16/  40] time: 287.8268, loss: 0.00011887\n",
      "Epoch: [25] [  17/  40] time: 288.0814, loss: 0.00002582\n",
      "Epoch: [25] [  18/  40] time: 288.3332, loss: 0.00003606\n",
      "Epoch: [25] [  19/  40] time: 288.5835, loss: 0.00001630\n",
      "Epoch: [25] [  20/  40] time: 288.8282, loss: 0.00003826\n",
      "Epoch: [25] [  21/  40] time: 289.0840, loss: 0.00220874\n",
      "Epoch: [25] [  22/  40] time: 289.3497, loss: 0.00005883\n",
      "Epoch: [25] [  23/  40] time: 289.5994, loss: 0.00009192\n",
      "Epoch: [25] [  24/  40] time: 289.8484, loss: 0.00005629\n",
      "Epoch: [25] [  25/  40] time: 290.1022, loss: 0.00057955\n",
      "Epoch: [25] [  26/  40] time: 290.3575, loss: 0.00010082\n",
      "Epoch: [25] [  27/  40] time: 290.6132, loss: 0.00002806\n",
      "Epoch: [25] [  28/  40] time: 290.8586, loss: 0.00001074\n",
      "Epoch: [25] [  29/  40] time: 291.1106, loss: 0.00017573\n",
      "Epoch: [25] [  30/  40] time: 291.3676, loss: 0.00001605\n",
      "Epoch: [25] [  31/  40] time: 291.6216, loss: 0.00001785\n",
      "Epoch: [25] [  32/  40] time: 291.8709, loss: 0.00009340\n",
      "Epoch: [25] [  33/  40] time: 292.1235, loss: 0.00003897\n",
      "Epoch: [25] [  34/  40] time: 292.3857, loss: 0.00017662\n",
      "Epoch: [25] [  35/  40] time: 292.6389, loss: 0.00012036\n",
      "Epoch: [25] [  36/  40] time: 292.8871, loss: 0.00005089\n",
      "Epoch: [25] [  37/  40] time: 293.1379, loss: 0.00000435\n",
      "Epoch: [25] [  38/  40] time: 293.4029, loss: 0.00006515\n",
      "Epoch: [25] [  39/  40] time: 293.6522, loss: 0.00003139\n",
      "[25/50] - ptime: 11.1337 loss: 0.00019597 acc: 0.73000 lr: 0.00081000\n",
      "Epoch: [26] [   0/  40] time: 295.4993, loss: 0.00017300\n",
      "Epoch: [26] [   1/  40] time: 295.7470, loss: 0.00002293\n",
      "Epoch: [26] [   2/  40] time: 295.9937, loss: 0.00044775\n",
      "Epoch: [26] [   3/  40] time: 296.2447, loss: 0.00002383\n",
      "Epoch: [26] [   4/  40] time: 296.4974, loss: 0.00002766\n",
      "Epoch: [26] [   5/  40] time: 296.7505, loss: 0.00052101\n",
      "Epoch: [26] [   6/  40] time: 297.0003, loss: 0.00003414\n",
      "Epoch: [26] [   7/  40] time: 297.2521, loss: 0.00025946\n",
      "Epoch: [26] [   8/  40] time: 297.5218, loss: 0.00002335\n",
      "Epoch: [26] [   9/  40] time: 297.7722, loss: 0.00000134\n",
      "Epoch: [26] [  10/  40] time: 298.0260, loss: 0.00003706\n",
      "Epoch: [26] [  11/  40] time: 298.2819, loss: 0.00005399\n",
      "Epoch: [26] [  12/  40] time: 298.5373, loss: 0.00003265\n",
      "Epoch: [26] [  13/  40] time: 298.7886, loss: 0.00009840\n",
      "Epoch: [26] [  14/  40] time: 299.0369, loss: 0.00008493\n",
      "Epoch: [26] [  15/  40] time: 299.2941, loss: 0.00003205\n",
      "Epoch: [26] [  16/  40] time: 299.5420, loss: 0.00000359\n",
      "Epoch: [26] [  17/  40] time: 299.7903, loss: 0.00000632\n",
      "Epoch: [26] [  18/  40] time: 300.0435, loss: 0.00088339\n",
      "Epoch: [26] [  19/  40] time: 300.3018, loss: 0.00001572\n",
      "Epoch: [26] [  20/  40] time: 300.5565, loss: 0.00015681\n",
      "Epoch: [26] [  21/  40] time: 300.8060, loss: 0.00000224\n",
      "Epoch: [26] [  22/  40] time: 301.0603, loss: 0.00013827\n",
      "Epoch: [26] [  23/  40] time: 301.3213, loss: 0.00000328\n",
      "Epoch: [26] [  24/  40] time: 301.5694, loss: 0.00005463\n",
      "Epoch: [26] [  25/  40] time: 301.8173, loss: 0.00019047\n",
      "Epoch: [26] [  26/  40] time: 302.0726, loss: 0.00000999\n",
      "Epoch: [26] [  27/  40] time: 302.3372, loss: 0.00001559\n",
      "Epoch: [26] [  28/  40] time: 302.5866, loss: 0.00003791\n",
      "Epoch: [26] [  29/  40] time: 302.8383, loss: 0.00024254\n",
      "Epoch: [26] [  30/  40] time: 303.0895, loss: 0.00004329\n",
      "Epoch: [26] [  31/  40] time: 303.3539, loss: 0.00002545\n",
      "Epoch: [26] [  32/  40] time: 303.6040, loss: 0.00000674\n",
      "Epoch: [26] [  33/  40] time: 303.8518, loss: 0.00007913\n",
      "Epoch: [26] [  34/  40] time: 304.1089, loss: 0.00001715\n",
      "Epoch: [26] [  35/  40] time: 304.3684, loss: 0.00006947\n",
      "Epoch: [26] [  36/  40] time: 304.6122, loss: 0.00004157\n",
      "Epoch: [26] [  37/  40] time: 304.8590, loss: 0.00000225\n",
      "Epoch: [26] [  38/  40] time: 305.1118, loss: 0.00003054\n",
      "Epoch: [26] [  39/  40] time: 305.3624, loss: 0.00001866\n",
      "[26/50] - ptime: 11.1449 loss: 0.00009921 acc: 0.71000 lr: 0.00081000\n",
      "Epoch: [27] [   0/  40] time: 307.4439, loss: 0.00001430\n",
      "Epoch: [27] [   1/  40] time: 307.6898, loss: 0.00002436\n",
      "Epoch: [27] [   2/  40] time: 307.9385, loss: 0.00008515\n",
      "Epoch: [27] [   3/  40] time: 308.1922, loss: 0.00013196\n",
      "Epoch: [27] [   4/  40] time: 308.4528, loss: 0.00004243\n",
      "Epoch: [27] [   5/  40] time: 308.7029, loss: 0.00000784\n",
      "Epoch: [27] [   6/  40] time: 308.9486, loss: 0.00003740\n",
      "Epoch: [27] [   7/  40] time: 309.2068, loss: 0.00003850\n",
      "Epoch: [27] [   8/  40] time: 309.4624, loss: 0.00001304\n",
      "Epoch: [27] [   9/  40] time: 309.7118, loss: 0.00003754\n",
      "Epoch: [27] [  10/  40] time: 309.9631, loss: 0.00002066\n",
      "Epoch: [27] [  11/  40] time: 310.2155, loss: 0.00018268\n",
      "Epoch: [27] [  12/  40] time: 310.4669, loss: 0.00000397\n",
      "Epoch: [27] [  13/  40] time: 310.7146, loss: 0.00012137\n",
      "Epoch: [27] [  14/  40] time: 310.9630, loss: 0.00002361\n",
      "Epoch: [27] [  15/  40] time: 311.2177, loss: 0.00004869\n",
      "Epoch: [27] [  16/  40] time: 311.4779, loss: 0.00004676\n",
      "Epoch: [27] [  17/  40] time: 311.7263, loss: 0.00001548\n",
      "Epoch: [27] [  18/  40] time: 311.9768, loss: 0.00003287\n",
      "Epoch: [27] [  19/  40] time: 312.2302, loss: 0.00012417\n",
      "Epoch: [27] [  20/  40] time: 312.4832, loss: 0.00013093\n",
      "Epoch: [27] [  21/  40] time: 312.7309, loss: 0.00008603\n",
      "Epoch: [27] [  22/  40] time: 312.9797, loss: 0.00001798\n",
      "Epoch: [27] [  23/  40] time: 313.2390, loss: 0.00001112\n",
      "Epoch: [27] [  24/  40] time: 313.4977, loss: 0.00011961\n",
      "Epoch: [27] [  25/  40] time: 313.7447, loss: 0.00040946\n",
      "Epoch: [27] [  26/  40] time: 313.9974, loss: 0.00015194\n",
      "Epoch: [27] [  27/  40] time: 314.2502, loss: 0.00004949\n",
      "Epoch: [27] [  28/  40] time: 314.5056, loss: 0.00006955\n",
      "Epoch: [27] [  29/  40] time: 314.7568, loss: 0.00001235\n",
      "Epoch: [27] [  30/  40] time: 315.0087, loss: 0.00011704\n",
      "Epoch: [27] [  31/  40] time: 315.2693, loss: 0.00014952\n",
      "Epoch: [27] [  32/  40] time: 315.5269, loss: 0.00001828\n",
      "Epoch: [27] [  33/  40] time: 315.7765, loss: 0.00006330\n",
      "Epoch: [27] [  34/  40] time: 316.0301, loss: 0.00000172\n",
      "Epoch: [27] [  35/  40] time: 316.2935, loss: 0.00013038\n",
      "Epoch: [27] [  36/  40] time: 316.5431, loss: 0.00003353\n",
      "Epoch: [27] [  37/  40] time: 316.7928, loss: 0.00002920\n",
      "Epoch: [27] [  38/  40] time: 317.0453, loss: 0.00005038\n",
      "Epoch: [27] [  39/  40] time: 317.3021, loss: 0.00044494\n",
      "[27/50] - ptime: 11.1019 loss: 0.00007874 acc: 0.71000 lr: 0.00081000\n",
      "Epoch: [28] [   0/  40] time: 319.0481, loss: 0.00019149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28] [   1/  40] time: 319.3025, loss: 0.00000847\n",
      "Epoch: [28] [   2/  40] time: 319.5599, loss: 0.00000299\n",
      "Epoch: [28] [   3/  40] time: 319.8197, loss: 0.00000438\n",
      "Epoch: [28] [   4/  40] time: 320.0731, loss: 0.00003061\n",
      "Epoch: [28] [   5/  40] time: 320.3301, loss: 0.00000067\n",
      "Epoch: [28] [   6/  40] time: 320.5875, loss: 0.00001503\n",
      "Epoch: [28] [   7/  40] time: 320.8363, loss: 0.00001350\n",
      "Epoch: [28] [   8/  40] time: 321.0860, loss: 0.00005725\n",
      "Epoch: [28] [   9/  40] time: 321.3453, loss: 0.00002154\n",
      "Epoch: [28] [  10/  40] time: 321.5978, loss: 0.00013242\n",
      "Epoch: [28] [  11/  40] time: 321.8462, loss: 0.00018846\n",
      "Epoch: [28] [  12/  40] time: 322.0987, loss: 0.00001020\n",
      "Epoch: [28] [  13/  40] time: 322.3575, loss: 0.00000501\n",
      "Epoch: [28] [  14/  40] time: 322.6116, loss: 0.00002528\n",
      "Epoch: [28] [  15/  40] time: 322.8673, loss: 0.00000433\n",
      "Epoch: [28] [  16/  40] time: 323.1233, loss: 0.00001541\n",
      "Epoch: [28] [  17/  40] time: 323.3829, loss: 0.00002469\n",
      "Epoch: [28] [  18/  40] time: 323.6377, loss: 0.00006947\n",
      "Epoch: [28] [  19/  40] time: 323.8864, loss: 0.00002236\n",
      "Epoch: [28] [  20/  40] time: 324.1385, loss: 0.00000760\n",
      "Epoch: [28] [  21/  40] time: 324.4010, loss: 0.00006118\n",
      "Epoch: [28] [  22/  40] time: 324.6520, loss: 0.00005874\n",
      "Epoch: [28] [  23/  40] time: 324.9031, loss: 0.00010670\n",
      "Epoch: [28] [  24/  40] time: 325.1563, loss: 0.00001475\n",
      "Epoch: [28] [  25/  40] time: 325.4200, loss: 0.00029340\n",
      "Epoch: [28] [  26/  40] time: 325.6703, loss: 0.00001051\n",
      "Epoch: [28] [  27/  40] time: 325.9188, loss: 0.00004249\n",
      "Epoch: [28] [  28/  40] time: 326.1723, loss: 0.00013533\n",
      "Epoch: [28] [  29/  40] time: 326.4242, loss: 0.00004759\n",
      "Epoch: [28] [  30/  40] time: 326.6732, loss: 0.00003110\n",
      "Epoch: [28] [  31/  40] time: 326.9243, loss: 0.00000840\n",
      "Epoch: [28] [  32/  40] time: 327.1776, loss: 0.00000100\n",
      "Epoch: [28] [  33/  40] time: 327.4271, loss: 0.00001798\n",
      "Epoch: [28] [  34/  40] time: 327.6779, loss: 0.00000790\n",
      "Epoch: [28] [  35/  40] time: 327.9259, loss: 0.00001507\n",
      "Epoch: [28] [  36/  40] time: 328.1800, loss: 0.00000363\n",
      "Epoch: [28] [  37/  40] time: 328.4275, loss: 0.00005512\n",
      "Epoch: [28] [  38/  40] time: 328.6751, loss: 0.00001646\n",
      "Epoch: [28] [  39/  40] time: 328.9322, loss: 0.00015476\n",
      "[28/50] - ptime: 11.1099 loss: 0.00004833 acc: 0.71000 lr: 0.00081000\n",
      "Epoch: [29] [   0/  40] time: 330.8253, loss: 0.00009733\n",
      "Epoch: [29] [   1/  40] time: 331.0764, loss: 0.00033356\n",
      "Epoch: [29] [   2/  40] time: 331.3354, loss: 0.00001854\n",
      "Epoch: [29] [   3/  40] time: 331.5902, loss: 0.00004428\n",
      "Epoch: [29] [   4/  40] time: 331.8370, loss: 0.00002678\n",
      "Epoch: [29] [   5/  40] time: 332.0943, loss: 0.00000741\n",
      "Epoch: [29] [   6/  40] time: 332.3579, loss: 0.00006346\n",
      "Epoch: [29] [   7/  40] time: 332.6078, loss: 0.00001962\n",
      "Epoch: [29] [   8/  40] time: 332.8561, loss: 0.00000494\n",
      "Epoch: [29] [   9/  40] time: 333.1084, loss: 0.00000839\n",
      "Epoch: [29] [  10/  40] time: 333.3608, loss: 0.00002231\n",
      "Epoch: [29] [  11/  40] time: 333.6174, loss: 0.00011791\n",
      "Epoch: [29] [  12/  40] time: 333.8639, loss: 0.00000985\n",
      "Epoch: [29] [  13/  40] time: 334.1169, loss: 0.00002975\n",
      "Epoch: [29] [  14/  40] time: 334.3740, loss: 0.00001553\n",
      "Epoch: [29] [  15/  40] time: 334.6208, loss: 0.00001397\n",
      "Epoch: [29] [  16/  40] time: 334.8708, loss: 0.00007672\n",
      "Epoch: [29] [  17/  40] time: 335.1240, loss: 0.00002920\n",
      "Epoch: [29] [  18/  40] time: 335.3801, loss: 0.00001510\n",
      "Epoch: [29] [  19/  40] time: 335.6312, loss: 0.00024808\n",
      "Epoch: [29] [  20/  40] time: 335.8791, loss: 0.00000830\n",
      "Epoch: [29] [  21/  40] time: 336.1323, loss: 0.00001685\n",
      "Epoch: [29] [  22/  40] time: 336.3792, loss: 0.00004247\n",
      "Epoch: [29] [  23/  40] time: 336.6280, loss: 0.00035851\n",
      "Epoch: [29] [  24/  40] time: 336.8876, loss: 0.00004147\n",
      "Epoch: [29] [  25/  40] time: 337.1414, loss: 0.00001149\n",
      "Epoch: [29] [  26/  40] time: 337.3923, loss: 0.00001486\n",
      "Epoch: [29] [  27/  40] time: 337.6458, loss: 0.00000970\n",
      "Epoch: [29] [  28/  40] time: 337.8972, loss: 0.00000792\n",
      "Epoch: [29] [  29/  40] time: 338.1584, loss: 0.00001390\n",
      "Epoch: [29] [  30/  40] time: 338.4124, loss: 0.00002573\n",
      "Epoch: [29] [  31/  40] time: 338.6592, loss: 0.00001127\n",
      "Epoch: [29] [  32/  40] time: 338.9175, loss: 0.00001587\n",
      "Epoch: [29] [  33/  40] time: 339.1848, loss: 0.00000198\n",
      "Epoch: [29] [  34/  40] time: 339.4447, loss: 0.00002425\n",
      "Epoch: [29] [  35/  40] time: 339.7067, loss: 0.00071583\n",
      "Epoch: [29] [  36/  40] time: 339.9575, loss: 0.00000615\n",
      "Epoch: [29] [  37/  40] time: 340.2161, loss: 0.00000023\n",
      "Epoch: [29] [  38/  40] time: 340.4668, loss: 0.00001231\n",
      "Epoch: [29] [  39/  40] time: 340.7158, loss: 0.00000184\n",
      "[29/50] - ptime: 11.1489 loss: 0.00006359 acc: 0.72000 lr: 0.00081000\n",
      "Epoch: [30] [   0/  40] time: 342.5315, loss: 0.00005755\n",
      "Epoch: [30] [   1/  40] time: 342.7811, loss: 0.00000325\n",
      "Epoch: [30] [   2/  40] time: 343.0341, loss: 0.00000955\n",
      "Epoch: [30] [   3/  40] time: 343.2955, loss: 0.00001183\n",
      "Epoch: [30] [   4/  40] time: 343.5446, loss: 0.00000398\n",
      "Epoch: [30] [   5/  40] time: 343.7886, loss: 0.00001596\n",
      "Epoch: [30] [   6/  40] time: 344.0396, loss: 0.00000784\n",
      "Epoch: [30] [   7/  40] time: 344.2949, loss: 0.00000268\n",
      "Epoch: [30] [   8/  40] time: 344.5425, loss: 0.00000638\n",
      "Epoch: [30] [   9/  40] time: 344.7918, loss: 0.00003749\n",
      "Epoch: [30] [  10/  40] time: 345.0456, loss: 0.00013163\n",
      "Epoch: [30] [  11/  40] time: 345.3032, loss: 0.00002602\n",
      "Epoch: [30] [  12/  40] time: 345.5540, loss: 0.00000299\n",
      "Epoch: [30] [  13/  40] time: 345.8016, loss: 0.00001142\n",
      "Epoch: [30] [  14/  40] time: 346.0535, loss: 0.00000326\n",
      "Epoch: [30] [  15/  40] time: 346.3212, loss: 0.00000290\n",
      "Epoch: [30] [  16/  40] time: 346.5699, loss: 0.00002701\n",
      "Epoch: [30] [  17/  40] time: 346.8174, loss: 0.00002042\n",
      "Epoch: [30] [  18/  40] time: 347.0716, loss: 0.00003803\n",
      "Epoch: [30] [  19/  40] time: 347.3251, loss: 0.00002102\n",
      "Epoch: [30] [  20/  40] time: 347.5801, loss: 0.00001258\n",
      "Epoch: [30] [  21/  40] time: 347.8263, loss: 0.00000985\n",
      "Epoch: [30] [  22/  40] time: 348.0811, loss: 0.00014487\n",
      "Epoch: [30] [  23/  40] time: 348.3418, loss: 0.00002092\n",
      "Epoch: [30] [  24/  40] time: 348.5926, loss: 0.00004496\n",
      "Epoch: [30] [  25/  40] time: 348.8422, loss: 0.00001663\n",
      "Epoch: [30] [  26/  40] time: 349.0988, loss: 0.00005519\n",
      "Epoch: [30] [  27/  40] time: 349.3506, loss: 0.00002128\n",
      "Epoch: [30] [  28/  40] time: 349.6029, loss: 0.00002791\n",
      "Epoch: [30] [  29/  40] time: 349.8505, loss: 0.00001318\n",
      "Epoch: [30] [  30/  40] time: 350.1080, loss: 0.00007698\n",
      "Epoch: [30] [  31/  40] time: 350.3626, loss: 0.00002360\n",
      "Epoch: [30] [  32/  40] time: 350.6108, loss: 0.00000612\n",
      "Epoch: [30] [  33/  40] time: 350.8614, loss: 0.00003214\n",
      "Epoch: [30] [  34/  40] time: 351.1230, loss: 0.00000358\n",
      "Epoch: [30] [  35/  40] time: 351.3756, loss: 0.00004493\n",
      "Epoch: [30] [  36/  40] time: 351.6285, loss: 0.00000917\n",
      "Epoch: [30] [  37/  40] time: 351.8768, loss: 0.00000080\n",
      "Epoch: [30] [  38/  40] time: 352.1388, loss: 0.00001832\n",
      "Epoch: [30] [  39/  40] time: 352.3901, loss: 0.00000293\n",
      "[30/50] - ptime: 11.1262 loss: 0.00002568 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [31] [   0/  40] time: 354.1720, loss: 0.00000075\n",
      "Epoch: [31] [   1/  40] time: 354.4231, loss: 0.00009031\n",
      "Epoch: [31] [   2/  40] time: 354.6717, loss: 0.00000727\n",
      "Epoch: [31] [   3/  40] time: 354.9237, loss: 0.00000805\n",
      "Epoch: [31] [   4/  40] time: 355.1839, loss: 0.00011102\n",
      "Epoch: [31] [   5/  40] time: 355.4380, loss: 0.00000827\n",
      "Epoch: [31] [   6/  40] time: 355.6919, loss: 0.00000784\n",
      "Epoch: [31] [   7/  40] time: 355.9439, loss: 0.00001062\n",
      "Epoch: [31] [   8/  40] time: 356.2059, loss: 0.00000291\n",
      "Epoch: [31] [   9/  40] time: 356.4571, loss: 0.00000969\n",
      "Epoch: [31] [  10/  40] time: 356.7054, loss: 0.00002717\n",
      "Epoch: [31] [  11/  40] time: 356.9568, loss: 0.00000110\n",
      "Epoch: [31] [  12/  40] time: 357.2166, loss: 0.00001539\n",
      "Epoch: [31] [  13/  40] time: 357.4693, loss: 0.00001097\n",
      "Epoch: [31] [  14/  40] time: 357.7255, loss: 0.00004965\n",
      "Epoch: [31] [  15/  40] time: 357.9773, loss: 0.00010643\n",
      "Epoch: [31] [  16/  40] time: 358.2318, loss: 0.00001630\n",
      "Epoch: [31] [  17/  40] time: 358.4866, loss: 0.00013310\n",
      "Epoch: [31] [  18/  40] time: 358.7346, loss: 0.00006957\n",
      "Epoch: [31] [  19/  40] time: 358.9876, loss: 0.00010409\n",
      "Epoch: [31] [  20/  40] time: 359.2501, loss: 0.00002352\n",
      "Epoch: [31] [  21/  40] time: 359.5025, loss: 0.00000147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31] [  22/  40] time: 359.7542, loss: 0.00011163\n",
      "Epoch: [31] [  23/  40] time: 360.0050, loss: 0.00007128\n",
      "Epoch: [31] [  24/  40] time: 360.2593, loss: 0.00010407\n",
      "Epoch: [31] [  25/  40] time: 360.5153, loss: 0.00012958\n",
      "Epoch: [31] [  26/  40] time: 360.7625, loss: 0.00006750\n",
      "Epoch: [31] [  27/  40] time: 361.0159, loss: 0.00000417\n",
      "Epoch: [31] [  28/  40] time: 361.2711, loss: 0.00014379\n",
      "Epoch: [31] [  29/  40] time: 361.5191, loss: 0.00001539\n",
      "Epoch: [31] [  30/  40] time: 361.7716, loss: 0.00000529\n",
      "Epoch: [31] [  31/  40] time: 362.0230, loss: 0.00002719\n",
      "Epoch: [31] [  32/  40] time: 362.2722, loss: 0.00000146\n",
      "Epoch: [31] [  33/  40] time: 362.5192, loss: 0.00000993\n",
      "Epoch: [31] [  34/  40] time: 362.7697, loss: 0.00013462\n",
      "Epoch: [31] [  35/  40] time: 363.0237, loss: 0.00001041\n",
      "Epoch: [31] [  36/  40] time: 363.2745, loss: 0.00000270\n",
      "Epoch: [31] [  37/  40] time: 363.5242, loss: 0.00000298\n",
      "Epoch: [31] [  38/  40] time: 363.7744, loss: 0.00001270\n",
      "Epoch: [31] [  39/  40] time: 364.0280, loss: 0.00002128\n",
      "[31/50] - ptime: 11.0957 loss: 0.00004229 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [32] [   0/  40] time: 365.8498, loss: 0.00001850\n",
      "Epoch: [32] [   1/  40] time: 366.1029, loss: 0.00007904\n",
      "Epoch: [32] [   2/  40] time: 366.3521, loss: 0.00000387\n",
      "Epoch: [32] [   3/  40] time: 366.5993, loss: 0.00001939\n",
      "Epoch: [32] [   4/  40] time: 366.8481, loss: 0.00001463\n",
      "Epoch: [32] [   5/  40] time: 367.1032, loss: 0.00000916\n",
      "Epoch: [32] [   6/  40] time: 367.3506, loss: 0.00000551\n",
      "Epoch: [32] [   7/  40] time: 367.6010, loss: 0.00119067\n",
      "Epoch: [32] [   8/  40] time: 367.8540, loss: 0.00003920\n",
      "Epoch: [32] [   9/  40] time: 368.1062, loss: 0.00000756\n",
      "Epoch: [32] [  10/  40] time: 368.3602, loss: 0.00000923\n",
      "Epoch: [32] [  11/  40] time: 368.6091, loss: 0.00176089\n",
      "Epoch: [32] [  12/  40] time: 368.8581, loss: 0.00026759\n",
      "Epoch: [32] [  13/  40] time: 369.1071, loss: 0.00002065\n",
      "Epoch: [32] [  14/  40] time: 369.3560, loss: 0.00000875\n",
      "Epoch: [32] [  15/  40] time: 369.6057, loss: 0.00016393\n",
      "Epoch: [32] [  16/  40] time: 369.8580, loss: 0.00001768\n",
      "Epoch: [32] [  17/  40] time: 370.1119, loss: 0.00002854\n",
      "Epoch: [32] [  18/  40] time: 370.3710, loss: 0.00000459\n",
      "Epoch: [32] [  19/  40] time: 370.6204, loss: 0.00000890\n",
      "Epoch: [32] [  20/  40] time: 370.8699, loss: 0.00001621\n",
      "Epoch: [32] [  21/  40] time: 371.1276, loss: 0.00000417\n",
      "Epoch: [32] [  22/  40] time: 371.3823, loss: 0.00000497\n",
      "Epoch: [32] [  23/  40] time: 371.6323, loss: 0.00009251\n",
      "Epoch: [32] [  24/  40] time: 371.8799, loss: 0.00000777\n",
      "Epoch: [32] [  25/  40] time: 372.1376, loss: 0.00000613\n",
      "Epoch: [32] [  26/  40] time: 372.3966, loss: 0.00001761\n",
      "Epoch: [32] [  27/  40] time: 372.6456, loss: 0.00019855\n",
      "Epoch: [32] [  28/  40] time: 372.8956, loss: 0.00002064\n",
      "Epoch: [32] [  29/  40] time: 373.1567, loss: 0.00000918\n",
      "Epoch: [32] [  30/  40] time: 373.4091, loss: 0.00002947\n",
      "Epoch: [32] [  31/  40] time: 373.6617, loss: 0.00000485\n",
      "Epoch: [32] [  32/  40] time: 373.9115, loss: 0.00008420\n",
      "Epoch: [32] [  33/  40] time: 374.1704, loss: 0.00003872\n",
      "Epoch: [32] [  34/  40] time: 374.4273, loss: 0.00003212\n",
      "Epoch: [32] [  35/  40] time: 374.6799, loss: 0.00001152\n",
      "Epoch: [32] [  36/  40] time: 374.9346, loss: 0.00001689\n",
      "Epoch: [32] [  37/  40] time: 375.1951, loss: 0.00002923\n",
      "Epoch: [32] [  38/  40] time: 375.4499, loss: 0.00000149\n",
      "Epoch: [32] [  39/  40] time: 375.7039, loss: 0.00020181\n",
      "[32/50] - ptime: 11.0955 loss: 0.00011266 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [33] [   0/  40] time: 377.3542, loss: 0.00000149\n",
      "Epoch: [33] [   1/  40] time: 377.6074, loss: 0.00000398\n",
      "Epoch: [33] [   2/  40] time: 377.8508, loss: 0.00002415\n",
      "Epoch: [33] [   3/  40] time: 378.0974, loss: 0.00005385\n",
      "Epoch: [33] [   4/  40] time: 378.3460, loss: 0.00003892\n",
      "Epoch: [33] [   5/  40] time: 378.5917, loss: 0.00010144\n",
      "Epoch: [33] [   6/  40] time: 378.8455, loss: 0.00001323\n",
      "Epoch: [33] [   7/  40] time: 379.0940, loss: 0.00005746\n",
      "Epoch: [33] [   8/  40] time: 379.3441, loss: 0.00001060\n",
      "Epoch: [33] [   9/  40] time: 379.6024, loss: 0.00000180\n",
      "Epoch: [33] [  10/  40] time: 379.8489, loss: 0.00004897\n",
      "Epoch: [33] [  11/  40] time: 380.0937, loss: 0.00000424\n",
      "Epoch: [33] [  12/  40] time: 380.3523, loss: 0.00001154\n",
      "Epoch: [33] [  13/  40] time: 380.5971, loss: 0.00011980\n",
      "Epoch: [33] [  14/  40] time: 380.8439, loss: 0.00000108\n",
      "Epoch: [33] [  15/  40] time: 381.0901, loss: 0.00002489\n",
      "Epoch: [33] [  16/  40] time: 381.3357, loss: 0.00003470\n",
      "Epoch: [33] [  17/  40] time: 381.5844, loss: 0.00002391\n",
      "Epoch: [33] [  18/  40] time: 381.8291, loss: 0.00001533\n",
      "Epoch: [33] [  19/  40] time: 382.0725, loss: 0.00000590\n",
      "Epoch: [33] [  20/  40] time: 382.3257, loss: 0.00000812\n",
      "Epoch: [33] [  21/  40] time: 382.5741, loss: 0.00016651\n",
      "Epoch: [33] [  22/  40] time: 382.8215, loss: 0.00000609\n",
      "Epoch: [33] [  23/  40] time: 383.0670, loss: 0.00000715\n",
      "Epoch: [33] [  24/  40] time: 383.3254, loss: 0.00000475\n",
      "Epoch: [33] [  25/  40] time: 383.5759, loss: 0.00007087\n",
      "Epoch: [33] [  26/  40] time: 383.8312, loss: 0.00000789\n",
      "Epoch: [33] [  27/  40] time: 384.0775, loss: 0.00003620\n",
      "Epoch: [33] [  28/  40] time: 384.3235, loss: 0.00000428\n",
      "Epoch: [33] [  29/  40] time: 384.5725, loss: 0.00006162\n",
      "Epoch: [33] [  30/  40] time: 384.8188, loss: 0.00005706\n",
      "Epoch: [33] [  31/  40] time: 385.0676, loss: 0.00033347\n",
      "Epoch: [33] [  32/  40] time: 385.3247, loss: 0.00000634\n",
      "Epoch: [33] [  33/  40] time: 385.5696, loss: 0.00001471\n",
      "Epoch: [33] [  34/  40] time: 385.8166, loss: 0.00003378\n",
      "Epoch: [33] [  35/  40] time: 386.0608, loss: 0.00000516\n",
      "Epoch: [33] [  36/  40] time: 386.3056, loss: 0.00000600\n",
      "Epoch: [33] [  37/  40] time: 386.5606, loss: 0.00001628\n",
      "Epoch: [33] [  38/  40] time: 386.8095, loss: 0.00000990\n",
      "Epoch: [33] [  39/  40] time: 387.0543, loss: 0.00011455\n",
      "[33/50] - ptime: 10.7536 loss: 0.00003920 acc: 0.71000 lr: 0.00072900\n",
      "Epoch: [34] [   0/  40] time: 388.4762, loss: 0.00029479\n",
      "Epoch: [34] [   1/  40] time: 388.7309, loss: 0.00000274\n",
      "Epoch: [34] [   2/  40] time: 388.9812, loss: 0.00000539\n",
      "Epoch: [34] [   3/  40] time: 389.2269, loss: 0.00001516\n",
      "Epoch: [34] [   4/  40] time: 389.4893, loss: 0.00000188\n",
      "Epoch: [34] [   5/  40] time: 389.7345, loss: 0.00002249\n",
      "Epoch: [34] [   6/  40] time: 389.9804, loss: 0.00000449\n",
      "Epoch: [34] [   7/  40] time: 390.2366, loss: 0.00002700\n",
      "Epoch: [34] [   8/  40] time: 390.4827, loss: 0.00000128\n",
      "Epoch: [34] [   9/  40] time: 390.7284, loss: 0.00001483\n",
      "Epoch: [34] [  10/  40] time: 390.9736, loss: 0.00000270\n",
      "Epoch: [34] [  11/  40] time: 391.2194, loss: 0.00001384\n",
      "Epoch: [34] [  12/  40] time: 391.4710, loss: 0.00007323\n",
      "Epoch: [34] [  13/  40] time: 391.7211, loss: 0.00013402\n",
      "Epoch: [34] [  14/  40] time: 391.9642, loss: 0.00001832\n",
      "Epoch: [34] [  15/  40] time: 392.2198, loss: 0.00006737\n",
      "Epoch: [34] [  16/  40] time: 392.4668, loss: 0.00002677\n",
      "Epoch: [34] [  17/  40] time: 392.7124, loss: 0.00000513\n",
      "Epoch: [34] [  18/  40] time: 392.9658, loss: 0.00000887\n",
      "Epoch: [34] [  19/  40] time: 393.2110, loss: 0.00002784\n",
      "Epoch: [34] [  20/  40] time: 393.4612, loss: 0.00000456\n",
      "Epoch: [34] [  21/  40] time: 393.6997, loss: 0.00001503\n",
      "Epoch: [34] [  22/  40] time: 393.9430, loss: 0.00002808\n",
      "Epoch: [34] [  23/  40] time: 394.1914, loss: 0.00003785\n",
      "Epoch: [34] [  24/  40] time: 394.4385, loss: 0.00000426\n",
      "Epoch: [34] [  25/  40] time: 394.6843, loss: 0.00000325\n",
      "Epoch: [34] [  26/  40] time: 394.9348, loss: 0.00003754\n",
      "Epoch: [34] [  27/  40] time: 395.1802, loss: 0.00004854\n",
      "Epoch: [34] [  28/  40] time: 395.4256, loss: 0.00006893\n",
      "Epoch: [34] [  29/  40] time: 395.6817, loss: 0.00002518\n",
      "Epoch: [34] [  30/  40] time: 395.9333, loss: 0.00000137\n",
      "Epoch: [34] [  31/  40] time: 396.1802, loss: 0.00000276\n",
      "Epoch: [34] [  32/  40] time: 396.4330, loss: 0.00000359\n",
      "Epoch: [34] [  33/  40] time: 396.6780, loss: 0.00000399\n",
      "Epoch: [34] [  34/  40] time: 396.9238, loss: 0.00000758\n",
      "Epoch: [34] [  35/  40] time: 397.1697, loss: 0.00000648\n",
      "Epoch: [34] [  36/  40] time: 397.4126, loss: 0.00003628\n",
      "Epoch: [34] [  37/  40] time: 397.6578, loss: 0.00003461\n",
      "Epoch: [34] [  38/  40] time: 397.9072, loss: 0.00000162\n",
      "Epoch: [34] [  39/  40] time: 398.1509, loss: 0.00000041\n",
      "[34/50] - ptime: 10.6771 loss: 0.00002850 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [35] [   0/  40] time: 399.5896, loss: 0.00001314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35] [   1/  40] time: 399.8355, loss: 0.00000965\n",
      "Epoch: [35] [   2/  40] time: 400.0936, loss: 0.00000325\n",
      "Epoch: [35] [   3/  40] time: 400.3387, loss: 0.00001335\n",
      "Epoch: [35] [   4/  40] time: 400.5862, loss: 0.00000370\n",
      "Epoch: [35] [   5/  40] time: 400.8411, loss: 0.00000678\n",
      "Epoch: [35] [   6/  40] time: 401.0839, loss: 0.00000094\n",
      "Epoch: [35] [   7/  40] time: 401.3291, loss: 0.00012290\n",
      "Epoch: [35] [   8/  40] time: 401.5855, loss: 0.00000035\n",
      "Epoch: [35] [   9/  40] time: 401.8295, loss: 0.00008944\n",
      "Epoch: [35] [  10/  40] time: 402.0773, loss: 0.00000507\n",
      "Epoch: [35] [  11/  40] time: 402.3287, loss: 0.00006015\n",
      "Epoch: [35] [  12/  40] time: 402.5743, loss: 0.00001480\n",
      "Epoch: [35] [  13/  40] time: 402.8210, loss: 0.00001667\n",
      "Epoch: [35] [  14/  40] time: 403.0652, loss: 0.00001041\n",
      "Epoch: [35] [  15/  40] time: 403.3105, loss: 0.00000382\n",
      "Epoch: [35] [  16/  40] time: 403.5621, loss: 0.00003517\n",
      "Epoch: [35] [  17/  40] time: 403.8090, loss: 0.00003426\n",
      "Epoch: [35] [  18/  40] time: 404.0534, loss: 0.00000156\n",
      "Epoch: [35] [  19/  40] time: 404.3094, loss: 0.00002470\n",
      "Epoch: [35] [  20/  40] time: 404.5611, loss: 0.00000211\n",
      "Epoch: [35] [  21/  40] time: 404.8053, loss: 0.00000101\n",
      "Epoch: [35] [  22/  40] time: 405.0611, loss: 0.00008116\n",
      "Epoch: [35] [  23/  40] time: 405.3076, loss: 0.00000383\n",
      "Epoch: [35] [  24/  40] time: 405.5532, loss: 0.00000645\n",
      "Epoch: [35] [  25/  40] time: 405.8073, loss: 0.00000317\n",
      "Epoch: [35] [  26/  40] time: 406.0514, loss: 0.00001324\n",
      "Epoch: [35] [  27/  40] time: 406.3003, loss: 0.00001594\n",
      "Epoch: [35] [  28/  40] time: 406.5453, loss: 0.00001265\n",
      "Epoch: [35] [  29/  40] time: 406.7905, loss: 0.00000949\n",
      "Epoch: [35] [  30/  40] time: 407.0389, loss: 0.00000657\n",
      "Epoch: [35] [  31/  40] time: 407.2932, loss: 0.00001951\n",
      "Epoch: [35] [  32/  40] time: 407.5468, loss: 0.00000435\n",
      "Epoch: [35] [  33/  40] time: 407.8006, loss: 0.00000501\n",
      "Epoch: [35] [  34/  40] time: 408.0505, loss: 0.00006314\n",
      "Epoch: [35] [  35/  40] time: 408.2972, loss: 0.00000348\n",
      "Epoch: [35] [  36/  40] time: 408.5540, loss: 0.00000271\n",
      "Epoch: [35] [  37/  40] time: 408.7989, loss: 0.00000662\n",
      "Epoch: [35] [  38/  40] time: 409.0428, loss: 0.00000120\n",
      "Epoch: [35] [  39/  40] time: 409.2953, loss: 0.00000811\n",
      "[35/50] - ptime: 10.7041 loss: 0.00001850 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [36] [   0/  40] time: 410.6497, loss: 0.00000339\n",
      "Epoch: [36] [   1/  40] time: 410.8941, loss: 0.00002479\n",
      "Epoch: [36] [   2/  40] time: 411.1379, loss: 0.00000205\n",
      "Epoch: [36] [   3/  40] time: 411.3945, loss: 0.00000106\n",
      "Epoch: [36] [   4/  40] time: 411.6460, loss: 0.00001005\n",
      "Epoch: [36] [   5/  40] time: 411.8894, loss: 0.00001212\n",
      "Epoch: [36] [   6/  40] time: 412.1404, loss: 0.00000933\n",
      "Epoch: [36] [   7/  40] time: 412.3861, loss: 0.00025304\n",
      "Epoch: [36] [   8/  40] time: 412.6318, loss: 0.00000596\n",
      "Epoch: [36] [   9/  40] time: 412.8858, loss: 0.00000378\n",
      "Epoch: [36] [  10/  40] time: 413.1298, loss: 0.00000749\n",
      "Epoch: [36] [  11/  40] time: 413.3773, loss: 0.00000428\n",
      "Epoch: [36] [  12/  40] time: 413.6349, loss: 0.00000215\n",
      "Epoch: [36] [  13/  40] time: 413.8780, loss: 0.00000570\n",
      "Epoch: [36] [  14/  40] time: 414.1249, loss: 0.00000336\n",
      "Epoch: [36] [  15/  40] time: 414.3700, loss: 0.00000120\n",
      "Epoch: [36] [  16/  40] time: 414.6119, loss: 0.00016139\n",
      "Epoch: [36] [  17/  40] time: 414.8607, loss: 0.00000046\n",
      "Epoch: [36] [  18/  40] time: 415.1093, loss: 0.00001703\n",
      "Epoch: [36] [  19/  40] time: 415.3555, loss: 0.00007262\n",
      "Epoch: [36] [  20/  40] time: 415.6076, loss: 0.00000263\n",
      "Epoch: [36] [  21/  40] time: 415.8568, loss: 0.00002099\n",
      "Epoch: [36] [  22/  40] time: 416.1012, loss: 0.00004229\n",
      "Epoch: [36] [  23/  40] time: 416.3584, loss: 0.00001330\n",
      "Epoch: [36] [  24/  40] time: 416.6058, loss: 0.00001795\n",
      "Epoch: [36] [  25/  40] time: 416.8490, loss: 0.00000270\n",
      "Epoch: [36] [  26/  40] time: 417.1074, loss: 0.00000788\n",
      "Epoch: [36] [  27/  40] time: 417.3516, loss: 0.00000847\n",
      "Epoch: [36] [  28/  40] time: 417.6009, loss: 0.00000576\n",
      "Epoch: [36] [  29/  40] time: 417.8495, loss: 0.00015472\n",
      "Epoch: [36] [  30/  40] time: 418.0934, loss: 0.00000489\n",
      "Epoch: [36] [  31/  40] time: 418.3439, loss: 0.00001706\n",
      "Epoch: [36] [  32/  40] time: 418.5902, loss: 0.00000199\n",
      "Epoch: [36] [  33/  40] time: 418.8344, loss: 0.00026442\n",
      "Epoch: [36] [  34/  40] time: 419.0888, loss: 0.00000028\n",
      "Epoch: [36] [  35/  40] time: 419.3389, loss: 0.00000766\n",
      "Epoch: [36] [  36/  40] time: 419.5842, loss: 0.00000289\n",
      "Epoch: [36] [  37/  40] time: 419.8413, loss: 0.00000370\n",
      "Epoch: [36] [  38/  40] time: 420.0853, loss: 0.00007748\n",
      "Epoch: [36] [  39/  40] time: 420.3318, loss: 0.00002265\n",
      "[36/50] - ptime: 10.6368 loss: 0.00003202 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [37] [   0/  40] time: 421.7547, loss: 0.00000014\n",
      "Epoch: [37] [   1/  40] time: 422.0113, loss: 0.00005233\n",
      "Epoch: [37] [   2/  40] time: 422.2570, loss: 0.00033807\n",
      "Epoch: [37] [   3/  40] time: 422.5070, loss: 0.00000799\n",
      "Epoch: [37] [   4/  40] time: 422.7617, loss: 0.00000891\n",
      "Epoch: [37] [   5/  40] time: 423.0056, loss: 0.00002828\n",
      "Epoch: [37] [   6/  40] time: 423.2531, loss: 0.00000840\n",
      "Epoch: [37] [   7/  40] time: 423.4975, loss: 0.00000140\n",
      "Epoch: [37] [   8/  40] time: 423.7416, loss: 0.00002538\n",
      "Epoch: [37] [   9/  40] time: 423.9901, loss: 0.00000521\n",
      "Epoch: [37] [  10/  40] time: 424.2400, loss: 0.00001275\n",
      "Epoch: [37] [  11/  40] time: 424.4856, loss: 0.00000286\n",
      "Epoch: [37] [  12/  40] time: 424.7375, loss: 0.00000668\n",
      "Epoch: [37] [  13/  40] time: 424.9860, loss: 0.00002802\n",
      "Epoch: [37] [  14/  40] time: 425.2305, loss: 0.00000033\n",
      "Epoch: [37] [  15/  40] time: 425.4867, loss: 0.00001147\n",
      "Epoch: [37] [  16/  40] time: 425.7312, loss: 0.00000225\n",
      "Epoch: [37] [  17/  40] time: 425.9746, loss: 0.00004652\n",
      "Epoch: [37] [  18/  40] time: 426.2298, loss: 0.00000574\n",
      "Epoch: [37] [  19/  40] time: 426.4753, loss: 0.00000085\n",
      "Epoch: [37] [  20/  40] time: 426.7190, loss: 0.00001115\n",
      "Epoch: [37] [  21/  40] time: 426.9710, loss: 0.00002427\n",
      "Epoch: [37] [  22/  40] time: 427.2157, loss: 0.00006036\n",
      "Epoch: [37] [  23/  40] time: 427.4647, loss: 0.00011989\n",
      "Epoch: [37] [  24/  40] time: 427.7097, loss: 0.00000035\n",
      "Epoch: [37] [  25/  40] time: 427.9536, loss: 0.00002870\n",
      "Epoch: [37] [  26/  40] time: 428.2031, loss: 0.00000230\n",
      "Epoch: [37] [  27/  40] time: 428.4546, loss: 0.00000141\n",
      "Epoch: [37] [  28/  40] time: 428.6996, loss: 0.00000216\n",
      "Epoch: [37] [  29/  40] time: 428.9524, loss: 0.00000985\n",
      "Epoch: [37] [  30/  40] time: 429.2022, loss: 0.00003455\n",
      "Epoch: [37] [  31/  40] time: 429.4496, loss: 0.00001195\n",
      "Epoch: [37] [  32/  40] time: 429.7081, loss: 0.00006082\n",
      "Epoch: [37] [  33/  40] time: 429.9528, loss: 0.00000402\n",
      "Epoch: [37] [  34/  40] time: 430.2011, loss: 0.00001566\n",
      "Epoch: [37] [  35/  40] time: 430.4595, loss: 0.00000463\n",
      "Epoch: [37] [  36/  40] time: 430.7042, loss: 0.00000233\n",
      "Epoch: [37] [  37/  40] time: 430.9510, loss: 0.00000299\n",
      "Epoch: [37] [  38/  40] time: 431.1968, loss: 0.00008032\n",
      "Epoch: [37] [  39/  40] time: 431.4429, loss: 0.00001408\n",
      "[37/50] - ptime: 10.6716 loss: 0.00002713 acc: 0.73000 lr: 0.00072900\n",
      "Epoch: [38] [   0/  40] time: 432.8828, loss: 0.00000705\n",
      "Epoch: [38] [   1/  40] time: 433.1298, loss: 0.00000552\n",
      "Epoch: [38] [   2/  40] time: 433.3765, loss: 0.00001717\n",
      "Epoch: [38] [   3/  40] time: 433.6207, loss: 0.00000290\n",
      "Epoch: [38] [   4/  40] time: 433.8728, loss: 0.00005531\n",
      "Epoch: [38] [   5/  40] time: 434.1268, loss: 0.00002595\n",
      "Epoch: [38] [   6/  40] time: 434.3744, loss: 0.00000480\n",
      "Epoch: [38] [   7/  40] time: 434.6351, loss: 0.00001399\n",
      "Epoch: [38] [   8/  40] time: 434.8798, loss: 0.00000353\n",
      "Epoch: [38] [   9/  40] time: 435.1237, loss: 0.00012222\n",
      "Epoch: [38] [  10/  40] time: 435.3714, loss: 0.00000124\n",
      "Epoch: [38] [  11/  40] time: 435.6165, loss: 0.00001186\n",
      "Epoch: [38] [  12/  40] time: 435.8619, loss: 0.00003873\n",
      "Epoch: [38] [  13/  40] time: 436.1157, loss: 0.00002144\n",
      "Epoch: [38] [  14/  40] time: 436.3618, loss: 0.00000198\n",
      "Epoch: [38] [  15/  40] time: 436.6096, loss: 0.00003714\n",
      "Epoch: [38] [  16/  40] time: 436.8555, loss: 0.00000728\n",
      "Epoch: [38] [  17/  40] time: 437.0955, loss: 0.00000142\n",
      "Epoch: [38] [  18/  40] time: 437.3459, loss: 0.00006713\n",
      "Epoch: [38] [  19/  40] time: 437.5992, loss: 0.00001247\n",
      "Epoch: [38] [  20/  40] time: 437.8503, loss: 0.00000398\n",
      "Epoch: [38] [  21/  40] time: 438.1031, loss: 0.00000386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38] [  22/  40] time: 438.3554, loss: 0.00001432\n",
      "Epoch: [38] [  23/  40] time: 438.6008, loss: 0.00002097\n",
      "Epoch: [38] [  24/  40] time: 438.8582, loss: 0.00000161\n",
      "Epoch: [38] [  25/  40] time: 439.1023, loss: 0.00000177\n",
      "Epoch: [38] [  26/  40] time: 439.3483, loss: 0.00001036\n",
      "Epoch: [38] [  27/  40] time: 439.6054, loss: 0.00000519\n",
      "Epoch: [38] [  28/  40] time: 439.8573, loss: 0.00001269\n",
      "Epoch: [38] [  29/  40] time: 440.1039, loss: 0.00000613\n",
      "Epoch: [38] [  30/  40] time: 440.3508, loss: 0.00001424\n",
      "Epoch: [38] [  31/  40] time: 440.5959, loss: 0.00001279\n",
      "Epoch: [38] [  32/  40] time: 440.8454, loss: 0.00000302\n",
      "Epoch: [38] [  33/  40] time: 441.0930, loss: 0.00000118\n",
      "Epoch: [38] [  34/  40] time: 441.3377, loss: 0.00004004\n",
      "Epoch: [38] [  35/  40] time: 441.5914, loss: 0.00001795\n",
      "Epoch: [38] [  36/  40] time: 441.8429, loss: 0.00000145\n",
      "Epoch: [38] [  37/  40] time: 442.0856, loss: 0.00000843\n",
      "Epoch: [38] [  38/  40] time: 442.3437, loss: 0.00000278\n",
      "Epoch: [38] [  39/  40] time: 442.5921, loss: 0.00000047\n",
      "[38/50] - ptime: 10.7125 loss: 0.00001606 acc: 0.72000 lr: 0.00072900\n",
      "Epoch: [39] [   0/  40] time: 444.0196, loss: 0.00001464\n",
      "Epoch: [39] [   1/  40] time: 444.2638, loss: 0.00000090\n",
      "Epoch: [39] [   2/  40] time: 444.5236, loss: 0.00000357\n",
      "Epoch: [39] [   3/  40] time: 444.7680, loss: 0.00000289\n",
      "Epoch: [39] [   4/  40] time: 445.0137, loss: 0.00001562\n",
      "Epoch: [39] [   5/  40] time: 445.2668, loss: 0.00000262\n",
      "Epoch: [39] [   6/  40] time: 445.5139, loss: 0.00000029\n",
      "Epoch: [39] [   7/  40] time: 445.7612, loss: 0.00000823\n",
      "Epoch: [39] [   8/  40] time: 446.0061, loss: 0.00000232\n",
      "Epoch: [39] [   9/  40] time: 446.2501, loss: 0.00000206\n",
      "Epoch: [39] [  10/  40] time: 446.5015, loss: 0.00000174\n",
      "Epoch: [39] [  11/  40] time: 446.7471, loss: 0.00000179\n",
      "Epoch: [39] [  12/  40] time: 446.9918, loss: 0.00000469\n",
      "Epoch: [39] [  13/  40] time: 447.2450, loss: 0.00004023\n",
      "Epoch: [39] [  14/  40] time: 447.4953, loss: 0.00000322\n",
      "Epoch: [39] [  15/  40] time: 447.7431, loss: 0.00003451\n",
      "Epoch: [39] [  16/  40] time: 448.0029, loss: 0.00000199\n",
      "Epoch: [39] [  17/  40] time: 448.2475, loss: 0.00010078\n",
      "Epoch: [39] [  18/  40] time: 448.4965, loss: 0.00004580\n",
      "Epoch: [39] [  19/  40] time: 448.7539, loss: 0.00000486\n",
      "Epoch: [39] [  20/  40] time: 448.9984, loss: 0.00016707\n",
      "Epoch: [39] [  21/  40] time: 449.2446, loss: 0.00003118\n",
      "Epoch: [39] [  22/  40] time: 449.5040, loss: 0.00000190\n",
      "Epoch: [39] [  23/  40] time: 449.7472, loss: 0.00002518\n",
      "Epoch: [39] [  24/  40] time: 449.9973, loss: 0.00000529\n",
      "Epoch: [39] [  25/  40] time: 450.2465, loss: 0.00002438\n",
      "Epoch: [39] [  26/  40] time: 450.4913, loss: 0.00001045\n",
      "Epoch: [39] [  27/  40] time: 450.7437, loss: 0.00005842\n",
      "Epoch: [39] [  28/  40] time: 450.9931, loss: 0.00000482\n",
      "Epoch: [39] [  29/  40] time: 451.2366, loss: 0.00001181\n",
      "Epoch: [39] [  30/  40] time: 451.4966, loss: 0.00000325\n",
      "Epoch: [39] [  31/  40] time: 451.7411, loss: 0.00002272\n",
      "Epoch: [39] [  32/  40] time: 451.9857, loss: 0.00004911\n",
      "Epoch: [39] [  33/  40] time: 452.2387, loss: 0.00000272\n",
      "Epoch: [39] [  34/  40] time: 452.4859, loss: 0.00000220\n",
      "Epoch: [39] [  35/  40] time: 452.7328, loss: 0.00000294\n",
      "Epoch: [39] [  36/  40] time: 452.9776, loss: 0.00000147\n",
      "Epoch: [39] [  37/  40] time: 453.2215, loss: 0.00001819\n",
      "Epoch: [39] [  38/  40] time: 453.4742, loss: 0.00000800\n",
      "Epoch: [39] [  39/  40] time: 453.7251, loss: 0.00004810\n",
      "[39/50] - ptime: 10.7001 loss: 0.00001980 acc: 0.73000 lr: 0.00072900\n",
      "Epoch: [40] [   0/  40] time: 455.1633, loss: 0.00000474\n",
      "Epoch: [40] [   1/  40] time: 455.4085, loss: 0.00000173\n",
      "Epoch: [40] [   2/  40] time: 455.6608, loss: 0.00006008\n",
      "Epoch: [40] [   3/  40] time: 455.9111, loss: 0.00000522\n",
      "Epoch: [40] [   4/  40] time: 456.1556, loss: 0.00002923\n",
      "Epoch: [40] [   5/  40] time: 456.4109, loss: 0.00051785\n",
      "Epoch: [40] [   6/  40] time: 456.6601, loss: 0.00000600\n",
      "Epoch: [40] [   7/  40] time: 456.9044, loss: 0.00000984\n",
      "Epoch: [40] [   8/  40] time: 457.1643, loss: 0.00000360\n",
      "Epoch: [40] [   9/  40] time: 457.4095, loss: 0.00000861\n",
      "Epoch: [40] [  10/  40] time: 457.6582, loss: 0.00001851\n",
      "Epoch: [40] [  11/  40] time: 457.9194, loss: 0.00000399\n",
      "Epoch: [40] [  12/  40] time: 458.1638, loss: 0.00000167\n",
      "Epoch: [40] [  13/  40] time: 458.4137, loss: 0.00004678\n",
      "Epoch: [40] [  14/  40] time: 458.6591, loss: 0.00000324\n",
      "Epoch: [40] [  15/  40] time: 458.9040, loss: 0.00000955\n",
      "Epoch: [40] [  16/  40] time: 459.1551, loss: 0.00000255\n",
      "Epoch: [40] [  17/  40] time: 459.4056, loss: 0.00000173\n",
      "Epoch: [40] [  18/  40] time: 459.6505, loss: 0.00000224\n",
      "Epoch: [40] [  19/  40] time: 459.9024, loss: 0.00000503\n",
      "Epoch: [40] [  20/  40] time: 460.1515, loss: 0.00000385\n",
      "Epoch: [40] [  21/  40] time: 460.3965, loss: 0.00010366\n",
      "Epoch: [40] [  22/  40] time: 460.6565, loss: 0.00000108\n",
      "Epoch: [40] [  23/  40] time: 460.9006, loss: 0.00010157\n",
      "Epoch: [40] [  24/  40] time: 461.1460, loss: 0.00000253\n",
      "Epoch: [40] [  25/  40] time: 461.4028, loss: 0.00000740\n",
      "Epoch: [40] [  26/  40] time: 461.6471, loss: 0.00001897\n",
      "Epoch: [40] [  27/  40] time: 461.8946, loss: 0.00000113\n",
      "Epoch: [40] [  28/  40] time: 462.1401, loss: 0.00000020\n",
      "Epoch: [40] [  29/  40] time: 462.3847, loss: 0.00000304\n",
      "Epoch: [40] [  30/  40] time: 462.6357, loss: 0.00002610\n",
      "Epoch: [40] [  31/  40] time: 462.8843, loss: 0.00001925\n",
      "Epoch: [40] [  32/  40] time: 463.1280, loss: 0.00000031\n",
      "Epoch: [40] [  33/  40] time: 463.3832, loss: 0.00000964\n",
      "Epoch: [40] [  34/  40] time: 463.6327, loss: 0.00000033\n",
      "Epoch: [40] [  35/  40] time: 463.8794, loss: 0.00001465\n",
      "Epoch: [40] [  36/  40] time: 464.1394, loss: 0.00000601\n",
      "Epoch: [40] [  37/  40] time: 464.3852, loss: 0.00000408\n",
      "Epoch: [40] [  38/  40] time: 464.6331, loss: 0.00000092\n",
      "Epoch: [40] [  39/  40] time: 464.8905, loss: 0.00000369\n",
      "[40/50] - ptime: 10.7221 loss: 0.00002676 acc: 0.72000 lr: 0.00065610\n",
      "Epoch: [41] [   0/  40] time: 466.3966, loss: 0.00000853\n",
      "Epoch: [41] [   1/  40] time: 466.6412, loss: 0.00002094\n",
      "Epoch: [41] [   2/  40] time: 466.8925, loss: 0.00003198\n",
      "Epoch: [41] [   3/  40] time: 467.1423, loss: 0.00000764\n",
      "Epoch: [41] [   4/  40] time: 467.3880, loss: 0.00000723\n",
      "Epoch: [41] [   5/  40] time: 467.6478, loss: 0.00000897\n",
      "Epoch: [41] [   6/  40] time: 467.8922, loss: 0.00000415\n",
      "Epoch: [41] [   7/  40] time: 468.1363, loss: 0.00005503\n",
      "Epoch: [41] [   8/  40] time: 468.3914, loss: 0.00001011\n",
      "Epoch: [41] [   9/  40] time: 468.6358, loss: 0.00000629\n",
      "Epoch: [41] [  10/  40] time: 468.8830, loss: 0.00027884\n",
      "Epoch: [41] [  11/  40] time: 469.1278, loss: 0.00012162\n",
      "Epoch: [41] [  12/  40] time: 469.3733, loss: 0.00000115\n",
      "Epoch: [41] [  13/  40] time: 469.6238, loss: 0.00005212\n",
      "Epoch: [41] [  14/  40] time: 469.8723, loss: 0.00001766\n",
      "Epoch: [41] [  15/  40] time: 470.1145, loss: 0.00000260\n",
      "Epoch: [41] [  16/  40] time: 470.3679, loss: 0.00000286\n",
      "Epoch: [41] [  17/  40] time: 470.6166, loss: 0.00005792\n",
      "Epoch: [41] [  18/  40] time: 470.8612, loss: 0.00001303\n",
      "Epoch: [41] [  19/  40] time: 471.1188, loss: 0.00000094\n",
      "Epoch: [41] [  20/  40] time: 471.3646, loss: 0.00000072\n",
      "Epoch: [41] [  21/  40] time: 471.6117, loss: 0.00000363\n",
      "Epoch: [41] [  22/  40] time: 471.8690, loss: 0.00000540\n",
      "Epoch: [41] [  23/  40] time: 472.1122, loss: 0.00000771\n",
      "Epoch: [41] [  24/  40] time: 472.3609, loss: 0.00003767\n",
      "Epoch: [41] [  25/  40] time: 472.6068, loss: 0.00001021\n",
      "Epoch: [41] [  26/  40] time: 472.8499, loss: 0.00000561\n",
      "Epoch: [41] [  27/  40] time: 473.1034, loss: 0.00000285\n",
      "Epoch: [41] [  28/  40] time: 473.3524, loss: 0.00000130\n",
      "Epoch: [41] [  29/  40] time: 473.6030, loss: 0.00000835\n",
      "Epoch: [41] [  30/  40] time: 473.8591, loss: 0.00000697\n",
      "Epoch: [41] [  31/  40] time: 474.1028, loss: 0.00000331\n",
      "Epoch: [41] [  32/  40] time: 474.3466, loss: 0.00001412\n",
      "Epoch: [41] [  33/  40] time: 474.6018, loss: 0.00000467\n",
      "Epoch: [41] [  34/  40] time: 474.8456, loss: 0.00000544\n",
      "Epoch: [41] [  35/  40] time: 475.0945, loss: 0.00000276\n",
      "Epoch: [41] [  36/  40] time: 475.3421, loss: 0.00000924\n",
      "Epoch: [41] [  37/  40] time: 475.5860, loss: 0.00000064\n",
      "Epoch: [41] [  38/  40] time: 475.8371, loss: 0.00000884\n",
      "Epoch: [41] [  39/  40] time: 476.0809, loss: 0.00000438\n",
      "[41/50] - ptime: 10.6746 loss: 0.00002134 acc: 0.73000 lr: 0.00065610\n",
      "Epoch: [42] [   0/  40] time: 477.5085, loss: 0.00000124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [42] [   1/  40] time: 477.7516, loss: 0.00000466\n",
      "Epoch: [42] [   2/  40] time: 478.0028, loss: 0.00002304\n",
      "Epoch: [42] [   3/  40] time: 478.2522, loss: 0.00000906\n",
      "Epoch: [42] [   4/  40] time: 478.4982, loss: 0.00001631\n",
      "Epoch: [42] [   5/  40] time: 478.7541, loss: 0.00000068\n",
      "Epoch: [42] [   6/  40] time: 478.9992, loss: 0.00000355\n",
      "Epoch: [42] [   7/  40] time: 479.2439, loss: 0.00006792\n",
      "Epoch: [42] [   8/  40] time: 479.5037, loss: 0.00000799\n",
      "Epoch: [42] [   9/  40] time: 479.7485, loss: 0.00000828\n",
      "Epoch: [42] [  10/  40] time: 479.9951, loss: 0.00000362\n",
      "Epoch: [42] [  11/  40] time: 480.2528, loss: 0.00000532\n",
      "Epoch: [42] [  12/  40] time: 480.4986, loss: 0.00002523\n",
      "Epoch: [42] [  13/  40] time: 480.7458, loss: 0.00001243\n",
      "Epoch: [42] [  14/  40] time: 480.9910, loss: 0.00001663\n",
      "Epoch: [42] [  15/  40] time: 481.2343, loss: 0.00000856\n",
      "Epoch: [42] [  16/  40] time: 481.4917, loss: 0.00000024\n",
      "Epoch: [42] [  17/  40] time: 481.7410, loss: 0.00003048\n",
      "Epoch: [42] [  18/  40] time: 481.9851, loss: 0.00000098\n",
      "Epoch: [42] [  19/  40] time: 482.2361, loss: 0.00000197\n",
      "Epoch: [42] [  20/  40] time: 482.4901, loss: 0.00000115\n",
      "Epoch: [42] [  21/  40] time: 482.7341, loss: 0.00001744\n",
      "Epoch: [42] [  22/  40] time: 482.9905, loss: 0.00011856\n",
      "Epoch: [42] [  23/  40] time: 483.2345, loss: 0.00001227\n",
      "Epoch: [42] [  24/  40] time: 483.4833, loss: 0.00004045\n",
      "Epoch: [42] [  25/  40] time: 483.7347, loss: 0.00000245\n",
      "Epoch: [42] [  26/  40] time: 483.9806, loss: 0.00001973\n",
      "Epoch: [42] [  27/  40] time: 484.2238, loss: 0.00001154\n",
      "Epoch: [42] [  28/  40] time: 484.4824, loss: 0.00006882\n",
      "Epoch: [42] [  29/  40] time: 484.7250, loss: 0.00000446\n",
      "Epoch: [42] [  30/  40] time: 484.9723, loss: 0.00001641\n",
      "Epoch: [42] [  31/  40] time: 485.2169, loss: 0.00002173\n",
      "Epoch: [42] [  32/  40] time: 485.4647, loss: 0.00000121\n",
      "Epoch: [42] [  33/  40] time: 485.7199, loss: 0.00000099\n",
      "Epoch: [42] [  34/  40] time: 485.9682, loss: 0.00001272\n",
      "Epoch: [42] [  35/  40] time: 486.2113, loss: 0.00000639\n",
      "Epoch: [42] [  36/  40] time: 486.4724, loss: 0.00001060\n",
      "Epoch: [42] [  37/  40] time: 486.7242, loss: 0.00001486\n",
      "Epoch: [42] [  38/  40] time: 486.9682, loss: 0.00002521\n",
      "Epoch: [42] [  39/  40] time: 487.2179, loss: 0.00001040\n",
      "[42/50] - ptime: 10.6968 loss: 0.00001664 acc: 0.72000 lr: 0.00065610\n",
      "Epoch: [43] [   0/  40] time: 488.8800, loss: 0.00000253\n",
      "Epoch: [43] [   1/  40] time: 489.1241, loss: 0.00000107\n",
      "Epoch: [43] [   2/  40] time: 489.3798, loss: 0.00001739\n",
      "Epoch: [43] [   3/  40] time: 489.6254, loss: 0.00001753\n",
      "Epoch: [43] [   4/  40] time: 489.8672, loss: 0.00000411\n",
      "Epoch: [43] [   5/  40] time: 490.1124, loss: 0.00000493\n",
      "Epoch: [43] [   6/  40] time: 490.3570, loss: 0.00000192\n",
      "Epoch: [43] [   7/  40] time: 490.6059, loss: 0.00004095\n",
      "Epoch: [43] [   8/  40] time: 490.8564, loss: 0.00000391\n",
      "Epoch: [43] [   9/  40] time: 491.1000, loss: 0.00000201\n",
      "Epoch: [43] [  10/  40] time: 491.3523, loss: 0.00003860\n",
      "Epoch: [43] [  11/  40] time: 491.6036, loss: 0.00000697\n",
      "Epoch: [43] [  12/  40] time: 491.8469, loss: 0.00000331\n",
      "Epoch: [43] [  13/  40] time: 492.1033, loss: 0.00003933\n",
      "Epoch: [43] [  14/  40] time: 492.3473, loss: 0.00000686\n",
      "Epoch: [43] [  15/  40] time: 492.5950, loss: 0.00007961\n",
      "Epoch: [43] [  16/  40] time: 492.8476, loss: 0.00001932\n",
      "Epoch: [43] [  17/  40] time: 493.0912, loss: 0.00000221\n",
      "Epoch: [43] [  18/  40] time: 493.3387, loss: 0.00000089\n",
      "Epoch: [43] [  19/  40] time: 493.5857, loss: 0.00000335\n",
      "Epoch: [43] [  20/  40] time: 493.8298, loss: 0.00000005\n",
      "Epoch: [43] [  21/  40] time: 494.0772, loss: 0.00000336\n",
      "Epoch: [43] [  22/  40] time: 494.3270, loss: 0.00000038\n",
      "Epoch: [43] [  23/  40] time: 494.5728, loss: 0.00000199\n",
      "Epoch: [43] [  24/  40] time: 494.8270, loss: 0.00000180\n",
      "Epoch: [43] [  25/  40] time: 495.0724, loss: 0.00000149\n",
      "Epoch: [43] [  26/  40] time: 495.3201, loss: 0.00000587\n",
      "Epoch: [43] [  27/  40] time: 495.5783, loss: 0.00002676\n",
      "Epoch: [43] [  28/  40] time: 495.8219, loss: 0.00000362\n",
      "Epoch: [43] [  29/  40] time: 496.0649, loss: 0.00003503\n",
      "Epoch: [43] [  30/  40] time: 496.3177, loss: 0.00000068\n",
      "Epoch: [43] [  31/  40] time: 496.5661, loss: 0.00002166\n",
      "Epoch: [43] [  32/  40] time: 496.8189, loss: 0.00000393\n",
      "Epoch: [43] [  33/  40] time: 497.0633, loss: 0.00000429\n",
      "Epoch: [43] [  34/  40] time: 497.3063, loss: 0.00000554\n",
      "Epoch: [43] [  35/  40] time: 497.5621, loss: 0.00000256\n",
      "Epoch: [43] [  36/  40] time: 497.8124, loss: 0.00000231\n",
      "Epoch: [43] [  37/  40] time: 498.0571, loss: 0.00001792\n",
      "Epoch: [43] [  38/  40] time: 498.3139, loss: 0.00001471\n",
      "Epoch: [43] [  39/  40] time: 498.5612, loss: 0.00009039\n",
      "[43/50] - ptime: 10.6744 loss: 0.00001353 acc: 0.72000 lr: 0.00065610\n",
      "Epoch: [44] [   0/  40] time: 500.0305, loss: 0.00000083\n",
      "Epoch: [44] [   1/  40] time: 500.2761, loss: 0.00001147\n",
      "Epoch: [44] [   2/  40] time: 500.5312, loss: 0.00000151\n",
      "Epoch: [44] [   3/  40] time: 500.7748, loss: 0.00000103\n",
      "Epoch: [44] [   4/  40] time: 501.0233, loss: 0.00000914\n",
      "Epoch: [44] [   5/  40] time: 501.2701, loss: 0.00001062\n",
      "Epoch: [44] [   6/  40] time: 501.5144, loss: 0.00000099\n",
      "Epoch: [44] [   7/  40] time: 501.7690, loss: 0.00000158\n",
      "Epoch: [44] [   8/  40] time: 502.0180, loss: 0.00001024\n",
      "Epoch: [44] [   9/  40] time: 502.2614, loss: 0.00000256\n",
      "Epoch: [44] [  10/  40] time: 502.5152, loss: 0.00001347\n",
      "Epoch: [44] [  11/  40] time: 502.7611, loss: 0.00003561\n",
      "Epoch: [44] [  12/  40] time: 503.0055, loss: 0.00001681\n",
      "Epoch: [44] [  13/  40] time: 503.2625, loss: 0.00000102\n",
      "Epoch: [44] [  14/  40] time: 503.5087, loss: 0.00000510\n",
      "Epoch: [44] [  15/  40] time: 503.7578, loss: 0.00000463\n",
      "Epoch: [44] [  16/  40] time: 504.0023, loss: 0.00000360\n",
      "Epoch: [44] [  17/  40] time: 504.2456, loss: 0.00000346\n",
      "Epoch: [44] [  18/  40] time: 504.4955, loss: 0.00000166\n",
      "Epoch: [44] [  19/  40] time: 504.7481, loss: 0.00002734\n",
      "Epoch: [44] [  20/  40] time: 504.9916, loss: 0.00000277\n",
      "Epoch: [44] [  21/  40] time: 505.2466, loss: 0.00001386\n",
      "Epoch: [44] [  22/  40] time: 505.4975, loss: 0.00000271\n",
      "Epoch: [44] [  23/  40] time: 505.7429, loss: 0.00008913\n",
      "Epoch: [44] [  24/  40] time: 506.0008, loss: 0.00000243\n",
      "Epoch: [44] [  25/  40] time: 506.2468, loss: 0.00001422\n",
      "Epoch: [44] [  26/  40] time: 506.4912, loss: 0.00046621\n",
      "Epoch: [44] [  27/  40] time: 506.7471, loss: 0.00001568\n",
      "Epoch: [44] [  28/  40] time: 506.9908, loss: 0.00000170\n",
      "Epoch: [44] [  29/  40] time: 507.2378, loss: 0.00017228\n",
      "Epoch: [44] [  30/  40] time: 507.4836, loss: 0.00000841\n",
      "Epoch: [44] [  31/  40] time: 507.7294, loss: 0.00008842\n",
      "Epoch: [44] [  32/  40] time: 507.9787, loss: 0.00001558\n",
      "Epoch: [44] [  33/  40] time: 508.2221, loss: 0.00000055\n",
      "Epoch: [44] [  34/  40] time: 508.4716, loss: 0.00001589\n",
      "Epoch: [44] [  35/  40] time: 508.7266, loss: 0.00007031\n",
      "Epoch: [44] [  36/  40] time: 508.9738, loss: 0.00000051\n",
      "Epoch: [44] [  37/  40] time: 509.2168, loss: 0.00004970\n",
      "Epoch: [44] [  38/  40] time: 509.4736, loss: 0.00000270\n",
      "Epoch: [44] [  39/  40] time: 509.7178, loss: 0.00000243\n",
      "[44/50] - ptime: 10.6912 loss: 0.00002995 acc: 0.72000 lr: 0.00065610\n",
      "Epoch: [45] [   0/  40] time: 511.1273, loss: 0.00000661\n",
      "Epoch: [45] [   1/  40] time: 511.3713, loss: 0.00000054\n",
      "Epoch: [45] [   2/  40] time: 511.6290, loss: 0.00000132\n",
      "Epoch: [45] [   3/  40] time: 511.8734, loss: 0.00001973\n",
      "Epoch: [45] [   4/  40] time: 512.1180, loss: 0.00000206\n",
      "Epoch: [45] [   5/  40] time: 512.3755, loss: 0.00002839\n",
      "Epoch: [45] [   6/  40] time: 512.6235, loss: 0.00000301\n",
      "Epoch: [45] [   7/  40] time: 512.8696, loss: 0.00000050\n",
      "Epoch: [45] [   8/  40] time: 513.1142, loss: 0.00000150\n",
      "Epoch: [45] [   9/  40] time: 513.3577, loss: 0.00000467\n",
      "Epoch: [45] [  10/  40] time: 513.6129, loss: 0.00000293\n",
      "Epoch: [45] [  11/  40] time: 513.8608, loss: 0.00000615\n",
      "Epoch: [45] [  12/  40] time: 514.1047, loss: 0.00001118\n",
      "Epoch: [45] [  13/  40] time: 514.3615, loss: 0.00000634\n",
      "Epoch: [45] [  14/  40] time: 514.6100, loss: 0.00000072\n",
      "Epoch: [45] [  15/  40] time: 514.8533, loss: 0.00002114\n",
      "Epoch: [45] [  16/  40] time: 515.1068, loss: 0.00005236\n",
      "Epoch: [45] [  17/  40] time: 515.3500, loss: 0.00000095\n",
      "Epoch: [45] [  18/  40] time: 515.5986, loss: 0.00000754\n",
      "Epoch: [45] [  19/  40] time: 515.8562, loss: 0.00000084\n",
      "Epoch: [45] [  20/  40] time: 516.0987, loss: 0.00009171\n",
      "Epoch: [45] [  21/  40] time: 516.3467, loss: 0.00015490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45] [  22/  40] time: 516.5980, loss: 0.00000300\n",
      "Epoch: [45] [  23/  40] time: 516.8415, loss: 0.00009332\n",
      "Epoch: [45] [  24/  40] time: 517.0944, loss: 0.00000440\n",
      "Epoch: [45] [  25/  40] time: 517.3423, loss: 0.00000799\n",
      "Epoch: [45] [  26/  40] time: 517.5893, loss: 0.00002820\n",
      "Epoch: [45] [  27/  40] time: 517.8460, loss: 0.00000058\n",
      "Epoch: [45] [  28/  40] time: 518.0891, loss: 0.00000237\n",
      "Epoch: [45] [  29/  40] time: 518.3326, loss: 0.00000398\n",
      "Epoch: [45] [  30/  40] time: 518.5885, loss: 0.00000251\n",
      "Epoch: [45] [  31/  40] time: 518.8318, loss: 0.00000120\n",
      "Epoch: [45] [  32/  40] time: 519.0801, loss: 0.00000074\n",
      "Epoch: [45] [  33/  40] time: 519.3248, loss: 0.00001918\n",
      "Epoch: [45] [  34/  40] time: 519.5703, loss: 0.00001449\n",
      "Epoch: [45] [  35/  40] time: 519.8242, loss: 0.00000176\n",
      "Epoch: [45] [  36/  40] time: 520.0691, loss: 0.00003714\n",
      "Epoch: [45] [  37/  40] time: 520.3149, loss: 0.00002993\n",
      "Epoch: [45] [  38/  40] time: 520.5732, loss: 0.00001285\n",
      "Epoch: [45] [  39/  40] time: 520.8231, loss: 0.00000500\n",
      "[45/50] - ptime: 10.6887 loss: 0.00001734 acc: 0.73000 lr: 0.00065610\n",
      "Epoch: [46] [   0/  40] time: 522.2691, loss: 0.00003565\n",
      "Epoch: [46] [   1/  40] time: 522.5147, loss: 0.00000227\n",
      "Epoch: [46] [   2/  40] time: 522.7746, loss: 0.00002524\n",
      "Epoch: [46] [   3/  40] time: 523.0186, loss: 0.00000402\n",
      "Epoch: [46] [   4/  40] time: 523.2618, loss: 0.00002156\n",
      "Epoch: [46] [   5/  40] time: 523.5145, loss: 0.00000835\n",
      "Epoch: [46] [   6/  40] time: 523.7606, loss: 0.00002273\n",
      "Epoch: [46] [   7/  40] time: 524.0074, loss: 0.00000232\n",
      "Epoch: [46] [   8/  40] time: 524.2529, loss: 0.00000439\n",
      "Epoch: [46] [   9/  40] time: 524.4997, loss: 0.00000268\n",
      "Epoch: [46] [  10/  40] time: 524.7496, loss: 0.00000842\n",
      "Epoch: [46] [  11/  40] time: 525.0003, loss: 0.00000005\n",
      "Epoch: [46] [  12/  40] time: 525.2437, loss: 0.00004106\n",
      "Epoch: [46] [  13/  40] time: 525.4958, loss: 0.00000526\n",
      "Epoch: [46] [  14/  40] time: 525.7464, loss: 0.00000437\n",
      "Epoch: [46] [  15/  40] time: 525.9923, loss: 0.00000744\n",
      "Epoch: [46] [  16/  40] time: 526.2506, loss: 0.00000153\n",
      "Epoch: [46] [  17/  40] time: 526.4956, loss: 0.00001696\n",
      "Epoch: [46] [  18/  40] time: 526.7415, loss: 0.00000198\n",
      "Epoch: [46] [  19/  40] time: 526.9965, loss: 0.00000129\n",
      "Epoch: [46] [  20/  40] time: 527.2467, loss: 0.00000049\n",
      "Epoch: [46] [  21/  40] time: 527.4983, loss: 0.00000058\n",
      "Epoch: [46] [  22/  40] time: 527.7449, loss: 0.00000183\n",
      "Epoch: [46] [  23/  40] time: 527.9890, loss: 0.00000232\n",
      "Epoch: [46] [  24/  40] time: 528.2404, loss: 0.00001389\n",
      "Epoch: [46] [  25/  40] time: 528.4911, loss: 0.00000112\n",
      "Epoch: [46] [  26/  40] time: 528.7361, loss: 0.00003465\n",
      "Epoch: [46] [  27/  40] time: 528.9937, loss: 0.00000321\n",
      "Epoch: [46] [  28/  40] time: 529.2494, loss: 0.00000074\n",
      "Epoch: [46] [  29/  40] time: 529.4986, loss: 0.00000601\n",
      "Epoch: [46] [  30/  40] time: 529.7496, loss: 0.00000359\n",
      "Epoch: [46] [  31/  40] time: 529.9939, loss: 0.00000323\n",
      "Epoch: [46] [  32/  40] time: 530.2422, loss: 0.00001189\n",
      "Epoch: [46] [  33/  40] time: 530.4872, loss: 0.00000456\n",
      "Epoch: [46] [  34/  40] time: 530.7322, loss: 0.00000981\n",
      "Epoch: [46] [  35/  40] time: 530.9835, loss: 0.00000565\n",
      "Epoch: [46] [  36/  40] time: 531.2282, loss: 0.00000091\n",
      "Epoch: [46] [  37/  40] time: 531.4748, loss: 0.00000150\n",
      "Epoch: [46] [  38/  40] time: 531.7302, loss: 0.00000204\n",
      "Epoch: [46] [  39/  40] time: 531.9751, loss: 0.00000144\n",
      "[46/50] - ptime: 10.7028 loss: 0.00000818 acc: 0.73000 lr: 0.00065610\n",
      "Epoch: [47] [   0/  40] time: 533.3995, loss: 0.00019382\n",
      "Epoch: [47] [   1/  40] time: 533.6458, loss: 0.00002811\n",
      "Epoch: [47] [   2/  40] time: 533.8978, loss: 0.00000068\n",
      "Epoch: [47] [   3/  40] time: 534.1484, loss: 0.00000732\n",
      "Epoch: [47] [   4/  40] time: 534.3920, loss: 0.00000191\n",
      "Epoch: [47] [   5/  40] time: 534.6541, loss: 0.00001432\n",
      "Epoch: [47] [   6/  40] time: 534.8978, loss: 0.00000108\n",
      "Epoch: [47] [   7/  40] time: 535.1437, loss: 0.00000200\n",
      "Epoch: [47] [   8/  40] time: 535.3934, loss: 0.00016185\n",
      "Epoch: [47] [   9/  40] time: 535.6392, loss: 0.00000817\n",
      "Epoch: [47] [  10/  40] time: 535.8873, loss: 0.00001711\n",
      "Epoch: [47] [  11/  40] time: 536.1320, loss: 0.00001166\n",
      "Epoch: [47] [  12/  40] time: 536.3759, loss: 0.00000187\n",
      "Epoch: [47] [  13/  40] time: 536.6257, loss: 0.00000127\n",
      "Epoch: [47] [  14/  40] time: 536.8759, loss: 0.00002533\n",
      "Epoch: [47] [  15/  40] time: 537.1192, loss: 0.00000308\n",
      "Epoch: [47] [  16/  40] time: 537.3718, loss: 0.00004187\n",
      "Epoch: [47] [  17/  40] time: 537.6203, loss: 0.00000071\n",
      "Epoch: [47] [  18/  40] time: 537.8638, loss: 0.00000421\n",
      "Epoch: [47] [  19/  40] time: 538.1192, loss: 0.00000015\n",
      "Epoch: [47] [  20/  40] time: 538.3629, loss: 0.00000173\n",
      "Epoch: [47] [  21/  40] time: 538.6072, loss: 0.00001240\n",
      "Epoch: [47] [  22/  40] time: 538.8613, loss: 0.00010557\n",
      "Epoch: [47] [  23/  40] time: 539.1049, loss: 0.00000018\n",
      "Epoch: [47] [  24/  40] time: 539.3520, loss: 0.00005802\n",
      "Epoch: [47] [  25/  40] time: 539.5971, loss: 0.00000669\n",
      "Epoch: [47] [  26/  40] time: 539.8444, loss: 0.00000322\n",
      "Epoch: [47] [  27/  40] time: 540.0917, loss: 0.00000070\n",
      "Epoch: [47] [  28/  40] time: 540.3410, loss: 0.00004413\n",
      "Epoch: [47] [  29/  40] time: 540.5864, loss: 0.00000385\n",
      "Epoch: [47] [  30/  40] time: 540.8389, loss: 0.00000155\n",
      "Epoch: [47] [  31/  40] time: 541.0886, loss: 0.00001166\n",
      "Epoch: [47] [  32/  40] time: 541.3341, loss: 0.00000371\n",
      "Epoch: [47] [  33/  40] time: 541.5935, loss: 0.00003753\n",
      "Epoch: [47] [  34/  40] time: 541.8395, loss: 0.00000010\n",
      "Epoch: [47] [  35/  40] time: 542.0823, loss: 0.00000363\n",
      "Epoch: [47] [  36/  40] time: 542.3352, loss: 0.00001338\n",
      "Epoch: [47] [  37/  40] time: 542.5803, loss: 0.00000185\n",
      "Epoch: [47] [  38/  40] time: 542.8287, loss: 0.00000300\n",
      "Epoch: [47] [  39/  40] time: 543.0759, loss: 0.00004041\n",
      "[47/50] - ptime: 10.6676 loss: 0.00002200 acc: 0.73000 lr: 0.00065610\n",
      "Epoch: [48] [   0/  40] time: 544.5249, loss: 0.00000244\n",
      "Epoch: [48] [   1/  40] time: 544.7658, loss: 0.00000138\n",
      "Epoch: [48] [   2/  40] time: 545.0104, loss: 0.00008643\n",
      "Epoch: [48] [   3/  40] time: 545.2562, loss: 0.00000082\n",
      "Epoch: [48] [   4/  40] time: 545.4975, loss: 0.00001066\n",
      "Epoch: [48] [   5/  40] time: 545.7487, loss: 0.00000736\n",
      "Epoch: [48] [   6/  40] time: 545.9979, loss: 0.00000032\n",
      "Epoch: [48] [   7/  40] time: 546.2433, loss: 0.00000029\n",
      "Epoch: [48] [   8/  40] time: 546.4992, loss: 0.00001566\n",
      "Epoch: [48] [   9/  40] time: 546.7507, loss: 0.00000632\n",
      "Epoch: [48] [  10/  40] time: 546.9946, loss: 0.00000817\n",
      "Epoch: [48] [  11/  40] time: 547.2540, loss: 0.00000681\n",
      "Epoch: [48] [  12/  40] time: 547.5014, loss: 0.00000198\n",
      "Epoch: [48] [  13/  40] time: 547.7508, loss: 0.00000150\n",
      "Epoch: [48] [  14/  40] time: 548.0068, loss: 0.00000158\n",
      "Epoch: [48] [  15/  40] time: 548.2502, loss: 0.00000316\n",
      "Epoch: [48] [  16/  40] time: 548.5006, loss: 0.00000374\n",
      "Epoch: [48] [  17/  40] time: 548.7472, loss: 0.00000790\n",
      "Epoch: [48] [  18/  40] time: 548.9905, loss: 0.00000808\n",
      "Epoch: [48] [  19/  40] time: 549.2381, loss: 0.00001341\n",
      "Epoch: [48] [  20/  40] time: 549.4906, loss: 0.00000085\n",
      "Epoch: [48] [  21/  40] time: 549.7377, loss: 0.00000015\n",
      "Epoch: [48] [  22/  40] time: 549.9897, loss: 0.00000385\n",
      "Epoch: [48] [  23/  40] time: 550.2399, loss: 0.00003197\n",
      "Epoch: [48] [  24/  40] time: 550.4848, loss: 0.00000130\n",
      "Epoch: [48] [  25/  40] time: 550.7442, loss: 0.00000762\n",
      "Epoch: [48] [  26/  40] time: 550.9886, loss: 0.00000319\n",
      "Epoch: [48] [  27/  40] time: 551.2328, loss: 0.00001440\n",
      "Epoch: [48] [  28/  40] time: 551.4877, loss: 0.00088643\n",
      "Epoch: [48] [  29/  40] time: 551.7329, loss: 0.00000102\n",
      "Epoch: [48] [  30/  40] time: 551.9797, loss: 0.00000354\n",
      "Epoch: [48] [  31/  40] time: 552.2253, loss: 0.00003966\n",
      "Epoch: [48] [  32/  40] time: 552.4734, loss: 0.00001642\n",
      "Epoch: [48] [  33/  40] time: 552.7259, loss: 0.00000645\n",
      "Epoch: [48] [  34/  40] time: 552.9818, loss: 0.00000056\n",
      "Epoch: [48] [  35/  40] time: 553.2254, loss: 0.00009515\n",
      "Epoch: [48] [  36/  40] time: 553.4814, loss: 0.00000086\n",
      "Epoch: [48] [  37/  40] time: 553.7369, loss: 0.00000799\n",
      "Epoch: [48] [  38/  40] time: 553.9802, loss: 0.00000354\n",
      "Epoch: [48] [  39/  40] time: 554.2333, loss: 0.00000354\n",
      "[48/50] - ptime: 10.7156 loss: 0.00003291 acc: 0.71000 lr: 0.00065610\n",
      "Epoch: [49] [   0/  40] time: 555.6054, loss: 0.00001185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [49] [   1/  40] time: 555.8527, loss: 0.00000305\n",
      "Epoch: [49] [   2/  40] time: 556.0975, loss: 0.00001014\n",
      "Epoch: [49] [   3/  40] time: 556.3527, loss: 0.00000069\n",
      "Epoch: [49] [   4/  40] time: 556.5996, loss: 0.00000320\n",
      "Epoch: [49] [   5/  40] time: 556.8482, loss: 0.00000556\n",
      "Epoch: [49] [   6/  40] time: 557.1026, loss: 0.00000354\n",
      "Epoch: [49] [   7/  40] time: 557.3459, loss: 0.00000779\n",
      "Epoch: [49] [   8/  40] time: 557.5955, loss: 0.00000518\n",
      "Epoch: [49] [   9/  40] time: 557.8563, loss: 0.00005999\n",
      "Epoch: [49] [  10/  40] time: 558.1007, loss: 0.00000146\n",
      "Epoch: [49] [  11/  40] time: 558.3475, loss: 0.00000485\n",
      "Epoch: [49] [  12/  40] time: 558.5943, loss: 0.00002216\n",
      "Epoch: [49] [  13/  40] time: 558.8406, loss: 0.00000244\n",
      "Epoch: [49] [  14/  40] time: 559.0924, loss: 0.00001120\n",
      "Epoch: [49] [  15/  40] time: 559.3453, loss: 0.00000150\n",
      "Epoch: [49] [  16/  40] time: 559.5901, loss: 0.00000267\n",
      "Epoch: [49] [  17/  40] time: 559.8539, loss: 0.00001767\n",
      "Epoch: [49] [  18/  40] time: 560.1043, loss: 0.00000102\n",
      "Epoch: [49] [  19/  40] time: 560.3500, loss: 0.00000114\n",
      "Epoch: [49] [  20/  40] time: 560.6048, loss: 0.00003762\n",
      "Epoch: [49] [  21/  40] time: 560.8507, loss: 0.00000215\n",
      "Epoch: [49] [  22/  40] time: 561.0975, loss: 0.00001160\n",
      "Epoch: [49] [  23/  40] time: 561.3424, loss: 0.00001681\n",
      "Epoch: [49] [  24/  40] time: 561.5881, loss: 0.00008344\n",
      "Epoch: [49] [  25/  40] time: 561.8385, loss: 0.00000829\n",
      "Epoch: [49] [  26/  40] time: 562.0891, loss: 0.00000708\n",
      "Epoch: [49] [  27/  40] time: 562.3335, loss: 0.00001922\n",
      "Epoch: [49] [  28/  40] time: 562.5876, loss: 0.00000136\n",
      "Epoch: [49] [  29/  40] time: 562.8365, loss: 0.00008612\n",
      "Epoch: [49] [  30/  40] time: 563.0798, loss: 0.00000117\n",
      "Epoch: [49] [  31/  40] time: 563.3361, loss: 0.00000904\n",
      "Epoch: [49] [  32/  40] time: 563.5814, loss: 0.00000344\n",
      "Epoch: [49] [  33/  40] time: 563.8264, loss: 0.00000521\n",
      "Epoch: [49] [  34/  40] time: 564.0775, loss: 0.00001032\n",
      "Epoch: [49] [  35/  40] time: 564.3225, loss: 0.00002777\n",
      "Epoch: [49] [  36/  40] time: 564.5710, loss: 0.00001842\n",
      "Epoch: [49] [  37/  40] time: 564.8255, loss: 0.00000670\n",
      "Epoch: [49] [  38/  40] time: 565.0690, loss: 0.00000428\n",
      "Epoch: [49] [  39/  40] time: 565.3193, loss: 0.00000647\n",
      "[49/50] - ptime: 10.6817 loss: 0.00001359 acc: 0.71000 lr: 0.00065610\n",
      "Epoch: [50] [   0/  40] time: 566.6921, loss: 0.00000104\n",
      "Epoch: [50] [   1/  40] time: 566.9472, loss: 0.00000030\n",
      "Epoch: [50] [   2/  40] time: 567.1913, loss: 0.00000045\n",
      "Epoch: [50] [   3/  40] time: 567.4378, loss: 0.00000575\n",
      "Epoch: [50] [   4/  40] time: 567.6841, loss: 0.00000050\n",
      "Epoch: [50] [   5/  40] time: 567.9273, loss: 0.00001486\n",
      "Epoch: [50] [   6/  40] time: 568.1777, loss: 0.00001948\n",
      "Epoch: [50] [   7/  40] time: 568.4286, loss: 0.00000140\n",
      "Epoch: [50] [   8/  40] time: 568.6736, loss: 0.00000420\n",
      "Epoch: [50] [   9/  40] time: 568.9281, loss: 0.00000274\n",
      "Epoch: [50] [  10/  40] time: 569.1782, loss: 0.00000110\n",
      "Epoch: [50] [  11/  40] time: 569.4232, loss: 0.00003223\n",
      "Epoch: [50] [  12/  40] time: 569.6819, loss: 0.00000718\n",
      "Epoch: [50] [  13/  40] time: 569.9261, loss: 0.00000354\n",
      "Epoch: [50] [  14/  40] time: 570.1703, loss: 0.00002075\n",
      "Epoch: [50] [  15/  40] time: 570.4243, loss: 0.00000085\n",
      "Epoch: [50] [  16/  40] time: 570.6692, loss: 0.00000953\n",
      "Epoch: [50] [  17/  40] time: 570.9160, loss: 0.00001566\n",
      "Epoch: [50] [  18/  40] time: 571.1631, loss: 0.00000084\n",
      "Epoch: [50] [  19/  40] time: 571.4067, loss: 0.00002901\n",
      "Epoch: [50] [  20/  40] time: 571.6584, loss: 0.00000873\n",
      "Epoch: [50] [  21/  40] time: 571.9059, loss: 0.00000158\n",
      "Epoch: [50] [  22/  40] time: 572.1502, loss: 0.00000349\n",
      "Epoch: [50] [  23/  40] time: 572.4200, loss: 0.00002931\n",
      "Epoch: [50] [  24/  40] time: 572.6646, loss: 0.00000756\n",
      "Epoch: [50] [  25/  40] time: 572.9104, loss: 0.00002581\n",
      "Epoch: [50] [  26/  40] time: 573.1696, loss: 0.00002132\n",
      "Epoch: [50] [  27/  40] time: 573.4131, loss: 0.00000165\n",
      "Epoch: [50] [  28/  40] time: 573.6581, loss: 0.00000233\n",
      "Epoch: [50] [  29/  40] time: 573.9134, loss: 0.00003332\n",
      "Epoch: [50] [  30/  40] time: 574.1529, loss: 0.00024072\n",
      "Epoch: [50] [  31/  40] time: 574.4008, loss: 0.00000133\n",
      "Epoch: [50] [  32/  40] time: 574.6469, loss: 0.00000367\n",
      "Epoch: [50] [  33/  40] time: 574.8942, loss: 0.00001614\n",
      "Epoch: [50] [  34/  40] time: 575.1439, loss: 0.00000167\n",
      "Epoch: [50] [  35/  40] time: 575.3934, loss: 0.00000168\n",
      "Epoch: [50] [  36/  40] time: 575.6380, loss: 0.00000240\n",
      "Epoch: [50] [  37/  40] time: 575.8973, loss: 0.00000297\n",
      "Epoch: [50] [  38/  40] time: 576.1406, loss: 0.00000322\n",
      "Epoch: [50] [  39/  40] time: 576.3847, loss: 0.00000252\n",
      "[50/50] - ptime: 10.6408 loss: 0.00001457 acc: 0.72000 lr: 0.00059049\n",
      "Avg per epoch ptime: 11.01, total 50 epochs ptime: 576.86\n",
      " [*] Training finished!\n",
      " [*] Best Epoch:  10 , Accuracy:  0.75\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/CNN_Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay/CNN_Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay-10\n",
      " [*] Finished testing Best Epoch: 10 , accuracy:  0.75 !\n"
     ]
    }
   ],
   "source": [
    "dataset = '4_Flowers_1s'\n",
    "epoch = 50\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "log_dir = 'logs'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    CNN = CNN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                log_dir=log_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    CNN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    CNN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    CNN.train()\n",
    "    \n",
    "#     CNN.test(epoch)\n",
    "        \n",
    "sess.close()\n",
    "        \n",
    "# lrdecay\n",
    "# [50/50] - ptime: 10.6408 loss: 0.00001457 acc: 0.72000 lr: 0.00059049\n",
    "# Avg per epoch ptime: 11.01, total 50 epochs ptime: 576.86\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  10 , Accuracy:  0.75\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay/CNN_Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay-10\n",
    "#  [*] Finished testing Best Epoch: 10 , accuracy:  0.75 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "file='/home/huiqy/Music/CloudMusic/All_Time_Low.mp3' #文件名是完整路径名\n",
    "pygame.mixer.init() #初始化音频\n",
    "track = pygame.mixer.music.load(file)#载入音乐文件\n",
    "pygame.mixer.music.play()#开始播放\n",
    "time.sleep(60)#播放10秒\n",
    "pygame.mixer.music.stop()#停止播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
