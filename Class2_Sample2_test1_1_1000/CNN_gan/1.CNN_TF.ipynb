{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "def load_flower_data():\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] handling images...\")\n",
    "    TRAIN_ORIGINAL_DIR = '../train/'\n",
    "    TRAIN_SUB_DIR = '../subsample/'\n",
    "    TRAIN_GAN = '../../image_gan/'\n",
    "    TEST_DIR = '../../test/'\n",
    "\n",
    "    # use this for full dataset\n",
    "    train_images_gan = [TRAIN_GAN + i for i in os.listdir(TRAIN_GAN)]\n",
    "    test_images = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "    \n",
    "    train_images = train_images_gan\n",
    "    \n",
    "    train_images.sort(key=natural_keys)\n",
    "    test_images.sort(key=natural_keys)\n",
    "\n",
    "    # initialize the features matrix and labels list\n",
    "    trainImage = []\n",
    "    trainLabels = []\n",
    "    testImage = []\n",
    "    testLabels = []\n",
    "\n",
    "    # loop over the input images\n",
    "    for (i, imagePath) in enumerate(train_images):\n",
    "        # extract the class label\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # read and resize image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        trainImage.append(img)\n",
    "        trainLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "            \n",
    "      # loop over the input images\n",
    "    for (i, imagePath) in enumerate(test_images):\n",
    "        # extract the class label\n",
    "        # our images were named as labels.image_number.format\n",
    "        # get the labels from the name of the images by extract the string before \".\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # extract CNN features in the image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        testImage.append(img)\n",
    "        testLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(test_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(test_images)))\n",
    "\n",
    "\n",
    "    trainImage = np.array(trainImage,dtype = float32)\n",
    "    trainLabels = np.array(trainLabels)\n",
    "    testImage = np.array(testImage,dtype = float32)\n",
    "    testLabels = np.array(testLabels)\n",
    "    print (trainImage.shape)\n",
    "    \n",
    "    trainImage = trainImage.astype(np.float32) / 255\n",
    "    testImage = testImage.astype(np.float32) / 255\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainLabels)\n",
    "    list(le.classes_)\n",
    "    trainLabels = le.transform(trainLabels) \n",
    "    testLabels = le.transform(testLabels) \n",
    "    \n",
    "    return trainImage, trainLabels, testImage, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "[INFO] processed 1000/4000\n",
      "[INFO] processed 2000/4000\n",
      "[INFO] processed 3000/4000\n",
      "[INFO] processed 4000/4000\n",
      "[INFO] processed 156/156\n",
      "(4000, 128, 128, 3)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(156, 2)\n",
      "[INFO] trainImage matrix: 768.00MB\n",
      "[INFO] trainLabels matrix: 0.0625MB\n",
      "[INFO] testImage matrix: 29.95MB\n",
      "[INFO] testLabels matrix: 0.0024MB\n"
     ]
    }
   ],
   "source": [
    "trainImage, trainLabels, testImage, testLabels = load_flower_data()\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "print (trainLabels)\n",
    "testLabels = keras.utils.to_categorical(testLabels, nb_classes)\n",
    "print (testLabels)\n",
    "print (testLabels.shape)\n",
    "\n",
    "np.save('../trainImage.npy', trainImage)\n",
    "np.save('../trainLabels.npy', trainLabels)\n",
    "np.save('../testImage.npy', testImage)\n",
    "np.save('../testLabels.npy', testLabels)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage matrix: {:.2f}MB\".format(\n",
    "    (testImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testLabels matrix: {:.4f}MB\".format(\n",
    "    (testLabels.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, log_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "        \n",
    "        # number of convolutional filters to use  \n",
    "        self.nb_CNN = [32, 64, 64, 64, 128]    \n",
    "        # number of dense filters to use  \n",
    "        self.nb_Dense = [128] \n",
    "        # size of pooling area for max pooling  \n",
    "        self.pool_size = (2, 2)  \n",
    "        # convolution kernel size  \n",
    "        self.kernel_size = (3, 3)\n",
    "        self.batch_normalization_control = True\n",
    "        \n",
    "        # train   \n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.initial_lr = 0.001 #初始学习率\n",
    "        self.decay_steps = 10\n",
    "        self.decay_rate = 0.9\n",
    "        self.lr = tf.train.exponential_decay( self.initial_lr,\n",
    "                                     global_step=self.global_step,\n",
    "                                     decay_steps=self.decay_steps,\n",
    "                                     decay_rate=self.decay_rate)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # name for checkpoint\n",
    "        self.model_name = 'CNN_C%d_D%d_Kernel(%d,%d)_%d_lrdecay0.0001' % (len(self.nb_CNN), len(self.nb_Dense),\n",
    "                                                          self.kernel_size[0], self.kernel_size[1], max(self.nb_CNN))    \n",
    "        \n",
    "        # test\n",
    "\n",
    "        #load_flower_data\n",
    "        self.train_x = np.load('../trainImage.npy')\n",
    "        self.train_y= np.load('../trainLabels.npy')\n",
    "        self.test_x = np.load('../testImage.npy')\n",
    "        self.test_y= np.load('../testLabels.npy')\n",
    "        \n",
    "        print (\"Training:\",self.train_x.shape[0])\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['losses'] = []\n",
    "        self.train_hist['accuracy'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches_train = len(self.train_x) // self.batch_size\n",
    "        self.num_batches_test= len(self.test_x) // self.batch_size\n",
    "\n",
    "    def cnn_model(self, x, keep_prob, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"cnn\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            B = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"CNN:x\",x.get_shape()) # 128, 128, 3 \n",
    "\n",
    "            #输入,卷积核为3*3 输出维度为32\n",
    "            net = tf.layers.conv2d(inputs = x,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "\n",
    "            if self.batch_normalization_control:\n",
    "                net = tf.layers.batch_normalization(net, training=is_training)\n",
    "            net = tf.nn.relu(net, name = 'relu_conv_1')\n",
    "            net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                          pool_size = self.pool_size,\n",
    "                                          strides = (2, 2),\n",
    "                                          padding='same',\n",
    "                                          name='pool_conv_' + str(1)\n",
    "                                         )\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            for i in range(2,len(self.nb_CNN)+1):\n",
    "                net = tf.layers.conv2d(inputs = net,                 # 输入,\n",
    "                                       filters = self.nb_CNN[i-1],      # 卷积核个数,\n",
    "                                       kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                       strides = (1, 1),\n",
    "                                       padding = 'same',              # padding方法\n",
    "                                       kernel_initializer = W,\n",
    "                                       bias_initializer = B,\n",
    "                                       kernel_regularizer = None,\n",
    "                                       bias_regularizer = None,\n",
    "                                       activity_regularizer = None,\n",
    "                                       name = 'conv_'+ str(i)        # 命名用于获取变量\n",
    "                                       )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "                if self.batch_normalization_control:\n",
    "                    net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_conv_' + str(i))\n",
    "                net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_' + str(i)\n",
    "                                             )\n",
    "\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "\n",
    "            #flatten\n",
    "            net = tf.reshape(net, [-1, int(net.get_shape()[1]*net.get_shape()[2]*net.get_shape()[3])],name='flatten')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #dense layer\n",
    "            for i in range(1,len(self.nb_Dense)+1):\n",
    "                net = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_Dense[i-1],\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_' + str(i)\n",
    "                                    )\n",
    "#                 net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_dense_' + str(i))\n",
    "                net = tf.layers.dropout(inputs = net,\n",
    "                                        rate=keep_prob,\n",
    "                                        noise_shape=None,\n",
    "                                        seed=None,\n",
    "                                        training = is_training,\n",
    "                                        name= 'dropout_dense_' + str(i)\n",
    "                                        )\n",
    "            #output\n",
    "            logit = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_class,\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_output'\n",
    "                                    )\n",
    "            out_logit = tf.nn.softmax(logit, name=\"softmax\")\n",
    "            print(\"CNN:out_logit\",out_logit.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out_logit, logit\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.c_dim], \n",
    "                                name='x_image')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[self.batch_size, self.nb_class], name='y_label')\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of cnn_model\n",
    "        self.out_logit, self.logit = self.cnn_model(self.x, self.keep_prob, is_training=True, reuse=False)\n",
    "        \n",
    "        self.loss_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,\n",
    "                                                                                         logits =self.logit))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        cnn_vars = [var for var in tf_vars if var.name.startswith('cnn')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.cnn_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.loss_cross_entropy,\n",
    "                                                                                        var_list=cnn_vars)\n",
    "            \n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        # output of cnn_model\n",
    "        self.out_logit_test, self.logit_test = self.cnn_model(self.x, self.keep_prob, is_training=False, reuse=True)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logit_test, 1), tf.argmax(self.y, 1))\n",
    "        self.predict = tf.argmax(self.logit_test, 1)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        self.loss_sum = tf.summary.scalar(\"loss\", self.loss_cross_entropy)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep = self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name+'_train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            CNN_losses = []\n",
    "  \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.train_x.shape[0]), self.train_x.shape[0])\n",
    "            shuffled_set = self.train_x[shuffle_idxs]\n",
    "            shuffled_label = self.train_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches_train):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, cnn_loss = self.sess.run([self.cnn_optim, self.loss_sum, self.loss_cross_entropy],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.y: batch_y,\n",
    "                                                          self.keep_prob: 0.5}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                CNN_losses.append(cnn_loss)\n",
    "\n",
    "                # display training status            \n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" % (epoch_loop, idx, \n",
    "                                                                                    self.num_batches_train, \n",
    "                                                                          time.time() - start_time, cnn_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            # Evaluates accuracy on test set\n",
    "            test_accuracy_list = []\n",
    "            for idx_test in range(self.num_batches_test):\n",
    "                rand_index = np.random.choice(len(self.train_x), size=batch_size)\n",
    "                batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                   self.y: batch_y_tes,\n",
    "                                                                   self.keep_prob: 1.0})\n",
    "                test_accuracy_list.append(accuracy)\n",
    "            test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "            \n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "                \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss: %.8f acc: %.5f lr: %.8f'% (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                    np.mean(CNN_losses), test_accuracy, rate))\n",
    "            self.train_hist['losses'].append(np.mean(CNN_losses))\n",
    "            self.train_hist['accuracy'].append(test_accuracy)\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "            \n",
    "            # save trainhist for train\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name + '_train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' \n",
    "                                 + self.model_name + '_train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "    \n",
    "        \"\"\"test after train\"\"\"\n",
    "        best_acc = max(self.train_hist['accuracy'])\n",
    "        beat_epoch = self.train_hist['accuracy'].index(best_acc) + 1\n",
    "        print (\" [*] Best Epoch: \", beat_epoch, \", Accuracy: \", best_acc)\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(beat_epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                               self.y: batch_y_tes,\n",
    "                                                               self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Best Epoch:\", beat_epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def test(self, epoch):\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                               self.y: batch_y_tes,\n",
    "                                                               self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Epoch:\", epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True) \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['losses'])+1)\n",
    "\n",
    "        y1 = hist['losses']\n",
    "        y2 = hist['accuracy']\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "                            \n",
    "        ax2 = ax1.twinx()  \n",
    "\n",
    "        ax1.plot(x, y1, 'b')\n",
    "        ax2.plot(x, y2, 'r')\n",
    "                            \n",
    "        ax1.set_xlabel('Epoch')\n",
    "                            \n",
    "        ax1.set_ylabel('CNN_loss')    \n",
    "        ax2.set_ylabel('accuracy')\n",
    "                          \n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 4000\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 64, 64, 32)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 64, 64, 32)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "cnn/conv_1/kernel:0 (float32_ref 3x3x3x32) [864, bytes: 3456]\n",
      "cnn/conv_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_2/kernel:0 (float32_ref 3x3x32x64) [18432, bytes: 73728]\n",
      "cnn/conv_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_3/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_3/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_4/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_5/kernel:0 (float32_ref 3x3x64x128) [73728, bytes: 294912]\n",
      "cnn/conv_5/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_1/kernel:0 (float32_ref 2048x128) [262144, bytes: 1048576]\n",
      "cnn/dense_1/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_output/kernel:0 (float32_ref 128x2) [256, bytes: 1024]\n",
      "cnn/dense_output/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 430338\n",
      "Total bytes of variables: 1721352\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 1] [   0/  40] time: 2.4102, loss: 0.67457521\n",
      "Epoch: [ 1] [   1/  40] time: 2.5607, loss: 0.52623576\n",
      "Epoch: [ 1] [   2/  40] time: 2.7175, loss: 0.28088766\n",
      "Epoch: [ 1] [   3/  40] time: 2.8687, loss: 0.26489919\n",
      "Epoch: [ 1] [   4/  40] time: 3.0293, loss: 0.12883414\n",
      "Epoch: [ 1] [   5/  40] time: 3.1848, loss: 0.17188384\n",
      "Epoch: [ 1] [   6/  40] time: 3.3423, loss: 0.11666642\n",
      "Epoch: [ 1] [   7/  40] time: 3.4909, loss: 0.20423512\n",
      "Epoch: [ 1] [   8/  40] time: 3.6458, loss: 0.06597812\n",
      "Epoch: [ 1] [   9/  40] time: 3.7948, loss: 0.23083398\n",
      "Epoch: [ 1] [  10/  40] time: 3.9477, loss: 0.12523043\n",
      "Epoch: [ 1] [  11/  40] time: 4.0990, loss: 0.08308793\n",
      "Epoch: [ 1] [  12/  40] time: 4.2527, loss: 0.08764858\n",
      "Epoch: [ 1] [  13/  40] time: 4.4027, loss: 0.05167756\n",
      "Epoch: [ 1] [  14/  40] time: 4.5582, loss: 0.06746431\n",
      "Epoch: [ 1] [  15/  40] time: 4.7069, loss: 0.05788181\n",
      "Epoch: [ 1] [  16/  40] time: 4.8612, loss: 0.06538890\n",
      "Epoch: [ 1] [  17/  40] time: 5.0125, loss: 0.03162529\n",
      "Epoch: [ 1] [  18/  40] time: 5.1703, loss: 0.15503863\n",
      "Epoch: [ 1] [  19/  40] time: 5.3258, loss: 0.18003002\n",
      "Epoch: [ 1] [  20/  40] time: 5.4840, loss: 0.07413516\n",
      "Epoch: [ 1] [  21/  40] time: 5.6396, loss: 0.16748433\n",
      "Epoch: [ 1] [  22/  40] time: 5.7942, loss: 0.12417895\n",
      "Epoch: [ 1] [  23/  40] time: 5.9425, loss: 0.16445175\n",
      "Epoch: [ 1] [  24/  40] time: 6.1019, loss: 0.07542626\n",
      "Epoch: [ 1] [  25/  40] time: 6.2702, loss: 0.08683446\n",
      "Epoch: [ 1] [  26/  40] time: 6.4374, loss: 0.03333740\n",
      "Epoch: [ 1] [  27/  40] time: 6.6034, loss: 0.03785783\n",
      "Epoch: [ 1] [  28/  40] time: 6.7766, loss: 0.04155523\n",
      "Epoch: [ 1] [  29/  40] time: 6.9431, loss: 0.02548155\n",
      "Epoch: [ 1] [  30/  40] time: 7.1061, loss: 0.06148827\n",
      "Epoch: [ 1] [  31/  40] time: 7.2755, loss: 0.09147100\n",
      "Epoch: [ 1] [  32/  40] time: 7.4560, loss: 0.14983100\n",
      "Epoch: [ 1] [  33/  40] time: 7.6098, loss: 0.06754102\n",
      "Epoch: [ 1] [  34/  40] time: 7.7738, loss: 0.06617418\n",
      "Epoch: [ 1] [  35/  40] time: 7.9218, loss: 0.11679485\n",
      "Epoch: [ 1] [  36/  40] time: 8.0795, loss: 0.04022538\n",
      "Epoch: [ 1] [  37/  40] time: 8.2340, loss: 0.05579297\n",
      "Epoch: [ 1] [  38/  40] time: 8.3936, loss: 0.05883673\n",
      "Epoch: [ 1] [  39/  40] time: 8.5526, loss: 0.03404314\n",
      "[1/50] - ptime: 8.6219 loss: 0.12857611 acc: 0.78000 lr: 0.00100000\n",
      "Epoch: [ 2] [   0/  40] time: 10.1176, loss: 0.04608561\n",
      "Epoch: [ 2] [   1/  40] time: 10.2660, loss: 0.04478595\n",
      "Epoch: [ 2] [   2/  40] time: 10.4195, loss: 0.03363502\n",
      "Epoch: [ 2] [   3/  40] time: 10.5686, loss: 0.04873699\n",
      "Epoch: [ 2] [   4/  40] time: 10.7295, loss: 0.08268648\n",
      "Epoch: [ 2] [   5/  40] time: 10.8810, loss: 0.05939200\n",
      "Epoch: [ 2] [   6/  40] time: 11.0399, loss: 0.07359742\n",
      "Epoch: [ 2] [   7/  40] time: 11.1960, loss: 0.06773622\n",
      "Epoch: [ 2] [   8/  40] time: 11.3610, loss: 0.05725913\n",
      "Epoch: [ 2] [   9/  40] time: 11.5190, loss: 0.03311471\n",
      "Epoch: [ 2] [  10/  40] time: 11.6766, loss: 0.06285548\n",
      "Epoch: [ 2] [  11/  40] time: 11.8341, loss: 0.01530017\n",
      "Epoch: [ 2] [  12/  40] time: 11.9911, loss: 0.01992013\n",
      "Epoch: [ 2] [  13/  40] time: 12.1437, loss: 0.05111600\n",
      "Epoch: [ 2] [  14/  40] time: 12.2980, loss: 0.00815013\n",
      "Epoch: [ 2] [  15/  40] time: 12.4560, loss: 0.11734641\n",
      "Epoch: [ 2] [  16/  40] time: 12.6131, loss: 0.04279675\n",
      "Epoch: [ 2] [  17/  40] time: 12.7704, loss: 0.06691668\n",
      "Epoch: [ 2] [  18/  40] time: 12.9387, loss: 0.03166885\n",
      "Epoch: [ 2] [  19/  40] time: 13.1040, loss: 0.03996855\n",
      "Epoch: [ 2] [  20/  40] time: 13.2630, loss: 0.02433475\n",
      "Epoch: [ 2] [  21/  40] time: 13.4273, loss: 0.02279349\n",
      "Epoch: [ 2] [  22/  40] time: 13.5936, loss: 0.03282034\n",
      "Epoch: [ 2] [  23/  40] time: 13.7431, loss: 0.05336529\n",
      "Epoch: [ 2] [  24/  40] time: 13.9001, loss: 0.05981660\n",
      "Epoch: [ 2] [  25/  40] time: 14.0533, loss: 0.03764023\n",
      "Epoch: [ 2] [  26/  40] time: 14.2117, loss: 0.09053311\n",
      "Epoch: [ 2] [  27/  40] time: 14.3643, loss: 0.09246833\n",
      "Epoch: [ 2] [  28/  40] time: 14.5184, loss: 0.02448341\n",
      "Epoch: [ 2] [  29/  40] time: 14.6779, loss: 0.05523859\n",
      "Epoch: [ 2] [  30/  40] time: 14.8348, loss: 0.04356226\n",
      "Epoch: [ 2] [  31/  40] time: 14.9846, loss: 0.01398189\n",
      "Epoch: [ 2] [  32/  40] time: 15.1420, loss: 0.02070825\n",
      "Epoch: [ 2] [  33/  40] time: 15.2918, loss: 0.01521759\n",
      "Epoch: [ 2] [  34/  40] time: 15.4455, loss: 0.05898615\n",
      "Epoch: [ 2] [  35/  40] time: 15.6187, loss: 0.03755815\n",
      "Epoch: [ 2] [  36/  40] time: 15.7848, loss: 0.07399882\n",
      "Epoch: [ 2] [  37/  40] time: 15.9348, loss: 0.07807271\n",
      "Epoch: [ 2] [  38/  40] time: 16.0924, loss: 0.03456797\n",
      "Epoch: [ 2] [  39/  40] time: 16.2417, loss: 0.04915710\n",
      "[2/50] - ptime: 6.8518 loss: 0.04805934 acc: 0.22000 lr: 0.00097915\n",
      "Epoch: [ 3] [   0/  40] time: 17.6058, loss: 0.06894781\n",
      "Epoch: [ 3] [   1/  40] time: 17.7631, loss: 0.14384207\n",
      "Epoch: [ 3] [   2/  40] time: 17.9350, loss: 0.02183429\n",
      "Epoch: [ 3] [   3/  40] time: 18.0862, loss: 0.01794216\n",
      "Epoch: [ 3] [   4/  40] time: 18.2405, loss: 0.02479139\n",
      "Epoch: [ 3] [   5/  40] time: 18.3932, loss: 0.07044559\n",
      "Epoch: [ 3] [   6/  40] time: 18.5509, loss: 0.06453218\n",
      "Epoch: [ 3] [   7/  40] time: 18.6994, loss: 0.05056431\n",
      "Epoch: [ 3] [   8/  40] time: 18.8571, loss: 0.09314292\n",
      "Epoch: [ 3] [   9/  40] time: 19.0068, loss: 0.01068731\n",
      "Epoch: [ 3] [  10/  40] time: 19.1630, loss: 0.01692523\n",
      "Epoch: [ 3] [  11/  40] time: 19.3119, loss: 0.02749511\n",
      "Epoch: [ 3] [  12/  40] time: 19.4653, loss: 0.06758732\n",
      "Epoch: [ 3] [  13/  40] time: 19.6147, loss: 0.04395024\n",
      "Epoch: [ 3] [  14/  40] time: 19.7677, loss: 0.03677973\n",
      "Epoch: [ 3] [  15/  40] time: 19.9162, loss: 0.01748180\n",
      "Epoch: [ 3] [  16/  40] time: 20.0749, loss: 0.04524287\n",
      "Epoch: [ 3] [  17/  40] time: 20.2223, loss: 0.02744275\n",
      "Epoch: [ 3] [  18/  40] time: 20.3764, loss: 0.00626842\n",
      "Epoch: [ 3] [  19/  40] time: 20.5297, loss: 0.03205732\n",
      "Epoch: [ 3] [  20/  40] time: 20.6838, loss: 0.01136496\n",
      "Epoch: [ 3] [  21/  40] time: 20.8403, loss: 0.04816173\n",
      "Epoch: [ 3] [  22/  40] time: 21.0000, loss: 0.04648480\n",
      "Epoch: [ 3] [  23/  40] time: 21.1549, loss: 0.07360307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 3] [  24/  40] time: 21.3074, loss: 0.01306694\n",
      "Epoch: [ 3] [  25/  40] time: 21.4600, loss: 0.04628280\n",
      "Epoch: [ 3] [  26/  40] time: 21.6160, loss: 0.08928043\n",
      "Epoch: [ 3] [  27/  40] time: 21.7662, loss: 0.02223783\n",
      "Epoch: [ 3] [  28/  40] time: 21.9235, loss: 0.01548863\n",
      "Epoch: [ 3] [  29/  40] time: 22.0744, loss: 0.07101583\n",
      "Epoch: [ 3] [  30/  40] time: 22.2346, loss: 0.04035655\n",
      "Epoch: [ 3] [  31/  40] time: 22.3928, loss: 0.04896369\n",
      "Epoch: [ 3] [  32/  40] time: 22.5502, loss: 0.03580499\n",
      "Epoch: [ 3] [  33/  40] time: 22.7007, loss: 0.07067007\n",
      "Epoch: [ 3] [  34/  40] time: 22.8567, loss: 0.02408116\n",
      "Epoch: [ 3] [  35/  40] time: 23.0219, loss: 0.02092214\n",
      "Epoch: [ 3] [  36/  40] time: 23.1936, loss: 0.04215020\n",
      "Epoch: [ 3] [  37/  40] time: 23.3527, loss: 0.00890536\n",
      "Epoch: [ 3] [  38/  40] time: 23.5248, loss: 0.05136000\n",
      "Epoch: [ 3] [  39/  40] time: 23.6766, loss: 0.09859882\n",
      "[3/50] - ptime: 6.7926 loss: 0.04416902 acc: 0.34000 lr: 0.00097915\n",
      "Epoch: [ 4] [   0/  40] time: 25.0118, loss: 0.04038604\n",
      "Epoch: [ 4] [   1/  40] time: 25.1595, loss: 0.07379352\n",
      "Epoch: [ 4] [   2/  40] time: 25.3120, loss: 0.07939645\n",
      "Epoch: [ 4] [   3/  40] time: 25.4668, loss: 0.03494479\n",
      "Epoch: [ 4] [   4/  40] time: 25.6253, loss: 0.02705199\n",
      "Epoch: [ 4] [   5/  40] time: 25.7787, loss: 0.01831113\n",
      "Epoch: [ 4] [   6/  40] time: 25.9379, loss: 0.01351103\n",
      "Epoch: [ 4] [   7/  40] time: 26.0946, loss: 0.03439143\n",
      "Epoch: [ 4] [   8/  40] time: 26.2580, loss: 0.01301512\n",
      "Epoch: [ 4] [   9/  40] time: 26.4125, loss: 0.02154984\n",
      "Epoch: [ 4] [  10/  40] time: 26.5857, loss: 0.06730152\n",
      "Epoch: [ 4] [  11/  40] time: 26.7365, loss: 0.01300618\n",
      "Epoch: [ 4] [  12/  40] time: 26.8955, loss: 0.06581587\n",
      "Epoch: [ 4] [  13/  40] time: 27.0481, loss: 0.04019133\n",
      "Epoch: [ 4] [  14/  40] time: 27.2016, loss: 0.03824847\n",
      "Epoch: [ 4] [  15/  40] time: 27.3629, loss: 0.03092636\n",
      "Epoch: [ 4] [  16/  40] time: 27.5281, loss: 0.00975273\n",
      "Epoch: [ 4] [  17/  40] time: 27.6905, loss: 0.04367090\n",
      "Epoch: [ 4] [  18/  40] time: 27.8557, loss: 0.02606858\n",
      "Epoch: [ 4] [  19/  40] time: 28.0108, loss: 0.07114506\n",
      "Epoch: [ 4] [  20/  40] time: 28.1893, loss: 0.00739360\n",
      "Epoch: [ 4] [  21/  40] time: 28.3398, loss: 0.09352877\n",
      "Epoch: [ 4] [  22/  40] time: 28.4937, loss: 0.00900397\n",
      "Epoch: [ 4] [  23/  40] time: 28.6454, loss: 0.01658272\n",
      "Epoch: [ 4] [  24/  40] time: 28.8010, loss: 0.12503955\n",
      "Epoch: [ 4] [  25/  40] time: 28.9546, loss: 0.00771877\n",
      "Epoch: [ 4] [  26/  40] time: 29.1235, loss: 0.02238485\n",
      "Epoch: [ 4] [  27/  40] time: 29.2730, loss: 0.01459356\n",
      "Epoch: [ 4] [  28/  40] time: 29.4277, loss: 0.01568891\n",
      "Epoch: [ 4] [  29/  40] time: 29.5783, loss: 0.02110665\n",
      "Epoch: [ 4] [  30/  40] time: 29.7325, loss: 0.00688975\n",
      "Epoch: [ 4] [  31/  40] time: 29.8864, loss: 0.01033915\n",
      "Epoch: [ 4] [  32/  40] time: 30.0578, loss: 0.01696632\n",
      "Epoch: [ 4] [  33/  40] time: 30.2098, loss: 0.03019577\n",
      "Epoch: [ 4] [  34/  40] time: 30.3637, loss: 0.02460480\n",
      "Epoch: [ 4] [  35/  40] time: 30.5178, loss: 0.10012519\n",
      "Epoch: [ 4] [  36/  40] time: 30.6789, loss: 0.05603629\n",
      "Epoch: [ 4] [  37/  40] time: 30.8463, loss: 0.04526453\n",
      "Epoch: [ 4] [  38/  40] time: 31.0077, loss: 0.03027879\n",
      "Epoch: [ 4] [  39/  40] time: 31.1659, loss: 0.06010575\n",
      "[4/50] - ptime: 6.8899 loss: 0.03690815 acc: 0.35000 lr: 0.00095873\n",
      "Epoch: [ 5] [   0/  40] time: 32.6881, loss: 0.01382118\n",
      "Epoch: [ 5] [   1/  40] time: 32.8409, loss: 0.02682099\n",
      "Epoch: [ 5] [   2/  40] time: 32.9959, loss: 0.01460413\n",
      "Epoch: [ 5] [   3/  40] time: 33.1443, loss: 0.00488350\n",
      "Epoch: [ 5] [   4/  40] time: 33.3031, loss: 0.00648790\n",
      "Epoch: [ 5] [   5/  40] time: 33.4595, loss: 0.02704814\n",
      "Epoch: [ 5] [   6/  40] time: 33.6211, loss: 0.01208556\n",
      "Epoch: [ 5] [   7/  40] time: 33.7757, loss: 0.02725525\n",
      "Epoch: [ 5] [   8/  40] time: 33.9508, loss: 0.00247107\n",
      "Epoch: [ 5] [   9/  40] time: 34.1020, loss: 0.02380945\n",
      "Epoch: [ 5] [  10/  40] time: 34.2600, loss: 0.00659555\n",
      "Epoch: [ 5] [  11/  40] time: 34.4111, loss: 0.00330857\n",
      "Epoch: [ 5] [  12/  40] time: 34.5643, loss: 0.03814522\n",
      "Epoch: [ 5] [  13/  40] time: 34.7134, loss: 0.01445094\n",
      "Epoch: [ 5] [  14/  40] time: 34.8716, loss: 0.02825931\n",
      "Epoch: [ 5] [  15/  40] time: 35.0327, loss: 0.01731689\n",
      "Epoch: [ 5] [  16/  40] time: 35.1939, loss: 0.01494322\n",
      "Epoch: [ 5] [  17/  40] time: 35.3501, loss: 0.00952574\n",
      "Epoch: [ 5] [  18/  40] time: 35.5108, loss: 0.02777153\n",
      "Epoch: [ 5] [  19/  40] time: 35.6660, loss: 0.02721235\n",
      "Epoch: [ 5] [  20/  40] time: 35.8351, loss: 0.00432142\n",
      "Epoch: [ 5] [  21/  40] time: 35.9969, loss: 0.00839832\n",
      "Epoch: [ 5] [  22/  40] time: 36.1689, loss: 0.01580009\n",
      "Epoch: [ 5] [  23/  40] time: 36.3197, loss: 0.02115960\n",
      "Epoch: [ 5] [  24/  40] time: 36.4753, loss: 0.00711279\n",
      "Epoch: [ 5] [  25/  40] time: 36.6229, loss: 0.00158378\n",
      "Epoch: [ 5] [  26/  40] time: 36.7847, loss: 0.01454082\n",
      "Epoch: [ 5] [  27/  40] time: 36.9357, loss: 0.00297924\n",
      "Epoch: [ 5] [  28/  40] time: 37.0992, loss: 0.00799671\n",
      "Epoch: [ 5] [  29/  40] time: 37.2505, loss: 0.02484004\n",
      "Epoch: [ 5] [  30/  40] time: 37.4091, loss: 0.03577705\n",
      "Epoch: [ 5] [  31/  40] time: 37.5622, loss: 0.00901129\n",
      "Epoch: [ 5] [  32/  40] time: 37.7193, loss: 0.04937425\n",
      "Epoch: [ 5] [  33/  40] time: 37.8703, loss: 0.04421170\n",
      "Epoch: [ 5] [  34/  40] time: 38.0249, loss: 0.10840248\n",
      "Epoch: [ 5] [  35/  40] time: 38.1749, loss: 0.00427078\n",
      "Epoch: [ 5] [  36/  40] time: 38.3289, loss: 0.01791990\n",
      "Epoch: [ 5] [  37/  40] time: 38.4789, loss: 0.02852749\n",
      "Epoch: [ 5] [  38/  40] time: 38.6332, loss: 0.01921295\n",
      "Epoch: [ 5] [  39/  40] time: 38.7853, loss: 0.00844531\n",
      "[5/50] - ptime: 6.8537 loss: 0.01951756 acc: 0.22000 lr: 0.00094868\n",
      "Epoch: [ 6] [   0/  40] time: 40.2901, loss: 0.04211758\n",
      "Epoch: [ 6] [   1/  40] time: 40.4370, loss: 0.01724496\n",
      "Epoch: [ 6] [   2/  40] time: 40.5896, loss: 0.01101591\n",
      "Epoch: [ 6] [   3/  40] time: 40.7440, loss: 0.01903341\n",
      "Epoch: [ 6] [   4/  40] time: 40.9116, loss: 0.01558747\n",
      "Epoch: [ 6] [   5/  40] time: 41.0661, loss: 0.02036565\n",
      "Epoch: [ 6] [   6/  40] time: 41.2267, loss: 0.02477784\n",
      "Epoch: [ 6] [   7/  40] time: 41.3770, loss: 0.01252678\n",
      "Epoch: [ 6] [   8/  40] time: 41.5360, loss: 0.00112462\n",
      "Epoch: [ 6] [   9/  40] time: 41.6848, loss: 0.05120346\n",
      "Epoch: [ 6] [  10/  40] time: 41.8469, loss: 0.02469725\n",
      "Epoch: [ 6] [  11/  40] time: 42.0001, loss: 0.02159278\n",
      "Epoch: [ 6] [  12/  40] time: 42.1649, loss: 0.00822904\n",
      "Epoch: [ 6] [  13/  40] time: 42.3134, loss: 0.00155279\n",
      "Epoch: [ 6] [  14/  40] time: 42.4678, loss: 0.01904633\n",
      "Epoch: [ 6] [  15/  40] time: 42.6171, loss: 0.00515020\n",
      "Epoch: [ 6] [  16/  40] time: 42.7769, loss: 0.00314159\n",
      "Epoch: [ 6] [  17/  40] time: 42.9287, loss: 0.03715443\n",
      "Epoch: [ 6] [  18/  40] time: 43.0826, loss: 0.00612877\n",
      "Epoch: [ 6] [  19/  40] time: 43.2308, loss: 0.01235624\n",
      "Epoch: [ 6] [  20/  40] time: 43.3842, loss: 0.01583600\n",
      "Epoch: [ 6] [  21/  40] time: 43.5388, loss: 0.00558988\n",
      "Epoch: [ 6] [  22/  40] time: 43.7031, loss: 0.00833833\n",
      "Epoch: [ 6] [  23/  40] time: 43.8550, loss: 0.00263829\n",
      "Epoch: [ 6] [  24/  40] time: 44.0136, loss: 0.00642730\n",
      "Epoch: [ 6] [  25/  40] time: 44.1691, loss: 0.02458608\n",
      "Epoch: [ 6] [  26/  40] time: 44.3281, loss: 0.00507810\n",
      "Epoch: [ 6] [  27/  40] time: 44.4818, loss: 0.00362315\n",
      "Epoch: [ 6] [  28/  40] time: 44.6363, loss: 0.00560242\n",
      "Epoch: [ 6] [  29/  40] time: 44.7858, loss: 0.00426438\n",
      "Epoch: [ 6] [  30/  40] time: 44.9425, loss: 0.02673988\n",
      "Epoch: [ 6] [  31/  40] time: 45.0927, loss: 0.00789769\n",
      "Epoch: [ 6] [  32/  40] time: 45.2454, loss: 0.00533309\n",
      "Epoch: [ 6] [  33/  40] time: 45.3932, loss: 0.02110094\n",
      "Epoch: [ 6] [  34/  40] time: 45.5456, loss: 0.00577816\n",
      "Epoch: [ 6] [  35/  40] time: 45.7056, loss: 0.00273920\n",
      "Epoch: [ 6] [  36/  40] time: 45.8603, loss: 0.03192313\n",
      "Epoch: [ 6] [  37/  40] time: 46.0142, loss: 0.03771301\n",
      "Epoch: [ 6] [  38/  40] time: 46.1729, loss: 0.01209670\n",
      "Epoch: [ 6] [  39/  40] time: 46.3225, loss: 0.00755908\n",
      "[6/50] - ptime: 6.7775 loss: 0.01487280 acc: 0.22000 lr: 0.00094868\n",
      "Epoch: [ 7] [   0/  40] time: 47.8741, loss: 0.00303793\n",
      "Epoch: [ 7] [   1/  40] time: 48.0254, loss: 0.02698273\n",
      "Epoch: [ 7] [   2/  40] time: 48.1889, loss: 0.00337261\n",
      "Epoch: [ 7] [   3/  40] time: 48.3431, loss: 0.01073530\n",
      "Epoch: [ 7] [   4/  40] time: 48.5017, loss: 0.05881359\n",
      "Epoch: [ 7] [   5/  40] time: 48.6821, loss: 0.12488295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 7] [   6/  40] time: 48.8461, loss: 0.02749561\n",
      "Epoch: [ 7] [   7/  40] time: 49.0226, loss: 0.00771043\n",
      "Epoch: [ 7] [   8/  40] time: 49.1935, loss: 0.00511702\n",
      "Epoch: [ 7] [   9/  40] time: 49.3561, loss: 0.02916348\n",
      "Epoch: [ 7] [  10/  40] time: 49.5146, loss: 0.02427277\n",
      "Epoch: [ 7] [  11/  40] time: 49.6629, loss: 0.02715941\n",
      "Epoch: [ 7] [  12/  40] time: 49.8186, loss: 0.01034558\n",
      "Epoch: [ 7] [  13/  40] time: 49.9897, loss: 0.02394614\n",
      "Epoch: [ 7] [  14/  40] time: 50.1509, loss: 0.00583769\n",
      "Epoch: [ 7] [  15/  40] time: 50.3072, loss: 0.01051149\n",
      "Epoch: [ 7] [  16/  40] time: 50.4627, loss: 0.00554628\n",
      "Epoch: [ 7] [  17/  40] time: 50.6180, loss: 0.01552878\n",
      "Epoch: [ 7] [  18/  40] time: 50.7729, loss: 0.01388592\n",
      "Epoch: [ 7] [  19/  40] time: 50.9295, loss: 0.02111232\n",
      "Epoch: [ 7] [  20/  40] time: 51.0861, loss: 0.00161551\n",
      "Epoch: [ 7] [  21/  40] time: 51.2409, loss: 0.00062732\n",
      "Epoch: [ 7] [  22/  40] time: 51.4052, loss: 0.00115230\n",
      "Epoch: [ 7] [  23/  40] time: 51.5608, loss: 0.01583889\n",
      "Epoch: [ 7] [  24/  40] time: 51.7195, loss: 0.00144930\n",
      "Epoch: [ 7] [  25/  40] time: 51.8837, loss: 0.00837356\n",
      "Epoch: [ 7] [  26/  40] time: 52.0494, loss: 0.00084032\n",
      "Epoch: [ 7] [  27/  40] time: 52.1980, loss: 0.00256062\n",
      "Epoch: [ 7] [  28/  40] time: 52.3514, loss: 0.00104018\n",
      "Epoch: [ 7] [  29/  40] time: 52.5114, loss: 0.01349107\n",
      "Epoch: [ 7] [  30/  40] time: 52.6758, loss: 0.00534380\n",
      "Epoch: [ 7] [  31/  40] time: 52.8297, loss: 0.00294531\n",
      "Epoch: [ 7] [  32/  40] time: 52.9908, loss: 0.00513239\n",
      "Epoch: [ 7] [  33/  40] time: 53.1621, loss: 0.03047420\n",
      "Epoch: [ 7] [  34/  40] time: 53.3315, loss: 0.02192211\n",
      "Epoch: [ 7] [  35/  40] time: 53.4998, loss: 0.02585346\n",
      "Epoch: [ 7] [  36/  40] time: 53.6624, loss: 0.01534744\n",
      "Epoch: [ 7] [  37/  40] time: 53.8232, loss: 0.01299758\n",
      "Epoch: [ 7] [  38/  40] time: 53.9861, loss: 0.00265459\n",
      "Epoch: [ 7] [  39/  40] time: 54.1518, loss: 0.00535807\n",
      "[7/50] - ptime: 7.0125 loss: 0.01576190 acc: 0.58000 lr: 0.00092890\n",
      "Epoch: [ 8] [   0/  40] time: 55.5249, loss: 0.00364483\n",
      "Epoch: [ 8] [   1/  40] time: 55.6741, loss: 0.00203759\n",
      "Epoch: [ 8] [   2/  40] time: 55.8361, loss: 0.00087225\n",
      "Epoch: [ 8] [   3/  40] time: 55.9899, loss: 0.04712436\n",
      "Epoch: [ 8] [   4/  40] time: 56.1550, loss: 0.01408024\n",
      "Epoch: [ 8] [   5/  40] time: 56.3040, loss: 0.04199980\n",
      "Epoch: [ 8] [   6/  40] time: 56.4602, loss: 0.00304752\n",
      "Epoch: [ 8] [   7/  40] time: 56.6143, loss: 0.01314095\n",
      "Epoch: [ 8] [   8/  40] time: 56.7682, loss: 0.00291214\n",
      "Epoch: [ 8] [   9/  40] time: 56.9187, loss: 0.00938139\n",
      "Epoch: [ 8] [  10/  40] time: 57.0781, loss: 0.04179325\n",
      "Epoch: [ 8] [  11/  40] time: 57.2270, loss: 0.01313055\n",
      "Epoch: [ 8] [  12/  40] time: 57.3841, loss: 0.03382764\n",
      "Epoch: [ 8] [  13/  40] time: 57.5326, loss: 0.02375888\n",
      "Epoch: [ 8] [  14/  40] time: 57.6872, loss: 0.00212963\n",
      "Epoch: [ 8] [  15/  40] time: 57.8360, loss: 0.01254495\n",
      "Epoch: [ 8] [  16/  40] time: 58.0125, loss: 0.01668925\n",
      "Epoch: [ 8] [  17/  40] time: 58.1687, loss: 0.00775619\n",
      "Epoch: [ 8] [  18/  40] time: 58.3372, loss: 0.00947193\n",
      "Epoch: [ 8] [  19/  40] time: 58.4877, loss: 0.00080505\n",
      "Epoch: [ 8] [  20/  40] time: 58.6414, loss: 0.00251882\n",
      "Epoch: [ 8] [  21/  40] time: 58.7913, loss: 0.01866425\n",
      "Epoch: [ 8] [  22/  40] time: 58.9465, loss: 0.01364267\n",
      "Epoch: [ 8] [  23/  40] time: 59.0965, loss: 0.01556220\n",
      "Epoch: [ 8] [  24/  40] time: 59.2520, loss: 0.00378360\n",
      "Epoch: [ 8] [  25/  40] time: 59.4002, loss: 0.01884800\n",
      "Epoch: [ 8] [  26/  40] time: 59.5564, loss: 0.00572967\n",
      "Epoch: [ 8] [  27/  40] time: 59.7039, loss: 0.00271746\n",
      "Epoch: [ 8] [  28/  40] time: 59.8643, loss: 0.00314207\n",
      "Epoch: [ 8] [  29/  40] time: 60.0161, loss: 0.00518648\n",
      "Epoch: [ 8] [  30/  40] time: 60.1698, loss: 0.00385176\n",
      "Epoch: [ 8] [  31/  40] time: 60.3185, loss: 0.00828039\n",
      "Epoch: [ 8] [  32/  40] time: 60.4737, loss: 0.00335112\n",
      "Epoch: [ 8] [  33/  40] time: 60.6245, loss: 0.00310030\n",
      "Epoch: [ 8] [  34/  40] time: 60.7852, loss: 0.00842239\n",
      "Epoch: [ 8] [  35/  40] time: 60.9436, loss: 0.00262685\n",
      "Epoch: [ 8] [  36/  40] time: 61.1078, loss: 0.00080242\n",
      "Epoch: [ 8] [  37/  40] time: 61.2684, loss: 0.01699635\n",
      "Epoch: [ 8] [  38/  40] time: 61.4340, loss: 0.02368457\n",
      "Epoch: [ 8] [  39/  40] time: 61.5937, loss: 0.00141233\n",
      "[8/50] - ptime: 6.8228 loss: 0.01156180 acc: 0.31000 lr: 0.00092890\n",
      "Epoch: [ 9] [   0/  40] time: 62.9404, loss: 0.00890320\n",
      "Epoch: [ 9] [   1/  40] time: 63.0894, loss: 0.00795620\n",
      "Epoch: [ 9] [   2/  40] time: 63.2431, loss: 0.00310053\n",
      "Epoch: [ 9] [   3/  40] time: 63.3985, loss: 0.00337994\n",
      "Epoch: [ 9] [   4/  40] time: 63.5762, loss: 0.00754380\n",
      "Epoch: [ 9] [   5/  40] time: 63.7386, loss: 0.00552815\n",
      "Epoch: [ 9] [   6/  40] time: 63.9029, loss: 0.00095571\n",
      "Epoch: [ 9] [   7/  40] time: 64.0586, loss: 0.00030793\n",
      "Epoch: [ 9] [   8/  40] time: 64.2202, loss: 0.03541222\n",
      "Epoch: [ 9] [   9/  40] time: 64.3690, loss: 0.00735526\n",
      "Epoch: [ 9] [  10/  40] time: 64.5296, loss: 0.00009068\n",
      "Epoch: [ 9] [  11/  40] time: 64.6896, loss: 0.01875053\n",
      "Epoch: [ 9] [  12/  40] time: 64.8500, loss: 0.00688603\n",
      "Epoch: [ 9] [  13/  40] time: 65.0044, loss: 0.00259549\n",
      "Epoch: [ 9] [  14/  40] time: 65.1887, loss: 0.00158278\n",
      "Epoch: [ 9] [  15/  40] time: 65.3393, loss: 0.00835528\n",
      "Epoch: [ 9] [  16/  40] time: 65.4943, loss: 0.00158417\n",
      "Epoch: [ 9] [  17/  40] time: 65.6431, loss: 0.00790571\n",
      "Epoch: [ 9] [  18/  40] time: 65.7967, loss: 0.00120776\n",
      "Epoch: [ 9] [  19/  40] time: 65.9470, loss: 0.00103977\n",
      "Epoch: [ 9] [  20/  40] time: 66.1158, loss: 0.00091156\n",
      "Epoch: [ 9] [  21/  40] time: 66.2706, loss: 0.00052163\n",
      "Epoch: [ 9] [  22/  40] time: 66.4292, loss: 0.02167449\n",
      "Epoch: [ 9] [  23/  40] time: 66.5788, loss: 0.00058744\n",
      "Epoch: [ 9] [  24/  40] time: 66.7353, loss: 0.00415089\n",
      "Epoch: [ 9] [  25/  40] time: 66.8945, loss: 0.09820853\n",
      "Epoch: [ 9] [  26/  40] time: 67.0525, loss: 0.00097619\n",
      "Epoch: [ 9] [  27/  40] time: 67.2049, loss: 0.00408701\n",
      "Epoch: [ 9] [  28/  40] time: 67.3701, loss: 0.02824717\n",
      "Epoch: [ 9] [  29/  40] time: 67.5237, loss: 0.00614876\n",
      "Epoch: [ 9] [  30/  40] time: 67.6800, loss: 0.00978968\n",
      "Epoch: [ 9] [  31/  40] time: 67.8311, loss: 0.00209339\n",
      "Epoch: [ 9] [  32/  40] time: 67.9864, loss: 0.02115387\n",
      "Epoch: [ 9] [  33/  40] time: 68.1406, loss: 0.01838198\n",
      "Epoch: [ 9] [  34/  40] time: 68.3010, loss: 0.00229244\n",
      "Epoch: [ 9] [  35/  40] time: 68.4508, loss: 0.03179486\n",
      "Epoch: [ 9] [  36/  40] time: 68.6066, loss: 0.01458654\n",
      "Epoch: [ 9] [  37/  40] time: 68.7557, loss: 0.00518175\n",
      "Epoch: [ 9] [  38/  40] time: 68.9186, loss: 0.03103389\n",
      "Epoch: [ 9] [  39/  40] time: 69.0738, loss: 0.09141187\n",
      "[9/50] - ptime: 6.8788 loss: 0.01309188 acc: 0.70000 lr: 0.00090953\n",
      "Epoch: [10] [   0/  40] time: 70.4735, loss: 0.06902415\n",
      "Epoch: [10] [   1/  40] time: 70.6236, loss: 0.00539064\n",
      "Epoch: [10] [   2/  40] time: 70.7895, loss: 0.01750986\n",
      "Epoch: [10] [   3/  40] time: 70.9389, loss: 0.01033796\n",
      "Epoch: [10] [   4/  40] time: 71.0923, loss: 0.10886276\n",
      "Epoch: [10] [   5/  40] time: 71.2403, loss: 0.00451677\n",
      "Epoch: [10] [   6/  40] time: 71.3941, loss: 0.01438560\n",
      "Epoch: [10] [   7/  40] time: 71.5420, loss: 0.00386451\n",
      "Epoch: [10] [   8/  40] time: 71.6962, loss: 0.00455794\n",
      "Epoch: [10] [   9/  40] time: 71.8463, loss: 0.00385119\n",
      "Epoch: [10] [  10/  40] time: 72.0030, loss: 0.01445397\n",
      "Epoch: [10] [  11/  40] time: 72.1798, loss: 0.00952854\n",
      "Epoch: [10] [  12/  40] time: 72.3372, loss: 0.09076532\n",
      "Epoch: [10] [  13/  40] time: 72.4910, loss: 0.00878932\n",
      "Epoch: [10] [  14/  40] time: 72.6655, loss: 0.05726311\n",
      "Epoch: [10] [  15/  40] time: 72.8230, loss: 0.03297133\n",
      "Epoch: [10] [  16/  40] time: 72.9840, loss: 0.01203813\n",
      "Epoch: [10] [  17/  40] time: 73.1340, loss: 0.01090147\n",
      "Epoch: [10] [  18/  40] time: 73.2890, loss: 0.00654386\n",
      "Epoch: [10] [  19/  40] time: 73.4462, loss: 0.06323474\n",
      "Epoch: [10] [  20/  40] time: 73.6144, loss: 0.01699021\n",
      "Epoch: [10] [  21/  40] time: 73.7680, loss: 0.00352029\n",
      "Epoch: [10] [  22/  40] time: 73.9284, loss: 0.02291244\n",
      "Epoch: [10] [  23/  40] time: 74.0852, loss: 0.03502052\n",
      "Epoch: [10] [  24/  40] time: 74.2488, loss: 0.08419359\n",
      "Epoch: [10] [  25/  40] time: 74.3980, loss: 0.03849103\n",
      "Epoch: [10] [  26/  40] time: 74.5610, loss: 0.00378252\n",
      "Epoch: [10] [  27/  40] time: 74.7181, loss: 0.11279054\n",
      "Epoch: [10] [  28/  40] time: 74.8906, loss: 0.01411709\n",
      "Epoch: [10] [  29/  40] time: 75.0507, loss: 0.08648708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10] [  30/  40] time: 75.2108, loss: 0.00860490\n",
      "Epoch: [10] [  31/  40] time: 75.3591, loss: 0.02214683\n",
      "Epoch: [10] [  32/  40] time: 75.5153, loss: 0.11415183\n",
      "Epoch: [10] [  33/  40] time: 75.6640, loss: 0.02901106\n",
      "Epoch: [10] [  34/  40] time: 75.8364, loss: 0.04108270\n",
      "Epoch: [10] [  35/  40] time: 75.9881, loss: 0.04647996\n",
      "Epoch: [10] [  36/  40] time: 76.1486, loss: 0.01326089\n",
      "Epoch: [10] [  37/  40] time: 76.2981, loss: 0.00674068\n",
      "Epoch: [10] [  38/  40] time: 76.4531, loss: 0.02375529\n",
      "Epoch: [10] [  39/  40] time: 76.6039, loss: 0.02278785\n",
      "[10/50] - ptime: 6.9144 loss: 0.03237797 acc: 0.60000 lr: 0.00090000\n",
      "Epoch: [11] [   0/  40] time: 77.9900, loss: 0.01676849\n",
      "Epoch: [11] [   1/  40] time: 78.1380, loss: 0.00887931\n",
      "Epoch: [11] [   2/  40] time: 78.2921, loss: 0.00597395\n",
      "Epoch: [11] [   3/  40] time: 78.4444, loss: 0.01290505\n",
      "Epoch: [11] [   4/  40] time: 78.6014, loss: 0.00592418\n",
      "Epoch: [11] [   5/  40] time: 78.7538, loss: 0.00909751\n",
      "Epoch: [11] [   6/  40] time: 78.9101, loss: 0.01786168\n",
      "Epoch: [11] [   7/  40] time: 79.0673, loss: 0.01455672\n",
      "Epoch: [11] [   8/  40] time: 79.2234, loss: 0.00903626\n",
      "Epoch: [11] [   9/  40] time: 79.3716, loss: 0.00496902\n",
      "Epoch: [11] [  10/  40] time: 79.5224, loss: 0.03390460\n",
      "Epoch: [11] [  11/  40] time: 79.6692, loss: 0.00881169\n",
      "Epoch: [11] [  12/  40] time: 79.8238, loss: 0.00063873\n",
      "Epoch: [11] [  13/  40] time: 79.9761, loss: 0.02632141\n",
      "Epoch: [11] [  14/  40] time: 80.1350, loss: 0.01344552\n",
      "Epoch: [11] [  15/  40] time: 80.2841, loss: 0.00500069\n",
      "Epoch: [11] [  16/  40] time: 80.4382, loss: 0.00302950\n",
      "Epoch: [11] [  17/  40] time: 80.5963, loss: 0.00403397\n",
      "Epoch: [11] [  18/  40] time: 80.7545, loss: 0.00995005\n",
      "Epoch: [11] [  19/  40] time: 80.9038, loss: 0.00252744\n",
      "Epoch: [11] [  20/  40] time: 81.0645, loss: 0.00362491\n",
      "Epoch: [11] [  21/  40] time: 81.2125, loss: 0.00165627\n",
      "Epoch: [11] [  22/  40] time: 81.3684, loss: 0.00685563\n",
      "Epoch: [11] [  23/  40] time: 81.5256, loss: 0.01078590\n",
      "Epoch: [11] [  24/  40] time: 81.6843, loss: 0.00039230\n",
      "Epoch: [11] [  25/  40] time: 81.8384, loss: 0.00169400\n",
      "Epoch: [11] [  26/  40] time: 81.9996, loss: 0.01039453\n",
      "Epoch: [11] [  27/  40] time: 82.1593, loss: 0.03546812\n",
      "Epoch: [11] [  28/  40] time: 82.3309, loss: 0.00800651\n",
      "Epoch: [11] [  29/  40] time: 82.4862, loss: 0.02212613\n",
      "Epoch: [11] [  30/  40] time: 82.6494, loss: 0.00704461\n",
      "Epoch: [11] [  31/  40] time: 82.8118, loss: 0.00254242\n",
      "Epoch: [11] [  32/  40] time: 82.9682, loss: 0.05309852\n",
      "Epoch: [11] [  33/  40] time: 83.1191, loss: 0.04890992\n",
      "Epoch: [11] [  34/  40] time: 83.2760, loss: 0.00566308\n",
      "Epoch: [11] [  35/  40] time: 83.4282, loss: 0.00139625\n",
      "Epoch: [11] [  36/  40] time: 83.5839, loss: 0.00434464\n",
      "Epoch: [11] [  37/  40] time: 83.7332, loss: 0.00663896\n",
      "Epoch: [11] [  38/  40] time: 83.8886, loss: 0.00031058\n",
      "Epoch: [11] [  39/  40] time: 84.0429, loss: 0.00192522\n",
      "[11/50] - ptime: 6.8285 loss: 0.01116286 acc: 0.65000 lr: 0.00090000\n",
      "Epoch: [12] [   0/  40] time: 85.4501, loss: 0.00362638\n",
      "Epoch: [12] [   1/  40] time: 85.5986, loss: 0.00129981\n",
      "Epoch: [12] [   2/  40] time: 85.7585, loss: 0.06466212\n",
      "Epoch: [12] [   3/  40] time: 85.9090, loss: 0.00251520\n",
      "Epoch: [12] [   4/  40] time: 86.0694, loss: 0.00372936\n",
      "Epoch: [12] [   5/  40] time: 86.2222, loss: 0.05652966\n",
      "Epoch: [12] [   6/  40] time: 86.3963, loss: 0.02019809\n",
      "Epoch: [12] [   7/  40] time: 86.5456, loss: 0.01237539\n",
      "Epoch: [12] [   8/  40] time: 86.7017, loss: 0.01117314\n",
      "Epoch: [12] [   9/  40] time: 86.8539, loss: 0.00163545\n",
      "Epoch: [12] [  10/  40] time: 87.0107, loss: 0.01212981\n",
      "Epoch: [12] [  11/  40] time: 87.1657, loss: 0.05772172\n",
      "Epoch: [12] [  12/  40] time: 87.3235, loss: 0.00334220\n",
      "Epoch: [12] [  13/  40] time: 87.4753, loss: 0.02053078\n",
      "Epoch: [12] [  14/  40] time: 87.6337, loss: 0.03329000\n",
      "Epoch: [12] [  15/  40] time: 87.7931, loss: 0.00148377\n",
      "Epoch: [12] [  16/  40] time: 87.9588, loss: 0.00395311\n",
      "Epoch: [12] [  17/  40] time: 88.1165, loss: 0.03314418\n",
      "Epoch: [12] [  18/  40] time: 88.2820, loss: 0.00238009\n",
      "Epoch: [12] [  19/  40] time: 88.4391, loss: 0.02970763\n",
      "Epoch: [12] [  20/  40] time: 88.6153, loss: 0.00174382\n",
      "Epoch: [12] [  21/  40] time: 88.7724, loss: 0.00096467\n",
      "Epoch: [12] [  22/  40] time: 88.9290, loss: 0.00183986\n",
      "Epoch: [12] [  23/  40] time: 89.0803, loss: 0.00163930\n",
      "Epoch: [12] [  24/  40] time: 89.2353, loss: 0.00108853\n",
      "Epoch: [12] [  25/  40] time: 89.3859, loss: 0.00602485\n",
      "Epoch: [12] [  26/  40] time: 89.5551, loss: 0.00640870\n",
      "Epoch: [12] [  27/  40] time: 89.7057, loss: 0.01105881\n",
      "Epoch: [12] [  28/  40] time: 89.8607, loss: 0.01045660\n",
      "Epoch: [12] [  29/  40] time: 90.0124, loss: 0.01778461\n",
      "Epoch: [12] [  30/  40] time: 90.1677, loss: 0.00143192\n",
      "Epoch: [12] [  31/  40] time: 90.3170, loss: 0.00323746\n",
      "Epoch: [12] [  32/  40] time: 90.4681, loss: 0.00010608\n",
      "Epoch: [12] [  33/  40] time: 90.6161, loss: 0.00138749\n",
      "Epoch: [12] [  34/  40] time: 90.7771, loss: 0.00477671\n",
      "Epoch: [12] [  35/  40] time: 90.9354, loss: 0.06812454\n",
      "Epoch: [12] [  36/  40] time: 91.0995, loss: 0.00506439\n",
      "Epoch: [12] [  37/  40] time: 91.2600, loss: 0.01136092\n",
      "Epoch: [12] [  38/  40] time: 91.4326, loss: 0.00119209\n",
      "Epoch: [12] [  39/  40] time: 91.5892, loss: 0.01188188\n",
      "[12/50] - ptime: 6.9094 loss: 0.01357503 acc: 0.52000 lr: 0.00088123\n",
      "Epoch: [13] [   0/  40] time: 92.9611, loss: 0.00349104\n",
      "Epoch: [13] [   1/  40] time: 93.1103, loss: 0.03679616\n",
      "Epoch: [13] [   2/  40] time: 93.2659, loss: 0.00555699\n",
      "Epoch: [13] [   3/  40] time: 93.4139, loss: 0.05610904\n",
      "Epoch: [13] [   4/  40] time: 93.5673, loss: 0.01378542\n",
      "Epoch: [13] [   5/  40] time: 93.7144, loss: 0.00760380\n",
      "Epoch: [13] [   6/  40] time: 93.8721, loss: 0.02491630\n",
      "Epoch: [13] [   7/  40] time: 94.0325, loss: 0.00672073\n",
      "Epoch: [13] [   8/  40] time: 94.1934, loss: 0.01237562\n",
      "Epoch: [13] [   9/  40] time: 94.3453, loss: 0.02411394\n",
      "Epoch: [13] [  10/  40] time: 94.5004, loss: 0.00425468\n",
      "Epoch: [13] [  11/  40] time: 94.6559, loss: 0.01226301\n",
      "Epoch: [13] [  12/  40] time: 94.8191, loss: 0.00047007\n",
      "Epoch: [13] [  13/  40] time: 94.9806, loss: 0.10892207\n",
      "Epoch: [13] [  14/  40] time: 95.1398, loss: 0.00144616\n",
      "Epoch: [13] [  15/  40] time: 95.2924, loss: 0.01316578\n",
      "Epoch: [13] [  16/  40] time: 95.4459, loss: 0.00051376\n",
      "Epoch: [13] [  17/  40] time: 95.6020, loss: 0.00116306\n",
      "Epoch: [13] [  18/  40] time: 95.7594, loss: 0.00663289\n",
      "Epoch: [13] [  19/  40] time: 95.9073, loss: 0.00061629\n",
      "Epoch: [13] [  20/  40] time: 96.0638, loss: 0.00152642\n",
      "Epoch: [13] [  21/  40] time: 96.2140, loss: 0.00039251\n",
      "Epoch: [13] [  22/  40] time: 96.3705, loss: 0.03809866\n",
      "Epoch: [13] [  23/  40] time: 96.5203, loss: 0.00037719\n",
      "Epoch: [13] [  24/  40] time: 96.6777, loss: 0.00159935\n",
      "Epoch: [13] [  25/  40] time: 96.8269, loss: 0.07923646\n",
      "Epoch: [13] [  26/  40] time: 96.9825, loss: 0.00458220\n",
      "Epoch: [13] [  27/  40] time: 97.1379, loss: 0.01087491\n",
      "Epoch: [13] [  28/  40] time: 97.3075, loss: 0.00138597\n",
      "Epoch: [13] [  29/  40] time: 97.4652, loss: 0.00718106\n",
      "Epoch: [13] [  30/  40] time: 97.6275, loss: 0.00016907\n",
      "Epoch: [13] [  31/  40] time: 97.7795, loss: 0.02614171\n",
      "Epoch: [13] [  32/  40] time: 97.9434, loss: 0.01856829\n",
      "Epoch: [13] [  33/  40] time: 98.0991, loss: 0.00753134\n",
      "Epoch: [13] [  34/  40] time: 98.2558, loss: 0.00341423\n",
      "Epoch: [13] [  35/  40] time: 98.4057, loss: 0.00276230\n",
      "Epoch: [13] [  36/  40] time: 98.5602, loss: 0.01414779\n",
      "Epoch: [13] [  37/  40] time: 98.7105, loss: 0.00472515\n",
      "Epoch: [13] [  38/  40] time: 98.8686, loss: 0.04334307\n",
      "Epoch: [13] [  39/  40] time: 99.0273, loss: 0.02890504\n",
      "[13/50] - ptime: 6.8286 loss: 0.01589699 acc: 0.59000 lr: 0.00087200\n",
      "Epoch: [14] [   0/  40] time: 100.5642, loss: 0.00442705\n",
      "Epoch: [14] [   1/  40] time: 100.7209, loss: 0.03642176\n",
      "Epoch: [14] [   2/  40] time: 100.8843, loss: 0.00146020\n",
      "Epoch: [14] [   3/  40] time: 101.0374, loss: 0.00004143\n",
      "Epoch: [14] [   4/  40] time: 101.1934, loss: 0.00036445\n",
      "Epoch: [14] [   5/  40] time: 101.3423, loss: 0.00081437\n",
      "Epoch: [14] [   6/  40] time: 101.4970, loss: 0.00524469\n",
      "Epoch: [14] [   7/  40] time: 101.6466, loss: 0.02630418\n",
      "Epoch: [14] [   8/  40] time: 101.8089, loss: 0.01852866\n",
      "Epoch: [14] [   9/  40] time: 101.9649, loss: 0.07013457\n",
      "Epoch: [14] [  10/  40] time: 102.1220, loss: 0.00374553\n",
      "Epoch: [14] [  11/  40] time: 102.2722, loss: 0.00105742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14] [  12/  40] time: 102.4266, loss: 0.05144624\n",
      "Epoch: [14] [  13/  40] time: 102.5823, loss: 0.00152056\n",
      "Epoch: [14] [  14/  40] time: 102.7514, loss: 0.00043089\n",
      "Epoch: [14] [  15/  40] time: 102.9049, loss: 0.00872677\n",
      "Epoch: [14] [  16/  40] time: 103.0702, loss: 0.00043393\n",
      "Epoch: [14] [  17/  40] time: 103.2204, loss: 0.00139476\n",
      "Epoch: [14] [  18/  40] time: 103.3774, loss: 0.01200331\n",
      "Epoch: [14] [  19/  40] time: 103.5302, loss: 0.00171811\n",
      "Epoch: [14] [  20/  40] time: 103.6868, loss: 0.00331893\n",
      "Epoch: [14] [  21/  40] time: 103.8484, loss: 0.00826681\n",
      "Epoch: [14] [  22/  40] time: 104.0196, loss: 0.00097071\n",
      "Epoch: [14] [  23/  40] time: 104.1762, loss: 0.00219566\n",
      "Epoch: [14] [  24/  40] time: 104.3388, loss: 0.00089363\n",
      "Epoch: [14] [  25/  40] time: 104.4898, loss: 0.00564110\n",
      "Epoch: [14] [  26/  40] time: 104.6462, loss: 0.00622439\n",
      "Epoch: [14] [  27/  40] time: 104.7951, loss: 0.00205146\n",
      "Epoch: [14] [  28/  40] time: 104.9596, loss: 0.00108913\n",
      "Epoch: [14] [  29/  40] time: 105.1097, loss: 0.00637575\n",
      "Epoch: [14] [  30/  40] time: 105.2648, loss: 0.00151700\n",
      "Epoch: [14] [  31/  40] time: 105.4167, loss: 0.00171497\n",
      "Epoch: [14] [  32/  40] time: 105.5730, loss: 0.01072686\n",
      "Epoch: [14] [  33/  40] time: 105.7231, loss: 0.00642700\n",
      "Epoch: [14] [  34/  40] time: 105.8812, loss: 0.01318126\n",
      "Epoch: [14] [  35/  40] time: 106.0369, loss: 0.00127033\n",
      "Epoch: [14] [  36/  40] time: 106.2132, loss: 0.00081378\n",
      "Epoch: [14] [  37/  40] time: 106.3614, loss: 0.01299048\n",
      "Epoch: [14] [  38/  40] time: 106.5161, loss: 0.00094724\n",
      "Epoch: [14] [  39/  40] time: 106.6704, loss: 0.00102500\n",
      "[14/50] - ptime: 6.8871 loss: 0.00834651 acc: 0.70000 lr: 0.00086286\n",
      "Epoch: [15] [   0/  40] time: 107.9978, loss: 0.00016704\n",
      "Epoch: [15] [   1/  40] time: 108.1451, loss: 0.00019484\n",
      "Epoch: [15] [   2/  40] time: 108.3014, loss: 0.00580599\n",
      "Epoch: [15] [   3/  40] time: 108.4519, loss: 0.00040387\n",
      "Epoch: [15] [   4/  40] time: 108.6092, loss: 0.00106196\n",
      "Epoch: [15] [   5/  40] time: 108.7659, loss: 0.00207579\n",
      "Epoch: [15] [   6/  40] time: 108.9269, loss: 0.00073198\n",
      "Epoch: [15] [   7/  40] time: 109.0771, loss: 0.00128060\n",
      "Epoch: [15] [   8/  40] time: 109.2354, loss: 0.00511452\n",
      "Epoch: [15] [   9/  40] time: 109.3840, loss: 0.00276914\n",
      "Epoch: [15] [  10/  40] time: 109.5389, loss: 0.00091921\n",
      "Epoch: [15] [  11/  40] time: 109.6934, loss: 0.00055548\n",
      "Epoch: [15] [  12/  40] time: 109.8528, loss: 0.00003747\n",
      "Epoch: [15] [  13/  40] time: 110.0145, loss: 0.00243325\n",
      "Epoch: [15] [  14/  40] time: 110.1777, loss: 0.00003657\n",
      "Epoch: [15] [  15/  40] time: 110.3259, loss: 0.00016648\n",
      "Epoch: [15] [  16/  40] time: 110.4866, loss: 0.00002448\n",
      "Epoch: [15] [  17/  40] time: 110.6381, loss: 0.00094712\n",
      "Epoch: [15] [  18/  40] time: 110.7948, loss: 0.00042626\n",
      "Epoch: [15] [  19/  40] time: 110.9498, loss: 0.00040824\n",
      "Epoch: [15] [  20/  40] time: 111.1110, loss: 0.02550998\n",
      "Epoch: [15] [  21/  40] time: 111.2762, loss: 0.00003532\n",
      "Epoch: [15] [  22/  40] time: 111.4375, loss: 0.00226730\n",
      "Epoch: [15] [  23/  40] time: 111.5882, loss: 0.00020643\n",
      "Epoch: [15] [  24/  40] time: 111.7526, loss: 0.01338966\n",
      "Epoch: [15] [  25/  40] time: 111.9110, loss: 0.00296256\n",
      "Epoch: [15] [  26/  40] time: 112.0753, loss: 0.00144162\n",
      "Epoch: [15] [  27/  40] time: 112.2332, loss: 0.00151854\n",
      "Epoch: [15] [  28/  40] time: 112.3962, loss: 0.04052749\n",
      "Epoch: [15] [  29/  40] time: 112.5503, loss: 0.00530578\n",
      "Epoch: [15] [  30/  40] time: 112.7114, loss: 0.00079957\n",
      "Epoch: [15] [  31/  40] time: 112.8596, loss: 0.00151973\n",
      "Epoch: [15] [  32/  40] time: 113.0233, loss: 0.01509556\n",
      "Epoch: [15] [  33/  40] time: 113.1725, loss: 0.00195255\n",
      "Epoch: [15] [  34/  40] time: 113.3271, loss: 0.00306504\n",
      "Epoch: [15] [  35/  40] time: 113.4781, loss: 0.00091160\n",
      "Epoch: [15] [  36/  40] time: 113.6380, loss: 0.00258078\n",
      "Epoch: [15] [  37/  40] time: 113.7997, loss: 0.00099570\n",
      "Epoch: [15] [  38/  40] time: 113.9629, loss: 0.00382574\n",
      "Epoch: [15] [  39/  40] time: 114.1294, loss: 0.00052431\n",
      "[15/50] - ptime: 6.8472 loss: 0.00374989 acc: 0.75000 lr: 0.00085381\n",
      "Epoch: [16] [   0/  40] time: 115.6015, loss: 0.00010007\n",
      "Epoch: [16] [   1/  40] time: 115.7505, loss: 0.00008591\n",
      "Epoch: [16] [   2/  40] time: 115.9157, loss: 0.00108422\n",
      "Epoch: [16] [   3/  40] time: 116.0692, loss: 0.00099272\n",
      "Epoch: [16] [   4/  40] time: 116.2313, loss: 0.00025555\n",
      "Epoch: [16] [   5/  40] time: 116.3911, loss: 0.00018502\n",
      "Epoch: [16] [   6/  40] time: 116.5572, loss: 0.00485641\n",
      "Epoch: [16] [   7/  40] time: 116.7067, loss: 0.00049974\n",
      "Epoch: [16] [   8/  40] time: 116.8868, loss: 0.00012996\n",
      "Epoch: [16] [   9/  40] time: 117.0506, loss: 0.00036840\n",
      "Epoch: [16] [  10/  40] time: 117.2224, loss: 0.01046851\n",
      "Epoch: [16] [  11/  40] time: 117.3838, loss: 0.00128427\n",
      "Epoch: [16] [  12/  40] time: 117.5627, loss: 0.00011980\n",
      "Epoch: [16] [  13/  40] time: 117.7293, loss: 0.00116590\n",
      "Epoch: [16] [  14/  40] time: 117.9025, loss: 0.00011960\n",
      "Epoch: [16] [  15/  40] time: 118.0646, loss: 0.00032092\n",
      "Epoch: [16] [  16/  40] time: 118.2221, loss: 0.00349079\n",
      "Epoch: [16] [  17/  40] time: 118.3948, loss: 0.00021697\n",
      "Epoch: [16] [  18/  40] time: 118.5668, loss: 0.00103636\n",
      "Epoch: [16] [  19/  40] time: 118.7325, loss: 0.00054321\n",
      "Epoch: [16] [  20/  40] time: 118.9034, loss: 0.00584160\n",
      "Epoch: [16] [  21/  40] time: 119.0672, loss: 0.00028872\n",
      "Epoch: [16] [  22/  40] time: 119.2279, loss: 0.00047614\n",
      "Epoch: [16] [  23/  40] time: 119.3933, loss: 0.00008968\n",
      "Epoch: [16] [  24/  40] time: 119.5599, loss: 0.00062814\n",
      "Epoch: [16] [  25/  40] time: 119.7169, loss: 0.00163287\n",
      "Epoch: [16] [  26/  40] time: 119.8807, loss: 0.00005626\n",
      "Epoch: [16] [  27/  40] time: 120.0322, loss: 0.00305586\n",
      "Epoch: [16] [  28/  40] time: 120.1874, loss: 0.00110282\n",
      "Epoch: [16] [  29/  40] time: 120.3388, loss: 0.00007786\n",
      "Epoch: [16] [  30/  40] time: 120.4930, loss: 0.00043607\n",
      "Epoch: [16] [  31/  40] time: 120.6578, loss: 0.00028802\n",
      "Epoch: [16] [  32/  40] time: 120.8194, loss: 0.00109222\n",
      "Epoch: [16] [  33/  40] time: 120.9873, loss: 0.00127700\n",
      "Epoch: [16] [  34/  40] time: 121.1509, loss: 0.00000451\n",
      "Epoch: [16] [  35/  40] time: 121.3051, loss: 0.00039034\n",
      "Epoch: [16] [  36/  40] time: 121.4618, loss: 0.00211696\n",
      "Epoch: [16] [  37/  40] time: 121.6233, loss: 0.00029356\n",
      "Epoch: [16] [  38/  40] time: 121.7967, loss: 0.00064868\n",
      "Epoch: [16] [  39/  40] time: 121.9626, loss: 0.00012700\n",
      "[16/50] - ptime: 7.1578 loss: 0.00118122 acc: 0.67000 lr: 0.00084487\n",
      "Epoch: [17] [   0/  40] time: 123.5149, loss: 0.00009985\n",
      "Epoch: [17] [   1/  40] time: 123.6649, loss: 0.00018403\n",
      "Epoch: [17] [   2/  40] time: 123.8294, loss: 0.00034675\n",
      "Epoch: [17] [   3/  40] time: 123.9869, loss: 0.00026266\n",
      "Epoch: [17] [   4/  40] time: 124.1501, loss: 0.00003360\n",
      "Epoch: [17] [   5/  40] time: 124.3175, loss: 0.00035361\n",
      "Epoch: [17] [   6/  40] time: 124.4844, loss: 0.00020295\n",
      "Epoch: [17] [   7/  40] time: 124.6342, loss: 0.00095308\n",
      "Epoch: [17] [   8/  40] time: 124.7880, loss: 0.00011147\n",
      "Epoch: [17] [   9/  40] time: 124.9373, loss: 0.00011387\n",
      "Epoch: [17] [  10/  40] time: 125.0979, loss: 0.00004381\n",
      "Epoch: [17] [  11/  40] time: 125.2474, loss: 0.00001471\n",
      "Epoch: [17] [  12/  40] time: 125.4034, loss: 0.00100344\n",
      "Epoch: [17] [  13/  40] time: 125.5535, loss: 0.00001164\n",
      "Epoch: [17] [  14/  40] time: 125.7094, loss: 0.00096030\n",
      "Epoch: [17] [  15/  40] time: 125.8708, loss: 0.00018782\n",
      "Epoch: [17] [  16/  40] time: 126.0429, loss: 0.00036685\n",
      "Epoch: [17] [  17/  40] time: 126.2094, loss: 0.00396782\n",
      "Epoch: [17] [  18/  40] time: 126.3857, loss: 0.00005440\n",
      "Epoch: [17] [  19/  40] time: 126.5501, loss: 0.00022761\n",
      "Epoch: [17] [  20/  40] time: 126.7145, loss: 0.00008978\n",
      "Epoch: [17] [  21/  40] time: 126.8798, loss: 0.00018545\n",
      "Epoch: [17] [  22/  40] time: 127.0436, loss: 0.00001265\n",
      "Epoch: [17] [  23/  40] time: 127.2036, loss: 0.00101060\n",
      "Epoch: [17] [  24/  40] time: 127.3762, loss: 0.00026190\n",
      "Epoch: [17] [  25/  40] time: 127.5438, loss: 0.00034603\n",
      "Epoch: [17] [  26/  40] time: 127.7079, loss: 0.00016293\n",
      "Epoch: [17] [  27/  40] time: 127.8658, loss: 0.00000361\n",
      "Epoch: [17] [  28/  40] time: 128.0334, loss: 0.00153688\n",
      "Epoch: [17] [  29/  40] time: 128.1908, loss: 0.00010315\n",
      "Epoch: [17] [  30/  40] time: 128.3648, loss: 0.00488512\n",
      "Epoch: [17] [  31/  40] time: 128.5322, loss: 0.00005258\n",
      "Epoch: [17] [  32/  40] time: 128.7213, loss: 0.00015346\n",
      "Epoch: [17] [  33/  40] time: 128.8975, loss: 0.00262113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17] [  34/  40] time: 129.0651, loss: 0.02520321\n",
      "Epoch: [17] [  35/  40] time: 129.2343, loss: 0.00005423\n",
      "Epoch: [17] [  36/  40] time: 129.3930, loss: 0.00725176\n",
      "Epoch: [17] [  37/  40] time: 129.5565, loss: 0.00038392\n",
      "Epoch: [17] [  38/  40] time: 129.7312, loss: 0.00028239\n",
      "Epoch: [17] [  39/  40] time: 129.8926, loss: 0.00069637\n",
      "[17/50] - ptime: 7.2688 loss: 0.00136994 acc: 0.69000 lr: 0.00083601\n",
      "Epoch: [18] [   0/  40] time: 131.3774, loss: 0.00015300\n",
      "Epoch: [18] [   1/  40] time: 131.5469, loss: 0.00345018\n",
      "Epoch: [18] [   2/  40] time: 131.7051, loss: 0.00004518\n",
      "Epoch: [18] [   3/  40] time: 131.8523, loss: 0.03366098\n",
      "Epoch: [18] [   4/  40] time: 132.0109, loss: 0.00004177\n",
      "Epoch: [18] [   5/  40] time: 132.1849, loss: 0.00138130\n",
      "Epoch: [18] [   6/  40] time: 132.3487, loss: 0.07285471\n",
      "Epoch: [18] [   7/  40] time: 132.5131, loss: 0.04407995\n",
      "Epoch: [18] [   8/  40] time: 132.6862, loss: 0.04356524\n",
      "Epoch: [18] [   9/  40] time: 132.8567, loss: 0.08055649\n",
      "Epoch: [18] [  10/  40] time: 133.0228, loss: 0.03429490\n",
      "Epoch: [18] [  11/  40] time: 133.1909, loss: 0.04157363\n",
      "Epoch: [18] [  12/  40] time: 133.3549, loss: 0.01964419\n",
      "Epoch: [18] [  13/  40] time: 133.5110, loss: 0.01429155\n",
      "Epoch: [18] [  14/  40] time: 133.6784, loss: 0.02754337\n",
      "Epoch: [18] [  15/  40] time: 133.8430, loss: 0.00872778\n",
      "Epoch: [18] [  16/  40] time: 134.0079, loss: 0.00848126\n",
      "Epoch: [18] [  17/  40] time: 134.1816, loss: 0.00350142\n",
      "Epoch: [18] [  18/  40] time: 134.3477, loss: 0.01126828\n",
      "Epoch: [18] [  19/  40] time: 134.5052, loss: 0.01783053\n",
      "Epoch: [18] [  20/  40] time: 134.6687, loss: 0.00848332\n",
      "Epoch: [18] [  21/  40] time: 134.8174, loss: 0.00024790\n",
      "Epoch: [18] [  22/  40] time: 134.9734, loss: 0.02026436\n",
      "Epoch: [18] [  23/  40] time: 135.1312, loss: 0.00900653\n",
      "Epoch: [18] [  24/  40] time: 135.3084, loss: 0.00319152\n",
      "Epoch: [18] [  25/  40] time: 135.4781, loss: 0.01067726\n",
      "Epoch: [18] [  26/  40] time: 135.6593, loss: 0.00228114\n",
      "Epoch: [18] [  27/  40] time: 135.8085, loss: 0.00499893\n",
      "Epoch: [18] [  28/  40] time: 135.9662, loss: 0.02342908\n",
      "Epoch: [18] [  29/  40] time: 136.1202, loss: 0.00976228\n",
      "Epoch: [18] [  30/  40] time: 136.2916, loss: 0.00230581\n",
      "Epoch: [18] [  31/  40] time: 136.4467, loss: 0.01599836\n",
      "Epoch: [18] [  32/  40] time: 136.6050, loss: 0.00062701\n",
      "Epoch: [18] [  33/  40] time: 136.7555, loss: 0.00331289\n",
      "Epoch: [18] [  34/  40] time: 136.9178, loss: 0.01093440\n",
      "Epoch: [18] [  35/  40] time: 137.0700, loss: 0.00493170\n",
      "Epoch: [18] [  36/  40] time: 137.2399, loss: 0.00316233\n",
      "Epoch: [18] [  37/  40] time: 137.4096, loss: 0.11038925\n",
      "Epoch: [18] [  38/  40] time: 137.5787, loss: 0.00127285\n",
      "Epoch: [18] [  39/  40] time: 137.7466, loss: 0.02399631\n",
      "[18/50] - ptime: 7.1745 loss: 0.01840547 acc: 0.75000 lr: 0.00082725\n",
      "Epoch: [19] [   0/  40] time: 139.4897, loss: 0.02120603\n",
      "Epoch: [19] [   1/  40] time: 139.6584, loss: 0.00014987\n",
      "Epoch: [19] [   2/  40] time: 139.8266, loss: 0.00074304\n",
      "Epoch: [19] [   3/  40] time: 139.9932, loss: 0.00863677\n",
      "Epoch: [19] [   4/  40] time: 140.1608, loss: 0.01011621\n",
      "Epoch: [19] [   5/  40] time: 140.3304, loss: 0.00214612\n",
      "Epoch: [19] [   6/  40] time: 140.4970, loss: 0.00070773\n",
      "Epoch: [19] [   7/  40] time: 140.6476, loss: 0.00025729\n",
      "Epoch: [19] [   8/  40] time: 140.8042, loss: 0.02033744\n",
      "Epoch: [19] [   9/  40] time: 140.9538, loss: 0.00406812\n",
      "Epoch: [19] [  10/  40] time: 141.1236, loss: 0.00906308\n",
      "Epoch: [19] [  11/  40] time: 141.2797, loss: 0.00125594\n",
      "Epoch: [19] [  12/  40] time: 141.4438, loss: 0.00243468\n",
      "Epoch: [19] [  13/  40] time: 141.5970, loss: 0.00082342\n",
      "Epoch: [19] [  14/  40] time: 141.7599, loss: 0.00106928\n",
      "Epoch: [19] [  15/  40] time: 141.9110, loss: 0.00215145\n",
      "Epoch: [19] [  16/  40] time: 142.0759, loss: 0.00102199\n",
      "Epoch: [19] [  17/  40] time: 142.2249, loss: 0.00115870\n",
      "Epoch: [19] [  18/  40] time: 142.3924, loss: 0.00257278\n",
      "Epoch: [19] [  19/  40] time: 142.5463, loss: 0.00103997\n",
      "Epoch: [19] [  20/  40] time: 142.7084, loss: 0.00103639\n",
      "Epoch: [19] [  21/  40] time: 142.8613, loss: 0.00391071\n",
      "Epoch: [19] [  22/  40] time: 143.0156, loss: 0.00077183\n",
      "Epoch: [19] [  23/  40] time: 143.1676, loss: 0.00111157\n",
      "Epoch: [19] [  24/  40] time: 143.3300, loss: 0.00019059\n",
      "Epoch: [19] [  25/  40] time: 143.4887, loss: 0.00177155\n",
      "Epoch: [19] [  26/  40] time: 143.6506, loss: 0.00020275\n",
      "Epoch: [19] [  27/  40] time: 143.8039, loss: 0.01879508\n",
      "Epoch: [19] [  28/  40] time: 143.9615, loss: 0.04952856\n",
      "Epoch: [19] [  29/  40] time: 144.1182, loss: 0.00112862\n",
      "Epoch: [19] [  30/  40] time: 144.2799, loss: 0.02163966\n",
      "Epoch: [19] [  31/  40] time: 144.4321, loss: 0.00009917\n",
      "Epoch: [19] [  32/  40] time: 144.5922, loss: 0.00624986\n",
      "Epoch: [19] [  33/  40] time: 144.7443, loss: 0.04056224\n",
      "Epoch: [19] [  34/  40] time: 144.9131, loss: 0.00344368\n",
      "Epoch: [19] [  35/  40] time: 145.0661, loss: 0.00815587\n",
      "Epoch: [19] [  36/  40] time: 145.2308, loss: 0.00380849\n",
      "Epoch: [19] [  37/  40] time: 145.3831, loss: 0.00452892\n",
      "Epoch: [19] [  38/  40] time: 145.5391, loss: 0.02107055\n",
      "Epoch: [19] [  39/  40] time: 145.6890, loss: 0.00500582\n",
      "[19/50] - ptime: 7.1390 loss: 0.00709930 acc: 0.74000 lr: 0.00082725\n",
      "Epoch: [20] [   0/  40] time: 147.4360, loss: 0.00042196\n",
      "Epoch: [20] [   1/  40] time: 147.5878, loss: 0.00158008\n",
      "Epoch: [20] [   2/  40] time: 147.7564, loss: 0.00345170\n",
      "Epoch: [20] [   3/  40] time: 147.9238, loss: 0.00400108\n",
      "Epoch: [20] [   4/  40] time: 148.0870, loss: 0.00240588\n",
      "Epoch: [20] [   5/  40] time: 148.2490, loss: 0.00181346\n",
      "Epoch: [20] [   6/  40] time: 148.4153, loss: 0.01233042\n",
      "Epoch: [20] [   7/  40] time: 148.5731, loss: 0.00556502\n",
      "Epoch: [20] [   8/  40] time: 148.7310, loss: 0.00087176\n",
      "Epoch: [20] [   9/  40] time: 148.8944, loss: 0.00148212\n",
      "Epoch: [20] [  10/  40] time: 149.0830, loss: 0.00120245\n",
      "Epoch: [20] [  11/  40] time: 149.2533, loss: 0.00045097\n",
      "Epoch: [20] [  12/  40] time: 149.4229, loss: 0.00007501\n",
      "Epoch: [20] [  13/  40] time: 149.5897, loss: 0.00061957\n",
      "Epoch: [20] [  14/  40] time: 149.7583, loss: 0.00263038\n",
      "Epoch: [20] [  15/  40] time: 149.9213, loss: 0.00002277\n",
      "Epoch: [20] [  16/  40] time: 150.1020, loss: 0.00129250\n",
      "Epoch: [20] [  17/  40] time: 150.2646, loss: 0.01064547\n",
      "Epoch: [20] [  18/  40] time: 150.4203, loss: 0.00003830\n",
      "Epoch: [20] [  19/  40] time: 150.5853, loss: 0.00012170\n",
      "Epoch: [20] [  20/  40] time: 150.7501, loss: 0.00022832\n",
      "Epoch: [20] [  21/  40] time: 150.9076, loss: 0.00073933\n",
      "Epoch: [20] [  22/  40] time: 151.0705, loss: 0.00045470\n",
      "Epoch: [20] [  23/  40] time: 151.2264, loss: 0.00388001\n",
      "Epoch: [20] [  24/  40] time: 151.3940, loss: 0.00368982\n",
      "Epoch: [20] [  25/  40] time: 151.5552, loss: 0.00035503\n",
      "Epoch: [20] [  26/  40] time: 151.7214, loss: 0.00000899\n",
      "Epoch: [20] [  27/  40] time: 151.8842, loss: 0.00847981\n",
      "Epoch: [20] [  28/  40] time: 152.0557, loss: 0.00058084\n",
      "Epoch: [20] [  29/  40] time: 152.2103, loss: 0.00012089\n",
      "Epoch: [20] [  30/  40] time: 152.3738, loss: 0.00158773\n",
      "Epoch: [20] [  31/  40] time: 152.5379, loss: 0.00058966\n",
      "Epoch: [20] [  32/  40] time: 152.7039, loss: 0.00172318\n",
      "Epoch: [20] [  33/  40] time: 152.8720, loss: 0.00019777\n",
      "Epoch: [20] [  34/  40] time: 153.0426, loss: 0.00253766\n",
      "Epoch: [20] [  35/  40] time: 153.2063, loss: 0.00038819\n",
      "Epoch: [20] [  36/  40] time: 153.3754, loss: 0.00093344\n",
      "Epoch: [20] [  37/  40] time: 153.5315, loss: 0.00081754\n",
      "Epoch: [20] [  38/  40] time: 153.6909, loss: 0.00005974\n",
      "Epoch: [20] [  39/  40] time: 153.8498, loss: 0.00444859\n",
      "[20/50] - ptime: 7.1749 loss: 0.00207110 acc: 0.74000 lr: 0.00081000\n",
      "Epoch: [21] [   0/  40] time: 155.2949, loss: 0.00021505\n",
      "Epoch: [21] [   1/  40] time: 155.4463, loss: 0.00908630\n",
      "Epoch: [21] [   2/  40] time: 155.6093, loss: 0.00792315\n",
      "Epoch: [21] [   3/  40] time: 155.7672, loss: 0.00000222\n",
      "Epoch: [21] [   4/  40] time: 155.9231, loss: 0.00050556\n",
      "Epoch: [21] [   5/  40] time: 156.0773, loss: 0.00013258\n",
      "Epoch: [21] [   6/  40] time: 156.2458, loss: 0.00475346\n",
      "Epoch: [21] [   7/  40] time: 156.4017, loss: 0.00159980\n",
      "Epoch: [21] [   8/  40] time: 156.5780, loss: 0.00019175\n",
      "Epoch: [21] [   9/  40] time: 156.7256, loss: 0.00003485\n",
      "Epoch: [21] [  10/  40] time: 156.8862, loss: 0.00111694\n",
      "Epoch: [21] [  11/  40] time: 157.0441, loss: 0.00218457\n",
      "Epoch: [21] [  12/  40] time: 157.2094, loss: 0.00184453\n",
      "Epoch: [21] [  13/  40] time: 157.3716, loss: 0.00003330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21] [  14/  40] time: 157.5339, loss: 0.00101491\n",
      "Epoch: [21] [  15/  40] time: 157.6892, loss: 0.00038216\n",
      "Epoch: [21] [  16/  40] time: 157.8557, loss: 0.00017330\n",
      "Epoch: [21] [  17/  40] time: 158.0182, loss: 0.00021456\n",
      "Epoch: [21] [  18/  40] time: 158.1963, loss: 0.00026169\n",
      "Epoch: [21] [  19/  40] time: 158.3727, loss: 0.00294193\n",
      "Epoch: [21] [  20/  40] time: 158.5428, loss: 0.00045237\n",
      "Epoch: [21] [  21/  40] time: 158.6910, loss: 0.00122033\n",
      "Epoch: [21] [  22/  40] time: 158.8587, loss: 0.00084472\n",
      "Epoch: [21] [  23/  40] time: 159.0092, loss: 0.00122073\n",
      "Epoch: [21] [  24/  40] time: 159.1745, loss: 0.00013037\n",
      "Epoch: [21] [  25/  40] time: 159.3307, loss: 0.00041393\n",
      "Epoch: [21] [  26/  40] time: 159.5062, loss: 0.00063421\n",
      "Epoch: [21] [  27/  40] time: 159.6555, loss: 0.00008767\n",
      "Epoch: [21] [  28/  40] time: 159.8152, loss: 0.00031562\n",
      "Epoch: [21] [  29/  40] time: 159.9662, loss: 0.00025482\n",
      "Epoch: [21] [  30/  40] time: 160.1287, loss: 0.00044476\n",
      "Epoch: [21] [  31/  40] time: 160.2777, loss: 0.00023024\n",
      "Epoch: [21] [  32/  40] time: 160.4348, loss: 0.00461513\n",
      "Epoch: [21] [  33/  40] time: 160.5842, loss: 0.00035905\n",
      "Epoch: [21] [  34/  40] time: 160.7413, loss: 0.00000616\n",
      "Epoch: [21] [  35/  40] time: 160.8900, loss: 0.00026352\n",
      "Epoch: [21] [  36/  40] time: 161.0458, loss: 0.00056796\n",
      "Epoch: [21] [  37/  40] time: 161.2008, loss: 0.00022710\n",
      "Epoch: [21] [  38/  40] time: 161.3730, loss: 0.00211732\n",
      "Epoch: [21] [  39/  40] time: 161.5306, loss: 0.00005473\n",
      "[21/50] - ptime: 7.0238 loss: 0.00122683 acc: 0.76000 lr: 0.00080151\n",
      "Epoch: [22] [   0/  40] time: 163.0398, loss: 0.00153332\n",
      "Epoch: [22] [   1/  40] time: 163.1968, loss: 0.00104175\n",
      "Epoch: [22] [   2/  40] time: 163.3621, loss: 0.00040381\n",
      "Epoch: [22] [   3/  40] time: 163.5292, loss: 0.00023834\n",
      "Epoch: [22] [   4/  40] time: 163.6945, loss: 0.00059734\n",
      "Epoch: [22] [   5/  40] time: 163.8754, loss: 0.00043648\n",
      "Epoch: [22] [   6/  40] time: 164.0423, loss: 0.00003910\n",
      "Epoch: [22] [   7/  40] time: 164.2313, loss: 0.00004826\n",
      "Epoch: [22] [   8/  40] time: 164.4102, loss: 0.00075849\n",
      "Epoch: [22] [   9/  40] time: 164.5810, loss: 0.00060483\n",
      "Epoch: [22] [  10/  40] time: 164.7421, loss: 0.00008573\n",
      "Epoch: [22] [  11/  40] time: 164.9113, loss: 0.00002312\n",
      "Epoch: [22] [  12/  40] time: 165.0705, loss: 0.00048667\n",
      "Epoch: [22] [  13/  40] time: 165.2387, loss: 0.00005127\n",
      "Epoch: [22] [  14/  40] time: 165.3994, loss: 0.00003178\n",
      "Epoch: [22] [  15/  40] time: 165.5679, loss: 0.00000355\n",
      "Epoch: [22] [  16/  40] time: 165.7305, loss: 0.00000070\n",
      "Epoch: [22] [  17/  40] time: 165.8945, loss: 0.00006903\n",
      "Epoch: [22] [  18/  40] time: 166.0734, loss: 0.00004510\n",
      "Epoch: [22] [  19/  40] time: 166.2417, loss: 0.00355351\n",
      "Epoch: [22] [  20/  40] time: 166.4047, loss: 0.00000678\n",
      "Epoch: [22] [  21/  40] time: 166.5814, loss: 0.00012292\n",
      "Epoch: [22] [  22/  40] time: 166.7476, loss: 0.00055001\n",
      "Epoch: [22] [  23/  40] time: 166.9093, loss: 0.00003369\n",
      "Epoch: [22] [  24/  40] time: 167.0914, loss: 0.00010961\n",
      "Epoch: [22] [  25/  40] time: 167.2655, loss: 0.00031033\n",
      "Epoch: [22] [  26/  40] time: 167.4272, loss: 0.00098689\n",
      "Epoch: [22] [  27/  40] time: 167.6112, loss: 0.00004044\n",
      "Epoch: [22] [  28/  40] time: 167.7940, loss: 0.00050182\n",
      "Epoch: [22] [  29/  40] time: 167.9615, loss: 0.00002324\n",
      "Epoch: [22] [  30/  40] time: 168.1222, loss: 0.00000419\n",
      "Epoch: [22] [  31/  40] time: 168.2928, loss: 0.00002020\n",
      "Epoch: [22] [  32/  40] time: 168.4626, loss: 0.00246900\n",
      "Epoch: [22] [  33/  40] time: 168.6461, loss: 0.00000628\n",
      "Epoch: [22] [  34/  40] time: 168.8009, loss: 0.00005636\n",
      "Epoch: [22] [  35/  40] time: 168.9561, loss: 0.00055606\n",
      "Epoch: [22] [  36/  40] time: 169.1267, loss: 0.00010987\n",
      "Epoch: [22] [  37/  40] time: 169.2948, loss: 0.00005114\n",
      "Epoch: [22] [  38/  40] time: 169.4715, loss: 0.00065718\n",
      "Epoch: [22] [  39/  40] time: 169.6362, loss: 0.00006593\n",
      "[22/50] - ptime: 7.3587 loss: 0.00041835 acc: 0.76000 lr: 0.00079311\n",
      "Epoch: [23] [   0/  40] time: 171.2624, loss: 0.00000692\n",
      "Epoch: [23] [   1/  40] time: 171.4266, loss: 0.00000439\n",
      "Epoch: [23] [   2/  40] time: 171.5937, loss: 0.00002503\n",
      "Epoch: [23] [   3/  40] time: 171.7647, loss: 0.00177710\n",
      "Epoch: [23] [   4/  40] time: 171.9289, loss: 0.00000575\n",
      "Epoch: [23] [   5/  40] time: 172.0995, loss: 0.00091289\n",
      "Epoch: [23] [   6/  40] time: 172.2650, loss: 0.00000692\n",
      "Epoch: [23] [   7/  40] time: 172.4303, loss: 0.00002108\n",
      "Epoch: [23] [   8/  40] time: 172.6034, loss: 0.00006256\n",
      "Epoch: [23] [   9/  40] time: 172.7709, loss: 0.00045408\n",
      "Epoch: [23] [  10/  40] time: 172.9352, loss: 0.00000744\n",
      "Epoch: [23] [  11/  40] time: 173.0981, loss: 0.00010546\n",
      "Epoch: [23] [  12/  40] time: 173.2574, loss: 0.00008097\n",
      "Epoch: [23] [  13/  40] time: 173.4077, loss: 0.00001166\n",
      "Epoch: [23] [  14/  40] time: 173.5637, loss: 0.00010754\n",
      "Epoch: [23] [  15/  40] time: 173.7135, loss: 0.00027161\n",
      "Epoch: [23] [  16/  40] time: 173.8830, loss: 0.00000666\n",
      "Epoch: [23] [  17/  40] time: 174.0494, loss: 0.00002992\n",
      "Epoch: [23] [  18/  40] time: 174.2240, loss: 0.00000862\n",
      "Epoch: [23] [  19/  40] time: 174.3790, loss: 0.00001972\n",
      "Epoch: [23] [  20/  40] time: 174.5396, loss: 0.00000686\n",
      "Epoch: [23] [  21/  40] time: 174.6888, loss: 0.00031876\n",
      "Epoch: [23] [  22/  40] time: 174.8430, loss: 0.00000945\n",
      "Epoch: [23] [  23/  40] time: 174.9931, loss: 0.00000517\n",
      "Epoch: [23] [  24/  40] time: 175.1601, loss: 0.00017561\n",
      "Epoch: [23] [  25/  40] time: 175.3253, loss: 0.00010246\n",
      "Epoch: [23] [  26/  40] time: 175.4902, loss: 0.00048288\n",
      "Epoch: [23] [  27/  40] time: 175.6557, loss: 0.00004020\n",
      "Epoch: [23] [  28/  40] time: 175.8324, loss: 0.00027915\n",
      "Epoch: [23] [  29/  40] time: 175.9990, loss: 0.00001528\n",
      "Epoch: [23] [  30/  40] time: 176.1669, loss: 0.00009113\n",
      "Epoch: [23] [  31/  40] time: 176.3355, loss: 0.00021337\n",
      "Epoch: [23] [  32/  40] time: 176.5032, loss: 0.00013729\n",
      "Epoch: [23] [  33/  40] time: 176.6718, loss: 0.00001024\n",
      "Epoch: [23] [  34/  40] time: 176.8354, loss: 0.00000744\n",
      "Epoch: [23] [  35/  40] time: 177.0096, loss: 0.00025849\n",
      "Epoch: [23] [  36/  40] time: 177.1676, loss: 0.00005151\n",
      "Epoch: [23] [  37/  40] time: 177.3437, loss: 0.00124198\n",
      "Epoch: [23] [  38/  40] time: 177.5093, loss: 0.00221507\n",
      "Epoch: [23] [  39/  40] time: 177.6896, loss: 0.00009507\n",
      "[23/50] - ptime: 7.3257 loss: 0.00024209 acc: 0.78000 lr: 0.00078480\n",
      "Epoch: [24] [   0/  40] time: 179.0738, loss: 0.00004235\n",
      "Epoch: [24] [   1/  40] time: 179.2360, loss: 0.00001276\n",
      "Epoch: [24] [   2/  40] time: 179.3984, loss: 0.00004481\n",
      "Epoch: [24] [   3/  40] time: 179.5832, loss: 0.00001357\n",
      "Epoch: [24] [   4/  40] time: 179.7491, loss: 0.00002586\n",
      "Epoch: [24] [   5/  40] time: 179.9124, loss: 0.00016676\n",
      "Epoch: [24] [   6/  40] time: 180.0807, loss: 0.00003003\n",
      "Epoch: [24] [   7/  40] time: 180.2445, loss: 0.00000184\n",
      "Epoch: [24] [   8/  40] time: 180.4128, loss: 0.00004069\n",
      "Epoch: [24] [   9/  40] time: 180.5971, loss: 0.00006377\n",
      "Epoch: [24] [  10/  40] time: 180.7796, loss: 0.00001300\n",
      "Epoch: [24] [  11/  40] time: 180.9432, loss: 0.00008113\n",
      "Epoch: [24] [  12/  40] time: 181.1099, loss: 0.00004893\n",
      "Epoch: [24] [  13/  40] time: 181.2744, loss: 0.00021880\n",
      "Epoch: [24] [  14/  40] time: 181.4333, loss: 0.00011340\n",
      "Epoch: [24] [  15/  40] time: 181.5895, loss: 0.00014319\n",
      "Epoch: [24] [  16/  40] time: 181.7515, loss: 0.00002223\n",
      "Epoch: [24] [  17/  40] time: 181.9072, loss: 0.00089426\n",
      "Epoch: [24] [  18/  40] time: 182.0784, loss: 0.00006891\n",
      "Epoch: [24] [  19/  40] time: 182.2312, loss: 0.00000167\n",
      "Epoch: [24] [  20/  40] time: 182.3960, loss: 0.00005881\n",
      "Epoch: [24] [  21/  40] time: 182.5463, loss: 0.00077820\n",
      "Epoch: [24] [  22/  40] time: 182.7034, loss: 0.00039861\n",
      "Epoch: [24] [  23/  40] time: 182.8542, loss: 0.00010046\n",
      "Epoch: [24] [  24/  40] time: 183.0079, loss: 0.00020203\n",
      "Epoch: [24] [  25/  40] time: 183.1609, loss: 0.00000752\n",
      "Epoch: [24] [  26/  40] time: 183.3197, loss: 0.00016655\n",
      "Epoch: [24] [  27/  40] time: 183.4725, loss: 0.00002072\n",
      "Epoch: [24] [  28/  40] time: 183.6265, loss: 0.00067496\n",
      "Epoch: [24] [  29/  40] time: 183.7757, loss: 0.00001110\n",
      "Epoch: [24] [  30/  40] time: 183.9595, loss: 0.00014833\n",
      "Epoch: [24] [  31/  40] time: 184.1165, loss: 0.00002700\n",
      "Epoch: [24] [  32/  40] time: 184.2796, loss: 0.00001021\n",
      "Epoch: [24] [  33/  40] time: 184.4339, loss: 0.00002954\n",
      "Epoch: [24] [  34/  40] time: 184.6004, loss: 0.00000022\n",
      "Epoch: [24] [  35/  40] time: 184.7498, loss: 0.00020599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24] [  36/  40] time: 184.9048, loss: 0.00002721\n",
      "Epoch: [24] [  37/  40] time: 185.0576, loss: 0.00003762\n",
      "Epoch: [24] [  38/  40] time: 185.2129, loss: 0.00003875\n",
      "Epoch: [24] [  39/  40] time: 185.3627, loss: 0.00001531\n",
      "[24/50] - ptime: 7.0708 loss: 0.00012518 acc: 0.80000 lr: 0.00077657\n",
      "Epoch: [25] [   0/  40] time: 186.7184, loss: 0.00005707\n",
      "Epoch: [25] [   1/  40] time: 186.8664, loss: 0.00006860\n",
      "Epoch: [25] [   2/  40] time: 187.0287, loss: 0.00006284\n",
      "Epoch: [25] [   3/  40] time: 187.1808, loss: 0.00044667\n",
      "Epoch: [25] [   4/  40] time: 187.3361, loss: 0.00001955\n",
      "Epoch: [25] [   5/  40] time: 187.4865, loss: 0.00071504\n",
      "Epoch: [25] [   6/  40] time: 187.6465, loss: 0.00010772\n",
      "Epoch: [25] [   7/  40] time: 187.7996, loss: 0.00001528\n",
      "Epoch: [25] [   8/  40] time: 187.9630, loss: 0.00002394\n",
      "Epoch: [25] [   9/  40] time: 188.1189, loss: 0.00000561\n",
      "Epoch: [25] [  10/  40] time: 188.2828, loss: 0.00000901\n",
      "Epoch: [25] [  11/  40] time: 188.4339, loss: 0.00000867\n",
      "Epoch: [25] [  12/  40] time: 188.5906, loss: 0.00002176\n",
      "Epoch: [25] [  13/  40] time: 188.7417, loss: 0.00003871\n",
      "Epoch: [25] [  14/  40] time: 188.8986, loss: 0.00000835\n",
      "Epoch: [25] [  15/  40] time: 189.0494, loss: 0.00013898\n",
      "Epoch: [25] [  16/  40] time: 189.2080, loss: 0.00006983\n",
      "Epoch: [25] [  17/  40] time: 189.3567, loss: 0.00000656\n",
      "Epoch: [25] [  18/  40] time: 189.5111, loss: 0.00003576\n",
      "Epoch: [25] [  19/  40] time: 189.6602, loss: 0.00005526\n",
      "Epoch: [25] [  20/  40] time: 189.8163, loss: 0.00000124\n",
      "Epoch: [25] [  21/  40] time: 189.9659, loss: 0.00018541\n",
      "Epoch: [25] [  22/  40] time: 190.1301, loss: 0.00003278\n",
      "Epoch: [25] [  23/  40] time: 190.2812, loss: 0.00001045\n",
      "Epoch: [25] [  24/  40] time: 190.4617, loss: 0.00004657\n",
      "Epoch: [25] [  25/  40] time: 190.6133, loss: 0.00026846\n",
      "Epoch: [25] [  26/  40] time: 190.7840, loss: 0.00047571\n",
      "Epoch: [25] [  27/  40] time: 190.9339, loss: 0.00015698\n",
      "Epoch: [25] [  28/  40] time: 191.0934, loss: 0.00006629\n",
      "Epoch: [25] [  29/  40] time: 191.2460, loss: 0.00003321\n",
      "Epoch: [25] [  30/  40] time: 191.4010, loss: 0.00003203\n",
      "Epoch: [25] [  31/  40] time: 191.5499, loss: 0.00000399\n",
      "Epoch: [25] [  32/  40] time: 191.7056, loss: 0.00001327\n",
      "Epoch: [25] [  33/  40] time: 191.8584, loss: 0.00000563\n",
      "Epoch: [25] [  34/  40] time: 192.0146, loss: 0.00016322\n",
      "Epoch: [25] [  35/  40] time: 192.1870, loss: 0.00003122\n",
      "Epoch: [25] [  36/  40] time: 192.3463, loss: 0.00004419\n",
      "Epoch: [25] [  37/  40] time: 192.4960, loss: 0.00032090\n",
      "Epoch: [25] [  38/  40] time: 192.6493, loss: 0.00003371\n",
      "Epoch: [25] [  39/  40] time: 192.8020, loss: 0.00014055\n",
      "[25/50] - ptime: 6.8404 loss: 0.00009953 acc: 0.80000 lr: 0.00077657\n",
      "Epoch: [26] [   0/  40] time: 194.2839, loss: 0.00000801\n",
      "Epoch: [26] [   1/  40] time: 194.4318, loss: 0.00005301\n",
      "Epoch: [26] [   2/  40] time: 194.5885, loss: 0.00027949\n",
      "Epoch: [26] [   3/  40] time: 194.7393, loss: 0.00015093\n",
      "Epoch: [26] [   4/  40] time: 194.8969, loss: 0.00000802\n",
      "Epoch: [26] [   5/  40] time: 195.0476, loss: 0.00024373\n",
      "Epoch: [26] [   6/  40] time: 195.2035, loss: 0.00069324\n",
      "Epoch: [26] [   7/  40] time: 195.3589, loss: 0.00000170\n",
      "Epoch: [26] [   8/  40] time: 195.5174, loss: 0.00023240\n",
      "Epoch: [26] [   9/  40] time: 195.6664, loss: 0.00003111\n",
      "Epoch: [26] [  10/  40] time: 195.8235, loss: 0.00001224\n",
      "Epoch: [26] [  11/  40] time: 195.9760, loss: 0.00001115\n",
      "Epoch: [26] [  12/  40] time: 196.1355, loss: 0.00005657\n",
      "Epoch: [26] [  13/  40] time: 196.2950, loss: 0.00007044\n",
      "Epoch: [26] [  14/  40] time: 196.4615, loss: 0.00001942\n",
      "Epoch: [26] [  15/  40] time: 196.6119, loss: 0.00011233\n",
      "Epoch: [26] [  16/  40] time: 196.7660, loss: 0.00003940\n",
      "Epoch: [26] [  17/  40] time: 196.9169, loss: 0.00000700\n",
      "Epoch: [26] [  18/  40] time: 197.0794, loss: 0.00003371\n",
      "Epoch: [26] [  19/  40] time: 197.2313, loss: 0.00059781\n",
      "Epoch: [26] [  20/  40] time: 197.3904, loss: 0.00002768\n",
      "Epoch: [26] [  21/  40] time: 197.5414, loss: 0.00000176\n",
      "Epoch: [26] [  22/  40] time: 197.6973, loss: 0.00014016\n",
      "Epoch: [26] [  23/  40] time: 197.8513, loss: 0.00001794\n",
      "Epoch: [26] [  24/  40] time: 198.0091, loss: 0.00001185\n",
      "Epoch: [26] [  25/  40] time: 198.1659, loss: 0.00001053\n",
      "Epoch: [26] [  26/  40] time: 198.3383, loss: 0.00101316\n",
      "Epoch: [26] [  27/  40] time: 198.4870, loss: 0.00002332\n",
      "Epoch: [26] [  28/  40] time: 198.6435, loss: 0.00003268\n",
      "Epoch: [26] [  29/  40] time: 198.7940, loss: 0.00190282\n",
      "Epoch: [26] [  30/  40] time: 198.9494, loss: 0.00011312\n",
      "Epoch: [26] [  31/  40] time: 199.1014, loss: 0.00068834\n",
      "Epoch: [26] [  32/  40] time: 199.2575, loss: 0.00003327\n",
      "Epoch: [26] [  33/  40] time: 199.4066, loss: 0.00000433\n",
      "Epoch: [26] [  34/  40] time: 199.5615, loss: 0.00000118\n",
      "Epoch: [26] [  35/  40] time: 199.7165, loss: 0.00006286\n",
      "Epoch: [26] [  36/  40] time: 199.8738, loss: 0.00029237\n",
      "Epoch: [26] [  37/  40] time: 200.0277, loss: 0.00008284\n",
      "Epoch: [26] [  38/  40] time: 200.1844, loss: 0.00010696\n",
      "Epoch: [26] [  39/  40] time: 200.3336, loss: 0.00001988\n",
      "[26/50] - ptime: 6.8303 loss: 0.00018122 acc: 0.80000 lr: 0.00076038\n",
      "Epoch: [27] [   0/  40] time: 201.7783, loss: 0.00049144\n",
      "Epoch: [27] [   1/  40] time: 201.9275, loss: 0.00000359\n",
      "Epoch: [27] [   2/  40] time: 202.0845, loss: 0.00005370\n",
      "Epoch: [27] [   3/  40] time: 202.2351, loss: 0.00007587\n",
      "Epoch: [27] [   4/  40] time: 202.3969, loss: 0.00001644\n",
      "Epoch: [27] [   5/  40] time: 202.5463, loss: 0.00002434\n",
      "Epoch: [27] [   6/  40] time: 202.7024, loss: 0.00002726\n",
      "Epoch: [27] [   7/  40] time: 202.8510, loss: 0.00049157\n",
      "Epoch: [27] [   8/  40] time: 203.0064, loss: 0.00005809\n",
      "Epoch: [27] [   9/  40] time: 203.1553, loss: 0.00000937\n",
      "Epoch: [27] [  10/  40] time: 203.3095, loss: 0.00000940\n",
      "Epoch: [27] [  11/  40] time: 203.4645, loss: 0.00001151\n",
      "Epoch: [27] [  12/  40] time: 203.6281, loss: 0.00033325\n",
      "Epoch: [27] [  13/  40] time: 203.7788, loss: 0.00002477\n",
      "Epoch: [27] [  14/  40] time: 203.9340, loss: 0.00001161\n",
      "Epoch: [27] [  15/  40] time: 204.0906, loss: 0.00004451\n",
      "Epoch: [27] [  16/  40] time: 204.2509, loss: 0.00001786\n",
      "Epoch: [27] [  17/  40] time: 204.4075, loss: 0.00001195\n",
      "Epoch: [27] [  18/  40] time: 204.5810, loss: 0.00015528\n",
      "Epoch: [27] [  19/  40] time: 204.7299, loss: 0.00026745\n",
      "Epoch: [27] [  20/  40] time: 204.8871, loss: 0.00000249\n",
      "Epoch: [27] [  21/  40] time: 205.0430, loss: 0.00000247\n",
      "Epoch: [27] [  22/  40] time: 205.2240, loss: 0.00015426\n",
      "Epoch: [27] [  23/  40] time: 205.3738, loss: 0.00003113\n",
      "Epoch: [27] [  24/  40] time: 205.5327, loss: 0.00005319\n",
      "Epoch: [27] [  25/  40] time: 205.6816, loss: 0.00009087\n",
      "Epoch: [27] [  26/  40] time: 205.8366, loss: 0.00019246\n",
      "Epoch: [27] [  27/  40] time: 205.9858, loss: 0.00001000\n",
      "Epoch: [27] [  28/  40] time: 206.1410, loss: 0.00000106\n",
      "Epoch: [27] [  29/  40] time: 206.2960, loss: 0.00000294\n",
      "Epoch: [27] [  30/  40] time: 206.4529, loss: 0.00000696\n",
      "Epoch: [27] [  31/  40] time: 206.6023, loss: 0.00006075\n",
      "Epoch: [27] [  32/  40] time: 206.7577, loss: 0.00002182\n",
      "Epoch: [27] [  33/  40] time: 206.9137, loss: 0.00004769\n",
      "Epoch: [27] [  34/  40] time: 207.0742, loss: 0.00009758\n",
      "Epoch: [27] [  35/  40] time: 207.2268, loss: 0.00001306\n",
      "Epoch: [27] [  36/  40] time: 207.3883, loss: 0.00000007\n",
      "Epoch: [27] [  37/  40] time: 207.5378, loss: 0.00018044\n",
      "Epoch: [27] [  38/  40] time: 207.6932, loss: 0.00000136\n",
      "Epoch: [27] [  39/  40] time: 207.8424, loss: 0.00002253\n",
      "[27/50] - ptime: 6.8013 loss: 0.00007831 acc: 0.81000 lr: 0.00076038\n",
      "Epoch: [28] [   0/  40] time: 209.2272, loss: 0.00001699\n",
      "Epoch: [28] [   1/  40] time: 209.3756, loss: 0.00000450\n",
      "Epoch: [28] [   2/  40] time: 209.5403, loss: 0.00000979\n",
      "Epoch: [28] [   3/  40] time: 209.6922, loss: 0.00011071\n",
      "Epoch: [28] [   4/  40] time: 209.8482, loss: 0.00001082\n",
      "Epoch: [28] [   5/  40] time: 210.0030, loss: 0.00000889\n",
      "Epoch: [28] [   6/  40] time: 210.1645, loss: 0.00000599\n",
      "Epoch: [28] [   7/  40] time: 210.3143, loss: 0.00004450\n",
      "Epoch: [28] [   8/  40] time: 210.4797, loss: 0.00002230\n",
      "Epoch: [28] [   9/  40] time: 210.6293, loss: 0.00001006\n",
      "Epoch: [28] [  10/  40] time: 210.7854, loss: 0.00010996\n",
      "Epoch: [28] [  11/  40] time: 210.9349, loss: 0.00003736\n",
      "Epoch: [28] [  12/  40] time: 211.0938, loss: 0.00003968\n",
      "Epoch: [28] [  13/  40] time: 211.2462, loss: 0.00008145\n",
      "Epoch: [28] [  14/  40] time: 211.4070, loss: 0.00000363\n",
      "Epoch: [28] [  15/  40] time: 211.5556, loss: 0.00072778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28] [  16/  40] time: 211.7134, loss: 0.00019016\n",
      "Epoch: [28] [  17/  40] time: 211.8648, loss: 0.00001859\n",
      "Epoch: [28] [  18/  40] time: 212.0195, loss: 0.00009039\n",
      "Epoch: [28] [  19/  40] time: 212.1714, loss: 0.00000549\n",
      "Epoch: [28] [  20/  40] time: 212.3323, loss: 0.00006370\n",
      "Epoch: [28] [  21/  40] time: 212.4889, loss: 0.00010606\n",
      "Epoch: [28] [  22/  40] time: 212.6504, loss: 0.00003617\n",
      "Epoch: [28] [  23/  40] time: 212.8002, loss: 0.00003333\n",
      "Epoch: [28] [  24/  40] time: 212.9589, loss: 0.00000255\n",
      "Epoch: [28] [  25/  40] time: 213.1139, loss: 0.00000057\n",
      "Epoch: [28] [  26/  40] time: 213.2788, loss: 0.00000769\n",
      "Epoch: [28] [  27/  40] time: 213.4283, loss: 0.00003063\n",
      "Epoch: [28] [  28/  40] time: 213.5843, loss: 0.00002088\n",
      "Epoch: [28] [  29/  40] time: 213.7378, loss: 0.00001393\n",
      "Epoch: [28] [  30/  40] time: 213.8997, loss: 0.00000065\n",
      "Epoch: [28] [  31/  40] time: 214.0581, loss: 0.00011959\n",
      "Epoch: [28] [  32/  40] time: 214.2120, loss: 0.00002671\n",
      "Epoch: [28] [  33/  40] time: 214.3685, loss: 0.00001581\n",
      "Epoch: [28] [  34/  40] time: 214.5257, loss: 0.00011046\n",
      "Epoch: [28] [  35/  40] time: 214.6821, loss: 0.00000573\n",
      "Epoch: [28] [  36/  40] time: 214.8404, loss: 0.00000162\n",
      "Epoch: [28] [  37/  40] time: 214.9949, loss: 0.00002125\n",
      "Epoch: [28] [  38/  40] time: 215.1622, loss: 0.00002870\n",
      "Epoch: [28] [  39/  40] time: 215.3201, loss: 0.00007099\n",
      "[28/50] - ptime: 6.8147 loss: 0.00005665 acc: 0.79000 lr: 0.00074452\n",
      "Epoch: [29] [   0/  40] time: 216.7901, loss: 0.00011917\n",
      "Epoch: [29] [   1/  40] time: 216.9395, loss: 0.00015799\n",
      "Epoch: [29] [   2/  40] time: 217.1033, loss: 0.00002508\n",
      "Epoch: [29] [   3/  40] time: 217.2565, loss: 0.00000084\n",
      "Epoch: [29] [   4/  40] time: 217.4311, loss: 0.00000362\n",
      "Epoch: [29] [   5/  40] time: 217.5875, loss: 0.00005319\n",
      "Epoch: [29] [   6/  40] time: 217.7470, loss: 0.00001806\n",
      "Epoch: [29] [   7/  40] time: 217.8983, loss: 0.00000241\n",
      "Epoch: [29] [   8/  40] time: 218.0624, loss: 0.00002187\n",
      "Epoch: [29] [   9/  40] time: 218.2134, loss: 0.00003412\n",
      "Epoch: [29] [  10/  40] time: 218.3805, loss: 0.00002911\n",
      "Epoch: [29] [  11/  40] time: 218.5291, loss: 0.00000503\n",
      "Epoch: [29] [  12/  40] time: 218.7059, loss: 0.00000675\n",
      "Epoch: [29] [  13/  40] time: 218.8545, loss: 0.00000118\n",
      "Epoch: [29] [  14/  40] time: 219.0312, loss: 0.00002981\n",
      "Epoch: [29] [  15/  40] time: 219.1845, loss: 0.00004666\n",
      "Epoch: [29] [  16/  40] time: 219.3549, loss: 0.00004534\n",
      "Epoch: [29] [  17/  40] time: 219.5074, loss: 0.00000781\n",
      "Epoch: [29] [  18/  40] time: 219.6610, loss: 0.00002050\n",
      "Epoch: [29] [  19/  40] time: 219.8101, loss: 0.00000945\n",
      "Epoch: [29] [  20/  40] time: 219.9675, loss: 0.00002562\n",
      "Epoch: [29] [  21/  40] time: 220.1184, loss: 0.00001451\n",
      "Epoch: [29] [  22/  40] time: 220.2840, loss: 0.00009653\n",
      "Epoch: [29] [  23/  40] time: 220.4343, loss: 0.00002475\n",
      "Epoch: [29] [  24/  40] time: 220.5938, loss: 0.00001106\n",
      "Epoch: [29] [  25/  40] time: 220.7431, loss: 0.00024313\n",
      "Epoch: [29] [  26/  40] time: 220.8977, loss: 0.00000777\n",
      "Epoch: [29] [  27/  40] time: 221.0478, loss: 0.00000585\n",
      "Epoch: [29] [  28/  40] time: 221.2102, loss: 0.00006514\n",
      "Epoch: [29] [  29/  40] time: 221.3624, loss: 0.00001307\n",
      "Epoch: [29] [  30/  40] time: 221.5184, loss: 0.00001266\n",
      "Epoch: [29] [  31/  40] time: 221.6687, loss: 0.00002933\n",
      "Epoch: [29] [  32/  40] time: 221.8249, loss: 0.00000912\n",
      "Epoch: [29] [  33/  40] time: 221.9746, loss: 0.00000042\n",
      "Epoch: [29] [  34/  40] time: 222.1320, loss: 0.00000250\n",
      "Epoch: [29] [  35/  40] time: 222.2854, loss: 0.00000759\n",
      "Epoch: [29] [  36/  40] time: 222.4473, loss: 0.00000374\n",
      "Epoch: [29] [  37/  40] time: 222.5994, loss: 0.00000811\n",
      "Epoch: [29] [  38/  40] time: 222.7575, loss: 0.00014693\n",
      "Epoch: [29] [  39/  40] time: 222.9134, loss: 0.00000741\n",
      "[29/50] - ptime: 6.8824 loss: 0.00003433 acc: 0.80000 lr: 0.00073672\n",
      "Epoch: [30] [   0/  40] time: 224.2583, loss: 0.00006541\n",
      "Epoch: [30] [   1/  40] time: 224.4066, loss: 0.00008255\n",
      "Epoch: [30] [   2/  40] time: 224.5663, loss: 0.00002831\n",
      "Epoch: [30] [   3/  40] time: 224.7170, loss: 0.00001097\n",
      "Epoch: [30] [   4/  40] time: 224.8711, loss: 0.00001230\n",
      "Epoch: [30] [   5/  40] time: 225.0216, loss: 0.00004517\n",
      "Epoch: [30] [   6/  40] time: 225.1759, loss: 0.00000032\n",
      "Epoch: [30] [   7/  40] time: 225.3261, loss: 0.00000184\n",
      "Epoch: [30] [   8/  40] time: 225.4910, loss: 0.00000797\n",
      "Epoch: [30] [   9/  40] time: 225.6421, loss: 0.00000632\n",
      "Epoch: [30] [  10/  40] time: 225.8013, loss: 0.00000810\n",
      "Epoch: [30] [  11/  40] time: 225.9508, loss: 0.00002209\n",
      "Epoch: [30] [  12/  40] time: 226.1087, loss: 0.00022436\n",
      "Epoch: [30] [  13/  40] time: 226.2675, loss: 0.00001318\n",
      "Epoch: [30] [  14/  40] time: 226.4286, loss: 0.00002111\n",
      "Epoch: [30] [  15/  40] time: 226.5968, loss: 0.00003772\n",
      "Epoch: [30] [  16/  40] time: 226.7596, loss: 0.00004588\n",
      "Epoch: [30] [  17/  40] time: 226.9253, loss: 0.00000085\n",
      "Epoch: [30] [  18/  40] time: 227.0939, loss: 0.00000768\n",
      "Epoch: [30] [  19/  40] time: 227.2754, loss: 0.00002349\n",
      "Epoch: [30] [  20/  40] time: 227.4304, loss: 0.00000327\n",
      "Epoch: [30] [  21/  40] time: 227.5785, loss: 0.00000422\n",
      "Epoch: [30] [  22/  40] time: 227.7438, loss: 0.00006535\n",
      "Epoch: [30] [  23/  40] time: 227.8974, loss: 0.00013969\n",
      "Epoch: [30] [  24/  40] time: 228.0602, loss: 0.00004984\n",
      "Epoch: [30] [  25/  40] time: 228.2120, loss: 0.00002910\n",
      "Epoch: [30] [  26/  40] time: 228.3717, loss: 0.00000836\n",
      "Epoch: [30] [  27/  40] time: 228.5216, loss: 0.00005718\n",
      "Epoch: [30] [  28/  40] time: 228.6861, loss: 0.00003140\n",
      "Epoch: [30] [  29/  40] time: 228.8372, loss: 0.00008314\n",
      "Epoch: [30] [  30/  40] time: 228.9985, loss: 0.00001547\n",
      "Epoch: [30] [  31/  40] time: 229.1611, loss: 0.00004896\n",
      "Epoch: [30] [  32/  40] time: 229.3258, loss: 0.00004893\n",
      "Epoch: [30] [  33/  40] time: 229.4879, loss: 0.00000866\n",
      "Epoch: [30] [  34/  40] time: 229.6489, loss: 0.00004367\n",
      "Epoch: [30] [  35/  40] time: 229.8182, loss: 0.00000734\n",
      "Epoch: [30] [  36/  40] time: 229.9793, loss: 0.00002712\n",
      "Epoch: [30] [  37/  40] time: 230.1453, loss: 0.00050578\n",
      "Epoch: [30] [  38/  40] time: 230.2992, loss: 0.00022971\n",
      "Epoch: [30] [  39/  40] time: 230.4503, loss: 0.00002134\n",
      "[30/50] - ptime: 6.9261 loss: 0.00005235 acc: 0.80000 lr: 0.00073672\n",
      "Epoch: [31] [   0/  40] time: 231.7712, loss: 0.00000245\n",
      "Epoch: [31] [   1/  40] time: 231.9190, loss: 0.00001231\n",
      "Epoch: [31] [   2/  40] time: 232.0801, loss: 0.00003031\n",
      "Epoch: [31] [   3/  40] time: 232.2328, loss: 0.00000060\n",
      "Epoch: [31] [   4/  40] time: 232.4087, loss: 0.00007185\n",
      "Epoch: [31] [   5/  40] time: 232.5748, loss: 0.00002440\n",
      "Epoch: [31] [   6/  40] time: 232.7605, loss: 0.00000986\n",
      "Epoch: [31] [   7/  40] time: 232.9127, loss: 0.00036274\n",
      "Epoch: [31] [   8/  40] time: 233.0740, loss: 0.00000094\n",
      "Epoch: [31] [   9/  40] time: 233.2326, loss: 0.00000301\n",
      "Epoch: [31] [  10/  40] time: 233.4103, loss: 0.00001864\n",
      "Epoch: [31] [  11/  40] time: 233.5602, loss: 0.00002023\n",
      "Epoch: [31] [  12/  40] time: 233.7160, loss: 0.00000162\n",
      "Epoch: [31] [  13/  40] time: 233.8671, loss: 0.00056808\n",
      "Epoch: [31] [  14/  40] time: 234.0238, loss: 0.00007824\n",
      "Epoch: [31] [  15/  40] time: 234.1743, loss: 0.00003408\n",
      "Epoch: [31] [  16/  40] time: 234.3304, loss: 0.00004140\n",
      "Epoch: [31] [  17/  40] time: 234.5193, loss: 0.00000272\n",
      "Epoch: [31] [  18/  40] time: 234.6826, loss: 0.00000060\n",
      "Epoch: [31] [  19/  40] time: 234.8502, loss: 0.00001313\n",
      "Epoch: [31] [  20/  40] time: 235.0171, loss: 0.00003211\n",
      "Epoch: [31] [  21/  40] time: 235.1873, loss: 0.00000595\n",
      "Epoch: [31] [  22/  40] time: 235.3498, loss: 0.00036365\n",
      "Epoch: [31] [  23/  40] time: 235.5222, loss: 0.00000133\n",
      "Epoch: [31] [  24/  40] time: 235.6859, loss: 0.00000518\n",
      "Epoch: [31] [  25/  40] time: 235.8528, loss: 0.00000761\n",
      "Epoch: [31] [  26/  40] time: 236.0171, loss: 0.00000564\n",
      "Epoch: [31] [  27/  40] time: 236.1759, loss: 0.00004112\n",
      "Epoch: [31] [  28/  40] time: 236.3361, loss: 0.00003995\n",
      "Epoch: [31] [  29/  40] time: 236.4919, loss: 0.00002692\n",
      "Epoch: [31] [  30/  40] time: 236.6495, loss: 0.00012442\n",
      "Epoch: [31] [  31/  40] time: 236.8108, loss: 0.00000240\n",
      "Epoch: [31] [  32/  40] time: 236.9892, loss: 0.00008382\n",
      "Epoch: [31] [  33/  40] time: 237.1535, loss: 0.00001761\n",
      "Epoch: [31] [  34/  40] time: 237.3258, loss: 0.00000542\n",
      "Epoch: [31] [  35/  40] time: 237.4864, loss: 0.00000546\n",
      "Epoch: [31] [  36/  40] time: 237.6546, loss: 0.00001557\n",
      "Epoch: [31] [  37/  40] time: 237.8124, loss: 0.00002079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31] [  38/  40] time: 237.9771, loss: 0.00000379\n",
      "Epoch: [31] [  39/  40] time: 238.1456, loss: 0.00000639\n",
      "[31/50] - ptime: 7.1272 loss: 0.00005281 acc: 0.80000 lr: 0.00072136\n",
      "Epoch: [32] [   0/  40] time: 239.7288, loss: 0.00000857\n",
      "Epoch: [32] [   1/  40] time: 239.8777, loss: 0.00006931\n",
      "Epoch: [32] [   2/  40] time: 240.0386, loss: 0.00012151\n",
      "Epoch: [32] [   3/  40] time: 240.1876, loss: 0.00000720\n",
      "Epoch: [32] [   4/  40] time: 240.3433, loss: 0.00001981\n",
      "Epoch: [32] [   5/  40] time: 240.4921, loss: 0.00008105\n",
      "Epoch: [32] [   6/  40] time: 240.6462, loss: 0.00000017\n",
      "Epoch: [32] [   7/  40] time: 240.7953, loss: 0.00000202\n",
      "Epoch: [32] [   8/  40] time: 240.9523, loss: 0.00002392\n",
      "Epoch: [32] [   9/  40] time: 241.1039, loss: 0.00000107\n",
      "Epoch: [32] [  10/  40] time: 241.2613, loss: 0.00000235\n",
      "Epoch: [32] [  11/  40] time: 241.4149, loss: 0.00001380\n",
      "Epoch: [32] [  12/  40] time: 241.5723, loss: 0.00032516\n",
      "Epoch: [32] [  13/  40] time: 241.7240, loss: 0.00002865\n",
      "Epoch: [32] [  14/  40] time: 241.8802, loss: 0.00002272\n",
      "Epoch: [32] [  15/  40] time: 242.0324, loss: 0.00018197\n",
      "Epoch: [32] [  16/  40] time: 242.1889, loss: 0.00000118\n",
      "Epoch: [32] [  17/  40] time: 242.3540, loss: 0.00002053\n",
      "Epoch: [32] [  18/  40] time: 242.5170, loss: 0.00000835\n",
      "Epoch: [32] [  19/  40] time: 242.6846, loss: 0.00049047\n",
      "Epoch: [32] [  20/  40] time: 242.8545, loss: 0.00008704\n",
      "Epoch: [32] [  21/  40] time: 243.0446, loss: 0.00000602\n",
      "Epoch: [32] [  22/  40] time: 243.2237, loss: 0.00000624\n",
      "Epoch: [32] [  23/  40] time: 243.3983, loss: 0.00000038\n",
      "Epoch: [32] [  24/  40] time: 243.5733, loss: 0.00001387\n",
      "Epoch: [32] [  25/  40] time: 243.7420, loss: 0.00000221\n",
      "Epoch: [32] [  26/  40] time: 243.9078, loss: 0.00001769\n",
      "Epoch: [32] [  27/  40] time: 244.0775, loss: 0.00004170\n",
      "Epoch: [32] [  28/  40] time: 244.2566, loss: 0.00003907\n",
      "Epoch: [32] [  29/  40] time: 244.4319, loss: 0.00004489\n",
      "Epoch: [32] [  30/  40] time: 244.5869, loss: 0.00000690\n",
      "Epoch: [32] [  31/  40] time: 244.7355, loss: 0.00000098\n",
      "Epoch: [32] [  32/  40] time: 244.8884, loss: 0.00000149\n",
      "Epoch: [32] [  33/  40] time: 245.0414, loss: 0.00001100\n",
      "Epoch: [32] [  34/  40] time: 245.2053, loss: 0.00000162\n",
      "Epoch: [32] [  35/  40] time: 245.3591, loss: 0.00002386\n",
      "Epoch: [32] [  36/  40] time: 245.5170, loss: 0.00007041\n",
      "Epoch: [32] [  37/  40] time: 245.6658, loss: 0.00001861\n",
      "Epoch: [32] [  38/  40] time: 245.8204, loss: 0.00006639\n",
      "Epoch: [32] [  39/  40] time: 245.9718, loss: 0.00002592\n",
      "[32/50] - ptime: 7.0952 loss: 0.00004790 acc: 0.81000 lr: 0.00071380\n",
      "Epoch: [33] [   0/  40] time: 247.3940, loss: 0.00000247\n",
      "Epoch: [33] [   1/  40] time: 247.5433, loss: 0.00000254\n",
      "Epoch: [33] [   2/  40] time: 247.6993, loss: 0.00000992\n",
      "Epoch: [33] [   3/  40] time: 247.8512, loss: 0.00004933\n",
      "Epoch: [33] [   4/  40] time: 248.0146, loss: 0.00000718\n",
      "Epoch: [33] [   5/  40] time: 248.1636, loss: 0.00000327\n",
      "Epoch: [33] [   6/  40] time: 248.3233, loss: 0.00004835\n",
      "Epoch: [33] [   7/  40] time: 248.4769, loss: 0.00006226\n",
      "Epoch: [33] [   8/  40] time: 248.6387, loss: 0.00000066\n",
      "Epoch: [33] [   9/  40] time: 248.7896, loss: 0.00000485\n",
      "Epoch: [33] [  10/  40] time: 248.9447, loss: 0.00001965\n",
      "Epoch: [33] [  11/  40] time: 249.1000, loss: 0.00000223\n",
      "Epoch: [33] [  12/  40] time: 249.2644, loss: 0.00002710\n",
      "Epoch: [33] [  13/  40] time: 249.4163, loss: 0.00000119\n",
      "Epoch: [33] [  14/  40] time: 249.5799, loss: 0.00000565\n",
      "Epoch: [33] [  15/  40] time: 249.7288, loss: 0.00005515\n",
      "Epoch: [33] [  16/  40] time: 249.8869, loss: 0.00006321\n",
      "Epoch: [33] [  17/  40] time: 250.0412, loss: 0.00002921\n",
      "Epoch: [33] [  18/  40] time: 250.2092, loss: 0.00003088\n",
      "Epoch: [33] [  19/  40] time: 250.3596, loss: 0.00010070\n",
      "Epoch: [33] [  20/  40] time: 250.5157, loss: 0.00000430\n",
      "Epoch: [33] [  21/  40] time: 250.6726, loss: 0.00003216\n",
      "Epoch: [33] [  22/  40] time: 250.8391, loss: 0.00005988\n",
      "Epoch: [33] [  23/  40] time: 250.9898, loss: 0.00000071\n",
      "Epoch: [33] [  24/  40] time: 251.1445, loss: 0.00000126\n",
      "Epoch: [33] [  25/  40] time: 251.2992, loss: 0.00000100\n",
      "Epoch: [33] [  26/  40] time: 251.4619, loss: 0.00002663\n",
      "Epoch: [33] [  27/  40] time: 251.6150, loss: 0.00000780\n",
      "Epoch: [33] [  28/  40] time: 251.7749, loss: 0.00001088\n",
      "Epoch: [33] [  29/  40] time: 251.9285, loss: 0.00014081\n",
      "Epoch: [33] [  30/  40] time: 252.1061, loss: 0.00004890\n",
      "Epoch: [33] [  31/  40] time: 252.2546, loss: 0.00001993\n",
      "Epoch: [33] [  32/  40] time: 252.4125, loss: 0.00014129\n",
      "Epoch: [33] [  33/  40] time: 252.5619, loss: 0.00000638\n",
      "Epoch: [33] [  34/  40] time: 252.7174, loss: 0.00000561\n",
      "Epoch: [33] [  35/  40] time: 252.8663, loss: 0.00000127\n",
      "Epoch: [33] [  36/  40] time: 253.0234, loss: 0.00004946\n",
      "Epoch: [33] [  37/  40] time: 253.1781, loss: 0.00000146\n",
      "Epoch: [33] [  38/  40] time: 253.3353, loss: 0.00008124\n",
      "Epoch: [33] [  39/  40] time: 253.4852, loss: 0.00003019\n",
      "[33/50] - ptime: 6.8733 loss: 0.00002992 acc: 0.80000 lr: 0.00070632\n",
      "Epoch: [34] [   0/  40] time: 254.8797, loss: 0.00001371\n",
      "Epoch: [34] [   1/  40] time: 255.0296, loss: 0.00000327\n",
      "Epoch: [34] [   2/  40] time: 255.1856, loss: 0.00000103\n",
      "Epoch: [34] [   3/  40] time: 255.3383, loss: 0.00001510\n",
      "Epoch: [34] [   4/  40] time: 255.5058, loss: 0.00002881\n",
      "Epoch: [34] [   5/  40] time: 255.6668, loss: 0.00004347\n",
      "Epoch: [34] [   6/  40] time: 255.8326, loss: 0.00003678\n",
      "Epoch: [34] [   7/  40] time: 255.9961, loss: 0.00009415\n",
      "Epoch: [34] [   8/  40] time: 256.1773, loss: 0.00000685\n",
      "Epoch: [34] [   9/  40] time: 256.3416, loss: 0.00000251\n",
      "Epoch: [34] [  10/  40] time: 256.5099, loss: 0.00002251\n",
      "Epoch: [34] [  11/  40] time: 256.6746, loss: 0.00000511\n",
      "Epoch: [34] [  12/  40] time: 256.8343, loss: 0.00000161\n",
      "Epoch: [34] [  13/  40] time: 256.9997, loss: 0.00000924\n",
      "Epoch: [34] [  14/  40] time: 257.1654, loss: 0.00000486\n",
      "Epoch: [34] [  15/  40] time: 257.3354, loss: 0.00000724\n",
      "Epoch: [34] [  16/  40] time: 257.4961, loss: 0.00001277\n",
      "Epoch: [34] [  17/  40] time: 257.6580, loss: 0.00000209\n",
      "Epoch: [34] [  18/  40] time: 257.8211, loss: 0.00000236\n",
      "Epoch: [34] [  19/  40] time: 257.9906, loss: 0.00002936\n",
      "Epoch: [34] [  20/  40] time: 258.1537, loss: 0.00000081\n",
      "Epoch: [34] [  21/  40] time: 258.3203, loss: 0.00001424\n",
      "Epoch: [34] [  22/  40] time: 258.4845, loss: 0.00000608\n",
      "Epoch: [34] [  23/  40] time: 258.6445, loss: 0.00000485\n",
      "Epoch: [34] [  24/  40] time: 258.8176, loss: 0.00000464\n",
      "Epoch: [34] [  25/  40] time: 258.9673, loss: 0.00008250\n",
      "Epoch: [34] [  26/  40] time: 259.1364, loss: 0.00001379\n",
      "Epoch: [34] [  27/  40] time: 259.2877, loss: 0.00001564\n",
      "Epoch: [34] [  28/  40] time: 259.4448, loss: 0.00006048\n",
      "Epoch: [34] [  29/  40] time: 259.6003, loss: 0.00001465\n",
      "Epoch: [34] [  30/  40] time: 259.7605, loss: 0.00000194\n",
      "Epoch: [34] [  31/  40] time: 259.9110, loss: 0.00002794\n",
      "Epoch: [34] [  32/  40] time: 260.0668, loss: 0.00000092\n",
      "Epoch: [34] [  33/  40] time: 260.2173, loss: 0.00000879\n",
      "Epoch: [34] [  34/  40] time: 260.3746, loss: 0.00000219\n",
      "Epoch: [34] [  35/  40] time: 260.5246, loss: 0.00000206\n",
      "Epoch: [34] [  36/  40] time: 260.6839, loss: 0.00003216\n",
      "Epoch: [34] [  37/  40] time: 260.8626, loss: 0.00001491\n",
      "Epoch: [34] [  38/  40] time: 261.0379, loss: 0.00007946\n",
      "Epoch: [34] [  39/  40] time: 261.2127, loss: 0.00000320\n",
      "[34/50] - ptime: 7.0849 loss: 0.00001835 acc: 0.80000 lr: 0.00069892\n",
      "Epoch: [35] [   0/  40] time: 263.2717, loss: 0.00001327\n",
      "Epoch: [35] [   1/  40] time: 263.4251, loss: 0.00002567\n",
      "Epoch: [35] [   2/  40] time: 263.6022, loss: 0.00000019\n",
      "Epoch: [35] [   3/  40] time: 263.7740, loss: 0.00000525\n",
      "Epoch: [35] [   4/  40] time: 263.9395, loss: 0.00003222\n",
      "Epoch: [35] [   5/  40] time: 264.1164, loss: 0.00000385\n",
      "Epoch: [35] [   6/  40] time: 264.2834, loss: 0.00000177\n",
      "Epoch: [35] [   7/  40] time: 264.4564, loss: 0.00001275\n",
      "Epoch: [35] [   8/  40] time: 264.6217, loss: 0.00009096\n",
      "Epoch: [35] [   9/  40] time: 264.7897, loss: 0.00000707\n",
      "Epoch: [35] [  10/  40] time: 264.9565, loss: 0.00002168\n",
      "Epoch: [35] [  11/  40] time: 265.1222, loss: 0.00003783\n",
      "Epoch: [35] [  12/  40] time: 265.2840, loss: 0.00005208\n",
      "Epoch: [35] [  13/  40] time: 265.4600, loss: 0.00001975\n",
      "Epoch: [35] [  14/  40] time: 265.6296, loss: 0.00000308\n",
      "Epoch: [35] [  15/  40] time: 265.7968, loss: 0.00000477\n",
      "Epoch: [35] [  16/  40] time: 265.9612, loss: 0.00031363\n",
      "Epoch: [35] [  17/  40] time: 266.1485, loss: 0.00002344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35] [  18/  40] time: 266.3111, loss: 0.00000140\n",
      "Epoch: [35] [  19/  40] time: 266.4911, loss: 0.00001276\n",
      "Epoch: [35] [  20/  40] time: 266.6536, loss: 0.00000112\n",
      "Epoch: [35] [  21/  40] time: 266.8234, loss: 0.00005341\n",
      "Epoch: [35] [  22/  40] time: 267.0009, loss: 0.00004144\n",
      "Epoch: [35] [  23/  40] time: 267.1659, loss: 0.00001383\n",
      "Epoch: [35] [  24/  40] time: 267.3381, loss: 0.00000274\n",
      "Epoch: [35] [  25/  40] time: 267.5023, loss: 0.00005257\n",
      "Epoch: [35] [  26/  40] time: 267.6844, loss: 0.00034424\n",
      "Epoch: [35] [  27/  40] time: 267.8354, loss: 0.00000497\n",
      "Epoch: [35] [  28/  40] time: 267.9932, loss: 0.00004734\n",
      "Epoch: [35] [  29/  40] time: 268.1433, loss: 0.00003187\n",
      "Epoch: [35] [  30/  40] time: 268.2975, loss: 0.00000133\n",
      "Epoch: [35] [  31/  40] time: 268.4549, loss: 0.00064091\n",
      "Epoch: [35] [  32/  40] time: 268.6182, loss: 0.00002484\n",
      "Epoch: [35] [  33/  40] time: 268.7675, loss: 0.00029297\n",
      "Epoch: [35] [  34/  40] time: 268.9278, loss: 0.00000474\n",
      "Epoch: [35] [  35/  40] time: 269.0777, loss: 0.00000141\n",
      "Epoch: [35] [  36/  40] time: 269.2403, loss: 0.00016630\n",
      "Epoch: [35] [  37/  40] time: 269.3935, loss: 0.00004292\n",
      "Epoch: [35] [  38/  40] time: 269.5556, loss: 0.00000036\n",
      "Epoch: [35] [  39/  40] time: 269.7094, loss: 0.00136621\n",
      "[35/50] - ptime: 7.3152 loss: 0.00009547 acc: 0.77000 lr: 0.00069159\n",
      "Epoch: [36] [   0/  40] time: 271.0767, loss: 0.00002700\n",
      "Epoch: [36] [   1/  40] time: 271.2250, loss: 0.00005737\n",
      "Epoch: [36] [   2/  40] time: 271.3879, loss: 0.04575307\n",
      "Epoch: [36] [   3/  40] time: 271.5367, loss: 0.00000665\n",
      "Epoch: [36] [   4/  40] time: 271.6931, loss: 0.00006175\n",
      "Epoch: [36] [   5/  40] time: 271.8435, loss: 0.00081218\n",
      "Epoch: [36] [   6/  40] time: 271.9967, loss: 0.00000723\n",
      "Epoch: [36] [   7/  40] time: 272.1452, loss: 0.00004526\n",
      "Epoch: [36] [   8/  40] time: 272.3024, loss: 0.00004041\n",
      "Epoch: [36] [   9/  40] time: 272.4563, loss: 0.00010693\n",
      "Epoch: [36] [  10/  40] time: 272.6125, loss: 0.00002289\n",
      "Epoch: [36] [  11/  40] time: 272.7640, loss: 0.00026781\n",
      "Epoch: [36] [  12/  40] time: 272.9199, loss: 0.00036700\n",
      "Epoch: [36] [  13/  40] time: 273.0718, loss: 0.00154904\n",
      "Epoch: [36] [  14/  40] time: 273.2450, loss: 0.00003365\n",
      "Epoch: [36] [  15/  40] time: 273.4013, loss: 0.00045263\n",
      "Epoch: [36] [  16/  40] time: 273.5592, loss: 0.00000553\n",
      "Epoch: [36] [  17/  40] time: 273.7089, loss: 0.00000701\n",
      "Epoch: [36] [  18/  40] time: 273.8718, loss: 0.00005082\n",
      "Epoch: [36] [  19/  40] time: 274.0215, loss: 0.00000573\n",
      "Epoch: [36] [  20/  40] time: 274.1877, loss: 0.00002326\n",
      "Epoch: [36] [  21/  40] time: 274.3369, loss: 0.00206056\n",
      "Epoch: [36] [  22/  40] time: 274.5023, loss: 0.00110230\n",
      "Epoch: [36] [  23/  40] time: 274.6515, loss: 0.00001812\n",
      "Epoch: [36] [  24/  40] time: 274.8083, loss: 0.00001889\n",
      "Epoch: [36] [  25/  40] time: 274.9605, loss: 0.00006057\n",
      "Epoch: [36] [  26/  40] time: 275.1194, loss: 0.00000108\n",
      "Epoch: [36] [  27/  40] time: 275.2699, loss: 0.00000059\n",
      "Epoch: [36] [  28/  40] time: 275.4270, loss: 0.00226031\n",
      "Epoch: [36] [  29/  40] time: 275.5763, loss: 0.00000379\n",
      "Epoch: [36] [  30/  40] time: 275.7345, loss: 0.00005302\n",
      "Epoch: [36] [  31/  40] time: 275.8929, loss: 0.00027033\n",
      "Epoch: [36] [  32/  40] time: 276.0571, loss: 0.00007802\n",
      "Epoch: [36] [  33/  40] time: 276.2053, loss: 0.00006633\n",
      "Epoch: [36] [  34/  40] time: 276.3603, loss: 0.00007338\n",
      "Epoch: [36] [  35/  40] time: 276.5163, loss: 0.00000830\n",
      "Epoch: [36] [  36/  40] time: 276.6790, loss: 0.00009092\n",
      "Epoch: [36] [  37/  40] time: 276.8346, loss: 0.00044447\n",
      "Epoch: [36] [  38/  40] time: 276.9967, loss: 0.00009981\n",
      "Epoch: [36] [  39/  40] time: 277.1508, loss: 0.00002726\n",
      "[36/50] - ptime: 6.8513 loss: 0.00141103 acc: 0.78000 lr: 0.00068434\n",
      "Epoch: [37] [   0/  40] time: 278.6503, loss: 0.00042247\n",
      "Epoch: [37] [   1/  40] time: 278.7982, loss: 0.00005803\n",
      "Epoch: [37] [   2/  40] time: 278.9545, loss: 0.00008584\n",
      "Epoch: [37] [   3/  40] time: 279.1060, loss: 0.00018007\n",
      "Epoch: [37] [   4/  40] time: 279.2645, loss: 0.00009301\n",
      "Epoch: [37] [   5/  40] time: 279.4167, loss: 0.00009566\n",
      "Epoch: [37] [   6/  40] time: 279.5731, loss: 0.00001695\n",
      "Epoch: [37] [   7/  40] time: 279.7257, loss: 0.00000321\n",
      "Epoch: [37] [   8/  40] time: 279.9075, loss: 0.00001007\n",
      "Epoch: [37] [   9/  40] time: 280.0581, loss: 0.00089533\n",
      "Epoch: [37] [  10/  40] time: 280.2184, loss: 0.00007139\n",
      "Epoch: [37] [  11/  40] time: 280.3708, loss: 0.00007190\n",
      "Epoch: [37] [  12/  40] time: 280.5414, loss: 0.00000527\n",
      "Epoch: [37] [  13/  40] time: 280.6953, loss: 0.00001641\n",
      "Epoch: [37] [  14/  40] time: 280.8523, loss: 0.00002907\n",
      "Epoch: [37] [  15/  40] time: 281.0201, loss: 0.00001320\n",
      "Epoch: [37] [  16/  40] time: 281.1836, loss: 0.00004456\n",
      "Epoch: [37] [  17/  40] time: 281.3356, loss: 0.00000296\n",
      "Epoch: [37] [  18/  40] time: 281.4979, loss: 0.00001463\n",
      "Epoch: [37] [  19/  40] time: 281.6624, loss: 0.00006608\n",
      "Epoch: [37] [  20/  40] time: 281.8175, loss: 0.00015846\n",
      "Epoch: [37] [  21/  40] time: 281.9686, loss: 0.00000381\n",
      "Epoch: [37] [  22/  40] time: 282.1301, loss: 0.00007404\n",
      "Epoch: [37] [  23/  40] time: 282.2783, loss: 0.00000115\n",
      "Epoch: [37] [  24/  40] time: 282.4330, loss: 0.00039304\n",
      "Epoch: [37] [  25/  40] time: 282.5843, loss: 0.00005106\n",
      "Epoch: [37] [  26/  40] time: 282.7392, loss: 0.00001400\n",
      "Epoch: [37] [  27/  40] time: 282.8923, loss: 0.00000721\n",
      "Epoch: [37] [  28/  40] time: 283.0664, loss: 0.00004627\n",
      "Epoch: [37] [  29/  40] time: 283.2157, loss: 0.00000828\n",
      "Epoch: [37] [  30/  40] time: 283.3912, loss: 0.00000870\n",
      "Epoch: [37] [  31/  40] time: 283.5440, loss: 0.00004940\n",
      "Epoch: [37] [  32/  40] time: 283.7109, loss: 0.00002465\n",
      "Epoch: [37] [  33/  40] time: 283.8637, loss: 0.00004054\n",
      "Epoch: [37] [  34/  40] time: 284.0268, loss: 0.00000342\n",
      "Epoch: [37] [  35/  40] time: 284.1944, loss: 0.00003690\n",
      "Epoch: [37] [  36/  40] time: 284.3616, loss: 0.00017979\n",
      "Epoch: [37] [  37/  40] time: 284.5255, loss: 0.00001716\n",
      "Epoch: [37] [  38/  40] time: 284.6885, loss: 0.00000281\n",
      "Epoch: [37] [  39/  40] time: 284.8578, loss: 0.00001874\n",
      "[37/50] - ptime: 6.9465 loss: 0.00008339 acc: 0.80000 lr: 0.00068434\n",
      "Epoch: [38] [   0/  40] time: 286.4555, loss: 0.00000847\n",
      "Epoch: [38] [   1/  40] time: 286.6316, loss: 0.00001558\n",
      "Epoch: [38] [   2/  40] time: 286.8074, loss: 0.00001788\n",
      "Epoch: [38] [   3/  40] time: 286.9812, loss: 0.00007496\n",
      "Epoch: [38] [   4/  40] time: 287.1509, loss: 0.00000484\n",
      "Epoch: [38] [   5/  40] time: 287.3208, loss: 0.00002661\n",
      "Epoch: [38] [   6/  40] time: 287.4896, loss: 0.00000194\n",
      "Epoch: [38] [   7/  40] time: 287.6545, loss: 0.00015486\n",
      "Epoch: [38] [   8/  40] time: 287.8235, loss: 0.00000769\n",
      "Epoch: [38] [   9/  40] time: 287.9827, loss: 0.00028244\n",
      "Epoch: [38] [  10/  40] time: 288.1413, loss: 0.00001042\n",
      "Epoch: [38] [  11/  40] time: 288.3213, loss: 0.00010718\n",
      "Epoch: [38] [  12/  40] time: 288.4904, loss: 0.00008287\n",
      "Epoch: [38] [  13/  40] time: 288.6509, loss: 0.00000650\n",
      "Epoch: [38] [  14/  40] time: 288.8156, loss: 0.00000122\n",
      "Epoch: [38] [  15/  40] time: 288.9854, loss: 0.00000805\n",
      "Epoch: [38] [  16/  40] time: 289.1544, loss: 0.00000637\n",
      "Epoch: [38] [  17/  40] time: 289.3237, loss: 0.00000458\n",
      "Epoch: [38] [  18/  40] time: 289.4915, loss: 0.00008901\n",
      "Epoch: [38] [  19/  40] time: 289.6590, loss: 0.00007296\n",
      "Epoch: [38] [  20/  40] time: 289.8230, loss: 0.00000349\n",
      "Epoch: [38] [  21/  40] time: 289.9773, loss: 0.00002287\n",
      "Epoch: [38] [  22/  40] time: 290.1369, loss: 0.00000721\n",
      "Epoch: [38] [  23/  40] time: 290.2860, loss: 0.00005426\n",
      "Epoch: [38] [  24/  40] time: 290.4423, loss: 0.00000894\n",
      "Epoch: [38] [  25/  40] time: 290.6014, loss: 0.00027277\n",
      "Epoch: [38] [  26/  40] time: 290.7708, loss: 0.00000293\n",
      "Epoch: [38] [  27/  40] time: 290.9231, loss: 0.00000551\n",
      "Epoch: [38] [  28/  40] time: 291.0837, loss: 0.00001623\n",
      "Epoch: [38] [  29/  40] time: 291.2399, loss: 0.00021972\n",
      "Epoch: [38] [  30/  40] time: 291.3992, loss: 0.00000140\n",
      "Epoch: [38] [  31/  40] time: 291.5500, loss: 0.00002420\n",
      "Epoch: [38] [  32/  40] time: 291.7050, loss: 0.00000198\n",
      "Epoch: [38] [  33/  40] time: 291.8553, loss: 0.00002832\n",
      "Epoch: [38] [  34/  40] time: 292.0123, loss: 0.00065865\n",
      "Epoch: [38] [  35/  40] time: 292.1619, loss: 0.00022845\n",
      "Epoch: [38] [  36/  40] time: 292.3171, loss: 0.00048636\n",
      "Epoch: [38] [  37/  40] time: 292.4683, loss: 0.00001343\n",
      "Epoch: [38] [  38/  40] time: 292.6250, loss: 0.00002892\n",
      "Epoch: [38] [  39/  40] time: 292.7767, loss: 0.00005424\n",
      "[38/50] - ptime: 7.1561 loss: 0.00007811 acc: 0.80000 lr: 0.00067717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [39] [   0/  40] time: 294.0925, loss: 0.00007590\n",
      "Epoch: [39] [   1/  40] time: 294.2521, loss: 0.00007666\n",
      "Epoch: [39] [   2/  40] time: 294.4219, loss: 0.00000092\n",
      "Epoch: [39] [   3/  40] time: 294.5708, loss: 0.00000129\n",
      "Epoch: [39] [   4/  40] time: 294.7324, loss: 0.00017422\n",
      "Epoch: [39] [   5/  40] time: 294.8829, loss: 0.00005605\n",
      "Epoch: [39] [   6/  40] time: 295.0387, loss: 0.00030538\n",
      "Epoch: [39] [   7/  40] time: 295.1873, loss: 0.00000067\n",
      "Epoch: [39] [   8/  40] time: 295.3446, loss: 0.00017702\n",
      "Epoch: [39] [   9/  40] time: 295.4960, loss: 0.00002023\n",
      "Epoch: [39] [  10/  40] time: 295.6681, loss: 0.00008377\n",
      "Epoch: [39] [  11/  40] time: 295.8176, loss: 0.00000649\n",
      "Epoch: [39] [  12/  40] time: 295.9795, loss: 0.00001069\n",
      "Epoch: [39] [  13/  40] time: 296.1317, loss: 0.00000319\n",
      "Epoch: [39] [  14/  40] time: 296.2884, loss: 0.00000760\n",
      "Epoch: [39] [  15/  40] time: 296.4460, loss: 0.00000832\n",
      "Epoch: [39] [  16/  40] time: 296.6046, loss: 0.00000586\n",
      "Epoch: [39] [  17/  40] time: 296.7529, loss: 0.00001512\n",
      "Epoch: [39] [  18/  40] time: 296.9078, loss: 0.00000098\n",
      "Epoch: [39] [  19/  40] time: 297.0591, loss: 0.00000748\n",
      "Epoch: [39] [  20/  40] time: 297.2159, loss: 0.00000276\n",
      "Epoch: [39] [  21/  40] time: 297.3687, loss: 0.00003159\n",
      "Epoch: [39] [  22/  40] time: 297.5337, loss: 0.00000297\n",
      "Epoch: [39] [  23/  40] time: 297.6824, loss: 0.00009298\n",
      "Epoch: [39] [  24/  40] time: 297.8390, loss: 0.00002267\n",
      "Epoch: [39] [  25/  40] time: 297.9904, loss: 0.00002455\n",
      "Epoch: [39] [  26/  40] time: 298.1652, loss: 0.00000928\n",
      "Epoch: [39] [  27/  40] time: 298.3138, loss: 0.00000858\n",
      "Epoch: [39] [  28/  40] time: 298.4709, loss: 0.00003358\n",
      "Epoch: [39] [  29/  40] time: 298.6212, loss: 0.00000136\n",
      "Epoch: [39] [  30/  40] time: 298.7770, loss: 0.00000081\n",
      "Epoch: [39] [  31/  40] time: 298.9305, loss: 0.00000062\n",
      "Epoch: [39] [  32/  40] time: 299.0870, loss: 0.00002382\n",
      "Epoch: [39] [  33/  40] time: 299.2402, loss: 0.00001773\n",
      "Epoch: [39] [  34/  40] time: 299.4061, loss: 0.00004496\n",
      "Epoch: [39] [  35/  40] time: 299.5581, loss: 0.00000580\n",
      "Epoch: [39] [  36/  40] time: 299.7126, loss: 0.00017418\n",
      "Epoch: [39] [  37/  40] time: 299.8621, loss: 0.00000890\n",
      "Epoch: [39] [  38/  40] time: 300.0185, loss: 0.00009627\n",
      "Epoch: [39] [  39/  40] time: 300.1765, loss: 0.00001953\n",
      "[39/50] - ptime: 6.8276 loss: 0.00004152 acc: 0.80000 lr: 0.00067007\n",
      "Epoch: [40] [   0/  40] time: 301.4882, loss: 0.00001482\n",
      "Epoch: [40] [   1/  40] time: 301.6411, loss: 0.00000023\n",
      "Epoch: [40] [   2/  40] time: 301.8015, loss: 0.00001215\n",
      "Epoch: [40] [   3/  40] time: 301.9542, loss: 0.00007565\n",
      "Epoch: [40] [   4/  40] time: 302.1130, loss: 0.00010317\n",
      "Epoch: [40] [   5/  40] time: 302.2669, loss: 0.00001139\n",
      "Epoch: [40] [   6/  40] time: 302.4362, loss: 0.00011039\n",
      "Epoch: [40] [   7/  40] time: 302.5873, loss: 0.00000085\n",
      "Epoch: [40] [   8/  40] time: 302.7522, loss: 0.00004945\n",
      "Epoch: [40] [   9/  40] time: 302.9016, loss: 0.00001672\n",
      "Epoch: [40] [  10/  40] time: 303.0574, loss: 0.00001522\n",
      "Epoch: [40] [  11/  40] time: 303.2082, loss: 0.00000832\n",
      "Epoch: [40] [  12/  40] time: 303.3751, loss: 0.00000542\n",
      "Epoch: [40] [  13/  40] time: 303.5320, loss: 0.00001682\n",
      "Epoch: [40] [  14/  40] time: 303.7055, loss: 0.00002194\n",
      "Epoch: [40] [  15/  40] time: 303.8553, loss: 0.00000657\n",
      "Epoch: [40] [  16/  40] time: 304.0119, loss: 0.00001516\n",
      "Epoch: [40] [  17/  40] time: 304.1623, loss: 0.00000073\n",
      "Epoch: [40] [  18/  40] time: 304.3185, loss: 0.00000772\n",
      "Epoch: [40] [  19/  40] time: 304.4758, loss: 0.00000113\n",
      "Epoch: [40] [  20/  40] time: 304.6317, loss: 0.00000055\n",
      "Epoch: [40] [  21/  40] time: 304.7820, loss: 0.00000509\n",
      "Epoch: [40] [  22/  40] time: 304.9377, loss: 0.00002591\n",
      "Epoch: [40] [  23/  40] time: 305.0886, loss: 0.00000082\n",
      "Epoch: [40] [  24/  40] time: 305.2444, loss: 0.00000028\n",
      "Epoch: [40] [  25/  40] time: 305.3947, loss: 0.00000161\n",
      "Epoch: [40] [  26/  40] time: 305.5509, loss: 0.00010792\n",
      "Epoch: [40] [  27/  40] time: 305.6997, loss: 0.00001641\n",
      "Epoch: [40] [  28/  40] time: 305.8573, loss: 0.00012892\n",
      "Epoch: [40] [  29/  40] time: 306.0131, loss: 0.00000586\n",
      "Epoch: [40] [  30/  40] time: 306.1771, loss: 0.00000283\n",
      "Epoch: [40] [  31/  40] time: 306.3449, loss: 0.00004801\n",
      "Epoch: [40] [  32/  40] time: 306.5146, loss: 0.00000023\n",
      "Epoch: [40] [  33/  40] time: 306.6885, loss: 0.00001114\n",
      "Epoch: [40] [  34/  40] time: 306.8588, loss: 0.00000474\n",
      "Epoch: [40] [  35/  40] time: 307.0234, loss: 0.00001747\n",
      "Epoch: [40] [  36/  40] time: 307.1916, loss: 0.00001424\n",
      "Epoch: [40] [  37/  40] time: 307.3572, loss: 0.00004034\n",
      "Epoch: [40] [  38/  40] time: 307.5252, loss: 0.00000010\n",
      "Epoch: [40] [  39/  40] time: 307.6892, loss: 0.00000991\n",
      "[40/50] - ptime: 6.9365 loss: 0.00002341 acc: 0.80000 lr: 0.00065610\n",
      "Epoch: [41] [   0/  40] time: 309.1835, loss: 0.00000038\n",
      "Epoch: [41] [   1/  40] time: 309.3435, loss: 0.00000355\n",
      "Epoch: [41] [   2/  40] time: 309.5068, loss: 0.00000396\n",
      "Epoch: [41] [   3/  40] time: 309.6686, loss: 0.00000315\n",
      "Epoch: [41] [   4/  40] time: 309.8459, loss: 0.00107358\n",
      "Epoch: [41] [   5/  40] time: 310.0099, loss: 0.00003559\n",
      "Epoch: [41] [   6/  40] time: 310.1806, loss: 0.00001996\n",
      "Epoch: [41] [   7/  40] time: 310.3509, loss: 0.00000659\n",
      "Epoch: [41] [   8/  40] time: 310.5186, loss: 0.00004335\n",
      "Epoch: [41] [   9/  40] time: 310.7003, loss: 0.00000128\n",
      "Epoch: [41] [  10/  40] time: 310.8640, loss: 0.00015250\n",
      "Epoch: [41] [  11/  40] time: 311.0268, loss: 0.00007054\n",
      "Epoch: [41] [  12/  40] time: 311.1913, loss: 0.00000892\n",
      "Epoch: [41] [  13/  40] time: 311.3481, loss: 0.00000210\n",
      "Epoch: [41] [  14/  40] time: 311.5214, loss: 0.00000411\n",
      "Epoch: [41] [  15/  40] time: 311.6754, loss: 0.00000785\n",
      "Epoch: [41] [  16/  40] time: 311.8429, loss: 0.00001822\n",
      "Epoch: [41] [  17/  40] time: 312.0021, loss: 0.00018941\n",
      "Epoch: [41] [  18/  40] time: 312.1638, loss: 0.00000098\n",
      "Epoch: [41] [  19/  40] time: 312.3335, loss: 0.00001584\n",
      "Epoch: [41] [  20/  40] time: 312.5024, loss: 0.00001586\n",
      "Epoch: [41] [  21/  40] time: 312.6661, loss: 0.00000620\n",
      "Epoch: [41] [  22/  40] time: 312.8313, loss: 0.00000109\n",
      "Epoch: [41] [  23/  40] time: 312.9820, loss: 0.00000055\n",
      "Epoch: [41] [  24/  40] time: 313.1381, loss: 0.00021061\n",
      "Epoch: [41] [  25/  40] time: 313.2887, loss: 0.00011542\n",
      "Epoch: [41] [  26/  40] time: 313.4587, loss: 0.00000029\n",
      "Epoch: [41] [  27/  40] time: 313.6089, loss: 0.00000642\n",
      "Epoch: [41] [  28/  40] time: 313.7735, loss: 0.00001791\n",
      "Epoch: [41] [  29/  40] time: 313.9230, loss: 0.00002443\n",
      "Epoch: [41] [  30/  40] time: 314.0804, loss: 0.00000218\n",
      "Epoch: [41] [  31/  40] time: 314.2372, loss: 0.00005255\n",
      "Epoch: [41] [  32/  40] time: 314.4107, loss: 0.00000349\n",
      "Epoch: [41] [  33/  40] time: 314.5791, loss: 0.00000147\n",
      "Epoch: [41] [  34/  40] time: 314.7445, loss: 0.00002519\n",
      "Epoch: [41] [  35/  40] time: 314.9083, loss: 0.00001114\n",
      "Epoch: [41] [  36/  40] time: 315.0697, loss: 0.00001183\n",
      "Epoch: [41] [  37/  40] time: 315.2257, loss: 0.00000136\n",
      "Epoch: [41] [  38/  40] time: 315.4055, loss: 0.00002712\n",
      "Epoch: [41] [  39/  40] time: 315.5661, loss: 0.00002756\n",
      "[41/50] - ptime: 7.2277 loss: 0.00005561 acc: 0.80000 lr: 0.00065610\n",
      "Epoch: [42] [   0/  40] time: 317.0324, loss: 0.00000635\n",
      "Epoch: [42] [   1/  40] time: 317.1909, loss: 0.00001148\n",
      "Epoch: [42] [   2/  40] time: 317.3551, loss: 0.00000724\n",
      "Epoch: [42] [   3/  40] time: 317.5189, loss: 0.00010172\n",
      "Epoch: [42] [   4/  40] time: 317.6827, loss: 0.00015652\n",
      "Epoch: [42] [   5/  40] time: 317.8538, loss: 0.00000614\n",
      "Epoch: [42] [   6/  40] time: 318.0270, loss: 0.00001324\n",
      "Epoch: [42] [   7/  40] time: 318.1909, loss: 0.00000361\n",
      "Epoch: [42] [   8/  40] time: 318.3567, loss: 0.00000612\n",
      "Epoch: [42] [   9/  40] time: 318.5112, loss: 0.00034093\n",
      "Epoch: [42] [  10/  40] time: 318.6853, loss: 0.00000183\n",
      "Epoch: [42] [  11/  40] time: 318.8433, loss: 0.00013496\n",
      "Epoch: [42] [  12/  40] time: 319.0173, loss: 0.00000123\n",
      "Epoch: [42] [  13/  40] time: 319.1807, loss: 0.00000415\n",
      "Epoch: [42] [  14/  40] time: 319.3403, loss: 0.00000644\n",
      "Epoch: [42] [  15/  40] time: 319.4976, loss: 0.00002279\n",
      "Epoch: [42] [  16/  40] time: 319.6633, loss: 0.00017139\n",
      "Epoch: [42] [  17/  40] time: 319.8221, loss: 0.00005758\n",
      "Epoch: [42] [  18/  40] time: 319.9785, loss: 0.00028100\n",
      "Epoch: [42] [  19/  40] time: 320.1348, loss: 0.00000149\n",
      "Epoch: [42] [  20/  40] time: 320.2910, loss: 0.00012766\n",
      "Epoch: [42] [  21/  40] time: 320.4615, loss: 0.00000066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [42] [  22/  40] time: 320.6282, loss: 0.00000034\n",
      "Epoch: [42] [  23/  40] time: 320.7935, loss: 0.00001698\n",
      "Epoch: [42] [  24/  40] time: 320.9665, loss: 0.00001534\n",
      "Epoch: [42] [  25/  40] time: 321.1299, loss: 0.00000225\n",
      "Epoch: [42] [  26/  40] time: 321.2956, loss: 0.00000458\n",
      "Epoch: [42] [  27/  40] time: 321.4617, loss: 0.00000180\n",
      "Epoch: [42] [  28/  40] time: 321.6515, loss: 0.00000299\n",
      "Epoch: [42] [  29/  40] time: 321.8223, loss: 0.00000740\n",
      "Epoch: [42] [  30/  40] time: 321.9894, loss: 0.00000812\n",
      "Epoch: [42] [  31/  40] time: 322.1649, loss: 0.00003682\n",
      "Epoch: [42] [  32/  40] time: 322.3282, loss: 0.00002156\n",
      "Epoch: [42] [  33/  40] time: 322.4933, loss: 0.00000126\n",
      "Epoch: [42] [  34/  40] time: 322.6548, loss: 0.00004510\n",
      "Epoch: [42] [  35/  40] time: 322.8259, loss: 0.00000237\n",
      "Epoch: [42] [  36/  40] time: 322.9988, loss: 0.00000017\n",
      "Epoch: [42] [  37/  40] time: 323.1781, loss: 0.00002239\n",
      "Epoch: [42] [  38/  40] time: 323.3350, loss: 0.00000109\n",
      "Epoch: [42] [  39/  40] time: 323.4958, loss: 0.00000564\n",
      "[42/50] - ptime: 7.2584 loss: 0.00004152 acc: 0.77000 lr: 0.00064242\n",
      "Epoch: [43] [   0/  40] time: 324.9895, loss: 0.00002708\n",
      "Epoch: [43] [   1/  40] time: 325.1543, loss: 0.00000064\n",
      "Epoch: [43] [   2/  40] time: 325.3252, loss: 0.00000074\n",
      "Epoch: [43] [   3/  40] time: 325.5006, loss: 0.00000054\n",
      "Epoch: [43] [   4/  40] time: 325.6764, loss: 0.00000001\n",
      "Epoch: [43] [   5/  40] time: 325.8525, loss: 0.00000086\n",
      "Epoch: [43] [   6/  40] time: 326.0183, loss: 0.00000117\n",
      "Epoch: [43] [   7/  40] time: 326.1841, loss: 0.00000232\n",
      "Epoch: [43] [   8/  40] time: 326.3527, loss: 0.00000044\n",
      "Epoch: [43] [   9/  40] time: 326.5199, loss: 0.00013249\n",
      "Epoch: [43] [  10/  40] time: 326.6832, loss: 0.00001449\n",
      "Epoch: [43] [  11/  40] time: 326.8401, loss: 0.00048306\n",
      "Epoch: [43] [  12/  40] time: 327.0146, loss: 0.00001822\n",
      "Epoch: [43] [  13/  40] time: 327.1781, loss: 0.00006497\n",
      "Epoch: [43] [  14/  40] time: 327.3444, loss: 0.00000614\n",
      "Epoch: [43] [  15/  40] time: 327.5027, loss: 0.00000705\n",
      "Epoch: [43] [  16/  40] time: 327.6617, loss: 0.00001936\n",
      "Epoch: [43] [  17/  40] time: 327.8146, loss: 0.00000053\n",
      "Epoch: [43] [  18/  40] time: 327.9705, loss: 0.00000882\n",
      "Epoch: [43] [  19/  40] time: 328.1202, loss: 0.00000027\n",
      "Epoch: [43] [  20/  40] time: 328.2758, loss: 0.00000183\n",
      "Epoch: [43] [  21/  40] time: 328.4399, loss: 0.00002565\n",
      "Epoch: [43] [  22/  40] time: 328.6075, loss: 0.00000282\n",
      "Epoch: [43] [  23/  40] time: 328.7693, loss: 0.00000073\n",
      "Epoch: [43] [  24/  40] time: 328.9435, loss: 0.00000291\n",
      "Epoch: [43] [  25/  40] time: 329.1117, loss: 0.00001694\n",
      "Epoch: [43] [  26/  40] time: 329.2878, loss: 0.00164167\n",
      "Epoch: [43] [  27/  40] time: 329.4508, loss: 0.00000857\n",
      "Epoch: [43] [  28/  40] time: 329.6166, loss: 0.00006499\n",
      "Epoch: [43] [  29/  40] time: 329.7782, loss: 0.00074879\n",
      "Epoch: [43] [  30/  40] time: 329.9469, loss: 0.00000236\n",
      "Epoch: [43] [  31/  40] time: 330.1084, loss: 0.00003722\n",
      "Epoch: [43] [  32/  40] time: 330.2688, loss: 0.00000420\n",
      "Epoch: [43] [  33/  40] time: 330.4321, loss: 0.00000144\n",
      "Epoch: [43] [  34/  40] time: 330.5933, loss: 0.00000311\n",
      "Epoch: [43] [  35/  40] time: 330.7489, loss: 0.00000579\n",
      "Epoch: [43] [  36/  40] time: 330.9093, loss: 0.00001693\n",
      "Epoch: [43] [  37/  40] time: 331.0695, loss: 0.00005381\n",
      "Epoch: [43] [  38/  40] time: 331.2300, loss: 0.00002190\n",
      "Epoch: [43] [  39/  40] time: 331.3788, loss: 0.00004289\n",
      "[43/50] - ptime: 7.2510 loss: 0.00008734 acc: 0.79000 lr: 0.00064242\n",
      "Epoch: [44] [   0/  40] time: 332.7874, loss: 0.00000113\n",
      "Epoch: [44] [   1/  40] time: 332.9359, loss: 0.00001469\n",
      "Epoch: [44] [   2/  40] time: 333.0935, loss: 0.00000075\n",
      "Epoch: [44] [   3/  40] time: 333.2457, loss: 0.00001190\n",
      "Epoch: [44] [   4/  40] time: 333.4015, loss: 0.00008830\n",
      "Epoch: [44] [   5/  40] time: 333.5549, loss: 0.00020081\n",
      "Epoch: [44] [   6/  40] time: 333.7236, loss: 0.00000061\n",
      "Epoch: [44] [   7/  40] time: 333.8728, loss: 0.00001399\n",
      "Epoch: [44] [   8/  40] time: 334.0338, loss: 0.00006624\n",
      "Epoch: [44] [   9/  40] time: 334.1845, loss: 0.00004274\n",
      "Epoch: [44] [  10/  40] time: 334.3405, loss: 0.00000966\n",
      "Epoch: [44] [  11/  40] time: 334.4880, loss: 0.00001774\n",
      "Epoch: [44] [  12/  40] time: 334.6509, loss: 0.00000867\n",
      "Epoch: [44] [  13/  40] time: 334.7984, loss: 0.00002812\n",
      "Epoch: [44] [  14/  40] time: 334.9542, loss: 0.00000338\n",
      "Epoch: [44] [  15/  40] time: 335.1046, loss: 0.00011742\n",
      "Epoch: [44] [  16/  40] time: 335.2589, loss: 0.00000117\n",
      "Epoch: [44] [  17/  40] time: 335.4066, loss: 0.00004186\n",
      "Epoch: [44] [  18/  40] time: 335.5619, loss: 0.00003902\n",
      "Epoch: [44] [  19/  40] time: 335.7143, loss: 0.00000171\n",
      "Epoch: [44] [  20/  40] time: 335.8691, loss: 0.00002211\n",
      "Epoch: [44] [  21/  40] time: 336.0182, loss: 0.00015485\n",
      "Epoch: [44] [  22/  40] time: 336.1730, loss: 0.00000495\n",
      "Epoch: [44] [  23/  40] time: 336.3207, loss: 0.00004645\n",
      "Epoch: [44] [  24/  40] time: 336.4789, loss: 0.00002077\n",
      "Epoch: [44] [  25/  40] time: 336.6297, loss: 0.00001894\n",
      "Epoch: [44] [  26/  40] time: 336.7838, loss: 0.00000968\n",
      "Epoch: [44] [  27/  40] time: 336.9379, loss: 0.00000232\n",
      "Epoch: [44] [  28/  40] time: 337.0927, loss: 0.00001404\n",
      "Epoch: [44] [  29/  40] time: 337.2418, loss: 0.00000913\n",
      "Epoch: [44] [  30/  40] time: 337.3961, loss: 0.00004192\n",
      "Epoch: [44] [  31/  40] time: 337.5460, loss: 0.00000373\n",
      "Epoch: [44] [  32/  40] time: 337.7012, loss: 0.00003664\n",
      "Epoch: [44] [  33/  40] time: 337.8488, loss: 0.00001806\n",
      "Epoch: [44] [  34/  40] time: 338.0029, loss: 0.00000424\n",
      "Epoch: [44] [  35/  40] time: 338.1501, loss: 0.00017311\n",
      "Epoch: [44] [  36/  40] time: 338.3037, loss: 0.00001179\n",
      "Epoch: [44] [  37/  40] time: 338.4530, loss: 0.00024376\n",
      "Epoch: [44] [  38/  40] time: 338.6077, loss: 0.00000082\n",
      "Epoch: [44] [  39/  40] time: 338.7562, loss: 0.00006828\n",
      "[44/50] - ptime: 6.7448 loss: 0.00004039 acc: 0.78000 lr: 0.00062902\n",
      "Epoch: [45] [   0/  40] time: 340.0776, loss: 0.00000246\n",
      "Epoch: [45] [   1/  40] time: 340.2248, loss: 0.00007781\n",
      "Epoch: [45] [   2/  40] time: 340.3800, loss: 0.00000093\n",
      "Epoch: [45] [   3/  40] time: 340.5301, loss: 0.00000663\n",
      "Epoch: [45] [   4/  40] time: 340.6841, loss: 0.00000145\n",
      "Epoch: [45] [   5/  40] time: 340.8369, loss: 0.00029444\n",
      "Epoch: [45] [   6/  40] time: 340.9917, loss: 0.00000438\n",
      "Epoch: [45] [   7/  40] time: 341.1395, loss: 0.00000012\n",
      "Epoch: [45] [   8/  40] time: 341.2943, loss: 0.00000766\n",
      "Epoch: [45] [   9/  40] time: 341.4430, loss: 0.00000337\n",
      "Epoch: [45] [  10/  40] time: 341.5984, loss: 0.00000416\n",
      "Epoch: [45] [  11/  40] time: 341.7461, loss: 0.00002215\n",
      "Epoch: [45] [  12/  40] time: 341.8997, loss: 0.00000146\n",
      "Epoch: [45] [  13/  40] time: 342.0500, loss: 0.00005861\n",
      "Epoch: [45] [  14/  40] time: 342.2076, loss: 0.00001334\n",
      "Epoch: [45] [  15/  40] time: 342.3569, loss: 0.00009381\n",
      "Epoch: [45] [  16/  40] time: 342.5108, loss: 0.00000932\n",
      "Epoch: [45] [  17/  40] time: 342.6603, loss: 0.00000365\n",
      "Epoch: [45] [  18/  40] time: 342.8138, loss: 0.00003098\n",
      "Epoch: [45] [  19/  40] time: 342.9623, loss: 0.00005702\n",
      "Epoch: [45] [  20/  40] time: 343.1196, loss: 0.00002887\n",
      "Epoch: [45] [  21/  40] time: 343.2684, loss: 0.00000802\n",
      "Epoch: [45] [  22/  40] time: 343.4224, loss: 0.00002387\n",
      "Epoch: [45] [  23/  40] time: 343.5727, loss: 0.00017343\n",
      "Epoch: [45] [  24/  40] time: 343.7365, loss: 0.00001767\n",
      "Epoch: [45] [  25/  40] time: 343.8926, loss: 0.00000666\n",
      "Epoch: [45] [  26/  40] time: 344.0522, loss: 0.00000006\n",
      "Epoch: [45] [  27/  40] time: 344.2023, loss: 0.00000157\n",
      "Epoch: [45] [  28/  40] time: 344.3559, loss: 0.00002504\n",
      "Epoch: [45] [  29/  40] time: 344.5101, loss: 0.00011129\n",
      "Epoch: [45] [  30/  40] time: 344.6671, loss: 0.00000110\n",
      "Epoch: [45] [  31/  40] time: 344.8182, loss: 0.00000558\n",
      "Epoch: [45] [  32/  40] time: 344.9733, loss: 0.00000274\n",
      "Epoch: [45] [  33/  40] time: 345.1235, loss: 0.00000251\n",
      "Epoch: [45] [  34/  40] time: 345.2777, loss: 0.00001813\n",
      "Epoch: [45] [  35/  40] time: 345.4257, loss: 0.00000258\n",
      "Epoch: [45] [  36/  40] time: 345.5771, loss: 0.00000143\n",
      "Epoch: [45] [  37/  40] time: 345.7301, loss: 0.00000606\n",
      "Epoch: [45] [  38/  40] time: 345.8840, loss: 0.00003000\n",
      "Epoch: [45] [  39/  40] time: 346.0397, loss: 0.00000169\n",
      "[45/50] - ptime: 6.6820 loss: 0.00002905 acc: 0.78000 lr: 0.00062902\n",
      "Epoch: [46] [   0/  40] time: 347.2169, loss: 0.00000080\n",
      "Epoch: [46] [   1/  40] time: 347.3650, loss: 0.00000260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46] [   2/  40] time: 347.5212, loss: 0.00000006\n",
      "Epoch: [46] [   3/  40] time: 347.6698, loss: 0.00000176\n",
      "Epoch: [46] [   4/  40] time: 347.8298, loss: 0.00002011\n",
      "Epoch: [46] [   5/  40] time: 347.9771, loss: 0.00006729\n",
      "Epoch: [46] [   6/  40] time: 348.1337, loss: 0.00003900\n",
      "Epoch: [46] [   7/  40] time: 348.2823, loss: 0.00000318\n",
      "Epoch: [46] [   8/  40] time: 348.4372, loss: 0.00000192\n",
      "Epoch: [46] [   9/  40] time: 348.5879, loss: 0.00000064\n",
      "Epoch: [46] [  10/  40] time: 348.7445, loss: 0.00000712\n",
      "Epoch: [46] [  11/  40] time: 348.8936, loss: 0.00000012\n",
      "Epoch: [46] [  12/  40] time: 349.0497, loss: 0.00001584\n",
      "Epoch: [46] [  13/  40] time: 349.2001, loss: 0.00000484\n",
      "Epoch: [46] [  14/  40] time: 349.3539, loss: 0.00000916\n",
      "Epoch: [46] [  15/  40] time: 349.5029, loss: 0.00002225\n",
      "Epoch: [46] [  16/  40] time: 349.6589, loss: 0.00001004\n",
      "Epoch: [46] [  17/  40] time: 349.8063, loss: 0.00002314\n",
      "Epoch: [46] [  18/  40] time: 349.9611, loss: 0.00000100\n",
      "Epoch: [46] [  19/  40] time: 350.1099, loss: 0.00000177\n",
      "Epoch: [46] [  20/  40] time: 350.2654, loss: 0.00001218\n",
      "Epoch: [46] [  21/  40] time: 350.4131, loss: 0.00002440\n",
      "Epoch: [46] [  22/  40] time: 350.5671, loss: 0.00004143\n",
      "Epoch: [46] [  23/  40] time: 350.7167, loss: 0.00000375\n",
      "Epoch: [46] [  24/  40] time: 350.8749, loss: 0.00000135\n",
      "Epoch: [46] [  25/  40] time: 351.0279, loss: 0.00001562\n",
      "Epoch: [46] [  26/  40] time: 351.1869, loss: 0.00004955\n",
      "Epoch: [46] [  27/  40] time: 351.3343, loss: 0.00000879\n",
      "Epoch: [46] [  28/  40] time: 351.4901, loss: 0.00000064\n",
      "Epoch: [46] [  29/  40] time: 351.6394, loss: 0.00000107\n",
      "Epoch: [46] [  30/  40] time: 351.7938, loss: 0.00000382\n",
      "Epoch: [46] [  31/  40] time: 351.9450, loss: 0.00000426\n",
      "Epoch: [46] [  32/  40] time: 352.1005, loss: 0.00005919\n",
      "Epoch: [46] [  33/  40] time: 352.2480, loss: 0.00003460\n",
      "Epoch: [46] [  34/  40] time: 352.4045, loss: 0.00000499\n",
      "Epoch: [46] [  35/  40] time: 352.5519, loss: 0.00000144\n",
      "Epoch: [46] [  36/  40] time: 352.7108, loss: 0.00000272\n",
      "Epoch: [46] [  37/  40] time: 352.8599, loss: 0.00000158\n",
      "Epoch: [46] [  38/  40] time: 353.0161, loss: 0.00000882\n",
      "Epoch: [46] [  39/  40] time: 353.1652, loss: 0.00001347\n",
      "[46/50] - ptime: 6.6244 loss: 0.00001316 acc: 0.78000 lr: 0.00061591\n",
      "Epoch: [47] [   0/  40] time: 354.4613, loss: 0.00000519\n",
      "Epoch: [47] [   1/  40] time: 354.6101, loss: 0.00012773\n",
      "Epoch: [47] [   2/  40] time: 354.7672, loss: 0.00000266\n",
      "Epoch: [47] [   3/  40] time: 354.9152, loss: 0.00000478\n",
      "Epoch: [47] [   4/  40] time: 355.0706, loss: 0.00000508\n",
      "Epoch: [47] [   5/  40] time: 355.2213, loss: 0.00000033\n",
      "Epoch: [47] [   6/  40] time: 355.3818, loss: 0.00001127\n",
      "Epoch: [47] [   7/  40] time: 355.5294, loss: 0.00000380\n",
      "Epoch: [47] [   8/  40] time: 355.6888, loss: 0.00004860\n",
      "Epoch: [47] [   9/  40] time: 355.8363, loss: 0.00000219\n",
      "Epoch: [47] [  10/  40] time: 355.9900, loss: 0.00000020\n",
      "Epoch: [47] [  11/  40] time: 356.1445, loss: 0.00000010\n",
      "Epoch: [47] [  12/  40] time: 356.3032, loss: 0.00000608\n",
      "Epoch: [47] [  13/  40] time: 356.4526, loss: 0.00000224\n",
      "Epoch: [47] [  14/  40] time: 356.6089, loss: 0.00000701\n",
      "Epoch: [47] [  15/  40] time: 356.7588, loss: 0.00000936\n",
      "Epoch: [47] [  16/  40] time: 356.9162, loss: 0.00000108\n",
      "Epoch: [47] [  17/  40] time: 357.0694, loss: 0.00001952\n",
      "Epoch: [47] [  18/  40] time: 357.2270, loss: 0.00001048\n",
      "Epoch: [47] [  19/  40] time: 357.3749, loss: 0.00002007\n",
      "Epoch: [47] [  20/  40] time: 357.5292, loss: 0.00000264\n",
      "Epoch: [47] [  21/  40] time: 357.6813, loss: 0.00001150\n",
      "Epoch: [47] [  22/  40] time: 357.8369, loss: 0.00000123\n",
      "Epoch: [47] [  23/  40] time: 357.9852, loss: 0.00000036\n",
      "Epoch: [47] [  24/  40] time: 358.1451, loss: 0.00003670\n",
      "Epoch: [47] [  25/  40] time: 358.2939, loss: 0.00002203\n",
      "Epoch: [47] [  26/  40] time: 358.4492, loss: 0.00006126\n",
      "Epoch: [47] [  27/  40] time: 358.6006, loss: 0.00000544\n",
      "Epoch: [47] [  28/  40] time: 358.7564, loss: 0.00001295\n",
      "Epoch: [47] [  29/  40] time: 358.9057, loss: 0.00001567\n",
      "Epoch: [47] [  30/  40] time: 359.0593, loss: 0.00000211\n",
      "Epoch: [47] [  31/  40] time: 359.2078, loss: 0.00000437\n",
      "Epoch: [47] [  32/  40] time: 359.3625, loss: 0.00000107\n",
      "Epoch: [47] [  33/  40] time: 359.5157, loss: 0.00000403\n",
      "Epoch: [47] [  34/  40] time: 359.6804, loss: 0.00000039\n",
      "Epoch: [47] [  35/  40] time: 359.8403, loss: 0.00000310\n",
      "Epoch: [47] [  36/  40] time: 360.0095, loss: 0.00001007\n",
      "Epoch: [47] [  37/  40] time: 360.1703, loss: 0.00000782\n",
      "Epoch: [47] [  38/  40] time: 360.3334, loss: 0.00000172\n",
      "Epoch: [47] [  39/  40] time: 360.4951, loss: 0.00001356\n",
      "[47/50] - ptime: 6.7580 loss: 0.00001264 acc: 0.78000 lr: 0.00060945\n",
      "Epoch: [48] [   0/  40] time: 361.8400, loss: 0.00000868\n",
      "Epoch: [48] [   1/  40] time: 361.9874, loss: 0.00000221\n",
      "Epoch: [48] [   2/  40] time: 362.1422, loss: 0.00000073\n",
      "Epoch: [48] [   3/  40] time: 362.2896, loss: 0.00002179\n",
      "Epoch: [48] [   4/  40] time: 362.4476, loss: 0.00000123\n",
      "Epoch: [48] [   5/  40] time: 362.5954, loss: 0.00000006\n",
      "Epoch: [48] [   6/  40] time: 362.7507, loss: 0.00000605\n",
      "Epoch: [48] [   7/  40] time: 362.9014, loss: 0.00000046\n",
      "Epoch: [48] [   8/  40] time: 363.0549, loss: 0.00015453\n",
      "Epoch: [48] [   9/  40] time: 363.2020, loss: 0.00001088\n",
      "Epoch: [48] [  10/  40] time: 363.3574, loss: 0.00000300\n",
      "Epoch: [48] [  11/  40] time: 363.5059, loss: 0.00001747\n",
      "Epoch: [48] [  12/  40] time: 363.6602, loss: 0.00006179\n",
      "Epoch: [48] [  13/  40] time: 363.8085, loss: 0.00008318\n",
      "Epoch: [48] [  14/  40] time: 363.9641, loss: 0.00000176\n",
      "Epoch: [48] [  15/  40] time: 364.1146, loss: 0.00003932\n",
      "Epoch: [48] [  16/  40] time: 364.2689, loss: 0.00000924\n",
      "Epoch: [48] [  17/  40] time: 364.4169, loss: 0.00002819\n",
      "Epoch: [48] [  18/  40] time: 364.5721, loss: 0.00005225\n",
      "Epoch: [48] [  19/  40] time: 364.7240, loss: 0.00000562\n",
      "Epoch: [48] [  20/  40] time: 364.8789, loss: 0.00000058\n",
      "Epoch: [48] [  21/  40] time: 365.0285, loss: 0.00001316\n",
      "Epoch: [48] [  22/  40] time: 365.1833, loss: 0.00001610\n",
      "Epoch: [48] [  23/  40] time: 365.3314, loss: 0.00004655\n",
      "Epoch: [48] [  24/  40] time: 365.4872, loss: 0.00006961\n",
      "Epoch: [48] [  25/  40] time: 365.6374, loss: 0.00001595\n",
      "Epoch: [48] [  26/  40] time: 365.7907, loss: 0.00000257\n",
      "Epoch: [48] [  27/  40] time: 365.9387, loss: 0.00001944\n",
      "Epoch: [48] [  28/  40] time: 366.0939, loss: 0.00019394\n",
      "Epoch: [48] [  29/  40] time: 366.2428, loss: 0.00000473\n",
      "Epoch: [48] [  30/  40] time: 366.4003, loss: 0.00119299\n",
      "Epoch: [48] [  31/  40] time: 366.5629, loss: 0.00001016\n",
      "Epoch: [48] [  32/  40] time: 366.7263, loss: 0.00000736\n",
      "Epoch: [48] [  33/  40] time: 366.8876, loss: 0.00000549\n",
      "Epoch: [48] [  34/  40] time: 367.0506, loss: 0.00007315\n",
      "Epoch: [48] [  35/  40] time: 367.2144, loss: 0.00000331\n",
      "Epoch: [48] [  36/  40] time: 367.3753, loss: 0.00000321\n",
      "Epoch: [48] [  37/  40] time: 367.5391, loss: 0.00001848\n",
      "Epoch: [48] [  38/  40] time: 367.7111, loss: 0.00001273\n",
      "Epoch: [48] [  39/  40] time: 367.8741, loss: 0.00000907\n",
      "[48/50] - ptime: 6.7914 loss: 0.00005568 acc: 0.79000 lr: 0.00060945\n",
      "Epoch: [49] [   0/  40] time: 369.1636, loss: 0.00000045\n",
      "Epoch: [49] [   1/  40] time: 369.3102, loss: 0.00000713\n",
      "Epoch: [49] [   2/  40] time: 369.4680, loss: 0.00000465\n",
      "Epoch: [49] [   3/  40] time: 369.6168, loss: 0.00000677\n",
      "Epoch: [49] [   4/  40] time: 369.7710, loss: 0.00000992\n",
      "Epoch: [49] [   5/  40] time: 369.9212, loss: 0.00000453\n",
      "Epoch: [49] [   6/  40] time: 370.0767, loss: 0.00006523\n",
      "Epoch: [49] [   7/  40] time: 370.2255, loss: 0.00001142\n",
      "Epoch: [49] [   8/  40] time: 370.3797, loss: 0.00000217\n",
      "Epoch: [49] [   9/  40] time: 370.5278, loss: 0.00000297\n",
      "Epoch: [49] [  10/  40] time: 370.6824, loss: 0.00008283\n",
      "Epoch: [49] [  11/  40] time: 370.8303, loss: 0.00000036\n",
      "Epoch: [49] [  12/  40] time: 370.9849, loss: 0.00000199\n",
      "Epoch: [49] [  13/  40] time: 371.1349, loss: 0.00002782\n",
      "Epoch: [49] [  14/  40] time: 371.2893, loss: 0.00001039\n",
      "Epoch: [49] [  15/  40] time: 371.4378, loss: 0.00001777\n",
      "Epoch: [49] [  16/  40] time: 371.5995, loss: 0.00000025\n",
      "Epoch: [49] [  17/  40] time: 371.7520, loss: 0.00001718\n",
      "Epoch: [49] [  18/  40] time: 371.9062, loss: 0.00000564\n",
      "Epoch: [49] [  19/  40] time: 372.0557, loss: 0.00000043\n",
      "Epoch: [49] [  20/  40] time: 372.2097, loss: 0.00001761\n",
      "Epoch: [49] [  21/  40] time: 372.3570, loss: 0.00001769\n",
      "Epoch: [49] [  22/  40] time: 372.5114, loss: 0.00002677\n",
      "Epoch: [49] [  23/  40] time: 372.6604, loss: 0.00007848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [49] [  24/  40] time: 372.8136, loss: 0.00000426\n",
      "Epoch: [49] [  25/  40] time: 372.9620, loss: 0.00000916\n",
      "Epoch: [49] [  26/  40] time: 373.1185, loss: 0.00006191\n",
      "Epoch: [49] [  27/  40] time: 373.2681, loss: 0.00000274\n",
      "Epoch: [49] [  28/  40] time: 373.4219, loss: 0.00000060\n",
      "Epoch: [49] [  29/  40] time: 373.5696, loss: 0.00001393\n",
      "Epoch: [49] [  30/  40] time: 373.7286, loss: 0.00001169\n",
      "Epoch: [49] [  31/  40] time: 373.8787, loss: 0.00000570\n",
      "Epoch: [49] [  32/  40] time: 374.0343, loss: 0.00001782\n",
      "Epoch: [49] [  33/  40] time: 374.1820, loss: 0.00000167\n",
      "Epoch: [49] [  34/  40] time: 374.3360, loss: 0.00000139\n",
      "Epoch: [49] [  35/  40] time: 374.4851, loss: 0.00000609\n",
      "Epoch: [49] [  36/  40] time: 374.6409, loss: 0.00000068\n",
      "Epoch: [49] [  37/  40] time: 374.7891, loss: 0.00002228\n",
      "Epoch: [49] [  38/  40] time: 374.9430, loss: 0.00000564\n",
      "Epoch: [49] [  39/  40] time: 375.0921, loss: 0.00000022\n",
      "[49/50] - ptime: 6.6242 loss: 0.00001466 acc: 0.79000 lr: 0.00059674\n",
      "Epoch: [50] [   0/  40] time: 376.3438, loss: 0.00000382\n",
      "Epoch: [50] [   1/  40] time: 376.4911, loss: 0.00002214\n",
      "Epoch: [50] [   2/  40] time: 376.6458, loss: 0.00002127\n",
      "Epoch: [50] [   3/  40] time: 376.7940, loss: 0.00000064\n",
      "Epoch: [50] [   4/  40] time: 376.9478, loss: 0.00001263\n",
      "Epoch: [50] [   5/  40] time: 377.1005, loss: 0.00000124\n",
      "Epoch: [50] [   6/  40] time: 377.2592, loss: 0.00006046\n",
      "Epoch: [50] [   7/  40] time: 377.4064, loss: 0.00000067\n",
      "Epoch: [50] [   8/  40] time: 377.5595, loss: 0.00001479\n",
      "Epoch: [50] [   9/  40] time: 377.7108, loss: 0.00000138\n",
      "Epoch: [50] [  10/  40] time: 377.8699, loss: 0.00001792\n",
      "Epoch: [50] [  11/  40] time: 378.0230, loss: 0.00000031\n",
      "Epoch: [50] [  12/  40] time: 378.1827, loss: 0.00000386\n",
      "Epoch: [50] [  13/  40] time: 378.3305, loss: 0.00197840\n",
      "Epoch: [50] [  14/  40] time: 378.4897, loss: 0.00000415\n",
      "Epoch: [50] [  15/  40] time: 378.6381, loss: 0.00000283\n",
      "Epoch: [50] [  16/  40] time: 378.7959, loss: 0.00000066\n",
      "Epoch: [50] [  17/  40] time: 378.9454, loss: 0.00001003\n",
      "Epoch: [50] [  18/  40] time: 379.1015, loss: 0.00000094\n",
      "Epoch: [50] [  19/  40] time: 379.2503, loss: 0.00000756\n",
      "Epoch: [50] [  20/  40] time: 379.4054, loss: 0.00001724\n",
      "Epoch: [50] [  21/  40] time: 379.5525, loss: 0.00000206\n",
      "Epoch: [50] [  22/  40] time: 379.7067, loss: 0.00000030\n",
      "Epoch: [50] [  23/  40] time: 379.8545, loss: 0.00004118\n",
      "Epoch: [50] [  24/  40] time: 380.0098, loss: 0.00001271\n",
      "Epoch: [50] [  25/  40] time: 380.1576, loss: 0.00000898\n",
      "Epoch: [50] [  26/  40] time: 380.3114, loss: 0.00000863\n",
      "Epoch: [50] [  27/  40] time: 380.4628, loss: 0.00000127\n",
      "Epoch: [50] [  28/  40] time: 380.6185, loss: 0.00000045\n",
      "Epoch: [50] [  29/  40] time: 380.7692, loss: 0.00000095\n",
      "Epoch: [50] [  30/  40] time: 380.9279, loss: 0.00003878\n",
      "Epoch: [50] [  31/  40] time: 381.0796, loss: 0.00000130\n",
      "Epoch: [50] [  32/  40] time: 381.2353, loss: 0.00000069\n",
      "Epoch: [50] [  33/  40] time: 381.3835, loss: 0.00004343\n",
      "Epoch: [50] [  34/  40] time: 381.5380, loss: 0.00001180\n",
      "Epoch: [50] [  35/  40] time: 381.6886, loss: 0.00003346\n",
      "Epoch: [50] [  36/  40] time: 381.8441, loss: 0.00000266\n",
      "Epoch: [50] [  37/  40] time: 381.9925, loss: 0.00000094\n",
      "Epoch: [50] [  38/  40] time: 382.1467, loss: 0.00002105\n",
      "Epoch: [50] [  39/  40] time: 382.2950, loss: 0.00005172\n",
      "[50/50] - ptime: 6.6421 loss: 0.00006163 acc: 0.81000 lr: 0.00059049\n",
      "Avg per epoch ptime: 6.99, total 50 epochs ptime: 382.90\n",
      " [*] Training finished!\n",
      " [*] Best Epoch:  32 , Accuracy:  0.8100000023841858\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/CNN_C5_D1_Kernel(3,3)_128_lrdecay0.0001/CNN_C5_D1_Kernel(3,3)_128_lrdecay0.0001-32\n",
      " [*] Finished testing Best Epoch: 32 , accuracy:  0.8100000023841858 !\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'CNN'\n",
    "dataset = '4_Flowers'\n",
    "epoch = 50\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "log_dir = 'logs'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    CNN = CNN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                log_dir=log_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    CNN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    CNN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    CNN.train()\n",
    "    \n",
    "    #CNN.test(epoch)\n",
    "        \n",
    "sess.close()\n",
    "        \n",
    "\n",
    "# lrdecay\n",
    "# Avg per epoch ptime: 6.99, total 50 epochs ptime: 382.90\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  32 , Accuracy:  0.8100000023841858\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_C5_D1_Kernel(3,3)_128_lrdecay0.0001/CNN_C5_D1_Kernel(3,3)_128_lrdecay0.0001-32\n",
    "#  [*] Finished testing Best Epoch: 32 , accuracy:  0.8100000023841858 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
