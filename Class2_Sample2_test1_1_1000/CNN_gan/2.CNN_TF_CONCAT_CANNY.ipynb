{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_canny(images):\n",
    "    canny_list = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "        canny_superposition = np.zeros(shape=(img.shape[0],img.shape[1]),dtype=np.uint16)\n",
    "        for channel in range(3):\n",
    "            img_ch = img[:,:,channel]\n",
    "            canny_ch = cv2.Canny(img_ch, 60, 150)\n",
    "            canny_superposition =  canny_superposition + (canny_ch).astype(np.uint16)\n",
    "        canny_superposition = cv2.normalize(canny_superposition, canny_superposition,0,255,cv2.NORM_MINMAX)\n",
    "        canny_list.append(np.array((canny_superposition).astype(np.uint8)).reshape([img.shape[0],img.shape[1],1]))\n",
    "    canny_list = np.array(canny_list,dtype = float32)\n",
    "    return canny_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "def load_flower_data():\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] handling images...\")\n",
    "    TRAIN_ORIGINAL_DIR = '../train/'\n",
    "    TRAIN_SUB_DIR = '../subsample/'\n",
    "    TRAIN_GAN = '../../image_gan/'\n",
    "    TEST_DIR = '../../test/'\n",
    "\n",
    "    # use this for full dataset\n",
    "#     train_images_original = [TRAIN_ORIGINAL_DIR + i for i in os.listdir(TRAIN_ORIGINAL_DIR)]\n",
    "#     train_images_sub = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "#     train_images = train_images_original + train_images_sub\n",
    "    train_images_gan = [TRAIN_GAN + i for i in os.listdir(TRAIN_GAN)]\n",
    "    test_images = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "    \n",
    "    train_images = train_images_gan\n",
    "    \n",
    "    train_images.sort(key=natural_keys)\n",
    "    test_images.sort(key=natural_keys)\n",
    "\n",
    "    # initialize the features matrix and labels list\n",
    "    trainImage = []\n",
    "    trainLabels = []\n",
    "    testImage = []\n",
    "    testLabels = []\n",
    "\n",
    "    # loop over the input images\n",
    "    for (i, imagePath) in enumerate(train_images):\n",
    "        # extract the class label\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # read and resize image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        trainImage.append(img)\n",
    "        trainLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "            \n",
    "      # loop over the input images\n",
    "    for (i, imagePath) in enumerate(test_images):\n",
    "        # extract the class label\n",
    "        # our images were named as labels.image_number.format\n",
    "        # get the labels from the name of the images by extract the string before \".\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # extract CNN features in the image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        testImage.append(img)\n",
    "        testLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(test_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(test_images)))\n",
    "\n",
    "\n",
    "    trainImage = np.array(trainImage,dtype = float32)\n",
    "    trainLabels = np.array(trainLabels)\n",
    "    testImage = np.array(testImage,dtype = float32)\n",
    "    testLabels = np.array(testLabels)\n",
    "    print (trainImage.shape)\n",
    "    \n",
    "    trainImage = trainImage.astype(np.float32) / 255\n",
    "    testImage = testImage.astype(np.float32) / 255\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainLabels)\n",
    "    list(le.classes_)\n",
    "    trainLabels = le.transform(trainLabels) \n",
    "    testLabels = le.transform(testLabels) \n",
    "    \n",
    "    return trainImage, trainLabels, testImage, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "[INFO] processed 1000/4000\n",
      "[INFO] processed 2000/4000\n",
      "[INFO] processed 3000/4000\n",
      "[INFO] processed 4000/4000\n",
      "[INFO] processed 156/156\n",
      "(4000, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [38:53<00:00,  1.71it/s]\n",
      "100%|██████████| 156/156 [00:01<00:00, 80.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(156, 2)\n",
      "[INFO] trainImage matrix: 768.00MB\n",
      "[INFO] trainLabels matrix: 0.0625MB\n",
      "[INFO] testImage matrix: 29.95MB\n",
      "[INFO] testLabels matrix: 0.0024MB\n",
      "[INFO] trainImage_canny matrix: 256.00MB\n",
      "[INFO] testImage_canny matrix: 9.9840MB\n"
     ]
    }
   ],
   "source": [
    "trainImage, trainLabels, testImage, testLabels = load_flower_data()\n",
    "\n",
    "trainImage_canny = batch_canny(trainImage)\n",
    "testImage_canny = batch_canny(testImage)\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "print (trainLabels)\n",
    "testLabels = keras.utils.to_categorical(testLabels, nb_classes)\n",
    "print (testLabels)\n",
    "print (testLabels.shape)\n",
    "\n",
    "np.save('../trainImage.npy', trainImage)\n",
    "np.save('../trainLabels.npy', trainLabels)\n",
    "np.save('../testImage.npy', testImage)\n",
    "np.save('../testLabels.npy', testLabels)\n",
    "np.save('../trainImage_canny.npy', trainImage_canny)\n",
    "np.save('../testImage_canny.npy', testImage_canny)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage matrix: {:.2f}MB\".format(\n",
    "    (testImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testLabels matrix: {:.4f}MB\".format(\n",
    "    (testLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainImage_canny matrix: {:.2f}MB\".format(\n",
    "    (trainImage_canny.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_canny matrix: {:.4f}MB\".format(\n",
    "    (testImage_canny.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, log_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "        \n",
    "        # number of convolutional filters to use  \n",
    "        self.nb_CNN = [32, 64, 64, 64, 128]  \n",
    "        # number of dense filters to use  \n",
    "        self.nb_Dense = [256] \n",
    "        # size of pooling area for max pooling  \n",
    "        self.pool_size = (2, 2)  \n",
    "        # convolution kernel size  \n",
    "        self.kernel_size = (3, 3)\n",
    "        self.batch_normalization_control = True\n",
    "        \n",
    "        # name for checkpoint\n",
    "        self.model_name = 'CNN_CANNY_C%d_D%d_Kernel(%d,%d)' % (len(self.nb_CNN), len(self.nb_Dense),\n",
    "                                                          self.kernel_size[0], self.kernel_size[1])    \n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "#         self.global_step = tf.Variable(0, trainable=False)\n",
    "#        self.lr = tf.train.exponential_decay(0.0002,  self.global_step, 500, 0.95, staircase=True)\n",
    "        self.lr = 0.001\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # test\n",
    "\n",
    "        #load_flower_data\n",
    "        self.train_x = np.load('../trainImage.npy')\n",
    "        self.train_y= np.load('../trainLabels.npy')\n",
    "        self.test_x = np.load('../testImage.npy')\n",
    "        self.test_y= np.load('../testLabels.npy')\n",
    "        self.train_x_canny = np.load('../trainImage_canny.npy')\n",
    "        self.test_x_canny = np.load('../testImage_canny.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['losses'] = []\n",
    "        self.train_hist['accuracy'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches_train = len(self.train_x) // self.batch_size\n",
    "        self.num_batches_test= len(self.test_x) // self.batch_size\n",
    "\n",
    "    def cnn_model(self, x, x_canny, keep_prob, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"cnn\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            B = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"CNN:x\",x.get_shape()) # 128, 128, 3 \n",
    "            print(\"CNN:x_canny\",x_canny.get_shape()) # 128, 128, 1\n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(inputs = x,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_1'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_1.get_shape())\n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_2 = tf.layers.conv2d(inputs = x_canny,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_2'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_2.get_shape())\n",
    "\n",
    "            #把数据和边缘进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)\n",
    "            net = tf.nn.relu(net, name = 'relu_conv_1')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_1'\n",
    "                                             )\n",
    "            \n",
    "            for i in range(2,len(self.nb_CNN)+1):\n",
    "                net = tf.layers.conv2d(inputs = net,                 # 输入,\n",
    "                                       filters = self.nb_CNN[i-1],      # 卷积核个数,\n",
    "                                       kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                       strides = (1, 1),\n",
    "                                       padding = 'same',              # padding方法\n",
    "                                       kernel_initializer = W,\n",
    "                                       bias_initializer = B,\n",
    "                                       kernel_regularizer = None,\n",
    "                                       bias_regularizer = None,\n",
    "                                       activity_regularizer = None,\n",
    "                                       name = 'conv_'+ str(i)        # 命名用于获取变量\n",
    "                                       )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "                if self.batch_normalization_control:\n",
    "                    net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_conv_' + str(i))\n",
    "                net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_' + str(i)\n",
    "                                             )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #flatten\n",
    "            net = tf.reshape(net, [-1, int(net.get_shape()[1]*net.get_shape()[2]*net.get_shape()[3])],name='flatten')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #dense layer\n",
    "            for i in range(1,len(self.nb_Dense)+1):\n",
    "                net = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_Dense[i-1],\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_' + str(i)\n",
    "                                    )\n",
    "#                 net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_dense_' + str(i))\n",
    "                net = tf.layers.dropout(inputs = net,\n",
    "                                        rate=keep_prob,\n",
    "                                        noise_shape=None,\n",
    "                                        seed=None,\n",
    "                                        training = is_training,\n",
    "                                        name= 'dropout_dense_' + str(i)\n",
    "                                        )\n",
    "            #output\n",
    "            logit = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_class,\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_output'\n",
    "                                    )\n",
    "            out_logit = tf.nn.softmax(logit, name=\"softmax\")\n",
    "            print(\"CNN:out_logit\",out_logit.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out_logit, logit\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.c_dim], \n",
    "                                name='x_image')\n",
    "        \n",
    "        self.x_canny = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, 1], \n",
    "                                name='x_canny')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[self.batch_size, self.nb_class], name='y_label')\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of cnn_model\n",
    "        self.out_logit, self.logit = self.cnn_model(self.x, self.x_canny, self.keep_prob, is_training=True, reuse=False)\n",
    "        \n",
    "        self.loss_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,\n",
    "                                                                                         logits =self.logit))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # trainable variables into a group\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        cnn_vars = [var for var in tf_vars if var.name.startswith('cnn')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.cnn_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.loss_cross_entropy,\n",
    "                                                                                        var_list=cnn_vars)\n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        # output of cnn_model\n",
    "        self.out_logit_test, self.logit_test = self.cnn_model(self.x, self.x_canny, self.keep_prob, is_training=False, reuse=True)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logit_test, 1), tf.argmax(self.y, 1))\n",
    "        self.predict = tf.argmax(self.logit_test, 1)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        self.loss_sum = tf.summary.scalar(\"loss\", self.loss_cross_entropy)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep = self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name+'_train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            CNN_losses = []\n",
    "  \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.train_x.shape[0]), self.train_x.shape[0])\n",
    "            shuffled_set = self.train_x[shuffle_idxs]\n",
    "            shuffled_set_canny = self.train_x_canny[shuffle_idxs]\n",
    "            shuffled_label = self.train_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches_train):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_canny = shuffled_set_canny[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, cnn_loss = self.sess.run([self.cnn_optim, self.loss_sum, self.loss_cross_entropy],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.x_canny: batch_x_canny,\n",
    "                                                          self.y: batch_y,\n",
    "                                                          self.keep_prob: 0.5}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                CNN_losses.append(cnn_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" % (epoch_loop, idx, self.num_batches_train, \n",
    "                                                                          time.time() - start_time, cnn_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            # Evaluates accuracy on test set\n",
    "                    # Evaluates accuracy on test set\n",
    "            test_accuracy_list = []\n",
    "            for idx_test in range(self.num_batches_test):\n",
    "                batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_canny_test = self.test_x_canny[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                    self.x_canny: batch_x_canny_test,\n",
    "                                                                    self.y: batch_y_tes,\n",
    "                                                                    self.keep_prob: 1.0})\n",
    "                test_accuracy_list.append(accuracy)\n",
    "            test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        \n",
    "        \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss: %.8f acc: %.5f'% (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                    np.mean(CNN_losses), test_accuracy))\n",
    "            self.train_hist['losses'].append(np.mean(CNN_losses))\n",
    "            self.train_hist['accuracy'].append( test_accuracy)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "            \n",
    "            # save trainhist for train\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name + '_train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' \n",
    "                                 + self.model_name + '_train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "        \"\"\"test after train\"\"\"\n",
    "        best_acc = max(self.train_hist['accuracy'])\n",
    "        beat_epoch = self.train_hist['accuracy'].index(best_acc) + 1\n",
    "        print (\" [*] Best Epoch: \", beat_epoch, \", Accuracy: \", best_acc)\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(beat_epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "                # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_canny_test = self.test_x_canny[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_canny: batch_x_canny_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Best Epoch:\", beat_epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "\n",
    "    def test(self, epoch):\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_canny_test = self.test_x_canny[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_canny: batch_x_canny_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Epoch:\", epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True) \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['losses'])+1)\n",
    "\n",
    "        y1 = hist['losses']\n",
    "        y2 = hist['accuracy']\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "                            \n",
    "        ax2 = ax1.twinx()  \n",
    "\n",
    "        ax1.plot(x, y1, 'b')\n",
    "        ax2.plot(x, y2, 'r')\n",
    "                            \n",
    "        ax1.set_xlabel('Epoch')\n",
    "                            \n",
    "        ax1.set_ylabel('CNN_loss')    \n",
    "        ax2.set_ylabel('accuracy')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_canny (100, 128, 128, 1)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 64)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_canny (100, 128, 128, 1)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 64)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "cnn/conv_1_1/kernel:0 (float32_ref 3x3x3x32) [864, bytes: 3456]\n",
      "cnn/conv_1_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_2/kernel:0 (float32_ref 3x3x1x32) [288, bytes: 1152]\n",
      "cnn/conv_1_2/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_2/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_3/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_3/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_4/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_5/kernel:0 (float32_ref 3x3x64x128) [73728, bytes: 294912]\n",
      "cnn/conv_5/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_1/kernel:0 (float32_ref 2048x256) [524288, bytes: 2097152]\n",
      "cnn/dense_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "cnn/dense_output/kernel:0 (float32_ref 256x2) [512, bytes: 2048]\n",
      "cnn/dense_output/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 711682\n",
      "Total bytes of variables: 2846728\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 1] [   0/  40] time: 2.3181, loss: 0.72969562\n",
      "Epoch: [ 1] [   1/  40] time: 2.5524, loss: 0.58595550\n",
      "Epoch: [ 1] [   2/  40] time: 2.7878, loss: 1.28445351\n",
      "Epoch: [ 1] [   3/  40] time: 3.0238, loss: 0.39501527\n",
      "Epoch: [ 1] [   4/  40] time: 3.2603, loss: 0.30662164\n",
      "Epoch: [ 1] [   5/  40] time: 3.4956, loss: 0.38147423\n",
      "Epoch: [ 1] [   6/  40] time: 3.7298, loss: 0.17524457\n",
      "Epoch: [ 1] [   7/  40] time: 3.9652, loss: 0.24516094\n",
      "Epoch: [ 1] [   8/  40] time: 4.2011, loss: 0.18111633\n",
      "Epoch: [ 1] [   9/  40] time: 4.4362, loss: 0.15957782\n",
      "Epoch: [ 1] [  10/  40] time: 4.6722, loss: 0.09623824\n",
      "Epoch: [ 1] [  11/  40] time: 4.9064, loss: 0.12184349\n",
      "Epoch: [ 1] [  12/  40] time: 5.1434, loss: 0.14393628\n",
      "Epoch: [ 1] [  13/  40] time: 5.3779, loss: 0.17308411\n",
      "Epoch: [ 1] [  14/  40] time: 5.6126, loss: 0.22315745\n",
      "Epoch: [ 1] [  15/  40] time: 5.8468, loss: 0.06319460\n",
      "Epoch: [ 1] [  16/  40] time: 6.0826, loss: 0.10085200\n",
      "Epoch: [ 1] [  17/  40] time: 6.3193, loss: 0.08202058\n",
      "Epoch: [ 1] [  18/  40] time: 6.5536, loss: 0.08657406\n",
      "Epoch: [ 1] [  19/  40] time: 6.7878, loss: 0.06488820\n",
      "Epoch: [ 1] [  20/  40] time: 7.0247, loss: 0.11198271\n",
      "Epoch: [ 1] [  21/  40] time: 7.2593, loss: 0.05388379\n",
      "Epoch: [ 1] [  22/  40] time: 7.4945, loss: 0.28040791\n",
      "Epoch: [ 1] [  23/  40] time: 7.7291, loss: 0.08017743\n",
      "Epoch: [ 1] [  24/  40] time: 7.9651, loss: 0.11851510\n",
      "Epoch: [ 1] [  25/  40] time: 8.2017, loss: 0.10243157\n",
      "Epoch: [ 1] [  26/  40] time: 8.4361, loss: 0.11799027\n",
      "Epoch: [ 1] [  27/  40] time: 8.6712, loss: 0.02660386\n",
      "Epoch: [ 1] [  28/  40] time: 8.9056, loss: 0.04414834\n",
      "Epoch: [ 1] [  29/  40] time: 9.1410, loss: 0.10738118\n",
      "Epoch: [ 1] [  30/  40] time: 9.3760, loss: 0.02175207\n",
      "Epoch: [ 1] [  31/  40] time: 9.6107, loss: 0.08298127\n",
      "Epoch: [ 1] [  32/  40] time: 9.8458, loss: 0.06792543\n",
      "Epoch: [ 1] [  33/  40] time: 10.0812, loss: 0.06004035\n",
      "Epoch: [ 1] [  34/  40] time: 10.3182, loss: 0.08416732\n",
      "Epoch: [ 1] [  35/  40] time: 10.5527, loss: 0.01689519\n",
      "Epoch: [ 1] [  36/  40] time: 10.7867, loss: 0.02288740\n",
      "Epoch: [ 1] [  37/  40] time: 11.0226, loss: 0.03905626\n",
      "Epoch: [ 1] [  38/  40] time: 11.2590, loss: 0.02548527\n",
      "Epoch: [ 1] [  39/  40] time: 11.4937, loss: 0.03704416\n",
      "[1/50] - ptime: 11.5553 loss: 0.17754653 acc: 0.84000\n",
      "Epoch: [ 2] [   0/  40] time: 12.8135, loss: 0.02941896\n",
      "Epoch: [ 2] [   1/  40] time: 13.0485, loss: 0.02842876\n",
      "Epoch: [ 2] [   2/  40] time: 13.2879, loss: 0.02631967\n",
      "Epoch: [ 2] [   3/  40] time: 13.5232, loss: 0.10696865\n",
      "Epoch: [ 2] [   4/  40] time: 13.7583, loss: 0.08942054\n",
      "Epoch: [ 2] [   5/  40] time: 13.9946, loss: 0.07810661\n",
      "Epoch: [ 2] [   6/  40] time: 14.2313, loss: 0.04430094\n",
      "Epoch: [ 2] [   7/  40] time: 14.4679, loss: 0.07889436\n",
      "Epoch: [ 2] [   8/  40] time: 14.7026, loss: 0.03455871\n",
      "Epoch: [ 2] [   9/  40] time: 14.9374, loss: 0.04302144\n",
      "Epoch: [ 2] [  10/  40] time: 15.1735, loss: 0.04230198\n",
      "Epoch: [ 2] [  11/  40] time: 15.4085, loss: 0.03187989\n",
      "Epoch: [ 2] [  12/  40] time: 15.6430, loss: 0.05806714\n",
      "Epoch: [ 2] [  13/  40] time: 15.8769, loss: 0.01135758\n",
      "Epoch: [ 2] [  14/  40] time: 16.1127, loss: 0.08082220\n",
      "Epoch: [ 2] [  15/  40] time: 16.3495, loss: 0.09914649\n",
      "Epoch: [ 2] [  16/  40] time: 16.5882, loss: 0.02893009\n",
      "Epoch: [ 2] [  17/  40] time: 16.8224, loss: 0.09208857\n",
      "Epoch: [ 2] [  18/  40] time: 17.0612, loss: 0.04453343\n",
      "Epoch: [ 2] [  19/  40] time: 17.2984, loss: 0.06846382\n",
      "Epoch: [ 2] [  20/  40] time: 17.5331, loss: 0.02653011\n",
      "Epoch: [ 2] [  21/  40] time: 17.7680, loss: 0.01817855\n",
      "Epoch: [ 2] [  22/  40] time: 18.0042, loss: 0.05822578\n",
      "Epoch: [ 2] [  23/  40] time: 18.2426, loss: 0.02800379\n",
      "Epoch: [ 2] [  24/  40] time: 18.4768, loss: 0.03440699\n",
      "Epoch: [ 2] [  25/  40] time: 18.7137, loss: 0.02959397\n",
      "Epoch: [ 2] [  26/  40] time: 18.9489, loss: 0.02319341\n",
      "Epoch: [ 2] [  27/  40] time: 19.1845, loss: 0.02221338\n",
      "Epoch: [ 2] [  28/  40] time: 19.4195, loss: 0.01281658\n",
      "Epoch: [ 2] [  29/  40] time: 19.6545, loss: 0.02775800\n",
      "Epoch: [ 2] [  30/  40] time: 19.8899, loss: 0.03023300\n",
      "Epoch: [ 2] [  31/  40] time: 20.1263, loss: 0.00775374\n",
      "Epoch: [ 2] [  32/  40] time: 20.3612, loss: 0.04439078\n",
      "Epoch: [ 2] [  33/  40] time: 20.5957, loss: 0.03828058\n",
      "Epoch: [ 2] [  34/  40] time: 20.8311, loss: 0.00749588\n",
      "Epoch: [ 2] [  35/  40] time: 21.0677, loss: 0.05842822\n",
      "Epoch: [ 2] [  36/  40] time: 21.3049, loss: 0.01753592\n",
      "Epoch: [ 2] [  37/  40] time: 21.5408, loss: 0.01974870\n",
      "Epoch: [ 2] [  38/  40] time: 21.7757, loss: 0.02234488\n",
      "Epoch: [ 2] [  39/  40] time: 22.0135, loss: 0.00773922\n",
      "[2/50] - ptime: 10.0092 loss: 0.04129753 acc: 0.85000\n",
      "Epoch: [ 3] [   0/  40] time: 24.0533, loss: 0.04906873\n",
      "Epoch: [ 3] [   1/  40] time: 24.2903, loss: 0.03122361\n",
      "Epoch: [ 3] [   2/  40] time: 24.5245, loss: 0.06021468\n",
      "Epoch: [ 3] [   3/  40] time: 24.7602, loss: 0.00541362\n",
      "Epoch: [ 3] [   4/  40] time: 24.9964, loss: 0.11189178\n",
      "Epoch: [ 3] [   5/  40] time: 25.2326, loss: 0.09963803\n",
      "Epoch: [ 3] [   6/  40] time: 25.4669, loss: 0.03438785\n",
      "Epoch: [ 3] [   7/  40] time: 25.7042, loss: 0.04450295\n",
      "Epoch: [ 3] [   8/  40] time: 25.9403, loss: 0.02289424\n",
      "Epoch: [ 3] [   9/  40] time: 26.1767, loss: 0.00943322\n",
      "Epoch: [ 3] [  10/  40] time: 26.4118, loss: 0.02721860\n",
      "Epoch: [ 3] [  11/  40] time: 26.6465, loss: 0.04963234\n",
      "Epoch: [ 3] [  12/  40] time: 26.8813, loss: 0.04901257\n",
      "Epoch: [ 3] [  13/  40] time: 27.1183, loss: 0.03873057\n",
      "Epoch: [ 3] [  14/  40] time: 27.3547, loss: 0.02727009\n",
      "Epoch: [ 3] [  15/  40] time: 27.5901, loss: 0.04415700\n",
      "Epoch: [ 3] [  16/  40] time: 27.8249, loss: 0.01167455\n",
      "Epoch: [ 3] [  17/  40] time: 28.0602, loss: 0.01797199\n",
      "Epoch: [ 3] [  18/  40] time: 28.2970, loss: 0.02165003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 3] [  19/  40] time: 28.5320, loss: 0.06021196\n",
      "Epoch: [ 3] [  20/  40] time: 28.7671, loss: 0.03430269\n",
      "Epoch: [ 3] [  21/  40] time: 29.0023, loss: 0.02499044\n",
      "Epoch: [ 3] [  22/  40] time: 29.2365, loss: 0.04367264\n",
      "Epoch: [ 3] [  23/  40] time: 29.4714, loss: 0.02704263\n",
      "Epoch: [ 3] [  24/  40] time: 29.7056, loss: 0.01596416\n",
      "Epoch: [ 3] [  25/  40] time: 29.9410, loss: 0.03019546\n",
      "Epoch: [ 3] [  26/  40] time: 30.1758, loss: 0.02261251\n",
      "Epoch: [ 3] [  27/  40] time: 30.4116, loss: 0.04230334\n",
      "Epoch: [ 3] [  28/  40] time: 30.6462, loss: 0.02593972\n",
      "Epoch: [ 3] [  29/  40] time: 30.8813, loss: 0.01395848\n",
      "Epoch: [ 3] [  30/  40] time: 31.1196, loss: 0.01984701\n",
      "Epoch: [ 3] [  31/  40] time: 31.3577, loss: 0.01142183\n",
      "Epoch: [ 3] [  32/  40] time: 31.5929, loss: 0.00779596\n",
      "Epoch: [ 3] [  33/  40] time: 31.8274, loss: 0.04454654\n",
      "Epoch: [ 3] [  34/  40] time: 32.0641, loss: 0.05497654\n",
      "Epoch: [ 3] [  35/  40] time: 32.3009, loss: 0.00817303\n",
      "Epoch: [ 3] [  36/  40] time: 32.5354, loss: 0.03595130\n",
      "Epoch: [ 3] [  37/  40] time: 32.7696, loss: 0.12529568\n",
      "Epoch: [ 3] [  38/  40] time: 33.0069, loss: 0.02039082\n",
      "Epoch: [ 3] [  39/  40] time: 33.2429, loss: 0.07552309\n",
      "[3/50] - ptime: 9.9644 loss: 0.03752755 acc: 0.88000\n",
      "Epoch: [ 4] [   0/  40] time: 34.4431, loss: 0.03086415\n",
      "Epoch: [ 4] [   1/  40] time: 34.6780, loss: 0.10881855\n",
      "Epoch: [ 4] [   2/  40] time: 34.9136, loss: 0.03112629\n",
      "Epoch: [ 4] [   3/  40] time: 35.1506, loss: 0.00718565\n",
      "Epoch: [ 4] [   4/  40] time: 35.3867, loss: 0.01821889\n",
      "Epoch: [ 4] [   5/  40] time: 35.6221, loss: 0.01510860\n",
      "Epoch: [ 4] [   6/  40] time: 35.8570, loss: 0.01313534\n",
      "Epoch: [ 4] [   7/  40] time: 36.0933, loss: 0.03842710\n",
      "Epoch: [ 4] [   8/  40] time: 36.3331, loss: 0.02770895\n",
      "Epoch: [ 4] [   9/  40] time: 36.5692, loss: 0.10477551\n",
      "Epoch: [ 4] [  10/  40] time: 36.8045, loss: 0.02272274\n",
      "Epoch: [ 4] [  11/  40] time: 37.0402, loss: 0.01276090\n",
      "Epoch: [ 4] [  12/  40] time: 37.2789, loss: 0.06575275\n",
      "Epoch: [ 4] [  13/  40] time: 37.5142, loss: 0.03799892\n",
      "Epoch: [ 4] [  14/  40] time: 37.7489, loss: 0.00766927\n",
      "Epoch: [ 4] [  15/  40] time: 37.9846, loss: 0.04242786\n",
      "Epoch: [ 4] [  16/  40] time: 38.2197, loss: 0.07363112\n",
      "Epoch: [ 4] [  17/  40] time: 38.4548, loss: 0.03994754\n",
      "Epoch: [ 4] [  18/  40] time: 38.6906, loss: 0.01891225\n",
      "Epoch: [ 4] [  19/  40] time: 38.9263, loss: 0.00683691\n",
      "Epoch: [ 4] [  20/  40] time: 39.1625, loss: 0.04713426\n",
      "Epoch: [ 4] [  21/  40] time: 39.4004, loss: 0.06065573\n",
      "Epoch: [ 4] [  22/  40] time: 39.6351, loss: 0.00604973\n",
      "Epoch: [ 4] [  23/  40] time: 39.8683, loss: 0.01633319\n",
      "Epoch: [ 4] [  24/  40] time: 40.1057, loss: 0.01436980\n",
      "Epoch: [ 4] [  25/  40] time: 40.3433, loss: 0.00749191\n",
      "Epoch: [ 4] [  26/  40] time: 40.5780, loss: 0.03051935\n",
      "Epoch: [ 4] [  27/  40] time: 40.8133, loss: 0.04399902\n",
      "Epoch: [ 4] [  28/  40] time: 41.0494, loss: 0.01845175\n",
      "Epoch: [ 4] [  29/  40] time: 41.2871, loss: 0.04904639\n",
      "Epoch: [ 4] [  30/  40] time: 41.5220, loss: 0.00714149\n",
      "Epoch: [ 4] [  31/  40] time: 41.7571, loss: 0.00272594\n",
      "Epoch: [ 4] [  32/  40] time: 41.9938, loss: 0.00739887\n",
      "Epoch: [ 4] [  33/  40] time: 42.2317, loss: 0.00385476\n",
      "Epoch: [ 4] [  34/  40] time: 42.4677, loss: 0.04855054\n",
      "Epoch: [ 4] [  35/  40] time: 42.7025, loss: 0.03390589\n",
      "Epoch: [ 4] [  36/  40] time: 42.9391, loss: 0.02440551\n",
      "Epoch: [ 4] [  37/  40] time: 43.1767, loss: 0.02991230\n",
      "Epoch: [ 4] [  38/  40] time: 43.4131, loss: 0.04294712\n",
      "Epoch: [ 4] [  39/  40] time: 43.6481, loss: 0.01550816\n",
      "[4/50] - ptime: 9.9750 loss: 0.03086078 acc: 0.86000\n",
      "Epoch: [ 5] [   0/  40] time: 44.9492, loss: 0.03059957\n",
      "Epoch: [ 5] [   1/  40] time: 45.1845, loss: 0.00867568\n",
      "Epoch: [ 5] [   2/  40] time: 45.4239, loss: 0.00780501\n",
      "Epoch: [ 5] [   3/  40] time: 45.6601, loss: 0.01881089\n",
      "Epoch: [ 5] [   4/  40] time: 45.8951, loss: 0.00562955\n",
      "Epoch: [ 5] [   5/  40] time: 46.1307, loss: 0.01386425\n",
      "Epoch: [ 5] [   6/  40] time: 46.3683, loss: 0.00435624\n",
      "Epoch: [ 5] [   7/  40] time: 46.6033, loss: 0.03934918\n",
      "Epoch: [ 5] [   8/  40] time: 46.8389, loss: 0.01095866\n",
      "Epoch: [ 5] [   9/  40] time: 47.0753, loss: 0.01536544\n",
      "Epoch: [ 5] [  10/  40] time: 47.3134, loss: 0.00484045\n",
      "Epoch: [ 5] [  11/  40] time: 47.5490, loss: 0.00459374\n",
      "Epoch: [ 5] [  12/  40] time: 47.7840, loss: 0.00447200\n",
      "Epoch: [ 5] [  13/  40] time: 48.0198, loss: 0.00139306\n",
      "Epoch: [ 5] [  14/  40] time: 48.2557, loss: 0.01591516\n",
      "Epoch: [ 5] [  15/  40] time: 48.4915, loss: 0.01222842\n",
      "Epoch: [ 5] [  16/  40] time: 48.7269, loss: 0.01457869\n",
      "Epoch: [ 5] [  17/  40] time: 48.9626, loss: 0.01175520\n",
      "Epoch: [ 5] [  18/  40] time: 49.1979, loss: 0.02154580\n",
      "Epoch: [ 5] [  19/  40] time: 49.4344, loss: 0.01215132\n",
      "Epoch: [ 5] [  20/  40] time: 49.6699, loss: 0.00394028\n",
      "Epoch: [ 5] [  21/  40] time: 49.9052, loss: 0.00975225\n",
      "Epoch: [ 5] [  22/  40] time: 50.1414, loss: 0.00262262\n",
      "Epoch: [ 5] [  23/  40] time: 50.3802, loss: 0.00228540\n",
      "Epoch: [ 5] [  24/  40] time: 50.6155, loss: 0.00148597\n",
      "Epoch: [ 5] [  25/  40] time: 50.8534, loss: 0.01397405\n",
      "Epoch: [ 5] [  26/  40] time: 51.0894, loss: 0.00102534\n",
      "Epoch: [ 5] [  27/  40] time: 51.3267, loss: 0.00878266\n",
      "Epoch: [ 5] [  28/  40] time: 51.5626, loss: 0.03638461\n",
      "Epoch: [ 5] [  29/  40] time: 51.7979, loss: 0.00193347\n",
      "Epoch: [ 5] [  30/  40] time: 52.0340, loss: 0.01955086\n",
      "Epoch: [ 5] [  31/  40] time: 52.2706, loss: 0.00130299\n",
      "Epoch: [ 5] [  32/  40] time: 52.5065, loss: 0.01452032\n",
      "Epoch: [ 5] [  33/  40] time: 52.7420, loss: 0.01426602\n",
      "Epoch: [ 5] [  34/  40] time: 52.9792, loss: 0.00365032\n",
      "Epoch: [ 5] [  35/  40] time: 53.2143, loss: 0.01796297\n",
      "Epoch: [ 5] [  36/  40] time: 53.4502, loss: 0.01279111\n",
      "Epoch: [ 5] [  37/  40] time: 53.6861, loss: 0.06288989\n",
      "Epoch: [ 5] [  38/  40] time: 53.9227, loss: 0.05071977\n",
      "Epoch: [ 5] [  39/  40] time: 54.1584, loss: 0.01013081\n",
      "[5/50] - ptime: 9.9788 loss: 0.01372150 acc: 0.78000\n",
      "Epoch: [ 6] [   0/  40] time: 55.3402, loss: 0.02077888\n",
      "Epoch: [ 6] [   1/  40] time: 55.5755, loss: 0.02949768\n",
      "Epoch: [ 6] [   2/  40] time: 55.8106, loss: 0.04117279\n",
      "Epoch: [ 6] [   3/  40] time: 56.0469, loss: 0.02673078\n",
      "Epoch: [ 6] [   4/  40] time: 56.2836, loss: 0.01456701\n",
      "Epoch: [ 6] [   5/  40] time: 56.5191, loss: 0.01143929\n",
      "Epoch: [ 6] [   6/  40] time: 56.7548, loss: 0.00840781\n",
      "Epoch: [ 6] [   7/  40] time: 56.9907, loss: 0.00196551\n",
      "Epoch: [ 6] [   8/  40] time: 57.2266, loss: 0.01522304\n",
      "Epoch: [ 6] [   9/  40] time: 57.4630, loss: 0.00047188\n",
      "Epoch: [ 6] [  10/  40] time: 57.6989, loss: 0.00215597\n",
      "Epoch: [ 6] [  11/  40] time: 57.9351, loss: 0.01324866\n",
      "Epoch: [ 6] [  12/  40] time: 58.1701, loss: 0.00466181\n",
      "Epoch: [ 6] [  13/  40] time: 58.4085, loss: 0.00516389\n",
      "Epoch: [ 6] [  14/  40] time: 58.6441, loss: 0.01790610\n",
      "Epoch: [ 6] [  15/  40] time: 58.8793, loss: 0.00384553\n",
      "Epoch: [ 6] [  16/  40] time: 59.1157, loss: 0.00186211\n",
      "Epoch: [ 6] [  17/  40] time: 59.3532, loss: 0.01763455\n",
      "Epoch: [ 6] [  18/  40] time: 59.5888, loss: 0.00394641\n",
      "Epoch: [ 6] [  19/  40] time: 59.8240, loss: 0.00208239\n",
      "Epoch: [ 6] [  20/  40] time: 60.0610, loss: 0.00599791\n",
      "Epoch: [ 6] [  21/  40] time: 60.2963, loss: 0.04717680\n",
      "Epoch: [ 6] [  22/  40] time: 60.5321, loss: 0.00420111\n",
      "Epoch: [ 6] [  23/  40] time: 60.7682, loss: 0.00604307\n",
      "Epoch: [ 6] [  24/  40] time: 61.0051, loss: 0.00136244\n",
      "Epoch: [ 6] [  25/  40] time: 61.2401, loss: 0.00376830\n",
      "Epoch: [ 6] [  26/  40] time: 61.4749, loss: 0.00316909\n",
      "Epoch: [ 6] [  27/  40] time: 61.7113, loss: 0.01945418\n",
      "Epoch: [ 6] [  28/  40] time: 61.9479, loss: 0.00594877\n",
      "Epoch: [ 6] [  29/  40] time: 62.1826, loss: 0.00073221\n",
      "Epoch: [ 6] [  30/  40] time: 62.4201, loss: 0.00523531\n",
      "Epoch: [ 6] [  31/  40] time: 62.6557, loss: 0.01963670\n",
      "Epoch: [ 6] [  32/  40] time: 62.8921, loss: 0.00398434\n",
      "Epoch: [ 6] [  33/  40] time: 63.1278, loss: 0.01989425\n",
      "Epoch: [ 6] [  34/  40] time: 63.3644, loss: 0.13538525\n",
      "Epoch: [ 6] [  35/  40] time: 63.6001, loss: 0.05791627\n",
      "Epoch: [ 6] [  36/  40] time: 63.8351, loss: 0.03603859\n",
      "Epoch: [ 6] [  37/  40] time: 64.0707, loss: 0.00630770\n",
      "Epoch: [ 6] [  38/  40] time: 64.3067, loss: 0.00480189\n",
      "Epoch: [ 6] [  39/  40] time: 64.5427, loss: 0.03416604\n",
      "[6/50] - ptime: 9.9724 loss: 0.01659956 acc: 0.77000\n",
      "Epoch: [ 7] [   0/  40] time: 65.6858, loss: 0.01915214\n",
      "Epoch: [ 7] [   1/  40] time: 65.9220, loss: 0.00366202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 7] [   2/  40] time: 66.1576, loss: 0.00409807\n",
      "Epoch: [ 7] [   3/  40] time: 66.3941, loss: 0.01304581\n",
      "Epoch: [ 7] [   4/  40] time: 66.6297, loss: 0.00682496\n",
      "Epoch: [ 7] [   5/  40] time: 66.8655, loss: 0.00943108\n",
      "Epoch: [ 7] [   6/  40] time: 67.1016, loss: 0.00845080\n",
      "Epoch: [ 7] [   7/  40] time: 67.3378, loss: 0.02088985\n",
      "Epoch: [ 7] [   8/  40] time: 67.5738, loss: 0.00644537\n",
      "Epoch: [ 7] [   9/  40] time: 67.8100, loss: 0.00549367\n",
      "Epoch: [ 7] [  10/  40] time: 68.0474, loss: 0.01016202\n",
      "Epoch: [ 7] [  11/  40] time: 68.2887, loss: 0.00319135\n",
      "Epoch: [ 7] [  12/  40] time: 68.5241, loss: 0.01030468\n",
      "Epoch: [ 7] [  13/  40] time: 68.7588, loss: 0.03085759\n",
      "Epoch: [ 7] [  14/  40] time: 68.9955, loss: 0.00262035\n",
      "Epoch: [ 7] [  15/  40] time: 69.2309, loss: 0.00644938\n",
      "Epoch: [ 7] [  16/  40] time: 69.4684, loss: 0.00530318\n",
      "Epoch: [ 7] [  17/  40] time: 69.7031, loss: 0.00226249\n",
      "Epoch: [ 7] [  18/  40] time: 69.9414, loss: 0.01920005\n",
      "Epoch: [ 7] [  19/  40] time: 70.1768, loss: 0.03479336\n",
      "Epoch: [ 7] [  20/  40] time: 70.4140, loss: 0.00070020\n",
      "Epoch: [ 7] [  21/  40] time: 70.6493, loss: 0.00957494\n",
      "Epoch: [ 7] [  22/  40] time: 70.8849, loss: 0.00127899\n",
      "Epoch: [ 7] [  23/  40] time: 71.1221, loss: 0.00965980\n",
      "Epoch: [ 7] [  24/  40] time: 71.3592, loss: 0.00566564\n",
      "Epoch: [ 7] [  25/  40] time: 71.5941, loss: 0.01700339\n",
      "Epoch: [ 7] [  26/  40] time: 71.8288, loss: 0.00086282\n",
      "Epoch: [ 7] [  27/  40] time: 72.0685, loss: 0.00047086\n",
      "Epoch: [ 7] [  28/  40] time: 72.3055, loss: 0.00048153\n",
      "Epoch: [ 7] [  29/  40] time: 72.5412, loss: 0.00069345\n",
      "Epoch: [ 7] [  30/  40] time: 72.7760, loss: 0.00392102\n",
      "Epoch: [ 7] [  31/  40] time: 73.0123, loss: 0.00201291\n",
      "Epoch: [ 7] [  32/  40] time: 73.2501, loss: 0.00281236\n",
      "Epoch: [ 7] [  33/  40] time: 73.4870, loss: 0.00654155\n",
      "Epoch: [ 7] [  34/  40] time: 73.7225, loss: 0.00358033\n",
      "Epoch: [ 7] [  35/  40] time: 73.9586, loss: 0.00096987\n",
      "Epoch: [ 7] [  36/  40] time: 74.1940, loss: 0.01137192\n",
      "Epoch: [ 7] [  37/  40] time: 74.4315, loss: 0.00406313\n",
      "Epoch: [ 7] [  38/  40] time: 74.6673, loss: 0.00233190\n",
      "Epoch: [ 7] [  39/  40] time: 74.9021, loss: 0.00071519\n",
      "[7/50] - ptime: 9.9859 loss: 0.00768375 acc: 0.82000\n",
      "Epoch: [ 8] [   0/  40] time: 76.0836, loss: 0.00078433\n",
      "Epoch: [ 8] [   1/  40] time: 76.3218, loss: 0.01969296\n",
      "Epoch: [ 8] [   2/  40] time: 76.5575, loss: 0.01396161\n",
      "Epoch: [ 8] [   3/  40] time: 76.7933, loss: 0.00201418\n",
      "Epoch: [ 8] [   4/  40] time: 77.0292, loss: 0.01866538\n",
      "Epoch: [ 8] [   5/  40] time: 77.2655, loss: 0.00099658\n",
      "Epoch: [ 8] [   6/  40] time: 77.5056, loss: 0.02761941\n",
      "Epoch: [ 8] [   7/  40] time: 77.7434, loss: 0.00960552\n",
      "Epoch: [ 8] [   8/  40] time: 77.9808, loss: 0.01562256\n",
      "Epoch: [ 8] [   9/  40] time: 78.2155, loss: 0.00890207\n",
      "Epoch: [ 8] [  10/  40] time: 78.4524, loss: 0.00340894\n",
      "Epoch: [ 8] [  11/  40] time: 78.6897, loss: 0.06381555\n",
      "Epoch: [ 8] [  12/  40] time: 78.9254, loss: 0.00375782\n",
      "Epoch: [ 8] [  13/  40] time: 79.1618, loss: 0.06177103\n",
      "Epoch: [ 8] [  14/  40] time: 79.3985, loss: 0.00804995\n",
      "Epoch: [ 8] [  15/  40] time: 79.6348, loss: 0.05139083\n",
      "Epoch: [ 8] [  16/  40] time: 79.8709, loss: 0.02624664\n",
      "Epoch: [ 8] [  17/  40] time: 80.1076, loss: 0.01184190\n",
      "Epoch: [ 8] [  18/  40] time: 80.3444, loss: 0.04070755\n",
      "Epoch: [ 8] [  19/  40] time: 80.5823, loss: 0.01027687\n",
      "Epoch: [ 8] [  20/  40] time: 80.8186, loss: 0.01499323\n",
      "Epoch: [ 8] [  21/  40] time: 81.0564, loss: 0.03255623\n",
      "Epoch: [ 8] [  22/  40] time: 81.2937, loss: 0.01166626\n",
      "Epoch: [ 8] [  23/  40] time: 81.5316, loss: 0.00891203\n",
      "Epoch: [ 8] [  24/  40] time: 81.7669, loss: 0.00495606\n",
      "Epoch: [ 8] [  25/  40] time: 82.0043, loss: 0.00566972\n",
      "Epoch: [ 8] [  26/  40] time: 82.2402, loss: 0.01997766\n",
      "Epoch: [ 8] [  27/  40] time: 82.4786, loss: 0.00377579\n",
      "Epoch: [ 8] [  28/  40] time: 82.7150, loss: 0.00459025\n",
      "Epoch: [ 8] [  29/  40] time: 82.9510, loss: 0.01488097\n",
      "Epoch: [ 8] [  30/  40] time: 83.1871, loss: 0.00857594\n",
      "Epoch: [ 8] [  31/  40] time: 83.4257, loss: 0.04227509\n",
      "Epoch: [ 8] [  32/  40] time: 83.6562, loss: 0.00234909\n",
      "Epoch: [ 8] [  33/  40] time: 83.8915, loss: 0.03486982\n",
      "Epoch: [ 8] [  34/  40] time: 84.1285, loss: 0.03456787\n",
      "Epoch: [ 8] [  35/  40] time: 84.3662, loss: 0.00586630\n",
      "Epoch: [ 8] [  36/  40] time: 84.6040, loss: 0.00185415\n",
      "Epoch: [ 8] [  37/  40] time: 84.8394, loss: 0.01468380\n",
      "Epoch: [ 8] [  38/  40] time: 85.0760, loss: 0.00994555\n",
      "Epoch: [ 8] [  39/  40] time: 85.3138, loss: 0.00202503\n",
      "[8/50] - ptime: 10.0035 loss: 0.01695306 acc: 0.60000\n",
      "Epoch: [ 9] [   0/  40] time: 86.5064, loss: 0.00118221\n",
      "Epoch: [ 9] [   1/  40] time: 86.7416, loss: 0.00253856\n",
      "Epoch: [ 9] [   2/  40] time: 86.9782, loss: 0.00091804\n",
      "Epoch: [ 9] [   3/  40] time: 87.2152, loss: 0.06590538\n",
      "Epoch: [ 9] [   4/  40] time: 87.4519, loss: 0.01169598\n",
      "Epoch: [ 9] [   5/  40] time: 87.6874, loss: 0.06567343\n",
      "Epoch: [ 9] [   6/  40] time: 87.9241, loss: 0.00599742\n",
      "Epoch: [ 9] [   7/  40] time: 88.1604, loss: 0.01335736\n",
      "Epoch: [ 9] [   8/  40] time: 88.3982, loss: 0.00857986\n",
      "Epoch: [ 9] [   9/  40] time: 88.6342, loss: 0.00281886\n",
      "Epoch: [ 9] [  10/  40] time: 88.8695, loss: 0.00178311\n",
      "Epoch: [ 9] [  11/  40] time: 89.1060, loss: 0.00589575\n",
      "Epoch: [ 9] [  12/  40] time: 89.3449, loss: 0.00576152\n",
      "Epoch: [ 9] [  13/  40] time: 89.5815, loss: 0.00546690\n",
      "Epoch: [ 9] [  14/  40] time: 89.8184, loss: 0.00229942\n",
      "Epoch: [ 9] [  15/  40] time: 90.0554, loss: 0.00377014\n",
      "Epoch: [ 9] [  16/  40] time: 90.2906, loss: 0.01947675\n",
      "Epoch: [ 9] [  17/  40] time: 90.5294, loss: 0.00916915\n",
      "Epoch: [ 9] [  18/  40] time: 90.7662, loss: 0.04367744\n",
      "Epoch: [ 9] [  19/  40] time: 91.0030, loss: 0.02888756\n",
      "Epoch: [ 9] [  20/  40] time: 91.2399, loss: 0.03477297\n",
      "Epoch: [ 9] [  21/  40] time: 91.4769, loss: 0.04579298\n",
      "Epoch: [ 9] [  22/  40] time: 91.7128, loss: 0.03596455\n",
      "Epoch: [ 9] [  23/  40] time: 91.9491, loss: 0.03730366\n",
      "Epoch: [ 9] [  24/  40] time: 92.1848, loss: 0.02242432\n",
      "Epoch: [ 9] [  25/  40] time: 92.4221, loss: 0.01347905\n",
      "Epoch: [ 9] [  26/  40] time: 92.6573, loss: 0.00347014\n",
      "Epoch: [ 9] [  27/  40] time: 92.8941, loss: 0.00728123\n",
      "Epoch: [ 9] [  28/  40] time: 93.1312, loss: 0.00739537\n",
      "Epoch: [ 9] [  29/  40] time: 93.3677, loss: 0.04186833\n",
      "Epoch: [ 9] [  30/  40] time: 93.6032, loss: 0.01514468\n",
      "Epoch: [ 9] [  31/  40] time: 93.8392, loss: 0.03939711\n",
      "Epoch: [ 9] [  32/  40] time: 94.0780, loss: 0.00555397\n",
      "Epoch: [ 9] [  33/  40] time: 94.3173, loss: 0.00358041\n",
      "Epoch: [ 9] [  34/  40] time: 94.5530, loss: 0.01224005\n",
      "Epoch: [ 9] [  35/  40] time: 94.7885, loss: 0.00187911\n",
      "Epoch: [ 9] [  36/  40] time: 95.0248, loss: 0.00700248\n",
      "Epoch: [ 9] [  37/  40] time: 95.2614, loss: 0.00439445\n",
      "Epoch: [ 9] [  38/  40] time: 95.4970, loss: 0.00708383\n",
      "Epoch: [ 9] [  39/  40] time: 95.7334, loss: 0.00095320\n",
      "[9/50] - ptime: 10.0048 loss: 0.01629592 acc: 0.79000\n",
      "Epoch: [10] [   0/  40] time: 96.9252, loss: 0.02322898\n",
      "Epoch: [10] [   1/  40] time: 97.1613, loss: 0.00065419\n",
      "Epoch: [10] [   2/  40] time: 97.3988, loss: 0.00518026\n",
      "Epoch: [10] [   3/  40] time: 97.6344, loss: 0.00097010\n",
      "Epoch: [10] [   4/  40] time: 97.8704, loss: 0.00074114\n",
      "Epoch: [10] [   5/  40] time: 98.1088, loss: 0.00939323\n",
      "Epoch: [10] [   6/  40] time: 98.3458, loss: 0.00140224\n",
      "Epoch: [10] [   7/  40] time: 98.5820, loss: 0.02176924\n",
      "Epoch: [10] [   8/  40] time: 98.8169, loss: 0.02747650\n",
      "Epoch: [10] [   9/  40] time: 99.0542, loss: 0.00315812\n",
      "Epoch: [10] [  10/  40] time: 99.2904, loss: 0.02275418\n",
      "Epoch: [10] [  11/  40] time: 99.5280, loss: 0.00529542\n",
      "Epoch: [10] [  12/  40] time: 99.7637, loss: 0.01451611\n",
      "Epoch: [10] [  13/  40] time: 99.9999, loss: 0.00093730\n",
      "Epoch: [10] [  14/  40] time: 100.2367, loss: 0.02612380\n",
      "Epoch: [10] [  15/  40] time: 100.4745, loss: 0.02769223\n",
      "Epoch: [10] [  16/  40] time: 100.7101, loss: 0.03102495\n",
      "Epoch: [10] [  17/  40] time: 100.9498, loss: 0.03124189\n",
      "Epoch: [10] [  18/  40] time: 101.1849, loss: 0.01482333\n",
      "Epoch: [10] [  19/  40] time: 101.4229, loss: 0.02716614\n",
      "Epoch: [10] [  20/  40] time: 101.6590, loss: 0.07802866\n",
      "Epoch: [10] [  21/  40] time: 101.8946, loss: 0.01227283\n",
      "Epoch: [10] [  22/  40] time: 102.1323, loss: 0.00779187\n",
      "Epoch: [10] [  23/  40] time: 102.3676, loss: 0.04585845\n",
      "Epoch: [10] [  24/  40] time: 102.6041, loss: 0.00767857\n",
      "Epoch: [10] [  25/  40] time: 102.8410, loss: 0.02855004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [10] [  26/  40] time: 103.0780, loss: 0.00246223\n",
      "Epoch: [10] [  27/  40] time: 103.3138, loss: 0.02246504\n",
      "Epoch: [10] [  28/  40] time: 103.5490, loss: 0.00113506\n",
      "Epoch: [10] [  29/  40] time: 103.7858, loss: 0.00083900\n",
      "Epoch: [10] [  30/  40] time: 104.0227, loss: 0.00917874\n",
      "Epoch: [10] [  31/  40] time: 104.2589, loss: 0.03520655\n",
      "Epoch: [10] [  32/  40] time: 104.4961, loss: 0.00267078\n",
      "Epoch: [10] [  33/  40] time: 104.7318, loss: 0.02139476\n",
      "Epoch: [10] [  34/  40] time: 104.9691, loss: 0.01236168\n",
      "Epoch: [10] [  35/  40] time: 105.2047, loss: 0.00998389\n",
      "Epoch: [10] [  36/  40] time: 105.4421, loss: 0.00595106\n",
      "Epoch: [10] [  37/  40] time: 105.6774, loss: 0.02624635\n",
      "Epoch: [10] [  38/  40] time: 105.9138, loss: 0.00272295\n",
      "Epoch: [10] [  39/  40] time: 106.1511, loss: 0.00230544\n",
      "[10/50] - ptime: 10.0039 loss: 0.01576633 acc: 0.82000\n",
      "Epoch: [11] [   0/  40] time: 107.3308, loss: 0.01598275\n",
      "Epoch: [11] [   1/  40] time: 107.5677, loss: 0.00582716\n",
      "Epoch: [11] [   2/  40] time: 107.8032, loss: 0.00025542\n",
      "Epoch: [11] [   3/  40] time: 108.0398, loss: 0.00118384\n",
      "Epoch: [11] [   4/  40] time: 108.2778, loss: 0.01657503\n",
      "Epoch: [11] [   5/  40] time: 108.5148, loss: 0.00135619\n",
      "Epoch: [11] [   6/  40] time: 108.7510, loss: 0.00263749\n",
      "Epoch: [11] [   7/  40] time: 108.9872, loss: 0.01647130\n",
      "Epoch: [11] [   8/  40] time: 109.2234, loss: 0.00257000\n",
      "Epoch: [11] [   9/  40] time: 109.4603, loss: 0.00288082\n",
      "Epoch: [11] [  10/  40] time: 109.6967, loss: 0.01399207\n",
      "Epoch: [11] [  11/  40] time: 109.9324, loss: 0.00023311\n",
      "Epoch: [11] [  12/  40] time: 110.1682, loss: 0.00662240\n",
      "Epoch: [11] [  13/  40] time: 110.4044, loss: 0.02100905\n",
      "Epoch: [11] [  14/  40] time: 110.6389, loss: 0.00026062\n",
      "Epoch: [11] [  15/  40] time: 110.8741, loss: 0.00378382\n",
      "Epoch: [11] [  16/  40] time: 111.1111, loss: 0.00240761\n",
      "Epoch: [11] [  17/  40] time: 111.3480, loss: 0.00623134\n",
      "Epoch: [11] [  18/  40] time: 111.5853, loss: 0.00054500\n",
      "Epoch: [11] [  19/  40] time: 111.8218, loss: 0.02487349\n",
      "Epoch: [11] [  20/  40] time: 112.0583, loss: 0.00051444\n",
      "Epoch: [11] [  21/  40] time: 112.2943, loss: 0.00138594\n",
      "Epoch: [11] [  22/  40] time: 112.5333, loss: 0.00421972\n",
      "Epoch: [11] [  23/  40] time: 112.7697, loss: 0.00205482\n",
      "Epoch: [11] [  24/  40] time: 113.0065, loss: 0.01764964\n",
      "Epoch: [11] [  25/  40] time: 113.2417, loss: 0.02482265\n",
      "Epoch: [11] [  26/  40] time: 113.4799, loss: 0.01127493\n",
      "Epoch: [11] [  27/  40] time: 113.7168, loss: 0.00021506\n",
      "Epoch: [11] [  28/  40] time: 113.9537, loss: 0.00468435\n",
      "Epoch: [11] [  29/  40] time: 114.1897, loss: 0.00072662\n",
      "Epoch: [11] [  30/  40] time: 114.4273, loss: 0.00446150\n",
      "Epoch: [11] [  31/  40] time: 114.6630, loss: 0.00048917\n",
      "Epoch: [11] [  32/  40] time: 114.9003, loss: 0.00068541\n",
      "Epoch: [11] [  33/  40] time: 115.1386, loss: 0.00017455\n",
      "Epoch: [11] [  34/  40] time: 115.3750, loss: 0.00114528\n",
      "Epoch: [11] [  35/  40] time: 115.6103, loss: 0.00029123\n",
      "Epoch: [11] [  36/  40] time: 115.8463, loss: 0.00135537\n",
      "Epoch: [11] [  37/  40] time: 116.0851, loss: 0.00075309\n",
      "Epoch: [11] [  38/  40] time: 116.3224, loss: 0.00792021\n",
      "Epoch: [11] [  39/  40] time: 116.5600, loss: 0.00067247\n",
      "[11/50] - ptime: 10.0042 loss: 0.00577987 acc: 0.79000\n",
      "Epoch: [12] [   0/  40] time: 117.7441, loss: 0.00730544\n",
      "Epoch: [12] [   1/  40] time: 117.9819, loss: 0.00103919\n",
      "Epoch: [12] [   2/  40] time: 118.2174, loss: 0.00064184\n",
      "Epoch: [12] [   3/  40] time: 118.4545, loss: 0.00011703\n",
      "Epoch: [12] [   4/  40] time: 118.6909, loss: 0.03512028\n",
      "Epoch: [12] [   5/  40] time: 118.9286, loss: 0.00829548\n",
      "Epoch: [12] [   6/  40] time: 119.1650, loss: 0.00155413\n",
      "Epoch: [12] [   7/  40] time: 119.4024, loss: 0.04563541\n",
      "Epoch: [12] [   8/  40] time: 119.6368, loss: 0.00135356\n",
      "Epoch: [12] [   9/  40] time: 119.8743, loss: 0.02916125\n",
      "Epoch: [12] [  10/  40] time: 120.1108, loss: 0.01319213\n",
      "Epoch: [12] [  11/  40] time: 120.3461, loss: 0.00028366\n",
      "Epoch: [12] [  12/  40] time: 120.5830, loss: 0.00663518\n",
      "Epoch: [12] [  13/  40] time: 120.8214, loss: 0.00061070\n",
      "Epoch: [12] [  14/  40] time: 121.0595, loss: 0.00187829\n",
      "Epoch: [12] [  15/  40] time: 121.2964, loss: 0.00070611\n",
      "Epoch: [12] [  16/  40] time: 121.5346, loss: 0.00020703\n",
      "Epoch: [12] [  17/  40] time: 121.7706, loss: 0.01656726\n",
      "Epoch: [12] [  18/  40] time: 122.0080, loss: 0.00067024\n",
      "Epoch: [12] [  19/  40] time: 122.2444, loss: 0.00573913\n",
      "Epoch: [12] [  20/  40] time: 122.4824, loss: 0.01375656\n",
      "Epoch: [12] [  21/  40] time: 122.7211, loss: 0.00164595\n",
      "Epoch: [12] [  22/  40] time: 122.9578, loss: 0.00053968\n",
      "Epoch: [12] [  23/  40] time: 123.1935, loss: 0.01876228\n",
      "Epoch: [12] [  24/  40] time: 123.4303, loss: 0.00281981\n",
      "Epoch: [12] [  25/  40] time: 123.6671, loss: 0.01640863\n",
      "Epoch: [12] [  26/  40] time: 123.9035, loss: 0.00050956\n",
      "Epoch: [12] [  27/  40] time: 124.1400, loss: 0.00580081\n",
      "Epoch: [12] [  28/  40] time: 124.3767, loss: 0.00077354\n",
      "Epoch: [12] [  29/  40] time: 124.6133, loss: 0.00043392\n",
      "Epoch: [12] [  30/  40] time: 124.8505, loss: 0.00048784\n",
      "Epoch: [12] [  31/  40] time: 125.0882, loss: 0.00197533\n",
      "Epoch: [12] [  32/  40] time: 125.3237, loss: 0.00022484\n",
      "Epoch: [12] [  33/  40] time: 125.5605, loss: 0.05050946\n",
      "Epoch: [12] [  34/  40] time: 125.7968, loss: 0.04064975\n",
      "Epoch: [12] [  35/  40] time: 126.0338, loss: 0.00048213\n",
      "Epoch: [12] [  36/  40] time: 126.2703, loss: 0.00367640\n",
      "Epoch: [12] [  37/  40] time: 126.5072, loss: 0.01192167\n",
      "Epoch: [12] [  38/  40] time: 126.7433, loss: 0.01536878\n",
      "Epoch: [12] [  39/  40] time: 126.9807, loss: 0.08780058\n",
      "[12/50] - ptime: 10.0141 loss: 0.01128152 acc: 0.82000\n",
      "Epoch: [13] [   0/  40] time: 128.1616, loss: 0.02682375\n",
      "Epoch: [13] [   1/  40] time: 128.3995, loss: 0.00745590\n",
      "Epoch: [13] [   2/  40] time: 128.6365, loss: 0.00439412\n",
      "Epoch: [13] [   3/  40] time: 128.8720, loss: 0.00092724\n",
      "Epoch: [13] [   4/  40] time: 129.1088, loss: 0.00345384\n",
      "Epoch: [13] [   5/  40] time: 129.3461, loss: 0.00297596\n",
      "Epoch: [13] [   6/  40] time: 129.5855, loss: 0.00815117\n",
      "Epoch: [13] [   7/  40] time: 129.8224, loss: 0.01547585\n",
      "Epoch: [13] [   8/  40] time: 130.0618, loss: 0.00215698\n",
      "Epoch: [13] [   9/  40] time: 130.2972, loss: 0.00248910\n",
      "Epoch: [13] [  10/  40] time: 130.5352, loss: 0.00336339\n",
      "Epoch: [13] [  11/  40] time: 130.7721, loss: 0.00057878\n",
      "Epoch: [13] [  12/  40] time: 131.0093, loss: 0.00041316\n",
      "Epoch: [13] [  13/  40] time: 131.2461, loss: 0.00799620\n",
      "Epoch: [13] [  14/  40] time: 131.4842, loss: 0.00459222\n",
      "Epoch: [13] [  15/  40] time: 131.7196, loss: 0.00359994\n",
      "Epoch: [13] [  16/  40] time: 131.9583, loss: 0.01111362\n",
      "Epoch: [13] [  17/  40] time: 132.1957, loss: 0.00013577\n",
      "Epoch: [13] [  18/  40] time: 132.4328, loss: 0.00272745\n",
      "Epoch: [13] [  19/  40] time: 132.6693, loss: 0.00909779\n",
      "Epoch: [13] [  20/  40] time: 132.9065, loss: 0.00016360\n",
      "Epoch: [13] [  21/  40] time: 133.1435, loss: 0.05547400\n",
      "Epoch: [13] [  22/  40] time: 133.3805, loss: 0.00114394\n",
      "Epoch: [13] [  23/  40] time: 133.6182, loss: 0.00706240\n",
      "Epoch: [13] [  24/  40] time: 133.8540, loss: 0.02552245\n",
      "Epoch: [13] [  25/  40] time: 134.0912, loss: 0.00036585\n",
      "Epoch: [13] [  26/  40] time: 134.3269, loss: 0.01080488\n",
      "Epoch: [13] [  27/  40] time: 134.5656, loss: 0.00170033\n",
      "Epoch: [13] [  28/  40] time: 134.8021, loss: 0.00161008\n",
      "Epoch: [13] [  29/  40] time: 135.0394, loss: 0.00201125\n",
      "Epoch: [13] [  30/  40] time: 135.2792, loss: 0.05477240\n",
      "Epoch: [13] [  31/  40] time: 135.5163, loss: 0.03673086\n",
      "Epoch: [13] [  32/  40] time: 135.7521, loss: 0.01239002\n",
      "Epoch: [13] [  33/  40] time: 135.9902, loss: 0.01315415\n",
      "Epoch: [13] [  34/  40] time: 136.2276, loss: 0.00167582\n",
      "Epoch: [13] [  35/  40] time: 136.4642, loss: 0.00070915\n",
      "Epoch: [13] [  36/  40] time: 136.6998, loss: 0.01473735\n",
      "Epoch: [13] [  37/  40] time: 136.9365, loss: 0.00080208\n",
      "Epoch: [13] [  38/  40] time: 137.1735, loss: 0.00075116\n",
      "Epoch: [13] [  39/  40] time: 137.4123, loss: 0.01837411\n",
      "[13/50] - ptime: 10.0267 loss: 0.00944695 acc: 0.69000\n",
      "Epoch: [14] [   0/  40] time: 138.5974, loss: 0.00087856\n",
      "Epoch: [14] [   1/  40] time: 138.8335, loss: 0.00346300\n",
      "Epoch: [14] [   2/  40] time: 139.0706, loss: 0.00262898\n",
      "Epoch: [14] [   3/  40] time: 139.3065, loss: 0.00077748\n",
      "Epoch: [14] [   4/  40] time: 139.5450, loss: 0.00406868\n",
      "Epoch: [14] [   5/  40] time: 139.7820, loss: 0.00151474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14] [   6/  40] time: 140.0192, loss: 0.02583711\n",
      "Epoch: [14] [   7/  40] time: 140.2554, loss: 0.00642702\n",
      "Epoch: [14] [   8/  40] time: 140.4924, loss: 0.00429023\n",
      "Epoch: [14] [   9/  40] time: 140.7283, loss: 0.00472482\n",
      "Epoch: [14] [  10/  40] time: 140.9666, loss: 0.00188809\n",
      "Epoch: [14] [  11/  40] time: 141.2036, loss: 0.00035437\n",
      "Epoch: [14] [  12/  40] time: 141.4417, loss: 0.02144909\n",
      "Epoch: [14] [  13/  40] time: 141.6783, loss: 0.04104402\n",
      "Epoch: [14] [  14/  40] time: 141.9136, loss: 0.00016959\n",
      "Epoch: [14] [  15/  40] time: 142.1523, loss: 0.00243199\n",
      "Epoch: [14] [  16/  40] time: 142.3886, loss: 0.00471053\n",
      "Epoch: [14] [  17/  40] time: 142.6254, loss: 0.00041296\n",
      "Epoch: [14] [  18/  40] time: 142.8620, loss: 0.00237658\n",
      "Epoch: [14] [  19/  40] time: 143.0995, loss: 0.00647125\n",
      "Epoch: [14] [  20/  40] time: 143.3358, loss: 0.00006609\n",
      "Epoch: [14] [  21/  40] time: 143.5754, loss: 0.00806849\n",
      "Epoch: [14] [  22/  40] time: 143.8127, loss: 0.00008752\n",
      "Epoch: [14] [  23/  40] time: 144.0496, loss: 0.00025098\n",
      "Epoch: [14] [  24/  40] time: 144.2851, loss: 0.00127751\n",
      "Epoch: [14] [  25/  40] time: 144.5224, loss: 0.00012903\n",
      "Epoch: [14] [  26/  40] time: 144.7600, loss: 0.00317682\n",
      "Epoch: [14] [  27/  40] time: 144.9989, loss: 0.00104719\n",
      "Epoch: [14] [  28/  40] time: 145.2333, loss: 0.00167469\n",
      "Epoch: [14] [  29/  40] time: 145.4688, loss: 0.00469556\n",
      "Epoch: [14] [  30/  40] time: 145.7043, loss: 0.00152495\n",
      "Epoch: [14] [  31/  40] time: 145.9442, loss: 0.00008628\n",
      "Epoch: [14] [  32/  40] time: 146.1813, loss: 0.00352574\n",
      "Epoch: [14] [  33/  40] time: 146.4176, loss: 0.00076826\n",
      "Epoch: [14] [  34/  40] time: 146.6544, loss: 0.00317079\n",
      "Epoch: [14] [  35/  40] time: 146.8900, loss: 0.00104397\n",
      "Epoch: [14] [  36/  40] time: 147.1288, loss: 0.00067504\n",
      "Epoch: [14] [  37/  40] time: 147.3647, loss: 0.00652959\n",
      "Epoch: [14] [  38/  40] time: 147.6032, loss: 0.00315341\n",
      "Epoch: [14] [  39/  40] time: 147.8413, loss: 0.00236883\n",
      "[14/50] - ptime: 10.0220 loss: 0.00448100 acc: 0.74000\n",
      "Epoch: [15] [   0/  40] time: 148.9981, loss: 0.04680918\n",
      "Epoch: [15] [   1/  40] time: 149.2343, loss: 0.00026115\n",
      "Epoch: [15] [   2/  40] time: 149.4733, loss: 0.00005544\n",
      "Epoch: [15] [   3/  40] time: 149.7106, loss: 0.00314295\n",
      "Epoch: [15] [   4/  40] time: 149.9500, loss: 0.00709988\n",
      "Epoch: [15] [   5/  40] time: 150.1875, loss: 0.00018684\n",
      "Epoch: [15] [   6/  40] time: 150.4234, loss: 0.00036058\n",
      "Epoch: [15] [   7/  40] time: 150.6604, loss: 0.00023589\n",
      "Epoch: [15] [   8/  40] time: 150.8984, loss: 0.00361601\n",
      "Epoch: [15] [   9/  40] time: 151.1364, loss: 0.00014434\n",
      "Epoch: [15] [  10/  40] time: 151.3732, loss: 0.00100909\n",
      "Epoch: [15] [  11/  40] time: 151.6113, loss: 0.00495891\n",
      "Epoch: [15] [  12/  40] time: 151.8495, loss: 0.00085634\n",
      "Epoch: [15] [  13/  40] time: 152.0870, loss: 0.00007738\n",
      "Epoch: [15] [  14/  40] time: 152.3238, loss: 0.00005669\n",
      "Epoch: [15] [  15/  40] time: 152.5621, loss: 0.00018536\n",
      "Epoch: [15] [  16/  40] time: 152.7984, loss: 0.00078479\n",
      "Epoch: [15] [  17/  40] time: 153.0357, loss: 0.00164584\n",
      "Epoch: [15] [  18/  40] time: 153.2710, loss: 0.00006434\n",
      "Epoch: [15] [  19/  40] time: 153.5094, loss: 0.00088818\n",
      "Epoch: [15] [  20/  40] time: 153.7459, loss: 0.00000741\n",
      "Epoch: [15] [  21/  40] time: 153.9848, loss: 0.00046451\n",
      "Epoch: [15] [  22/  40] time: 154.2211, loss: 0.00019749\n",
      "Epoch: [15] [  23/  40] time: 154.4549, loss: 0.00233072\n",
      "Epoch: [15] [  24/  40] time: 154.6915, loss: 0.00002953\n",
      "Epoch: [15] [  25/  40] time: 154.9285, loss: 0.00537704\n",
      "Epoch: [15] [  26/  40] time: 155.1656, loss: 0.00002197\n",
      "Epoch: [15] [  27/  40] time: 155.4016, loss: 0.00420188\n",
      "Epoch: [15] [  28/  40] time: 155.6363, loss: 0.00003172\n",
      "Epoch: [15] [  29/  40] time: 155.8732, loss: 0.00164733\n",
      "Epoch: [15] [  30/  40] time: 156.1109, loss: 0.00002843\n",
      "Epoch: [15] [  31/  40] time: 156.3474, loss: 0.00093470\n",
      "Epoch: [15] [  32/  40] time: 156.5850, loss: 0.00149676\n",
      "Epoch: [15] [  33/  40] time: 156.8199, loss: 0.00000893\n",
      "Epoch: [15] [  34/  40] time: 157.0580, loss: 0.00003741\n",
      "Epoch: [15] [  35/  40] time: 157.2945, loss: 0.00002722\n",
      "Epoch: [15] [  36/  40] time: 157.5328, loss: 0.00043458\n",
      "Epoch: [15] [  37/  40] time: 157.7693, loss: 0.00204444\n",
      "Epoch: [15] [  38/  40] time: 158.0078, loss: 0.00468799\n",
      "Epoch: [15] [  39/  40] time: 158.2441, loss: 0.00439570\n",
      "[15/50] - ptime: 10.0220 loss: 0.00252112 acc: 0.81000\n",
      "Epoch: [16] [   0/  40] time: 159.4408, loss: 0.00060770\n",
      "Epoch: [16] [   1/  40] time: 159.6781, loss: 0.00045169\n",
      "Epoch: [16] [   2/  40] time: 159.9149, loss: 0.00013305\n",
      "Epoch: [16] [   3/  40] time: 160.1519, loss: 0.00030012\n",
      "Epoch: [16] [   4/  40] time: 160.3892, loss: 0.00012006\n",
      "Epoch: [16] [   5/  40] time: 160.6264, loss: 0.00002309\n",
      "Epoch: [16] [   6/  40] time: 160.8628, loss: 0.00032098\n",
      "Epoch: [16] [   7/  40] time: 161.0999, loss: 0.00001196\n",
      "Epoch: [16] [   8/  40] time: 161.3361, loss: 0.00011722\n",
      "Epoch: [16] [   9/  40] time: 161.5749, loss: 0.00149672\n",
      "Epoch: [16] [  10/  40] time: 161.8117, loss: 0.00409494\n",
      "Epoch: [16] [  11/  40] time: 162.0498, loss: 0.00031666\n",
      "Epoch: [16] [  12/  40] time: 162.2865, loss: 0.00002243\n",
      "Epoch: [16] [  13/  40] time: 162.5234, loss: 0.00007804\n",
      "Epoch: [16] [  14/  40] time: 162.7594, loss: 0.00002699\n",
      "Epoch: [16] [  15/  40] time: 162.9969, loss: 0.00078044\n",
      "Epoch: [16] [  16/  40] time: 163.2334, loss: 0.00004663\n",
      "Epoch: [16] [  17/  40] time: 163.4693, loss: 0.00070221\n",
      "Epoch: [16] [  18/  40] time: 163.7048, loss: 0.00003587\n",
      "Epoch: [16] [  19/  40] time: 163.9429, loss: 0.00045256\n",
      "Epoch: [16] [  20/  40] time: 164.1804, loss: 0.00005871\n",
      "Epoch: [16] [  21/  40] time: 164.4195, loss: 0.00024543\n",
      "Epoch: [16] [  22/  40] time: 164.6549, loss: 0.00219888\n",
      "Epoch: [16] [  23/  40] time: 164.8902, loss: 0.00011430\n",
      "Epoch: [16] [  24/  40] time: 165.1274, loss: 0.00199177\n",
      "Epoch: [16] [  25/  40] time: 165.3647, loss: 0.00139751\n",
      "Epoch: [16] [  26/  40] time: 165.6036, loss: 0.00011420\n",
      "Epoch: [16] [  27/  40] time: 165.8391, loss: 0.00110220\n",
      "Epoch: [16] [  28/  40] time: 166.0756, loss: 0.00003320\n",
      "Epoch: [16] [  29/  40] time: 166.3117, loss: 0.00002770\n",
      "Epoch: [16] [  30/  40] time: 166.5513, loss: 0.00120263\n",
      "Epoch: [16] [  31/  40] time: 166.7885, loss: 0.00003671\n",
      "Epoch: [16] [  32/  40] time: 167.0284, loss: 0.00062523\n",
      "Epoch: [16] [  33/  40] time: 167.2666, loss: 0.00008307\n",
      "Epoch: [16] [  34/  40] time: 167.5025, loss: 0.00010528\n",
      "Epoch: [16] [  35/  40] time: 167.7380, loss: 0.00006063\n",
      "Epoch: [16] [  36/  40] time: 167.9757, loss: 0.00013460\n",
      "Epoch: [16] [  37/  40] time: 168.2151, loss: 0.00018032\n",
      "Epoch: [16] [  38/  40] time: 168.4522, loss: 0.00006718\n",
      "Epoch: [16] [  39/  40] time: 168.6887, loss: 0.00000944\n",
      "[16/50] - ptime: 10.0157 loss: 0.00049821 acc: 0.81000\n",
      "Epoch: [17] [   0/  40] time: 169.8748, loss: 0.00004753\n",
      "Epoch: [17] [   1/  40] time: 170.1107, loss: 0.00026994\n",
      "Epoch: [17] [   2/  40] time: 170.3480, loss: 0.00001289\n",
      "Epoch: [17] [   3/  40] time: 170.5860, loss: 0.00039414\n",
      "Epoch: [17] [   4/  40] time: 170.8221, loss: 0.00005794\n",
      "Epoch: [17] [   5/  40] time: 171.0599, loss: 0.00006594\n",
      "Epoch: [17] [   6/  40] time: 171.2963, loss: 0.00010358\n",
      "Epoch: [17] [   7/  40] time: 171.5345, loss: 0.00009877\n",
      "Epoch: [17] [   8/  40] time: 171.7702, loss: 0.00048493\n",
      "Epoch: [17] [   9/  40] time: 172.0092, loss: 0.00008562\n",
      "Epoch: [17] [  10/  40] time: 172.2475, loss: 0.00009662\n",
      "Epoch: [17] [  11/  40] time: 172.4840, loss: 0.00008373\n",
      "Epoch: [17] [  12/  40] time: 172.7209, loss: 0.00021257\n",
      "Epoch: [17] [  13/  40] time: 172.9581, loss: 0.00005571\n",
      "Epoch: [17] [  14/  40] time: 173.1939, loss: 0.00033472\n",
      "Epoch: [17] [  15/  40] time: 173.4312, loss: 0.00002308\n",
      "Epoch: [17] [  16/  40] time: 173.6687, loss: 0.00052586\n",
      "Epoch: [17] [  17/  40] time: 173.9048, loss: 0.00020059\n",
      "Epoch: [17] [  18/  40] time: 174.1418, loss: 0.00001220\n",
      "Epoch: [17] [  19/  40] time: 174.3773, loss: 0.00006383\n",
      "Epoch: [17] [  20/  40] time: 174.6193, loss: 0.00081436\n",
      "Epoch: [17] [  21/  40] time: 174.8555, loss: 0.00022531\n",
      "Epoch: [17] [  22/  40] time: 175.0941, loss: 0.00000142\n",
      "Epoch: [17] [  23/  40] time: 175.3307, loss: 0.00047573\n",
      "Epoch: [17] [  24/  40] time: 175.5683, loss: 0.00002176\n",
      "Epoch: [17] [  25/  40] time: 175.8038, loss: 0.00003738\n",
      "Epoch: [17] [  26/  40] time: 176.0413, loss: 0.00022625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17] [  27/  40] time: 176.2786, loss: 0.00028976\n",
      "Epoch: [17] [  28/  40] time: 176.5173, loss: 0.00014027\n",
      "Epoch: [17] [  29/  40] time: 176.7546, loss: 0.00006386\n",
      "Epoch: [17] [  30/  40] time: 176.9919, loss: 0.00001045\n",
      "Epoch: [17] [  31/  40] time: 177.2278, loss: 0.00001579\n",
      "Epoch: [17] [  32/  40] time: 177.4648, loss: 0.00129244\n",
      "Epoch: [17] [  33/  40] time: 177.7034, loss: 0.00010714\n",
      "Epoch: [17] [  34/  40] time: 177.9407, loss: 0.00023891\n",
      "Epoch: [17] [  35/  40] time: 178.1770, loss: 0.00044100\n",
      "Epoch: [17] [  36/  40] time: 178.4142, loss: 0.00033211\n",
      "Epoch: [17] [  37/  40] time: 178.6543, loss: 0.00004631\n",
      "Epoch: [17] [  38/  40] time: 178.8904, loss: 0.00005248\n",
      "Epoch: [17] [  39/  40] time: 179.1287, loss: 0.00002245\n",
      "[17/50] - ptime: 10.0251 loss: 0.00020213 acc: 0.81000\n",
      "Epoch: [18] [   0/  40] time: 180.4312, loss: 0.00004466\n",
      "Epoch: [18] [   1/  40] time: 180.6703, loss: 0.00034533\n",
      "Epoch: [18] [   2/  40] time: 180.9063, loss: 0.00001291\n",
      "Epoch: [18] [   3/  40] time: 181.1448, loss: 0.00008806\n",
      "Epoch: [18] [   4/  40] time: 181.3803, loss: 0.00002156\n",
      "Epoch: [18] [   5/  40] time: 181.6199, loss: 0.00001958\n",
      "Epoch: [18] [   6/  40] time: 181.8564, loss: 0.00001236\n",
      "Epoch: [18] [   7/  40] time: 182.0940, loss: 0.00002254\n",
      "Epoch: [18] [   8/  40] time: 182.3317, loss: 0.00005613\n",
      "Epoch: [18] [   9/  40] time: 182.5700, loss: 0.00012461\n",
      "Epoch: [18] [  10/  40] time: 182.8066, loss: 0.00022203\n",
      "Epoch: [18] [  11/  40] time: 183.0434, loss: 0.00000512\n",
      "Epoch: [18] [  12/  40] time: 183.2810, loss: 0.00001986\n",
      "Epoch: [18] [  13/  40] time: 183.5185, loss: 0.00029971\n",
      "Epoch: [18] [  14/  40] time: 183.7547, loss: 0.00009810\n",
      "Epoch: [18] [  15/  40] time: 183.9915, loss: 0.00007684\n",
      "Epoch: [18] [  16/  40] time: 184.2273, loss: 0.00011782\n",
      "Epoch: [18] [  17/  40] time: 184.4642, loss: 0.00027262\n",
      "Epoch: [18] [  18/  40] time: 184.7028, loss: 0.00022374\n",
      "Epoch: [18] [  19/  40] time: 184.9399, loss: 0.00021821\n",
      "Epoch: [18] [  20/  40] time: 185.1762, loss: 0.00000654\n",
      "Epoch: [18] [  21/  40] time: 185.4145, loss: 0.00002236\n",
      "Epoch: [18] [  22/  40] time: 185.6521, loss: 0.00000402\n",
      "Epoch: [18] [  23/  40] time: 185.8882, loss: 0.00003817\n",
      "Epoch: [18] [  24/  40] time: 186.1275, loss: 0.00040797\n",
      "Epoch: [18] [  25/  40] time: 186.3652, loss: 0.00018888\n",
      "Epoch: [18] [  26/  40] time: 186.6028, loss: 0.00003011\n",
      "Epoch: [18] [  27/  40] time: 186.8384, loss: 0.00000749\n",
      "Epoch: [18] [  28/  40] time: 187.0757, loss: 0.00000584\n",
      "Epoch: [18] [  29/  40] time: 187.3129, loss: 0.00000831\n",
      "Epoch: [18] [  30/  40] time: 187.5495, loss: 0.00000624\n",
      "Epoch: [18] [  31/  40] time: 187.7858, loss: 0.00003906\n",
      "Epoch: [18] [  32/  40] time: 188.0225, loss: 0.00003548\n",
      "Epoch: [18] [  33/  40] time: 188.2585, loss: 0.00000962\n",
      "Epoch: [18] [  34/  40] time: 188.4970, loss: 0.00004072\n",
      "Epoch: [18] [  35/  40] time: 188.7335, loss: 0.00007015\n",
      "Epoch: [18] [  36/  40] time: 188.9713, loss: 0.00006554\n",
      "Epoch: [18] [  37/  40] time: 189.2077, loss: 0.00001479\n",
      "Epoch: [18] [  38/  40] time: 189.4436, loss: 0.00008950\n",
      "Epoch: [18] [  39/  40] time: 189.6820, loss: 0.00006119\n",
      "[18/50] - ptime: 10.0243 loss: 0.00008634 acc: 0.81000\n",
      "Epoch: [19] [   0/  40] time: 190.8259, loss: 0.00004556\n",
      "Epoch: [19] [   1/  40] time: 191.0638, loss: 0.00000891\n",
      "Epoch: [19] [   2/  40] time: 191.3005, loss: 0.00003685\n",
      "Epoch: [19] [   3/  40] time: 191.5389, loss: 0.00046471\n",
      "Epoch: [19] [   4/  40] time: 191.7744, loss: 0.00002447\n",
      "Epoch: [19] [   5/  40] time: 192.0108, loss: 0.00009740\n",
      "Epoch: [19] [   6/  40] time: 192.2473, loss: 0.00001893\n",
      "Epoch: [19] [   7/  40] time: 192.4839, loss: 0.00000715\n",
      "Epoch: [19] [   8/  40] time: 192.7217, loss: 0.00003836\n",
      "Epoch: [19] [   9/  40] time: 192.9584, loss: 0.00001946\n",
      "Epoch: [19] [  10/  40] time: 193.1944, loss: 0.00022667\n",
      "Epoch: [19] [  11/  40] time: 193.4306, loss: 0.00008990\n",
      "Epoch: [19] [  12/  40] time: 193.6689, loss: 0.00035414\n",
      "Epoch: [19] [  13/  40] time: 193.9060, loss: 0.00011267\n",
      "Epoch: [19] [  14/  40] time: 194.1431, loss: 0.00002399\n",
      "Epoch: [19] [  15/  40] time: 194.3790, loss: 0.00000137\n",
      "Epoch: [19] [  16/  40] time: 194.6186, loss: 0.00015884\n",
      "Epoch: [19] [  17/  40] time: 194.8554, loss: 0.00001439\n",
      "Epoch: [19] [  18/  40] time: 195.0928, loss: 0.00002779\n",
      "Epoch: [19] [  19/  40] time: 195.3294, loss: 0.00006954\n",
      "Epoch: [19] [  20/  40] time: 195.5669, loss: 0.00002449\n",
      "Epoch: [19] [  21/  40] time: 195.8028, loss: 0.00000273\n",
      "Epoch: [19] [  22/  40] time: 196.0415, loss: 0.00041246\n",
      "Epoch: [19] [  23/  40] time: 196.2780, loss: 0.00000524\n",
      "Epoch: [19] [  24/  40] time: 196.5142, loss: 0.00009649\n",
      "Epoch: [19] [  25/  40] time: 196.7501, loss: 0.00002098\n",
      "Epoch: [19] [  26/  40] time: 196.9878, loss: 0.00059568\n",
      "Epoch: [19] [  27/  40] time: 197.2244, loss: 0.00005011\n",
      "Epoch: [19] [  28/  40] time: 197.4615, loss: 0.00008674\n",
      "Epoch: [19] [  29/  40] time: 197.6989, loss: 0.00001154\n",
      "Epoch: [19] [  30/  40] time: 197.9360, loss: 0.00000264\n",
      "Epoch: [19] [  31/  40] time: 198.1714, loss: 0.00011934\n",
      "Epoch: [19] [  32/  40] time: 198.4101, loss: 0.00001812\n",
      "Epoch: [19] [  33/  40] time: 198.6522, loss: 0.00021531\n",
      "Epoch: [19] [  34/  40] time: 198.8893, loss: 0.00009083\n",
      "Epoch: [19] [  35/  40] time: 199.1279, loss: 0.00002471\n",
      "Epoch: [19] [  36/  40] time: 199.3647, loss: 0.00000883\n",
      "Epoch: [19] [  37/  40] time: 199.6034, loss: 0.00001612\n",
      "Epoch: [19] [  38/  40] time: 199.8413, loss: 0.00006955\n",
      "Epoch: [19] [  39/  40] time: 200.0807, loss: 0.00025578\n",
      "[19/50] - ptime: 10.0220 loss: 0.00009922 acc: 0.80000\n",
      "Epoch: [20] [   0/  40] time: 201.2412, loss: 0.00001414\n",
      "Epoch: [20] [   1/  40] time: 201.4774, loss: 0.00001282\n",
      "Epoch: [20] [   2/  40] time: 201.7182, loss: 0.00001035\n",
      "Epoch: [20] [   3/  40] time: 201.9554, loss: 0.00002335\n",
      "Epoch: [20] [   4/  40] time: 202.1925, loss: 0.00000690\n",
      "Epoch: [20] [   5/  40] time: 202.4304, loss: 0.00012491\n",
      "Epoch: [20] [   6/  40] time: 202.6698, loss: 0.00001060\n",
      "Epoch: [20] [   7/  40] time: 202.9054, loss: 0.00004727\n",
      "Epoch: [20] [   8/  40] time: 203.1427, loss: 0.00008026\n",
      "Epoch: [20] [   9/  40] time: 203.3789, loss: 0.00007759\n",
      "Epoch: [20] [  10/  40] time: 203.6178, loss: 0.00004913\n",
      "Epoch: [20] [  11/  40] time: 203.8539, loss: 0.00000385\n",
      "Epoch: [20] [  12/  40] time: 204.0924, loss: 0.00000077\n",
      "Epoch: [20] [  13/  40] time: 204.3294, loss: 0.00039030\n",
      "Epoch: [20] [  14/  40] time: 204.5678, loss: 0.00012730\n",
      "Epoch: [20] [  15/  40] time: 204.8042, loss: 0.00000383\n",
      "Epoch: [20] [  16/  40] time: 205.0427, loss: 0.00010226\n",
      "Epoch: [20] [  17/  40] time: 205.2789, loss: 0.00003305\n",
      "Epoch: [20] [  18/  40] time: 205.5152, loss: 0.00004936\n",
      "Epoch: [20] [  19/  40] time: 205.7527, loss: 0.00008763\n",
      "Epoch: [20] [  20/  40] time: 205.9910, loss: 0.00003182\n",
      "Epoch: [20] [  21/  40] time: 206.2283, loss: 0.00021906\n",
      "Epoch: [20] [  22/  40] time: 206.4651, loss: 0.00006479\n",
      "Epoch: [20] [  23/  40] time: 206.7028, loss: 0.00000170\n",
      "Epoch: [20] [  24/  40] time: 206.9396, loss: 0.00004583\n",
      "Epoch: [20] [  25/  40] time: 207.1758, loss: 0.00000118\n",
      "Epoch: [20] [  26/  40] time: 207.4128, loss: 0.00005637\n",
      "Epoch: [20] [  27/  40] time: 207.6504, loss: 0.00002356\n",
      "Epoch: [20] [  28/  40] time: 207.8862, loss: 0.00000731\n",
      "Epoch: [20] [  29/  40] time: 208.1235, loss: 0.00002101\n",
      "Epoch: [20] [  30/  40] time: 208.3598, loss: 0.00002231\n",
      "Epoch: [20] [  31/  40] time: 208.5977, loss: 0.00003423\n",
      "Epoch: [20] [  32/  40] time: 208.8346, loss: 0.00003392\n",
      "Epoch: [20] [  33/  40] time: 209.0720, loss: 0.00001811\n",
      "Epoch: [20] [  34/  40] time: 209.3076, loss: 0.00002264\n",
      "Epoch: [20] [  35/  40] time: 209.5454, loss: 0.00002318\n",
      "Epoch: [20] [  36/  40] time: 209.7826, loss: 0.00001120\n",
      "Epoch: [20] [  37/  40] time: 210.0199, loss: 0.00009616\n",
      "Epoch: [20] [  38/  40] time: 210.2558, loss: 0.00135072\n",
      "Epoch: [20] [  39/  40] time: 210.4918, loss: 0.00003294\n",
      "[20/50] - ptime: 10.0233 loss: 0.00008434 acc: 0.80000\n",
      "Epoch: [21] [   0/  40] time: 211.6435, loss: 0.00000423\n",
      "Epoch: [21] [   1/  40] time: 211.8791, loss: 0.00012980\n",
      "Epoch: [21] [   2/  40] time: 212.1160, loss: 0.00002106\n",
      "Epoch: [21] [   3/  40] time: 212.3540, loss: 0.00000805\n",
      "Epoch: [21] [   4/  40] time: 212.5924, loss: 0.00004226\n",
      "Epoch: [21] [   5/  40] time: 212.8290, loss: 0.00001275\n",
      "Epoch: [21] [   6/  40] time: 213.0666, loss: 0.00001848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21] [   7/  40] time: 213.3029, loss: 0.00080706\n",
      "Epoch: [21] [   8/  40] time: 213.5392, loss: 0.00000496\n",
      "Epoch: [21] [   9/  40] time: 213.7766, loss: 0.00006814\n",
      "Epoch: [21] [  10/  40] time: 214.0140, loss: 0.00000771\n",
      "Epoch: [21] [  11/  40] time: 214.2516, loss: 0.00003783\n",
      "Epoch: [21] [  12/  40] time: 214.4880, loss: 0.00001941\n",
      "Epoch: [21] [  13/  40] time: 214.7252, loss: 0.00005495\n",
      "Epoch: [21] [  14/  40] time: 214.9630, loss: 0.00000853\n",
      "Epoch: [21] [  15/  40] time: 215.1991, loss: 0.00002447\n",
      "Epoch: [21] [  16/  40] time: 215.4360, loss: 0.00000523\n",
      "Epoch: [21] [  17/  40] time: 215.6746, loss: 0.00004092\n",
      "Epoch: [21] [  18/  40] time: 215.9106, loss: 0.00000936\n",
      "Epoch: [21] [  19/  40] time: 216.1479, loss: 0.00006416\n",
      "Epoch: [21] [  20/  40] time: 216.3847, loss: 0.00001878\n",
      "Epoch: [21] [  21/  40] time: 216.6240, loss: 0.00027353\n",
      "Epoch: [21] [  22/  40] time: 216.8604, loss: 0.00007560\n",
      "Epoch: [21] [  23/  40] time: 217.0988, loss: 0.00000958\n",
      "Epoch: [21] [  24/  40] time: 217.3351, loss: 0.00009666\n",
      "Epoch: [21] [  25/  40] time: 217.5723, loss: 0.00000348\n",
      "Epoch: [21] [  26/  40] time: 217.8093, loss: 0.00000136\n",
      "Epoch: [21] [  27/  40] time: 218.0468, loss: 0.00001850\n",
      "Epoch: [21] [  28/  40] time: 218.2839, loss: 0.00026567\n",
      "Epoch: [21] [  29/  40] time: 218.5203, loss: 0.00003906\n",
      "Epoch: [21] [  30/  40] time: 218.7562, loss: 0.00012285\n",
      "Epoch: [21] [  31/  40] time: 218.9946, loss: 0.00006600\n",
      "Epoch: [21] [  32/  40] time: 219.2316, loss: 0.00000663\n",
      "Epoch: [21] [  33/  40] time: 219.4694, loss: 0.00021519\n",
      "Epoch: [21] [  34/  40] time: 219.7077, loss: 0.00004480\n",
      "Epoch: [21] [  35/  40] time: 219.9455, loss: 0.00000686\n",
      "Epoch: [21] [  36/  40] time: 220.1815, loss: 0.00000178\n",
      "Epoch: [21] [  37/  40] time: 220.4180, loss: 0.00006328\n",
      "Epoch: [21] [  38/  40] time: 220.6562, loss: 0.00000998\n",
      "Epoch: [21] [  39/  40] time: 220.8935, loss: 0.00001902\n",
      "[21/50] - ptime: 10.0193 loss: 0.00006870 acc: 0.82000\n",
      "Epoch: [22] [   0/  40] time: 222.0583, loss: 0.00007868\n",
      "Epoch: [22] [   1/  40] time: 222.2952, loss: 0.00000427\n",
      "Epoch: [22] [   2/  40] time: 222.5313, loss: 0.00021201\n",
      "Epoch: [22] [   3/  40] time: 222.7688, loss: 0.00003998\n",
      "Epoch: [22] [   4/  40] time: 223.0072, loss: 0.00004351\n",
      "Epoch: [22] [   5/  40] time: 223.2444, loss: 0.00000651\n",
      "Epoch: [22] [   6/  40] time: 223.4821, loss: 0.00020951\n",
      "Epoch: [22] [   7/  40] time: 223.7209, loss: 0.00067742\n",
      "Epoch: [22] [   8/  40] time: 223.9578, loss: 0.00003618\n",
      "Epoch: [22] [   9/  40] time: 224.1939, loss: 0.00001546\n",
      "Epoch: [22] [  10/  40] time: 224.4305, loss: 0.00001655\n",
      "Epoch: [22] [  11/  40] time: 224.6713, loss: 0.00021482\n",
      "Epoch: [22] [  12/  40] time: 224.9076, loss: 0.00001853\n",
      "Epoch: [22] [  13/  40] time: 225.1463, loss: 0.00025216\n",
      "Epoch: [22] [  14/  40] time: 225.3828, loss: 0.00001157\n",
      "Epoch: [22] [  15/  40] time: 225.6205, loss: 0.00000125\n",
      "Epoch: [22] [  16/  40] time: 225.8567, loss: 0.00000752\n",
      "Epoch: [22] [  17/  40] time: 226.0945, loss: 0.00000803\n",
      "Epoch: [22] [  18/  40] time: 226.3314, loss: 0.00002141\n",
      "Epoch: [22] [  19/  40] time: 226.5693, loss: 0.00003933\n",
      "Epoch: [22] [  20/  40] time: 226.8050, loss: 0.00007362\n",
      "Epoch: [22] [  21/  40] time: 227.0425, loss: 0.00004018\n",
      "Epoch: [22] [  22/  40] time: 227.2794, loss: 0.00001215\n",
      "Epoch: [22] [  23/  40] time: 227.5171, loss: 0.00007208\n",
      "Epoch: [22] [  24/  40] time: 227.7553, loss: 0.00000420\n",
      "Epoch: [22] [  25/  40] time: 227.9936, loss: 0.00000122\n",
      "Epoch: [22] [  26/  40] time: 228.2301, loss: 0.00000216\n",
      "Epoch: [22] [  27/  40] time: 228.4663, loss: 0.00001860\n",
      "Epoch: [22] [  28/  40] time: 228.7059, loss: 0.00000324\n",
      "Epoch: [22] [  29/  40] time: 228.9435, loss: 0.00001696\n",
      "Epoch: [22] [  30/  40] time: 229.1805, loss: 0.00001425\n",
      "Epoch: [22] [  31/  40] time: 229.4173, loss: 0.00006862\n",
      "Epoch: [22] [  32/  40] time: 229.6548, loss: 0.00002913\n",
      "Epoch: [22] [  33/  40] time: 229.8906, loss: 0.00004373\n",
      "Epoch: [22] [  34/  40] time: 230.1284, loss: 0.00000779\n",
      "Epoch: [22] [  35/  40] time: 230.3663, loss: 0.00000251\n",
      "Epoch: [22] [  36/  40] time: 230.6045, loss: 0.00000047\n",
      "Epoch: [22] [  37/  40] time: 230.8413, loss: 0.00002106\n",
      "Epoch: [22] [  38/  40] time: 231.0787, loss: 0.00000330\n",
      "Epoch: [22] [  39/  40] time: 231.3148, loss: 0.00002585\n",
      "[22/50] - ptime: 10.0317 loss: 0.00005940 acc: 0.82000\n",
      "Epoch: [23] [   0/  40] time: 232.4459, loss: 0.00009256\n",
      "Epoch: [23] [   1/  40] time: 232.6852, loss: 0.00000270\n",
      "Epoch: [23] [   2/  40] time: 232.9218, loss: 0.00005732\n",
      "Epoch: [23] [   3/  40] time: 233.1585, loss: 0.00001608\n",
      "Epoch: [23] [   4/  40] time: 233.3959, loss: 0.00002746\n",
      "Epoch: [23] [   5/  40] time: 233.6331, loss: 0.00000220\n",
      "Epoch: [23] [   6/  40] time: 233.8700, loss: 0.00003520\n",
      "Epoch: [23] [   7/  40] time: 234.1073, loss: 0.00002056\n",
      "Epoch: [23] [   8/  40] time: 234.3431, loss: 0.00001087\n",
      "Epoch: [23] [   9/  40] time: 234.5809, loss: 0.00004359\n",
      "Epoch: [23] [  10/  40] time: 234.8189, loss: 0.00001768\n",
      "Epoch: [23] [  11/  40] time: 235.0571, loss: 0.00006481\n",
      "Epoch: [23] [  12/  40] time: 235.2935, loss: 0.00001116\n",
      "Epoch: [23] [  13/  40] time: 235.5292, loss: 0.00000206\n",
      "Epoch: [23] [  14/  40] time: 235.7664, loss: 0.00000266\n",
      "Epoch: [23] [  15/  40] time: 236.0047, loss: 0.00000281\n",
      "Epoch: [23] [  16/  40] time: 236.2420, loss: 0.00002013\n",
      "Epoch: [23] [  17/  40] time: 236.4783, loss: 0.00001110\n",
      "Epoch: [23] [  18/  40] time: 236.7164, loss: 0.00000186\n",
      "Epoch: [23] [  19/  40] time: 236.9536, loss: 0.00010409\n",
      "Epoch: [23] [  20/  40] time: 237.1896, loss: 0.00000614\n",
      "Epoch: [23] [  21/  40] time: 237.4274, loss: 0.00005138\n",
      "Epoch: [23] [  22/  40] time: 237.6688, loss: 0.00000176\n",
      "Epoch: [23] [  23/  40] time: 237.9082, loss: 0.00000579\n",
      "Epoch: [23] [  24/  40] time: 238.1454, loss: 0.00000170\n",
      "Epoch: [23] [  25/  40] time: 238.3826, loss: 0.00005100\n",
      "Epoch: [23] [  26/  40] time: 238.6200, loss: 0.00002815\n",
      "Epoch: [23] [  27/  40] time: 238.8561, loss: 0.00000021\n",
      "Epoch: [23] [  28/  40] time: 239.0944, loss: 0.00028593\n",
      "Epoch: [23] [  29/  40] time: 239.3330, loss: 0.00000712\n",
      "Epoch: [23] [  30/  40] time: 239.5697, loss: 0.00000477\n",
      "Epoch: [23] [  31/  40] time: 239.8059, loss: 0.00002715\n",
      "Epoch: [23] [  32/  40] time: 240.0428, loss: 0.00000523\n",
      "Epoch: [23] [  33/  40] time: 240.2793, loss: 0.00000259\n",
      "Epoch: [23] [  34/  40] time: 240.5156, loss: 0.00005636\n",
      "Epoch: [23] [  35/  40] time: 240.7557, loss: 0.00000966\n",
      "Epoch: [23] [  36/  40] time: 240.9930, loss: 0.00009962\n",
      "Epoch: [23] [  37/  40] time: 241.2291, loss: 0.00000963\n",
      "Epoch: [23] [  38/  40] time: 241.4651, loss: 0.00000952\n",
      "Epoch: [23] [  39/  40] time: 241.7046, loss: 0.00000338\n",
      "[23/50] - ptime: 10.0240 loss: 0.00003035 acc: 0.81000\n",
      "Epoch: [24] [   0/  40] time: 242.8809, loss: 0.00000907\n",
      "Epoch: [24] [   1/  40] time: 243.1195, loss: 0.00002486\n",
      "Epoch: [24] [   2/  40] time: 243.3557, loss: 0.00012201\n",
      "Epoch: [24] [   3/  40] time: 243.5935, loss: 0.00000573\n",
      "Epoch: [24] [   4/  40] time: 243.8305, loss: 0.00000907\n",
      "Epoch: [24] [   5/  40] time: 244.0709, loss: 0.00000441\n",
      "Epoch: [24] [   6/  40] time: 244.3087, loss: 0.00000766\n",
      "Epoch: [24] [   7/  40] time: 244.5460, loss: 0.00003545\n",
      "Epoch: [24] [   8/  40] time: 244.7840, loss: 0.00010990\n",
      "Epoch: [24] [   9/  40] time: 245.0212, loss: 0.00012489\n",
      "Epoch: [24] [  10/  40] time: 245.2569, loss: 0.00001792\n",
      "Epoch: [24] [  11/  40] time: 245.5004, loss: 0.00005409\n",
      "Epoch: [24] [  12/  40] time: 245.7389, loss: 0.00001109\n",
      "Epoch: [24] [  13/  40] time: 245.9773, loss: 0.00000653\n",
      "Epoch: [24] [  14/  40] time: 246.2143, loss: 0.00000960\n",
      "Epoch: [24] [  15/  40] time: 246.4520, loss: 0.00005592\n",
      "Epoch: [24] [  16/  40] time: 246.6893, loss: 0.00000554\n",
      "Epoch: [24] [  17/  40] time: 246.9262, loss: 0.00000291\n",
      "Epoch: [24] [  18/  40] time: 247.1624, loss: 0.00000967\n",
      "Epoch: [24] [  19/  40] time: 247.3996, loss: 0.00000472\n",
      "Epoch: [24] [  20/  40] time: 247.6378, loss: 0.00002318\n",
      "Epoch: [24] [  21/  40] time: 247.8740, loss: 0.00005707\n",
      "Epoch: [24] [  22/  40] time: 248.1110, loss: 0.00001010\n",
      "Epoch: [24] [  23/  40] time: 248.3468, loss: 0.00000616\n",
      "Epoch: [24] [  24/  40] time: 248.5841, loss: 0.00000198\n",
      "Epoch: [24] [  25/  40] time: 248.8216, loss: 0.00003496\n",
      "Epoch: [24] [  26/  40] time: 249.0590, loss: 0.00010299\n",
      "Epoch: [24] [  27/  40] time: 249.2951, loss: 0.00000633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24] [  28/  40] time: 249.5311, loss: 0.00021662\n",
      "Epoch: [24] [  29/  40] time: 249.7701, loss: 0.00000258\n",
      "Epoch: [24] [  30/  40] time: 250.0080, loss: 0.00000631\n",
      "Epoch: [24] [  31/  40] time: 250.2449, loss: 0.00020545\n",
      "Epoch: [24] [  32/  40] time: 250.4824, loss: 0.00010773\n",
      "Epoch: [24] [  33/  40] time: 250.7213, loss: 0.00048529\n",
      "Epoch: [24] [  34/  40] time: 250.9581, loss: 0.00000080\n",
      "Epoch: [24] [  35/  40] time: 251.1944, loss: 0.00004684\n",
      "Epoch: [24] [  36/  40] time: 251.4348, loss: 0.00000263\n",
      "Epoch: [24] [  37/  40] time: 251.6734, loss: 0.00001965\n",
      "Epoch: [24] [  38/  40] time: 251.9094, loss: 0.00000457\n",
      "Epoch: [24] [  39/  40] time: 252.1487, loss: 0.00003456\n",
      "[24/50] - ptime: 10.0374 loss: 0.00005017 acc: 0.81000\n",
      "Epoch: [25] [   0/  40] time: 253.2986, loss: 0.00007174\n",
      "Epoch: [25] [   1/  40] time: 253.5351, loss: 0.00006544\n",
      "Epoch: [25] [   2/  40] time: 253.7737, loss: 0.00017170\n",
      "Epoch: [25] [   3/  40] time: 254.0112, loss: 0.00000311\n",
      "Epoch: [25] [   4/  40] time: 254.2471, loss: 0.00000514\n",
      "Epoch: [25] [   5/  40] time: 254.4842, loss: 0.00000796\n",
      "Epoch: [25] [   6/  40] time: 254.7221, loss: 0.00002612\n",
      "Epoch: [25] [   7/  40] time: 254.9597, loss: 0.00043566\n",
      "Epoch: [25] [   8/  40] time: 255.1964, loss: 0.00000202\n",
      "Epoch: [25] [   9/  40] time: 255.4345, loss: 0.00000356\n",
      "Epoch: [25] [  10/  40] time: 255.6720, loss: 0.00000199\n",
      "Epoch: [25] [  11/  40] time: 255.9085, loss: 0.00000192\n",
      "Epoch: [25] [  12/  40] time: 256.1470, loss: 0.00011841\n",
      "Epoch: [25] [  13/  40] time: 256.3833, loss: 0.00005445\n",
      "Epoch: [25] [  14/  40] time: 256.6194, loss: 0.00000201\n",
      "Epoch: [25] [  15/  40] time: 256.8553, loss: 0.00002200\n",
      "Epoch: [25] [  16/  40] time: 257.0924, loss: 0.00003086\n",
      "Epoch: [25] [  17/  40] time: 257.3294, loss: 0.00017325\n",
      "Epoch: [25] [  18/  40] time: 257.5665, loss: 0.00000780\n",
      "Epoch: [25] [  19/  40] time: 257.8026, loss: 0.00000184\n",
      "Epoch: [25] [  20/  40] time: 258.0401, loss: 0.00001692\n",
      "Epoch: [25] [  21/  40] time: 258.2769, loss: 0.00000075\n",
      "Epoch: [25] [  22/  40] time: 258.5090, loss: 0.00001698\n",
      "Epoch: [25] [  23/  40] time: 258.7469, loss: 0.00006605\n",
      "Epoch: [25] [  24/  40] time: 258.9865, loss: 0.00043307\n",
      "Epoch: [25] [  25/  40] time: 259.2225, loss: 0.00000874\n",
      "Epoch: [25] [  26/  40] time: 259.4618, loss: 0.00000962\n",
      "Epoch: [25] [  27/  40] time: 259.7013, loss: 0.00016216\n",
      "Epoch: [25] [  28/  40] time: 259.9394, loss: 0.00000208\n",
      "Epoch: [25] [  29/  40] time: 260.1764, loss: 0.00000025\n",
      "Epoch: [25] [  30/  40] time: 260.4128, loss: 0.00002964\n",
      "Epoch: [25] [  31/  40] time: 260.6486, loss: 0.00000130\n",
      "Epoch: [25] [  32/  40] time: 260.8854, loss: 0.00001457\n",
      "Epoch: [25] [  33/  40] time: 261.1232, loss: 0.00000095\n",
      "Epoch: [25] [  34/  40] time: 261.3599, loss: 0.00005656\n",
      "Epoch: [25] [  35/  40] time: 261.5961, loss: 0.00005573\n",
      "Epoch: [25] [  36/  40] time: 261.8331, loss: 0.00002603\n",
      "Epoch: [25] [  37/  40] time: 262.0708, loss: 0.00000452\n",
      "Epoch: [25] [  38/  40] time: 262.3095, loss: 0.00000415\n",
      "Epoch: [25] [  39/  40] time: 262.5472, loss: 0.00005329\n",
      "[25/50] - ptime: 10.0194 loss: 0.00005426 acc: 0.81000\n",
      "Epoch: [26] [   0/  40] time: 263.6860, loss: 0.00000045\n",
      "Epoch: [26] [   1/  40] time: 263.9227, loss: 0.00002544\n",
      "Epoch: [26] [   2/  40] time: 264.1616, loss: 0.00000461\n",
      "Epoch: [26] [   3/  40] time: 264.3980, loss: 0.00004323\n",
      "Epoch: [26] [   4/  40] time: 264.6355, loss: 0.00001393\n",
      "Epoch: [26] [   5/  40] time: 264.8731, loss: 0.00000645\n",
      "Epoch: [26] [   6/  40] time: 265.1115, loss: 0.00000144\n",
      "Epoch: [26] [   7/  40] time: 265.3477, loss: 0.00004405\n",
      "Epoch: [26] [   8/  40] time: 265.5837, loss: 0.00132163\n",
      "Epoch: [26] [   9/  40] time: 265.8208, loss: 0.00000652\n",
      "Epoch: [26] [  10/  40] time: 266.0611, loss: 0.00009426\n",
      "Epoch: [26] [  11/  40] time: 266.2981, loss: 0.00027551\n",
      "Epoch: [26] [  12/  40] time: 266.5347, loss: 0.00000415\n",
      "Epoch: [26] [  13/  40] time: 266.7734, loss: 0.00001054\n",
      "Epoch: [26] [  14/  40] time: 267.0104, loss: 0.00001588\n",
      "Epoch: [26] [  15/  40] time: 267.2471, loss: 0.00002550\n",
      "Epoch: [26] [  16/  40] time: 267.4840, loss: 0.00006851\n",
      "Epoch: [26] [  17/  40] time: 267.7226, loss: 0.00003883\n",
      "Epoch: [26] [  18/  40] time: 267.9597, loss: 0.00000554\n",
      "Epoch: [26] [  19/  40] time: 268.1961, loss: 0.00005643\n",
      "Epoch: [26] [  20/  40] time: 268.4323, loss: 0.00003377\n",
      "Epoch: [26] [  21/  40] time: 268.6709, loss: 0.00000800\n",
      "Epoch: [26] [  22/  40] time: 268.9081, loss: 0.00000642\n",
      "Epoch: [26] [  23/  40] time: 269.1465, loss: 0.00000944\n",
      "Epoch: [26] [  24/  40] time: 269.3839, loss: 0.00011105\n",
      "Epoch: [26] [  25/  40] time: 269.6199, loss: 0.00001199\n",
      "Epoch: [26] [  26/  40] time: 269.8558, loss: 0.00002120\n",
      "Epoch: [26] [  27/  40] time: 270.0940, loss: 0.00001366\n",
      "Epoch: [26] [  28/  40] time: 270.3306, loss: 0.00000332\n",
      "Epoch: [26] [  29/  40] time: 270.5678, loss: 0.00003487\n",
      "Epoch: [26] [  30/  40] time: 270.8060, loss: 0.00001186\n",
      "Epoch: [26] [  31/  40] time: 271.0432, loss: 0.00005003\n",
      "Epoch: [26] [  32/  40] time: 271.2789, loss: 0.00000149\n",
      "Epoch: [26] [  33/  40] time: 271.5162, loss: 0.00000010\n",
      "Epoch: [26] [  34/  40] time: 271.7553, loss: 0.00000032\n",
      "Epoch: [26] [  35/  40] time: 271.9923, loss: 0.00001077\n",
      "Epoch: [26] [  36/  40] time: 272.2291, loss: 0.00002633\n",
      "Epoch: [26] [  37/  40] time: 272.4658, loss: 0.00000711\n",
      "Epoch: [26] [  38/  40] time: 272.7033, loss: 0.00000939\n",
      "Epoch: [26] [  39/  40] time: 272.9413, loss: 0.00000898\n",
      "[26/50] - ptime: 10.0235 loss: 0.00006107 acc: 0.78000\n",
      "Epoch: [27] [   0/  40] time: 274.0794, loss: 0.00000562\n",
      "Epoch: [27] [   1/  40] time: 274.3157, loss: 0.00003389\n",
      "Epoch: [27] [   2/  40] time: 274.5518, loss: 0.00002360\n",
      "Epoch: [27] [   3/  40] time: 274.7892, loss: 0.00000098\n",
      "Epoch: [27] [   4/  40] time: 275.0276, loss: 0.00012082\n",
      "Epoch: [27] [   5/  40] time: 275.2666, loss: 0.00007724\n",
      "Epoch: [27] [   6/  40] time: 275.5032, loss: 0.00000507\n",
      "Epoch: [27] [   7/  40] time: 275.7411, loss: 0.00001867\n",
      "Epoch: [27] [   8/  40] time: 275.9787, loss: 0.00000253\n",
      "Epoch: [27] [   9/  40] time: 276.2141, loss: 0.00000502\n",
      "Epoch: [27] [  10/  40] time: 276.4519, loss: 0.00001784\n",
      "Epoch: [27] [  11/  40] time: 276.6895, loss: 0.00000225\n",
      "Epoch: [27] [  12/  40] time: 276.9284, loss: 0.00001162\n",
      "Epoch: [27] [  13/  40] time: 277.1661, loss: 0.00000313\n",
      "Epoch: [27] [  14/  40] time: 277.4020, loss: 0.00001002\n",
      "Epoch: [27] [  15/  40] time: 277.6381, loss: 0.00000927\n",
      "Epoch: [27] [  16/  40] time: 277.8776, loss: 0.00000593\n",
      "Epoch: [27] [  17/  40] time: 278.1167, loss: 0.00000261\n",
      "Epoch: [27] [  18/  40] time: 278.3527, loss: 0.00000210\n",
      "Epoch: [27] [  19/  40] time: 278.5889, loss: 0.00025537\n",
      "Epoch: [27] [  20/  40] time: 278.8266, loss: 0.00002955\n",
      "Epoch: [27] [  21/  40] time: 279.0639, loss: 0.00000962\n",
      "Epoch: [27] [  22/  40] time: 279.3005, loss: 0.00000485\n",
      "Epoch: [27] [  23/  40] time: 279.5373, loss: 0.00002309\n",
      "Epoch: [27] [  24/  40] time: 279.7760, loss: 0.00000833\n",
      "Epoch: [27] [  25/  40] time: 280.0130, loss: 0.00048482\n",
      "Epoch: [27] [  26/  40] time: 280.2491, loss: 0.00002483\n",
      "Epoch: [27] [  27/  40] time: 280.4858, loss: 0.00000093\n",
      "Epoch: [27] [  28/  40] time: 280.7231, loss: 0.00000136\n",
      "Epoch: [27] [  29/  40] time: 280.9629, loss: 0.00001566\n",
      "Epoch: [27] [  30/  40] time: 281.1999, loss: 0.00001695\n",
      "Epoch: [27] [  31/  40] time: 281.4369, loss: 0.00001123\n",
      "Epoch: [27] [  32/  40] time: 281.6734, loss: 0.00000744\n",
      "Epoch: [27] [  33/  40] time: 281.9100, loss: 0.00016892\n",
      "Epoch: [27] [  34/  40] time: 282.1484, loss: 0.00015175\n",
      "Epoch: [27] [  35/  40] time: 282.3849, loss: 0.00000160\n",
      "Epoch: [27] [  36/  40] time: 282.6220, loss: 0.00005924\n",
      "Epoch: [27] [  37/  40] time: 282.8579, loss: 0.00001012\n",
      "Epoch: [27] [  38/  40] time: 283.0957, loss: 0.00001616\n",
      "Epoch: [27] [  39/  40] time: 283.3342, loss: 0.00001734\n",
      "[27/50] - ptime: 10.0247 loss: 0.00004193 acc: 0.79000\n",
      "Epoch: [28] [   0/  40] time: 284.5118, loss: 0.00001283\n",
      "Epoch: [28] [   1/  40] time: 284.7515, loss: 0.00002479\n",
      "Epoch: [28] [   2/  40] time: 284.9903, loss: 0.00004843\n",
      "Epoch: [28] [   3/  40] time: 285.2266, loss: 0.00000067\n",
      "Epoch: [28] [   4/  40] time: 285.4639, loss: 0.00001061\n",
      "Epoch: [28] [   5/  40] time: 285.7022, loss: 0.00001706\n",
      "Epoch: [28] [   6/  40] time: 285.9421, loss: 0.00000416\n",
      "Epoch: [28] [   7/  40] time: 286.1789, loss: 0.00002478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [28] [   8/  40] time: 286.4153, loss: 0.00003035\n",
      "Epoch: [28] [   9/  40] time: 286.6515, loss: 0.00000330\n",
      "Epoch: [28] [  10/  40] time: 286.8877, loss: 0.00029346\n",
      "Epoch: [28] [  11/  40] time: 287.1256, loss: 0.00001836\n",
      "Epoch: [28] [  12/  40] time: 287.3624, loss: 0.00004652\n",
      "Epoch: [28] [  13/  40] time: 287.5991, loss: 0.00000172\n",
      "Epoch: [28] [  14/  40] time: 287.8391, loss: 0.00000781\n",
      "Epoch: [28] [  15/  40] time: 288.0763, loss: 0.00000135\n",
      "Epoch: [28] [  16/  40] time: 288.3123, loss: 0.00004090\n",
      "Epoch: [28] [  17/  40] time: 288.5491, loss: 0.00001231\n",
      "Epoch: [28] [  18/  40] time: 288.7892, loss: 0.00003835\n",
      "Epoch: [28] [  19/  40] time: 289.0286, loss: 0.00000601\n",
      "Epoch: [28] [  20/  40] time: 289.2660, loss: 0.00000437\n",
      "Epoch: [28] [  21/  40] time: 289.5041, loss: 0.00008253\n",
      "Epoch: [28] [  22/  40] time: 289.7397, loss: 0.00010777\n",
      "Epoch: [28] [  23/  40] time: 289.9775, loss: 0.00004623\n",
      "Epoch: [28] [  24/  40] time: 290.2147, loss: 0.00000032\n",
      "Epoch: [28] [  25/  40] time: 290.4516, loss: 0.00012482\n",
      "Epoch: [28] [  26/  40] time: 290.6885, loss: 0.00002845\n",
      "Epoch: [28] [  27/  40] time: 290.9253, loss: 0.00013861\n",
      "Epoch: [28] [  28/  40] time: 291.1617, loss: 0.00003716\n",
      "Epoch: [28] [  29/  40] time: 291.3984, loss: 0.00002554\n",
      "Epoch: [28] [  30/  40] time: 291.6360, loss: 0.00000451\n",
      "Epoch: [28] [  31/  40] time: 291.8748, loss: 0.00000963\n",
      "Epoch: [28] [  32/  40] time: 292.1127, loss: 0.00000363\n",
      "Epoch: [28] [  33/  40] time: 292.3497, loss: 0.00001520\n",
      "Epoch: [28] [  34/  40] time: 292.5857, loss: 0.00000809\n",
      "Epoch: [28] [  35/  40] time: 292.8252, loss: 0.00000624\n",
      "Epoch: [28] [  36/  40] time: 293.0637, loss: 0.00008314\n",
      "Epoch: [28] [  37/  40] time: 293.3006, loss: 0.00000950\n",
      "Epoch: [28] [  38/  40] time: 293.5371, loss: 0.00002491\n",
      "Epoch: [28] [  39/  40] time: 293.7751, loss: 0.00000138\n",
      "[28/50] - ptime: 10.0360 loss: 0.00003514 acc: 0.79000\n",
      "Epoch: [29] [   0/  40] time: 294.9521, loss: 0.00002792\n",
      "Epoch: [29] [   1/  40] time: 295.1903, loss: 0.00000306\n",
      "Epoch: [29] [   2/  40] time: 295.4279, loss: 0.00008071\n",
      "Epoch: [29] [   3/  40] time: 295.6644, loss: 0.00001837\n",
      "Epoch: [29] [   4/  40] time: 295.9020, loss: 0.00002907\n",
      "Epoch: [29] [   5/  40] time: 296.1391, loss: 0.00000589\n",
      "Epoch: [29] [   6/  40] time: 296.3760, loss: 0.00000059\n",
      "Epoch: [29] [   7/  40] time: 296.6129, loss: 0.00000076\n",
      "Epoch: [29] [   8/  40] time: 296.8526, loss: 0.00000177\n",
      "Epoch: [29] [   9/  40] time: 297.0901, loss: 0.00000928\n",
      "Epoch: [29] [  10/  40] time: 297.3265, loss: 0.00002398\n",
      "Epoch: [29] [  11/  40] time: 297.5635, loss: 0.00000279\n",
      "Epoch: [29] [  12/  40] time: 297.8030, loss: 0.00001368\n",
      "Epoch: [29] [  13/  40] time: 298.0413, loss: 0.00000254\n",
      "Epoch: [29] [  14/  40] time: 298.2767, loss: 0.00001298\n",
      "Epoch: [29] [  15/  40] time: 298.5132, loss: 0.00005915\n",
      "Epoch: [29] [  16/  40] time: 298.7512, loss: 0.00003311\n",
      "Epoch: [29] [  17/  40] time: 298.9882, loss: 0.00000146\n",
      "Epoch: [29] [  18/  40] time: 299.2251, loss: 0.00002883\n",
      "Epoch: [29] [  19/  40] time: 299.4618, loss: 0.00003797\n",
      "Epoch: [29] [  20/  40] time: 299.7003, loss: 0.00000042\n",
      "Epoch: [29] [  21/  40] time: 299.9385, loss: 0.00004031\n",
      "Epoch: [29] [  22/  40] time: 300.1744, loss: 0.00000956\n",
      "Epoch: [29] [  23/  40] time: 300.4102, loss: 0.00000208\n",
      "Epoch: [29] [  24/  40] time: 300.6479, loss: 0.00000765\n",
      "Epoch: [29] [  25/  40] time: 300.8855, loss: 0.00001416\n",
      "Epoch: [29] [  26/  40] time: 301.1249, loss: 0.00000620\n",
      "Epoch: [29] [  27/  40] time: 301.3621, loss: 0.00001138\n",
      "Epoch: [29] [  28/  40] time: 301.5980, loss: 0.00000050\n",
      "Epoch: [29] [  29/  40] time: 301.8361, loss: 0.00000085\n",
      "Epoch: [29] [  30/  40] time: 302.0742, loss: 0.00000160\n",
      "Epoch: [29] [  31/  40] time: 302.3125, loss: 0.00000213\n",
      "Epoch: [29] [  32/  40] time: 302.5496, loss: 0.00000383\n",
      "Epoch: [29] [  33/  40] time: 302.7892, loss: 0.00005707\n",
      "Epoch: [29] [  34/  40] time: 303.0265, loss: 0.00000255\n",
      "Epoch: [29] [  35/  40] time: 303.2646, loss: 0.00000034\n",
      "Epoch: [29] [  36/  40] time: 303.5015, loss: 0.00001427\n",
      "Epoch: [29] [  37/  40] time: 303.7395, loss: 0.00002909\n",
      "Epoch: [29] [  38/  40] time: 303.9773, loss: 0.00000627\n",
      "Epoch: [29] [  39/  40] time: 304.2142, loss: 0.00001231\n",
      "[29/50] - ptime: 10.0341 loss: 0.00001541 acc: 0.79000\n",
      "Epoch: [30] [   0/  40] time: 305.3472, loss: 0.00005322\n",
      "Epoch: [30] [   1/  40] time: 305.5841, loss: 0.00000392\n",
      "Epoch: [30] [   2/  40] time: 305.8219, loss: 0.00000757\n",
      "Epoch: [30] [   3/  40] time: 306.0607, loss: 0.00015370\n",
      "Epoch: [30] [   4/  40] time: 306.2968, loss: 0.00000437\n",
      "Epoch: [30] [   5/  40] time: 306.5326, loss: 0.00000571\n",
      "Epoch: [30] [   6/  40] time: 306.7700, loss: 0.00003727\n",
      "Epoch: [30] [   7/  40] time: 307.0099, loss: 0.00001073\n",
      "Epoch: [30] [   8/  40] time: 307.2480, loss: 0.00001060\n",
      "Epoch: [30] [   9/  40] time: 307.4843, loss: 0.00000028\n",
      "Epoch: [30] [  10/  40] time: 307.7223, loss: 0.00000386\n",
      "Epoch: [30] [  11/  40] time: 307.9610, loss: 0.00000597\n",
      "Epoch: [30] [  12/  40] time: 308.1975, loss: 0.00000542\n",
      "Epoch: [30] [  13/  40] time: 308.4342, loss: 0.00000132\n",
      "Epoch: [30] [  14/  40] time: 308.6708, loss: 0.00000304\n",
      "Epoch: [30] [  15/  40] time: 308.9090, loss: 0.00004782\n",
      "Epoch: [30] [  16/  40] time: 309.1467, loss: 0.00000936\n",
      "Epoch: [30] [  17/  40] time: 309.3828, loss: 0.00000016\n",
      "Epoch: [30] [  18/  40] time: 309.6193, loss: 0.00000876\n",
      "Epoch: [30] [  19/  40] time: 309.8580, loss: 0.00000354\n",
      "Epoch: [30] [  20/  40] time: 310.0998, loss: 0.00006448\n",
      "Epoch: [30] [  21/  40] time: 310.3365, loss: 0.00001632\n",
      "Epoch: [30] [  22/  40] time: 310.5721, loss: 0.00001524\n",
      "Epoch: [30] [  23/  40] time: 310.8102, loss: 0.00000822\n",
      "Epoch: [30] [  24/  40] time: 311.0489, loss: 0.00000302\n",
      "Epoch: [30] [  25/  40] time: 311.2855, loss: 0.00000064\n",
      "Epoch: [30] [  26/  40] time: 311.5252, loss: 0.00000607\n",
      "Epoch: [30] [  27/  40] time: 311.7625, loss: 0.00000278\n",
      "Epoch: [30] [  28/  40] time: 311.9997, loss: 0.00000412\n",
      "Epoch: [30] [  29/  40] time: 312.2362, loss: 0.00055251\n",
      "Epoch: [30] [  30/  40] time: 312.4737, loss: 0.00000611\n",
      "Epoch: [30] [  31/  40] time: 312.7104, loss: 0.00002051\n",
      "Epoch: [30] [  32/  40] time: 312.9505, loss: 0.00000099\n",
      "Epoch: [30] [  33/  40] time: 313.1866, loss: 0.00001210\n",
      "Epoch: [30] [  34/  40] time: 313.4232, loss: 0.00004722\n",
      "Epoch: [30] [  35/  40] time: 313.6596, loss: 0.00011493\n",
      "Epoch: [30] [  36/  40] time: 313.8978, loss: 0.00000379\n",
      "Epoch: [30] [  37/  40] time: 314.1355, loss: 0.00001095\n",
      "Epoch: [30] [  38/  40] time: 314.3725, loss: 0.00019202\n",
      "Epoch: [30] [  39/  40] time: 314.6095, loss: 0.00007299\n",
      "[30/50] - ptime: 10.0232 loss: 0.00003829 acc: 0.79000\n",
      "Epoch: [31] [   0/  40] time: 315.7886, loss: 0.00001348\n",
      "Epoch: [31] [   1/  40] time: 316.0258, loss: 0.00000099\n",
      "Epoch: [31] [   2/  40] time: 316.2617, loss: 0.00000846\n",
      "Epoch: [31] [   3/  40] time: 316.4979, loss: 0.00000992\n",
      "Epoch: [31] [   4/  40] time: 316.7354, loss: 0.00000070\n",
      "Epoch: [31] [   5/  40] time: 316.9746, loss: 0.00000077\n",
      "Epoch: [31] [   6/  40] time: 317.2113, loss: 0.00000560\n",
      "Epoch: [31] [   7/  40] time: 317.4475, loss: 0.00000982\n",
      "Epoch: [31] [   8/  40] time: 317.6839, loss: 0.00000792\n",
      "Epoch: [31] [   9/  40] time: 317.9227, loss: 0.00000629\n",
      "Epoch: [31] [  10/  40] time: 318.1604, loss: 0.00002937\n",
      "Epoch: [31] [  11/  40] time: 318.3970, loss: 0.00000336\n",
      "Epoch: [31] [  12/  40] time: 318.6334, loss: 0.00000181\n",
      "Epoch: [31] [  13/  40] time: 318.8742, loss: 0.00000243\n",
      "Epoch: [31] [  14/  40] time: 319.1135, loss: 0.00000182\n",
      "Epoch: [31] [  15/  40] time: 319.3497, loss: 0.00013066\n",
      "Epoch: [31] [  16/  40] time: 319.5872, loss: 0.00000686\n",
      "Epoch: [31] [  17/  40] time: 319.8261, loss: 0.00001571\n",
      "Epoch: [31] [  18/  40] time: 320.0633, loss: 0.00000875\n",
      "Epoch: [31] [  19/  40] time: 320.2995, loss: 0.00003881\n",
      "Epoch: [31] [  20/  40] time: 320.5372, loss: 0.00000185\n",
      "Epoch: [31] [  21/  40] time: 320.7755, loss: 0.00007734\n",
      "Epoch: [31] [  22/  40] time: 321.0147, loss: 0.00000155\n",
      "Epoch: [31] [  23/  40] time: 321.2474, loss: 0.00000419\n",
      "Epoch: [31] [  24/  40] time: 321.4858, loss: 0.00000686\n",
      "Epoch: [31] [  25/  40] time: 321.7217, loss: 0.00006440\n",
      "Epoch: [31] [  26/  40] time: 321.9617, loss: 0.00000067\n",
      "Epoch: [31] [  27/  40] time: 322.1978, loss: 0.00000248\n",
      "Epoch: [31] [  28/  40] time: 322.4352, loss: 0.00000638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31] [  29/  40] time: 322.6723, loss: 0.00000322\n",
      "Epoch: [31] [  30/  40] time: 322.9097, loss: 0.00023616\n",
      "Epoch: [31] [  31/  40] time: 323.1468, loss: 0.00001779\n",
      "Epoch: [31] [  32/  40] time: 323.3836, loss: 0.00000055\n",
      "Epoch: [31] [  33/  40] time: 323.6207, loss: 0.00003787\n",
      "Epoch: [31] [  34/  40] time: 323.8591, loss: 0.00000831\n",
      "Epoch: [31] [  35/  40] time: 324.0969, loss: 0.00002580\n",
      "Epoch: [31] [  36/  40] time: 324.3342, loss: 0.00000116\n",
      "Epoch: [31] [  37/  40] time: 324.5703, loss: 0.00000839\n",
      "Epoch: [31] [  38/  40] time: 324.8067, loss: 0.00003426\n",
      "Epoch: [31] [  39/  40] time: 325.0456, loss: 0.00000233\n",
      "[31/50] - ptime: 10.0310 loss: 0.00002113 acc: 0.79000\n",
      "Epoch: [32] [   0/  40] time: 326.2221, loss: 0.00000527\n",
      "Epoch: [32] [   1/  40] time: 326.4593, loss: 0.00001244\n",
      "Epoch: [32] [   2/  40] time: 326.6952, loss: 0.00000337\n",
      "Epoch: [32] [   3/  40] time: 326.9328, loss: 0.00000136\n",
      "Epoch: [32] [   4/  40] time: 327.1701, loss: 0.00000131\n",
      "Epoch: [32] [   5/  40] time: 327.4064, loss: 0.00008592\n",
      "Epoch: [32] [   6/  40] time: 327.6437, loss: 0.00002212\n",
      "Epoch: [32] [   7/  40] time: 327.8812, loss: 0.00001346\n",
      "Epoch: [32] [   8/  40] time: 328.1182, loss: 0.00000424\n",
      "Epoch: [32] [   9/  40] time: 328.3549, loss: 0.00000367\n",
      "Epoch: [32] [  10/  40] time: 328.5915, loss: 0.00000263\n",
      "Epoch: [32] [  11/  40] time: 328.8305, loss: 0.00001240\n",
      "Epoch: [32] [  12/  40] time: 329.0683, loss: 0.00006087\n",
      "Epoch: [32] [  13/  40] time: 329.3042, loss: 0.00002383\n",
      "Epoch: [32] [  14/  40] time: 329.5402, loss: 0.00000197\n",
      "Epoch: [32] [  15/  40] time: 329.7785, loss: 0.00000038\n",
      "Epoch: [32] [  16/  40] time: 330.0173, loss: 0.00000946\n",
      "Epoch: [32] [  17/  40] time: 330.2533, loss: 0.00002656\n",
      "Epoch: [32] [  18/  40] time: 330.4905, loss: 0.00000013\n",
      "Epoch: [32] [  19/  40] time: 330.7292, loss: 0.00002260\n",
      "Epoch: [32] [  20/  40] time: 330.9636, loss: 0.00000394\n",
      "Epoch: [32] [  21/  40] time: 331.2010, loss: 0.00001280\n",
      "Epoch: [32] [  22/  40] time: 331.4381, loss: 0.00004623\n",
      "Epoch: [32] [  23/  40] time: 331.6746, loss: 0.00000990\n",
      "Epoch: [32] [  24/  40] time: 331.9123, loss: 0.00000641\n",
      "Epoch: [32] [  25/  40] time: 332.1503, loss: 0.00009840\n",
      "Epoch: [32] [  26/  40] time: 332.3882, loss: 0.00000687\n",
      "Epoch: [32] [  27/  40] time: 332.6231, loss: 0.00000028\n",
      "Epoch: [32] [  28/  40] time: 332.8623, loss: 0.00003049\n",
      "Epoch: [32] [  29/  40] time: 333.0994, loss: 0.00049438\n",
      "Epoch: [32] [  30/  40] time: 333.3382, loss: 0.00000360\n",
      "Epoch: [32] [  31/  40] time: 333.5742, loss: 0.00000259\n",
      "Epoch: [32] [  32/  40] time: 333.8123, loss: 0.00002496\n",
      "Epoch: [32] [  33/  40] time: 334.0526, loss: 0.00000136\n",
      "Epoch: [32] [  34/  40] time: 334.2889, loss: 0.00000544\n",
      "Epoch: [32] [  35/  40] time: 334.5254, loss: 0.00001440\n",
      "Epoch: [32] [  36/  40] time: 334.7615, loss: 0.00014505\n",
      "Epoch: [32] [  37/  40] time: 334.9983, loss: 0.00000116\n",
      "Epoch: [32] [  38/  40] time: 335.2354, loss: 0.00000129\n",
      "Epoch: [32] [  39/  40] time: 335.4719, loss: 0.00000540\n",
      "[32/50] - ptime: 10.0219 loss: 0.00003072 acc: 0.79000\n",
      "Epoch: [33] [   0/  40] time: 336.7483, loss: 0.00000442\n",
      "Epoch: [33] [   1/  40] time: 336.9860, loss: 0.00000077\n",
      "Epoch: [33] [   2/  40] time: 337.2233, loss: 0.00002841\n",
      "Epoch: [33] [   3/  40] time: 337.4605, loss: 0.00000044\n",
      "Epoch: [33] [   4/  40] time: 337.6973, loss: 0.00002323\n",
      "Epoch: [33] [   5/  40] time: 337.9355, loss: 0.00000248\n",
      "Epoch: [33] [   6/  40] time: 338.1723, loss: 0.00005088\n",
      "Epoch: [33] [   7/  40] time: 338.4086, loss: 0.00000834\n",
      "Epoch: [33] [   8/  40] time: 338.6478, loss: 0.00000041\n",
      "Epoch: [33] [   9/  40] time: 338.8859, loss: 0.00000104\n",
      "Epoch: [33] [  10/  40] time: 339.1231, loss: 0.00004416\n",
      "Epoch: [33] [  11/  40] time: 339.3592, loss: 0.00001146\n",
      "Epoch: [33] [  12/  40] time: 339.5952, loss: 0.00000153\n",
      "Epoch: [33] [  13/  40] time: 339.8332, loss: 0.00000231\n",
      "Epoch: [33] [  14/  40] time: 340.0726, loss: 0.00000031\n",
      "Epoch: [33] [  15/  40] time: 340.3094, loss: 0.00000541\n",
      "Epoch: [33] [  16/  40] time: 340.5459, loss: 0.00000597\n",
      "Epoch: [33] [  17/  40] time: 340.7826, loss: 0.00000717\n",
      "Epoch: [33] [  18/  40] time: 341.0201, loss: 0.00002126\n",
      "Epoch: [33] [  19/  40] time: 341.2569, loss: 0.00000388\n",
      "Epoch: [33] [  20/  40] time: 341.4935, loss: 0.00000200\n",
      "Epoch: [33] [  21/  40] time: 341.7301, loss: 0.00000043\n",
      "Epoch: [33] [  22/  40] time: 341.9682, loss: 0.00004553\n",
      "Epoch: [33] [  23/  40] time: 342.2038, loss: 0.00000051\n",
      "Epoch: [33] [  24/  40] time: 342.4405, loss: 0.00000453\n",
      "Epoch: [33] [  25/  40] time: 342.6769, loss: 0.00001506\n",
      "Epoch: [33] [  26/  40] time: 342.9193, loss: 0.00000053\n",
      "Epoch: [33] [  27/  40] time: 343.1562, loss: 0.00005051\n",
      "Epoch: [33] [  28/  40] time: 343.3919, loss: 0.00000967\n",
      "Epoch: [33] [  29/  40] time: 343.6281, loss: 0.00000118\n",
      "Epoch: [33] [  30/  40] time: 343.8670, loss: 0.00000159\n",
      "Epoch: [33] [  31/  40] time: 344.1039, loss: 0.00002695\n",
      "Epoch: [33] [  32/  40] time: 344.3400, loss: 0.00002993\n",
      "Epoch: [33] [  33/  40] time: 344.5758, loss: 0.00002397\n",
      "Epoch: [33] [  34/  40] time: 344.8119, loss: 0.00000153\n",
      "Epoch: [33] [  35/  40] time: 345.0511, loss: 0.00000301\n",
      "Epoch: [33] [  36/  40] time: 345.2879, loss: 0.00000727\n",
      "Epoch: [33] [  37/  40] time: 345.5244, loss: 0.00000006\n",
      "Epoch: [33] [  38/  40] time: 345.7608, loss: 0.00001348\n",
      "Epoch: [33] [  39/  40] time: 346.0010, loss: 0.00000907\n",
      "[33/50] - ptime: 10.0179 loss: 0.00001177 acc: 0.79000\n",
      "Epoch: [34] [   0/  40] time: 347.1877, loss: 0.00001085\n",
      "Epoch: [34] [   1/  40] time: 347.4239, loss: 0.00002411\n",
      "Epoch: [34] [   2/  40] time: 347.6601, loss: 0.00000065\n",
      "Epoch: [34] [   3/  40] time: 347.8990, loss: 0.00000846\n",
      "Epoch: [34] [   4/  40] time: 348.1370, loss: 0.00000790\n",
      "Epoch: [34] [   5/  40] time: 348.3744, loss: 0.00000086\n",
      "Epoch: [34] [   6/  40] time: 348.6137, loss: 0.00002277\n",
      "Epoch: [34] [   7/  40] time: 348.8521, loss: 0.00000991\n",
      "Epoch: [34] [   8/  40] time: 349.0892, loss: 0.00000725\n",
      "Epoch: [34] [   9/  40] time: 349.3249, loss: 0.00007925\n",
      "Epoch: [34] [  10/  40] time: 349.5624, loss: 0.00000194\n",
      "Epoch: [34] [  11/  40] time: 349.8022, loss: 0.00001105\n",
      "Epoch: [34] [  12/  40] time: 350.0410, loss: 0.00000184\n",
      "Epoch: [34] [  13/  40] time: 350.2777, loss: 0.00000156\n",
      "Epoch: [34] [  14/  40] time: 350.5141, loss: 0.00000374\n",
      "Epoch: [34] [  15/  40] time: 350.7500, loss: 0.00004301\n",
      "Epoch: [34] [  16/  40] time: 350.9899, loss: 0.00001163\n",
      "Epoch: [34] [  17/  40] time: 351.2305, loss: 0.00002147\n",
      "Epoch: [34] [  18/  40] time: 351.4676, loss: 0.00000150\n",
      "Epoch: [34] [  19/  40] time: 351.7038, loss: 0.00000310\n",
      "Epoch: [34] [  20/  40] time: 351.9446, loss: 0.00001997\n",
      "Epoch: [34] [  21/  40] time: 352.1811, loss: 0.00000091\n",
      "Epoch: [34] [  22/  40] time: 352.4185, loss: 0.00000080\n",
      "Epoch: [34] [  23/  40] time: 352.6547, loss: 0.00000068\n",
      "Epoch: [34] [  24/  40] time: 352.8941, loss: 0.00001750\n",
      "Epoch: [34] [  25/  40] time: 353.1329, loss: 0.00000083\n",
      "Epoch: [34] [  26/  40] time: 353.3692, loss: 0.00000040\n",
      "Epoch: [34] [  27/  40] time: 353.6005, loss: 0.00001443\n",
      "Epoch: [34] [  28/  40] time: 353.8384, loss: 0.00003426\n",
      "Epoch: [34] [  29/  40] time: 354.0765, loss: 0.00001139\n",
      "Epoch: [34] [  30/  40] time: 354.3145, loss: 0.00007358\n",
      "Epoch: [34] [  31/  40] time: 354.5506, loss: 0.00000013\n",
      "Epoch: [34] [  32/  40] time: 354.7863, loss: 0.00000073\n",
      "Epoch: [34] [  33/  40] time: 355.0235, loss: 0.00001301\n",
      "Epoch: [34] [  34/  40] time: 355.2609, loss: 0.00000278\n",
      "Epoch: [34] [  35/  40] time: 355.4978, loss: 0.00000957\n",
      "Epoch: [34] [  36/  40] time: 355.7341, loss: 0.00000384\n",
      "Epoch: [34] [  37/  40] time: 355.9734, loss: 0.00004013\n",
      "Epoch: [34] [  38/  40] time: 356.2092, loss: 0.00000396\n",
      "Epoch: [34] [  39/  40] time: 356.4461, loss: 0.00004797\n",
      "[34/50] - ptime: 10.0370 loss: 0.00001424 acc: 0.80000\n",
      "Epoch: [35] [   0/  40] time: 357.6292, loss: 0.00047863\n",
      "Epoch: [35] [   1/  40] time: 357.8679, loss: 0.00000902\n",
      "Epoch: [35] [   2/  40] time: 358.1068, loss: 0.00003621\n",
      "Epoch: [35] [   3/  40] time: 358.3434, loss: 0.00003365\n",
      "Epoch: [35] [   4/  40] time: 358.5803, loss: 0.00002699\n",
      "Epoch: [35] [   5/  40] time: 358.8171, loss: 0.00000200\n",
      "Epoch: [35] [   6/  40] time: 359.0556, loss: 0.00000167\n",
      "Epoch: [35] [   7/  40] time: 359.2949, loss: 0.00000189\n",
      "Epoch: [35] [   8/  40] time: 359.5314, loss: 0.00000134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [35] [   9/  40] time: 359.7683, loss: 0.00005654\n",
      "Epoch: [35] [  10/  40] time: 360.0089, loss: 0.00004831\n",
      "Epoch: [35] [  11/  40] time: 360.2448, loss: 0.00000111\n",
      "Epoch: [35] [  12/  40] time: 360.4809, loss: 0.00000297\n",
      "Epoch: [35] [  13/  40] time: 360.7195, loss: 0.00080629\n",
      "Epoch: [35] [  14/  40] time: 360.9607, loss: 0.00002151\n",
      "Epoch: [35] [  15/  40] time: 361.1975, loss: 0.00023505\n",
      "Epoch: [35] [  16/  40] time: 361.4339, loss: 0.00000581\n",
      "Epoch: [35] [  17/  40] time: 361.6701, loss: 0.00000160\n",
      "Epoch: [35] [  18/  40] time: 361.9083, loss: 0.00000800\n",
      "Epoch: [35] [  19/  40] time: 362.1461, loss: 0.00000072\n",
      "Epoch: [35] [  20/  40] time: 362.3826, loss: 0.00003493\n",
      "Epoch: [35] [  21/  40] time: 362.6197, loss: 0.00000891\n",
      "Epoch: [35] [  22/  40] time: 362.8564, loss: 0.00000111\n",
      "Epoch: [35] [  23/  40] time: 363.0936, loss: 0.00000761\n",
      "Epoch: [35] [  24/  40] time: 363.3295, loss: 0.00000226\n",
      "Epoch: [35] [  25/  40] time: 363.5671, loss: 0.00000309\n",
      "Epoch: [35] [  26/  40] time: 363.8040, loss: 0.00000035\n",
      "Epoch: [35] [  27/  40] time: 364.0435, loss: 0.00000078\n",
      "Epoch: [35] [  28/  40] time: 364.2807, loss: 0.00000207\n",
      "Epoch: [35] [  29/  40] time: 364.5169, loss: 0.00000083\n",
      "Epoch: [35] [  30/  40] time: 364.7535, loss: 0.00000014\n",
      "Epoch: [35] [  31/  40] time: 364.9933, loss: 0.00009497\n",
      "Epoch: [35] [  32/  40] time: 365.2307, loss: 0.00000182\n",
      "Epoch: [35] [  33/  40] time: 365.4675, loss: 0.00014002\n",
      "Epoch: [35] [  34/  40] time: 365.7048, loss: 0.00000124\n",
      "Epoch: [35] [  35/  40] time: 365.9446, loss: 0.00000792\n",
      "Epoch: [35] [  36/  40] time: 366.1806, loss: 0.00003457\n",
      "Epoch: [35] [  37/  40] time: 366.4177, loss: 0.00000413\n",
      "Epoch: [35] [  38/  40] time: 366.6552, loss: 0.00001726\n",
      "Epoch: [35] [  39/  40] time: 366.8949, loss: 0.00000036\n",
      "[35/50] - ptime: 10.0413 loss: 0.00005359 acc: 0.78000\n",
      "Epoch: [36] [   0/  40] time: 368.0353, loss: 0.00000226\n",
      "Epoch: [36] [   1/  40] time: 368.2708, loss: 0.00002285\n",
      "Epoch: [36] [   2/  40] time: 368.5087, loss: 0.00000132\n",
      "Epoch: [36] [   3/  40] time: 368.7446, loss: 0.00001117\n",
      "Epoch: [36] [   4/  40] time: 368.9839, loss: 0.00000229\n",
      "Epoch: [36] [   5/  40] time: 369.2212, loss: 0.00000028\n",
      "Epoch: [36] [   6/  40] time: 369.4582, loss: 0.00002124\n",
      "Epoch: [36] [   7/  40] time: 369.6949, loss: 0.00000549\n",
      "Epoch: [36] [   8/  40] time: 369.9325, loss: 0.00000121\n",
      "Epoch: [36] [   9/  40] time: 370.1695, loss: 0.00001187\n",
      "Epoch: [36] [  10/  40] time: 370.4063, loss: 0.00003206\n",
      "Epoch: [36] [  11/  40] time: 370.6430, loss: 0.00001126\n",
      "Epoch: [36] [  12/  40] time: 370.8806, loss: 0.00000200\n",
      "Epoch: [36] [  13/  40] time: 371.1181, loss: 0.00013127\n",
      "Epoch: [36] [  14/  40] time: 371.3544, loss: 0.00000172\n",
      "Epoch: [36] [  15/  40] time: 371.5909, loss: 0.00000010\n",
      "Epoch: [36] [  16/  40] time: 371.8287, loss: 0.00000122\n",
      "Epoch: [36] [  17/  40] time: 372.0632, loss: 0.00002031\n",
      "Epoch: [36] [  18/  40] time: 372.2992, loss: 0.00002964\n",
      "Epoch: [36] [  19/  40] time: 372.5361, loss: 0.00000988\n",
      "Epoch: [36] [  20/  40] time: 372.7730, loss: 0.00000012\n",
      "Epoch: [36] [  21/  40] time: 373.0137, loss: 0.00000178\n",
      "Epoch: [36] [  22/  40] time: 373.2506, loss: 0.00000151\n",
      "Epoch: [36] [  23/  40] time: 373.4870, loss: 0.00000563\n",
      "Epoch: [36] [  24/  40] time: 373.7228, loss: 0.00000379\n",
      "Epoch: [36] [  25/  40] time: 373.9627, loss: 0.00002400\n",
      "Epoch: [36] [  26/  40] time: 374.2004, loss: 0.00000650\n",
      "Epoch: [36] [  27/  40] time: 374.4374, loss: 0.00000119\n",
      "Epoch: [36] [  28/  40] time: 374.6741, loss: 0.00000110\n",
      "Epoch: [36] [  29/  40] time: 374.9114, loss: 0.00000138\n",
      "Epoch: [36] [  30/  40] time: 375.1491, loss: 0.00000062\n",
      "Epoch: [36] [  31/  40] time: 375.3862, loss: 0.00000787\n",
      "Epoch: [36] [  32/  40] time: 375.6239, loss: 0.00000128\n",
      "Epoch: [36] [  33/  40] time: 375.8625, loss: 0.00000021\n",
      "Epoch: [36] [  34/  40] time: 376.0999, loss: 0.00000881\n",
      "Epoch: [36] [  35/  40] time: 376.3362, loss: 0.00000697\n",
      "Epoch: [36] [  36/  40] time: 376.5721, loss: 0.00000082\n",
      "Epoch: [36] [  37/  40] time: 376.8090, loss: 0.00010327\n",
      "Epoch: [36] [  38/  40] time: 377.0500, loss: 0.00001947\n",
      "Epoch: [36] [  39/  40] time: 377.2865, loss: 0.00000814\n",
      "[36/50] - ptime: 10.0207 loss: 0.00001310 acc: 0.79000\n",
      "Epoch: [37] [   0/  40] time: 378.4673, loss: 0.00000349\n",
      "Epoch: [37] [   1/  40] time: 378.7041, loss: 0.00000139\n",
      "Epoch: [37] [   2/  40] time: 378.9419, loss: 0.00000211\n",
      "Epoch: [37] [   3/  40] time: 379.1782, loss: 0.00000017\n",
      "Epoch: [37] [   4/  40] time: 379.4154, loss: 0.00000644\n",
      "Epoch: [37] [   5/  40] time: 379.6529, loss: 0.00003128\n",
      "Epoch: [37] [   6/  40] time: 379.8912, loss: 0.00000590\n",
      "Epoch: [37] [   7/  40] time: 380.1291, loss: 0.00000113\n",
      "Epoch: [37] [   8/  40] time: 380.3651, loss: 0.00000182\n",
      "Epoch: [37] [   9/  40] time: 380.6015, loss: 0.00001767\n",
      "Epoch: [37] [  10/  40] time: 380.8381, loss: 0.00001628\n",
      "Epoch: [37] [  11/  40] time: 381.0792, loss: 0.00005274\n",
      "Epoch: [37] [  12/  40] time: 381.3153, loss: 0.00002166\n",
      "Epoch: [37] [  13/  40] time: 381.5516, loss: 0.00000139\n",
      "Epoch: [37] [  14/  40] time: 381.7874, loss: 0.00001350\n",
      "Epoch: [37] [  15/  40] time: 382.0278, loss: 0.00016123\n",
      "Epoch: [37] [  16/  40] time: 382.2643, loss: 0.00000929\n",
      "Epoch: [37] [  17/  40] time: 382.5020, loss: 0.00020889\n",
      "Epoch: [37] [  18/  40] time: 382.7388, loss: 0.00000141\n",
      "Epoch: [37] [  19/  40] time: 382.9782, loss: 0.00000061\n",
      "Epoch: [37] [  20/  40] time: 383.2139, loss: 0.00000190\n",
      "Epoch: [37] [  21/  40] time: 383.4510, loss: 0.00000106\n",
      "Epoch: [37] [  22/  40] time: 383.6881, loss: 0.00004217\n",
      "Epoch: [37] [  23/  40] time: 383.9272, loss: 0.00004345\n",
      "Epoch: [37] [  24/  40] time: 384.1643, loss: 0.00000261\n",
      "Epoch: [37] [  25/  40] time: 384.4004, loss: 0.00000021\n",
      "Epoch: [37] [  26/  40] time: 384.6365, loss: 0.00000112\n",
      "Epoch: [37] [  27/  40] time: 384.8744, loss: 0.00000134\n",
      "Epoch: [37] [  28/  40] time: 385.1130, loss: 0.00000074\n",
      "Epoch: [37] [  29/  40] time: 385.3506, loss: 0.00000602\n",
      "Epoch: [37] [  30/  40] time: 385.5870, loss: 0.00005413\n",
      "Epoch: [37] [  31/  40] time: 385.8231, loss: 0.00000938\n",
      "Epoch: [37] [  32/  40] time: 386.0575, loss: 0.00000306\n",
      "Epoch: [37] [  33/  40] time: 386.2949, loss: 0.00002733\n",
      "Epoch: [37] [  34/  40] time: 386.5309, loss: 0.00000049\n",
      "Epoch: [37] [  35/  40] time: 386.7668, loss: 0.00007139\n",
      "Epoch: [37] [  36/  40] time: 387.0066, loss: 0.00003398\n",
      "Epoch: [37] [  37/  40] time: 387.2437, loss: 0.00005168\n",
      "Epoch: [37] [  38/  40] time: 387.4816, loss: 0.00002874\n",
      "Epoch: [37] [  39/  40] time: 387.7174, loss: 0.00000414\n",
      "[37/50] - ptime: 10.0185 loss: 0.00002358 acc: 0.78000\n",
      "Epoch: [38] [   0/  40] time: 388.8836, loss: 0.00000128\n",
      "Epoch: [38] [   1/  40] time: 389.1224, loss: 0.00000200\n",
      "Epoch: [38] [   2/  40] time: 389.3591, loss: 0.00000294\n",
      "Epoch: [38] [   3/  40] time: 389.5951, loss: 0.00000125\n",
      "Epoch: [38] [   4/  40] time: 389.8314, loss: 0.00000809\n",
      "Epoch: [38] [   5/  40] time: 390.0737, loss: 0.00000773\n",
      "Epoch: [38] [   6/  40] time: 390.3132, loss: 0.00001791\n",
      "Epoch: [38] [   7/  40] time: 390.5507, loss: 0.00000519\n",
      "Epoch: [38] [   8/  40] time: 390.7873, loss: 0.00001598\n",
      "Epoch: [38] [   9/  40] time: 391.0301, loss: 0.00000134\n",
      "Epoch: [38] [  10/  40] time: 391.2668, loss: 0.00000206\n",
      "Epoch: [38] [  11/  40] time: 391.5033, loss: 0.00000176\n",
      "Epoch: [38] [  12/  40] time: 391.7394, loss: 0.00000012\n",
      "Epoch: [38] [  13/  40] time: 391.9815, loss: 0.00000448\n",
      "Epoch: [38] [  14/  40] time: 392.2179, loss: 0.00006851\n",
      "Epoch: [38] [  15/  40] time: 392.4553, loss: 0.00000015\n",
      "Epoch: [38] [  16/  40] time: 392.6918, loss: 0.00000205\n",
      "Epoch: [38] [  17/  40] time: 392.9296, loss: 0.00000537\n",
      "Epoch: [38] [  18/  40] time: 393.1661, loss: 0.00001191\n",
      "Epoch: [38] [  19/  40] time: 393.4029, loss: 0.00002706\n",
      "Epoch: [38] [  20/  40] time: 393.6403, loss: 0.00000070\n",
      "Epoch: [38] [  21/  40] time: 393.8769, loss: 0.00000372\n",
      "Epoch: [38] [  22/  40] time: 394.1153, loss: 0.00000053\n",
      "Epoch: [38] [  23/  40] time: 394.3514, loss: 0.00000270\n",
      "Epoch: [38] [  24/  40] time: 394.5876, loss: 0.00000448\n",
      "Epoch: [38] [  25/  40] time: 394.8255, loss: 0.00000137\n",
      "Epoch: [38] [  26/  40] time: 395.0638, loss: 0.00000959\n",
      "Epoch: [38] [  27/  40] time: 395.3003, loss: 0.00000171\n",
      "Epoch: [38] [  28/  40] time: 395.5366, loss: 0.00000132\n",
      "Epoch: [38] [  29/  40] time: 395.7723, loss: 0.00002255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38] [  30/  40] time: 396.0133, loss: 0.00000427\n",
      "Epoch: [38] [  31/  40] time: 396.2494, loss: 0.00000067\n",
      "Epoch: [38] [  32/  40] time: 396.4866, loss: 0.00000259\n",
      "Epoch: [38] [  33/  40] time: 396.7227, loss: 0.00001352\n",
      "Epoch: [38] [  34/  40] time: 396.9647, loss: 0.00000043\n",
      "Epoch: [38] [  35/  40] time: 397.2009, loss: 0.00000050\n",
      "Epoch: [38] [  36/  40] time: 397.4373, loss: 0.00000313\n",
      "Epoch: [38] [  37/  40] time: 397.6746, loss: 0.00000136\n",
      "Epoch: [38] [  38/  40] time: 397.9125, loss: 0.00000283\n",
      "Epoch: [38] [  39/  40] time: 398.1507, loss: 0.00000171\n",
      "[38/50] - ptime: 10.0379 loss: 0.00000667 acc: 0.78000\n",
      "Epoch: [39] [   0/  40] time: 399.3360, loss: 0.00001365\n",
      "Epoch: [39] [   1/  40] time: 399.5722, loss: 0.00006602\n",
      "Epoch: [39] [   2/  40] time: 399.8080, loss: 0.00001357\n",
      "Epoch: [39] [   3/  40] time: 400.0464, loss: 0.00000373\n",
      "Epoch: [39] [   4/  40] time: 400.2835, loss: 0.00000167\n",
      "Epoch: [39] [   5/  40] time: 400.5208, loss: 0.00003024\n",
      "Epoch: [39] [   6/  40] time: 400.7568, loss: 0.00002992\n",
      "Epoch: [39] [   7/  40] time: 400.9936, loss: 0.00000774\n",
      "Epoch: [39] [   8/  40] time: 401.2306, loss: 0.00000021\n",
      "Epoch: [39] [   9/  40] time: 401.4673, loss: 0.00000014\n",
      "Epoch: [39] [  10/  40] time: 401.7057, loss: 0.00000301\n",
      "Epoch: [39] [  11/  40] time: 401.9453, loss: 0.00000166\n",
      "Epoch: [39] [  12/  40] time: 402.1824, loss: 0.00001724\n",
      "Epoch: [39] [  13/  40] time: 402.4191, loss: 0.00001817\n",
      "Epoch: [39] [  14/  40] time: 402.6551, loss: 0.00000038\n",
      "Epoch: [39] [  15/  40] time: 402.8921, loss: 0.00002052\n",
      "Epoch: [39] [  16/  40] time: 403.1332, loss: 0.00000175\n",
      "Epoch: [39] [  17/  40] time: 403.3718, loss: 0.00000074\n",
      "Epoch: [39] [  18/  40] time: 403.6081, loss: 0.00004013\n",
      "Epoch: [39] [  19/  40] time: 403.8447, loss: 0.00000717\n",
      "Epoch: [39] [  20/  40] time: 404.0832, loss: 0.00001113\n",
      "Epoch: [39] [  21/  40] time: 404.3195, loss: 0.00002020\n",
      "Epoch: [39] [  22/  40] time: 404.5563, loss: 0.00001963\n",
      "Epoch: [39] [  23/  40] time: 404.7938, loss: 0.00000878\n",
      "Epoch: [39] [  24/  40] time: 405.0328, loss: 0.00002591\n",
      "Epoch: [39] [  25/  40] time: 405.2691, loss: 0.00000784\n",
      "Epoch: [39] [  26/  40] time: 405.5056, loss: 0.00000034\n",
      "Epoch: [39] [  27/  40] time: 405.7423, loss: 0.00000962\n",
      "Epoch: [39] [  28/  40] time: 405.9823, loss: 0.00002947\n",
      "Epoch: [39] [  29/  40] time: 406.2206, loss: 0.00000045\n",
      "Epoch: [39] [  30/  40] time: 406.4569, loss: 0.00000128\n",
      "Epoch: [39] [  31/  40] time: 406.6932, loss: 0.00000430\n",
      "Epoch: [39] [  32/  40] time: 406.9293, loss: 0.00000065\n",
      "Epoch: [39] [  33/  40] time: 407.1670, loss: 0.00001713\n",
      "Epoch: [39] [  34/  40] time: 407.4041, loss: 0.00000546\n",
      "Epoch: [39] [  35/  40] time: 407.6404, loss: 0.00000292\n",
      "Epoch: [39] [  36/  40] time: 407.8784, loss: 0.00000167\n",
      "Epoch: [39] [  37/  40] time: 408.1156, loss: 0.00000185\n",
      "Epoch: [39] [  38/  40] time: 408.3517, loss: 0.00000538\n",
      "Epoch: [39] [  39/  40] time: 408.5885, loss: 0.00000642\n",
      "[39/50] - ptime: 10.0263 loss: 0.00001145 acc: 0.79000\n",
      "Epoch: [40] [   0/  40] time: 409.7321, loss: 0.00001009\n",
      "Epoch: [40] [   1/  40] time: 409.9713, loss: 0.00003472\n",
      "Epoch: [40] [   2/  40] time: 410.2080, loss: 0.00000258\n",
      "Epoch: [40] [   3/  40] time: 410.4453, loss: 0.00000100\n",
      "Epoch: [40] [   4/  40] time: 410.6813, loss: 0.00000841\n",
      "Epoch: [40] [   5/  40] time: 410.9184, loss: 0.00000414\n",
      "Epoch: [40] [   6/  40] time: 411.1563, loss: 0.00000411\n",
      "Epoch: [40] [   7/  40] time: 411.3944, loss: 0.00000673\n",
      "Epoch: [40] [   8/  40] time: 411.6307, loss: 0.00000124\n",
      "Epoch: [40] [   9/  40] time: 411.8668, loss: 0.00003079\n",
      "Epoch: [40] [  10/  40] time: 412.1075, loss: 0.00000441\n",
      "Epoch: [40] [  11/  40] time: 412.3438, loss: 0.00000153\n",
      "Epoch: [40] [  12/  40] time: 412.5821, loss: 0.00000885\n",
      "Epoch: [40] [  13/  40] time: 412.8190, loss: 0.00000262\n",
      "Epoch: [40] [  14/  40] time: 413.0592, loss: 0.00000247\n",
      "Epoch: [40] [  15/  40] time: 413.2957, loss: 0.00000423\n",
      "Epoch: [40] [  16/  40] time: 413.5317, loss: 0.00000463\n",
      "Epoch: [40] [  17/  40] time: 413.7679, loss: 0.00000970\n",
      "Epoch: [40] [  18/  40] time: 414.0071, loss: 0.00000021\n",
      "Epoch: [40] [  19/  40] time: 414.2447, loss: 0.00000780\n",
      "Epoch: [40] [  20/  40] time: 414.4819, loss: 0.00000073\n",
      "Epoch: [40] [  21/  40] time: 414.7179, loss: 0.00003678\n",
      "Epoch: [40] [  22/  40] time: 414.9574, loss: 0.00001034\n",
      "Epoch: [40] [  23/  40] time: 415.1941, loss: 0.00001398\n",
      "Epoch: [40] [  24/  40] time: 415.4316, loss: 0.00000741\n",
      "Epoch: [40] [  25/  40] time: 415.6683, loss: 0.00000113\n",
      "Epoch: [40] [  26/  40] time: 415.9056, loss: 0.00001663\n",
      "Epoch: [40] [  27/  40] time: 416.1429, loss: 0.00000026\n",
      "Epoch: [40] [  28/  40] time: 416.3785, loss: 0.00000086\n",
      "Epoch: [40] [  29/  40] time: 416.6111, loss: 0.00000564\n",
      "Epoch: [40] [  30/  40] time: 416.8479, loss: 0.00000003\n",
      "Epoch: [40] [  31/  40] time: 417.0869, loss: 0.00000333\n",
      "Epoch: [40] [  32/  40] time: 417.3231, loss: 0.00000716\n",
      "Epoch: [40] [  33/  40] time: 417.5601, loss: 0.00000250\n",
      "Epoch: [40] [  34/  40] time: 417.7971, loss: 0.00000232\n",
      "Epoch: [40] [  35/  40] time: 418.0361, loss: 0.00004487\n",
      "Epoch: [40] [  36/  40] time: 418.2730, loss: 0.00000033\n",
      "Epoch: [40] [  37/  40] time: 418.5092, loss: 0.00000309\n",
      "Epoch: [40] [  38/  40] time: 418.7452, loss: 0.00005454\n",
      "Epoch: [40] [  39/  40] time: 418.9858, loss: 0.00002072\n",
      "[40/50] - ptime: 10.0186 loss: 0.00000957 acc: 0.78000\n",
      "Epoch: [41] [   0/  40] time: 420.1152, loss: 0.00000092\n",
      "Epoch: [41] [   1/  40] time: 420.3514, loss: 0.00000008\n",
      "Epoch: [41] [   2/  40] time: 420.5883, loss: 0.00000131\n",
      "Epoch: [41] [   3/  40] time: 420.8250, loss: 0.00002132\n",
      "Epoch: [41] [   4/  40] time: 421.0640, loss: 0.00004502\n",
      "Epoch: [41] [   5/  40] time: 421.3007, loss: 0.00000948\n",
      "Epoch: [41] [   6/  40] time: 421.5366, loss: 0.00000828\n",
      "Epoch: [41] [   7/  40] time: 421.7726, loss: 0.00000680\n",
      "Epoch: [41] [   8/  40] time: 422.0111, loss: 0.00000053\n",
      "Epoch: [41] [   9/  40] time: 422.2487, loss: 0.00000022\n",
      "Epoch: [41] [  10/  40] time: 422.4859, loss: 0.00000394\n",
      "Epoch: [41] [  11/  40] time: 422.7221, loss: 0.00000364\n",
      "Epoch: [41] [  12/  40] time: 422.9602, loss: 0.00000197\n",
      "Epoch: [41] [  13/  40] time: 423.1966, loss: 0.00000139\n",
      "Epoch: [41] [  14/  40] time: 423.4363, loss: 0.00000059\n",
      "Epoch: [41] [  15/  40] time: 423.6738, loss: 0.00000133\n",
      "Epoch: [41] [  16/  40] time: 423.9117, loss: 0.00000607\n",
      "Epoch: [41] [  17/  40] time: 424.1501, loss: 0.00001242\n",
      "Epoch: [41] [  18/  40] time: 424.3862, loss: 0.00000028\n",
      "Epoch: [41] [  19/  40] time: 424.6228, loss: 0.00000142\n",
      "Epoch: [41] [  20/  40] time: 424.8596, loss: 0.00001204\n",
      "Epoch: [41] [  21/  40] time: 425.1006, loss: 0.00000705\n",
      "Epoch: [41] [  22/  40] time: 425.3377, loss: 0.00000450\n",
      "Epoch: [41] [  23/  40] time: 425.5742, loss: 0.00000689\n",
      "Epoch: [41] [  24/  40] time: 425.8137, loss: 0.00001815\n",
      "Epoch: [41] [  25/  40] time: 426.0516, loss: 0.00001386\n",
      "Epoch: [41] [  26/  40] time: 426.2882, loss: 0.00000565\n",
      "Epoch: [41] [  27/  40] time: 426.5251, loss: 0.00000073\n",
      "Epoch: [41] [  28/  40] time: 426.7625, loss: 0.00001702\n",
      "Epoch: [41] [  29/  40] time: 427.0015, loss: 0.00001245\n",
      "Epoch: [41] [  30/  40] time: 427.2376, loss: 0.00000446\n",
      "Epoch: [41] [  31/  40] time: 427.4735, loss: 0.00000466\n",
      "Epoch: [41] [  32/  40] time: 427.7103, loss: 0.00000868\n",
      "Epoch: [41] [  33/  40] time: 427.9479, loss: 0.00000350\n",
      "Epoch: [41] [  34/  40] time: 428.1854, loss: 0.00002470\n",
      "Epoch: [41] [  35/  40] time: 428.4216, loss: 0.00000202\n",
      "Epoch: [41] [  36/  40] time: 428.6569, loss: 0.00000755\n",
      "Epoch: [41] [  37/  40] time: 428.8935, loss: 0.00002050\n",
      "Epoch: [41] [  38/  40] time: 429.1330, loss: 0.00000466\n",
      "Epoch: [41] [  39/  40] time: 429.3698, loss: 0.00000276\n",
      "[41/50] - ptime: 10.0116 loss: 0.00000772 acc: 0.78000\n",
      "Epoch: [42] [   0/  40] time: 430.5038, loss: 0.00000030\n",
      "Epoch: [42] [   1/  40] time: 430.7402, loss: 0.00004822\n",
      "Epoch: [42] [   2/  40] time: 430.9794, loss: 0.00000075\n",
      "Epoch: [42] [   3/  40] time: 431.2162, loss: 0.00002629\n",
      "Epoch: [42] [   4/  40] time: 431.4536, loss: 0.00000267\n",
      "Epoch: [42] [   5/  40] time: 431.6900, loss: 0.00000171\n",
      "Epoch: [42] [   6/  40] time: 431.9268, loss: 0.00000331\n",
      "Epoch: [42] [   7/  40] time: 432.1659, loss: 0.00001506\n",
      "Epoch: [42] [   8/  40] time: 432.4027, loss: 0.00001236\n",
      "Epoch: [42] [   9/  40] time: 432.6400, loss: 0.00000019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [42] [  10/  40] time: 432.8766, loss: 0.00000903\n",
      "Epoch: [42] [  11/  40] time: 433.1154, loss: 0.00001204\n",
      "Epoch: [42] [  12/  40] time: 433.3517, loss: 0.00000008\n",
      "Epoch: [42] [  13/  40] time: 433.5884, loss: 0.00000812\n",
      "Epoch: [42] [  14/  40] time: 433.8249, loss: 0.00000069\n",
      "Epoch: [42] [  15/  40] time: 434.0639, loss: 0.00000008\n",
      "Epoch: [42] [  16/  40] time: 434.3002, loss: 0.00002404\n",
      "Epoch: [42] [  17/  40] time: 434.5362, loss: 0.00005591\n",
      "Epoch: [42] [  18/  40] time: 434.7734, loss: 0.00001186\n",
      "Epoch: [42] [  19/  40] time: 435.0120, loss: 0.00001261\n",
      "Epoch: [42] [  20/  40] time: 435.2481, loss: 0.00000521\n",
      "Epoch: [42] [  21/  40] time: 435.4838, loss: 0.00000189\n",
      "Epoch: [42] [  22/  40] time: 435.7199, loss: 0.00000672\n",
      "Epoch: [42] [  23/  40] time: 435.9588, loss: 0.00000022\n",
      "Epoch: [42] [  24/  40] time: 436.1976, loss: 0.00000141\n",
      "Epoch: [42] [  25/  40] time: 436.4336, loss: 0.00000573\n",
      "Epoch: [42] [  26/  40] time: 436.6704, loss: 0.00001815\n",
      "Epoch: [42] [  27/  40] time: 436.9065, loss: 0.00000576\n",
      "Epoch: [42] [  28/  40] time: 437.1452, loss: 0.00000281\n",
      "Epoch: [42] [  29/  40] time: 437.3821, loss: 0.00015185\n",
      "Epoch: [42] [  30/  40] time: 437.6203, loss: 0.00001089\n",
      "Epoch: [42] [  31/  40] time: 437.8582, loss: 0.00001512\n",
      "Epoch: [42] [  32/  40] time: 438.0973, loss: 0.00000137\n",
      "Epoch: [42] [  33/  40] time: 438.3338, loss: 0.00001864\n",
      "Epoch: [42] [  34/  40] time: 438.5699, loss: 0.00000176\n",
      "Epoch: [42] [  35/  40] time: 438.8073, loss: 0.00000152\n",
      "Epoch: [42] [  36/  40] time: 439.0489, loss: 0.00001252\n",
      "Epoch: [42] [  37/  40] time: 439.2858, loss: 0.00000068\n",
      "Epoch: [42] [  38/  40] time: 439.5241, loss: 0.00000619\n",
      "Epoch: [42] [  39/  40] time: 439.7605, loss: 0.00000012\n",
      "[42/50] - ptime: 10.0223 loss: 0.00001285 acc: 0.78000\n",
      "Epoch: [43] [   0/  40] time: 440.9034, loss: 0.00000098\n",
      "Epoch: [43] [   1/  40] time: 441.1445, loss: 0.00000103\n",
      "Epoch: [43] [   2/  40] time: 441.3811, loss: 0.00000881\n",
      "Epoch: [43] [   3/  40] time: 441.6171, loss: 0.00000003\n",
      "Epoch: [43] [   4/  40] time: 441.8559, loss: 0.00000102\n",
      "Epoch: [43] [   5/  40] time: 442.0961, loss: 0.00000124\n",
      "Epoch: [43] [   6/  40] time: 442.3339, loss: 0.00001809\n",
      "Epoch: [43] [   7/  40] time: 442.5725, loss: 0.00000544\n",
      "Epoch: [43] [   8/  40] time: 442.8092, loss: 0.00000551\n",
      "Epoch: [43] [   9/  40] time: 443.0493, loss: 0.00000244\n",
      "Epoch: [43] [  10/  40] time: 443.2852, loss: 0.00001614\n",
      "Epoch: [43] [  11/  40] time: 443.5213, loss: 0.00000361\n",
      "Epoch: [43] [  12/  40] time: 443.7613, loss: 0.00003735\n",
      "Epoch: [43] [  13/  40] time: 444.0034, loss: 0.00000006\n",
      "Epoch: [43] [  14/  40] time: 444.2413, loss: 0.00000887\n",
      "Epoch: [43] [  15/  40] time: 444.4777, loss: 0.00000168\n",
      "Epoch: [43] [  16/  40] time: 444.7149, loss: 0.00000045\n",
      "Epoch: [43] [  17/  40] time: 444.9517, loss: 0.00000211\n",
      "Epoch: [43] [  18/  40] time: 445.1877, loss: 0.00001572\n",
      "Epoch: [43] [  19/  40] time: 445.4247, loss: 0.00007794\n",
      "Epoch: [43] [  20/  40] time: 445.6614, loss: 0.00000161\n",
      "Epoch: [43] [  21/  40] time: 445.8986, loss: 0.00000808\n",
      "Epoch: [43] [  22/  40] time: 446.1375, loss: 0.00000556\n",
      "Epoch: [43] [  23/  40] time: 446.3734, loss: 0.00000098\n",
      "Epoch: [43] [  24/  40] time: 446.6100, loss: 0.00000018\n",
      "Epoch: [43] [  25/  40] time: 446.8489, loss: 0.00000661\n",
      "Epoch: [43] [  26/  40] time: 447.0896, loss: 0.00000018\n",
      "Epoch: [43] [  27/  40] time: 447.3258, loss: 0.00009996\n",
      "Epoch: [43] [  28/  40] time: 447.5624, loss: 0.00000366\n",
      "Epoch: [43] [  29/  40] time: 447.8010, loss: 0.00000016\n",
      "Epoch: [43] [  30/  40] time: 448.0398, loss: 0.00000012\n",
      "Epoch: [43] [  31/  40] time: 448.2765, loss: 0.00000252\n",
      "Epoch: [43] [  32/  40] time: 448.5141, loss: 0.00000694\n",
      "Epoch: [43] [  33/  40] time: 448.7498, loss: 0.00000219\n",
      "Epoch: [43] [  34/  40] time: 448.9877, loss: 0.00000209\n",
      "Epoch: [43] [  35/  40] time: 449.2253, loss: 0.00000576\n",
      "Epoch: [43] [  36/  40] time: 449.4618, loss: 0.00000084\n",
      "Epoch: [43] [  37/  40] time: 449.6989, loss: 0.00002764\n",
      "Epoch: [43] [  38/  40] time: 449.9380, loss: 0.00000064\n",
      "Epoch: [43] [  39/  40] time: 450.1766, loss: 0.00000301\n",
      "[43/50] - ptime: 10.0314 loss: 0.00000968 acc: 0.79000\n",
      "Epoch: [44] [   0/  40] time: 451.3101, loss: 0.00000129\n",
      "Epoch: [44] [   1/  40] time: 451.5430, loss: 0.00000069\n",
      "Epoch: [44] [   2/  40] time: 451.7799, loss: 0.00000207\n",
      "Epoch: [44] [   3/  40] time: 452.0151, loss: 0.00001913\n",
      "Epoch: [44] [   4/  40] time: 452.2513, loss: 0.00000019\n",
      "Epoch: [44] [   5/  40] time: 452.4879, loss: 0.00000248\n",
      "Epoch: [44] [   6/  40] time: 452.7252, loss: 0.00002049\n",
      "Epoch: [44] [   7/  40] time: 452.9632, loss: 0.00000120\n",
      "Epoch: [44] [   8/  40] time: 453.2014, loss: 0.00002524\n",
      "Epoch: [44] [   9/  40] time: 453.4417, loss: 0.00000376\n",
      "Epoch: [44] [  10/  40] time: 453.6778, loss: 0.00000018\n",
      "Epoch: [44] [  11/  40] time: 453.9145, loss: 0.00000200\n",
      "Epoch: [44] [  12/  40] time: 454.1538, loss: 0.00000535\n",
      "Epoch: [44] [  13/  40] time: 454.3917, loss: 0.00000293\n",
      "Epoch: [44] [  14/  40] time: 454.6289, loss: 0.00000034\n",
      "Epoch: [44] [  15/  40] time: 454.8654, loss: 0.00001110\n",
      "Epoch: [44] [  16/  40] time: 455.1046, loss: 0.00000803\n",
      "Epoch: [44] [  17/  40] time: 455.3405, loss: 0.00000118\n",
      "Epoch: [44] [  18/  40] time: 455.5777, loss: 0.00000427\n",
      "Epoch: [44] [  19/  40] time: 455.8145, loss: 0.00000028\n",
      "Epoch: [44] [  20/  40] time: 456.0539, loss: 0.00000124\n",
      "Epoch: [44] [  21/  40] time: 456.2908, loss: 0.00000085\n",
      "Epoch: [44] [  22/  40] time: 456.5268, loss: 0.00000219\n",
      "Epoch: [44] [  23/  40] time: 456.7639, loss: 0.00000212\n",
      "Epoch: [44] [  24/  40] time: 457.0015, loss: 0.00000004\n",
      "Epoch: [44] [  25/  40] time: 457.2394, loss: 0.00000113\n",
      "Epoch: [44] [  26/  40] time: 457.4762, loss: 0.00000849\n",
      "Epoch: [44] [  27/  40] time: 457.7124, loss: 0.00000284\n",
      "Epoch: [44] [  28/  40] time: 457.9496, loss: 0.00000123\n",
      "Epoch: [44] [  29/  40] time: 458.1884, loss: 0.00000042\n",
      "Epoch: [44] [  30/  40] time: 458.4259, loss: 0.00000181\n",
      "Epoch: [44] [  31/  40] time: 458.6637, loss: 0.00000299\n",
      "Epoch: [44] [  32/  40] time: 458.9004, loss: 0.00000113\n",
      "Epoch: [44] [  33/  40] time: 459.1403, loss: 0.00000806\n",
      "Epoch: [44] [  34/  40] time: 459.3761, loss: 0.00000964\n",
      "Epoch: [44] [  35/  40] time: 459.6126, loss: 0.00000063\n",
      "Epoch: [44] [  36/  40] time: 459.8489, loss: 0.00000899\n",
      "Epoch: [44] [  37/  40] time: 460.0868, loss: 0.00000293\n",
      "Epoch: [44] [  38/  40] time: 460.3235, loss: 0.00000404\n",
      "Epoch: [44] [  39/  40] time: 460.5595, loss: 0.00000183\n",
      "[44/50] - ptime: 10.0104 loss: 0.00000437 acc: 0.79000\n",
      "Epoch: [45] [   0/  40] time: 461.6820, loss: 0.00000010\n",
      "Epoch: [45] [   1/  40] time: 461.9186, loss: 0.00000545\n",
      "Epoch: [45] [   2/  40] time: 462.1573, loss: 0.00001597\n",
      "Epoch: [45] [   3/  40] time: 462.3948, loss: 0.00000574\n",
      "Epoch: [45] [   4/  40] time: 462.6325, loss: 0.00000033\n",
      "Epoch: [45] [   5/  40] time: 462.8686, loss: 0.00000936\n",
      "Epoch: [45] [   6/  40] time: 463.1068, loss: 0.00000015\n",
      "Epoch: [45] [   7/  40] time: 463.3431, loss: 0.00000796\n",
      "Epoch: [45] [   8/  40] time: 463.5811, loss: 0.00000321\n",
      "Epoch: [45] [   9/  40] time: 463.8190, loss: 0.00000204\n",
      "Epoch: [45] [  10/  40] time: 464.0564, loss: 0.00000176\n",
      "Epoch: [45] [  11/  40] time: 464.2939, loss: 0.00000377\n",
      "Epoch: [45] [  12/  40] time: 464.5332, loss: 0.00000120\n",
      "Epoch: [45] [  13/  40] time: 464.7698, loss: 0.00000176\n",
      "Epoch: [45] [  14/  40] time: 465.0096, loss: 0.00000047\n",
      "Epoch: [45] [  15/  40] time: 465.2479, loss: 0.00000215\n",
      "Epoch: [45] [  16/  40] time: 465.4848, loss: 0.00000428\n",
      "Epoch: [45] [  17/  40] time: 465.7210, loss: 0.00000163\n",
      "Epoch: [45] [  18/  40] time: 465.9588, loss: 0.00000637\n",
      "Epoch: [45] [  19/  40] time: 466.1968, loss: 0.00000088\n",
      "Epoch: [45] [  20/  40] time: 466.4333, loss: 0.00000009\n",
      "Epoch: [45] [  21/  40] time: 466.6711, loss: 0.00000274\n",
      "Epoch: [45] [  22/  40] time: 466.9073, loss: 0.00000198\n",
      "Epoch: [45] [  23/  40] time: 467.1505, loss: 0.00000206\n",
      "Epoch: [45] [  24/  40] time: 467.3868, loss: 0.00000005\n",
      "Epoch: [45] [  25/  40] time: 467.6228, loss: 0.00000556\n",
      "Epoch: [45] [  26/  40] time: 467.8588, loss: 0.00000901\n",
      "Epoch: [45] [  27/  40] time: 468.0983, loss: 0.00001172\n",
      "Epoch: [45] [  28/  40] time: 468.3363, loss: 0.00000638\n",
      "Epoch: [45] [  29/  40] time: 468.5737, loss: 0.00000041\n",
      "Epoch: [45] [  30/  40] time: 468.8103, loss: 0.00001070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [45] [  31/  40] time: 469.0477, loss: 0.00000348\n",
      "Epoch: [45] [  32/  40] time: 469.2833, loss: 0.00000110\n",
      "Epoch: [45] [  33/  40] time: 469.5205, loss: 0.00002307\n",
      "Epoch: [45] [  34/  40] time: 469.7568, loss: 0.00000004\n",
      "Epoch: [45] [  35/  40] time: 469.9946, loss: 0.00000157\n",
      "Epoch: [45] [  36/  40] time: 470.2306, loss: 0.00001341\n",
      "Epoch: [45] [  37/  40] time: 470.4668, loss: 0.00000103\n",
      "Epoch: [45] [  38/  40] time: 470.7041, loss: 0.00000039\n",
      "Epoch: [45] [  39/  40] time: 470.9419, loss: 0.00000137\n",
      "[45/50] - ptime: 10.0159 loss: 0.00000427 acc: 0.78000\n",
      "Epoch: [46] [   0/  40] time: 472.1169, loss: 0.00000027\n",
      "Epoch: [46] [   1/  40] time: 472.3528, loss: 0.00000225\n",
      "Epoch: [46] [   2/  40] time: 472.5924, loss: 0.00000358\n",
      "Epoch: [46] [   3/  40] time: 472.8300, loss: 0.00000292\n",
      "Epoch: [46] [   4/  40] time: 473.0710, loss: 0.00000182\n",
      "Epoch: [46] [   5/  40] time: 473.3078, loss: 0.00000194\n",
      "Epoch: [46] [   6/  40] time: 473.5450, loss: 0.00000072\n",
      "Epoch: [46] [   7/  40] time: 473.7812, loss: 0.00005665\n",
      "Epoch: [46] [   8/  40] time: 474.0187, loss: 0.00000018\n",
      "Epoch: [46] [   9/  40] time: 474.2572, loss: 0.00000159\n",
      "Epoch: [46] [  10/  40] time: 474.4949, loss: 0.00000375\n",
      "Epoch: [46] [  11/  40] time: 474.7314, loss: 0.00000825\n",
      "Epoch: [46] [  12/  40] time: 474.9684, loss: 0.00000194\n",
      "Epoch: [46] [  13/  40] time: 475.2062, loss: 0.00000873\n",
      "Epoch: [46] [  14/  40] time: 475.4427, loss: 0.00000019\n",
      "Epoch: [46] [  15/  40] time: 475.6799, loss: 0.00000224\n",
      "Epoch: [46] [  16/  40] time: 475.9167, loss: 0.00000249\n",
      "Epoch: [46] [  17/  40] time: 476.1558, loss: 0.00000076\n",
      "Epoch: [46] [  18/  40] time: 476.3924, loss: 0.00000117\n",
      "Epoch: [46] [  19/  40] time: 476.6289, loss: 0.00000415\n",
      "Epoch: [46] [  20/  40] time: 476.8663, loss: 0.00000097\n",
      "Epoch: [46] [  21/  40] time: 477.1043, loss: 0.00000039\n",
      "Epoch: [46] [  22/  40] time: 477.3410, loss: 0.00000077\n",
      "Epoch: [46] [  23/  40] time: 477.5776, loss: 0.00000588\n",
      "Epoch: [46] [  24/  40] time: 477.8134, loss: 0.00000132\n",
      "Epoch: [46] [  25/  40] time: 478.0521, loss: 0.00000279\n",
      "Epoch: [46] [  26/  40] time: 478.2893, loss: 0.00000005\n",
      "Epoch: [46] [  27/  40] time: 478.5258, loss: 0.00000063\n",
      "Epoch: [46] [  28/  40] time: 478.7631, loss: 0.00000051\n",
      "Epoch: [46] [  29/  40] time: 479.0010, loss: 0.00003514\n",
      "Epoch: [46] [  30/  40] time: 479.2388, loss: 0.00000233\n",
      "Epoch: [46] [  31/  40] time: 479.4754, loss: 0.00000751\n",
      "Epoch: [46] [  32/  40] time: 479.7131, loss: 0.00000066\n",
      "Epoch: [46] [  33/  40] time: 479.9503, loss: 0.00004508\n",
      "Epoch: [46] [  34/  40] time: 480.1888, loss: 0.00000006\n",
      "Epoch: [46] [  35/  40] time: 480.4248, loss: 0.00000436\n",
      "Epoch: [46] [  36/  40] time: 480.6609, loss: 0.00000011\n",
      "Epoch: [46] [  37/  40] time: 480.8988, loss: 0.00000124\n",
      "Epoch: [46] [  38/  40] time: 481.1436, loss: 0.00000451\n",
      "Epoch: [46] [  39/  40] time: 481.3806, loss: 0.00000055\n",
      "[46/50] - ptime: 10.0327 loss: 0.00000551 acc: 0.79000\n",
      "Epoch: [47] [   0/  40] time: 482.5492, loss: 0.00000094\n",
      "Epoch: [47] [   1/  40] time: 482.7851, loss: 0.00000068\n",
      "Epoch: [47] [   2/  40] time: 483.0242, loss: 0.00000060\n",
      "Epoch: [47] [   3/  40] time: 483.2632, loss: 0.00000066\n",
      "Epoch: [47] [   4/  40] time: 483.5000, loss: 0.00001171\n",
      "Epoch: [47] [   5/  40] time: 483.7372, loss: 0.00000068\n",
      "Epoch: [47] [   6/  40] time: 483.9742, loss: 0.00000012\n",
      "Epoch: [47] [   7/  40] time: 484.2124, loss: 0.00003567\n",
      "Epoch: [47] [   8/  40] time: 484.4496, loss: 0.00000026\n",
      "Epoch: [47] [   9/  40] time: 484.6868, loss: 0.00000001\n",
      "Epoch: [47] [  10/  40] time: 484.9249, loss: 0.00000042\n",
      "Epoch: [47] [  11/  40] time: 485.1641, loss: 0.00000489\n",
      "Epoch: [47] [  12/  40] time: 485.4001, loss: 0.00000281\n",
      "Epoch: [47] [  13/  40] time: 485.6359, loss: 0.00000179\n",
      "Epoch: [47] [  14/  40] time: 485.8734, loss: 0.00001277\n",
      "Epoch: [47] [  15/  40] time: 486.1130, loss: 0.00000356\n",
      "Epoch: [47] [  16/  40] time: 486.3494, loss: 0.00000071\n",
      "Epoch: [47] [  17/  40] time: 486.5868, loss: 0.00000478\n",
      "Epoch: [47] [  18/  40] time: 486.8253, loss: 0.00000339\n",
      "Epoch: [47] [  19/  40] time: 487.0630, loss: 0.00000088\n",
      "Epoch: [47] [  20/  40] time: 487.3018, loss: 0.00000023\n",
      "Epoch: [47] [  21/  40] time: 487.5396, loss: 0.00000484\n",
      "Epoch: [47] [  22/  40] time: 487.7782, loss: 0.00002189\n",
      "Epoch: [47] [  23/  40] time: 488.0156, loss: 0.00000542\n",
      "Epoch: [47] [  24/  40] time: 488.2518, loss: 0.00000364\n",
      "Epoch: [47] [  25/  40] time: 488.4877, loss: 0.00002633\n",
      "Epoch: [47] [  26/  40] time: 488.7254, loss: 0.00000068\n",
      "Epoch: [47] [  27/  40] time: 488.9639, loss: 0.00000030\n",
      "Epoch: [47] [  28/  40] time: 489.2027, loss: 0.00003807\n",
      "Epoch: [47] [  29/  40] time: 489.4406, loss: 0.00000354\n",
      "Epoch: [47] [  30/  40] time: 489.6805, loss: 0.00000100\n",
      "Epoch: [47] [  31/  40] time: 489.9172, loss: 0.00000111\n",
      "Epoch: [47] [  32/  40] time: 490.1565, loss: 0.00000138\n",
      "Epoch: [47] [  33/  40] time: 490.3931, loss: 0.00000254\n",
      "Epoch: [47] [  34/  40] time: 490.6326, loss: 0.00000090\n",
      "Epoch: [47] [  35/  40] time: 490.8706, loss: 0.00004411\n",
      "Epoch: [47] [  36/  40] time: 491.1105, loss: 0.00000262\n",
      "Epoch: [47] [  37/  40] time: 491.3469, loss: 0.00000660\n",
      "Epoch: [47] [  38/  40] time: 491.5839, loss: 0.00000316\n",
      "Epoch: [47] [  39/  40] time: 491.8199, loss: 0.00001028\n",
      "[47/50] - ptime: 10.0381 loss: 0.00000665 acc: 0.79000\n",
      "Epoch: [48] [   0/  40] time: 492.9883, loss: 0.00000329\n",
      "Epoch: [48] [   1/  40] time: 493.2259, loss: 0.00000218\n",
      "Epoch: [48] [   2/  40] time: 493.4628, loss: 0.00002858\n",
      "Epoch: [48] [   3/  40] time: 493.6994, loss: 0.00000012\n",
      "Epoch: [48] [   4/  40] time: 493.9376, loss: 0.00000717\n",
      "Epoch: [48] [   5/  40] time: 494.1760, loss: 0.00000455\n",
      "Epoch: [48] [   6/  40] time: 494.4136, loss: 0.00000120\n",
      "Epoch: [48] [   7/  40] time: 494.6498, loss: 0.00000052\n",
      "Epoch: [48] [   8/  40] time: 494.8857, loss: 0.00000411\n",
      "Epoch: [48] [   9/  40] time: 495.1248, loss: 0.00000744\n",
      "Epoch: [48] [  10/  40] time: 495.3625, loss: 0.00000530\n",
      "Epoch: [48] [  11/  40] time: 495.5996, loss: 0.00002620\n",
      "Epoch: [48] [  12/  40] time: 495.8359, loss: 0.00003976\n",
      "Epoch: [48] [  13/  40] time: 496.0729, loss: 0.00000120\n",
      "Epoch: [48] [  14/  40] time: 496.3104, loss: 0.00000082\n",
      "Epoch: [48] [  15/  40] time: 496.5479, loss: 0.00000107\n",
      "Epoch: [48] [  16/  40] time: 496.7846, loss: 0.00004277\n",
      "Epoch: [48] [  17/  40] time: 497.0252, loss: 0.00000399\n",
      "Epoch: [48] [  18/  40] time: 497.2643, loss: 0.00000049\n",
      "Epoch: [48] [  19/  40] time: 497.5007, loss: 0.00000439\n",
      "Epoch: [48] [  20/  40] time: 497.7366, loss: 0.00011252\n",
      "Epoch: [48] [  21/  40] time: 497.9752, loss: 0.00000386\n",
      "Epoch: [48] [  22/  40] time: 498.2180, loss: 0.00004069\n",
      "Epoch: [48] [  23/  40] time: 498.4552, loss: 0.00000048\n",
      "Epoch: [48] [  24/  40] time: 498.6918, loss: 0.00000724\n",
      "Epoch: [48] [  25/  40] time: 498.9294, loss: 0.00000613\n",
      "Epoch: [48] [  26/  40] time: 499.1661, loss: 0.00000121\n",
      "Epoch: [48] [  27/  40] time: 499.4021, loss: 0.00004108\n",
      "Epoch: [48] [  28/  40] time: 499.6399, loss: 0.00000011\n",
      "Epoch: [48] [  29/  40] time: 499.8775, loss: 0.00000021\n",
      "Epoch: [48] [  30/  40] time: 500.1161, loss: 0.00000056\n",
      "Epoch: [48] [  31/  40] time: 500.3523, loss: 0.00000022\n",
      "Epoch: [48] [  32/  40] time: 500.5888, loss: 0.00000047\n",
      "Epoch: [48] [  33/  40] time: 500.8257, loss: 0.00000183\n",
      "Epoch: [48] [  34/  40] time: 501.0640, loss: 0.00000126\n",
      "Epoch: [48] [  35/  40] time: 501.3012, loss: 0.00000315\n",
      "Epoch: [48] [  36/  40] time: 501.5377, loss: 0.00001457\n",
      "Epoch: [48] [  37/  40] time: 501.7737, loss: 0.00000323\n",
      "Epoch: [48] [  38/  40] time: 502.0114, loss: 0.00000084\n",
      "Epoch: [48] [  39/  40] time: 502.2500, loss: 0.00000456\n",
      "[48/50] - ptime: 10.0297 loss: 0.00001073 acc: 0.78000\n",
      "Epoch: [49] [   0/  40] time: 503.3760, loss: 0.00000015\n",
      "Epoch: [49] [   1/  40] time: 503.6129, loss: 0.00000191\n",
      "Epoch: [49] [   2/  40] time: 503.8497, loss: 0.00000090\n",
      "Epoch: [49] [   3/  40] time: 504.0880, loss: 0.00000006\n",
      "Epoch: [49] [   4/  40] time: 504.3262, loss: 0.00000144\n",
      "Epoch: [49] [   5/  40] time: 504.5622, loss: 0.00004519\n",
      "Epoch: [49] [   6/  40] time: 504.7986, loss: 0.00000042\n",
      "Epoch: [49] [   7/  40] time: 505.0369, loss: 0.00000006\n",
      "Epoch: [49] [   8/  40] time: 505.2751, loss: 0.00000490\n",
      "Epoch: [49] [   9/  40] time: 505.5124, loss: 0.00000039\n",
      "Epoch: [49] [  10/  40] time: 505.7485, loss: 0.00002184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [49] [  11/  40] time: 505.9855, loss: 0.00000304\n",
      "Epoch: [49] [  12/  40] time: 506.2237, loss: 0.00000365\n",
      "Epoch: [49] [  13/  40] time: 506.4611, loss: 0.00000091\n",
      "Epoch: [49] [  14/  40] time: 506.6986, loss: 0.00000049\n",
      "Epoch: [49] [  15/  40] time: 506.9358, loss: 0.00011351\n",
      "Epoch: [49] [  16/  40] time: 507.1723, loss: 0.00000250\n",
      "Epoch: [49] [  17/  40] time: 507.4083, loss: 0.00000098\n",
      "Epoch: [49] [  18/  40] time: 507.6461, loss: 0.00000064\n",
      "Epoch: [49] [  19/  40] time: 507.8844, loss: 0.00000062\n",
      "Epoch: [49] [  20/  40] time: 508.1222, loss: 0.00000042\n",
      "Epoch: [49] [  21/  40] time: 508.3590, loss: 0.00000053\n",
      "Epoch: [49] [  22/  40] time: 508.5949, loss: 0.00000730\n",
      "Epoch: [49] [  23/  40] time: 508.8319, loss: 0.00001184\n",
      "Epoch: [49] [  24/  40] time: 509.0701, loss: 0.00000057\n",
      "Epoch: [49] [  25/  40] time: 509.3091, loss: 0.00000002\n",
      "Epoch: [49] [  26/  40] time: 509.5463, loss: 0.00002365\n",
      "Epoch: [49] [  27/  40] time: 509.7826, loss: 0.00003353\n",
      "Epoch: [49] [  28/  40] time: 510.0195, loss: 0.00000208\n",
      "Epoch: [49] [  29/  40] time: 510.2571, loss: 0.00000145\n",
      "Epoch: [49] [  30/  40] time: 510.4944, loss: 0.00000146\n",
      "Epoch: [49] [  31/  40] time: 510.7312, loss: 0.00001212\n",
      "Epoch: [49] [  32/  40] time: 510.9690, loss: 0.00000074\n",
      "Epoch: [49] [  33/  40] time: 511.2078, loss: 0.00001194\n",
      "Epoch: [49] [  34/  40] time: 511.4442, loss: 0.00000967\n",
      "Epoch: [49] [  35/  40] time: 511.6811, loss: 0.00000057\n",
      "Epoch: [49] [  36/  40] time: 511.9208, loss: 0.00000087\n",
      "Epoch: [49] [  37/  40] time: 512.1603, loss: 0.00000789\n",
      "Epoch: [49] [  38/  40] time: 512.3979, loss: 0.00004686\n",
      "Epoch: [49] [  39/  40] time: 512.6341, loss: 0.00000174\n",
      "[49/50] - ptime: 10.0128 loss: 0.00000947 acc: 0.78000\n",
      "Epoch: [50] [   0/  40] time: 513.7637, loss: 0.00000247\n",
      "Epoch: [50] [   1/  40] time: 514.0021, loss: 0.00000679\n",
      "Epoch: [50] [   2/  40] time: 514.2399, loss: 0.00001178\n",
      "Epoch: [50] [   3/  40] time: 514.4758, loss: 0.00001123\n",
      "Epoch: [50] [   4/  40] time: 514.7120, loss: 0.00000010\n",
      "Epoch: [50] [   5/  40] time: 514.9502, loss: 0.00000058\n",
      "Epoch: [50] [   6/  40] time: 515.1904, loss: 0.00000008\n",
      "Epoch: [50] [   7/  40] time: 515.4272, loss: 0.00000749\n",
      "Epoch: [50] [   8/  40] time: 515.6638, loss: 0.00000099\n",
      "Epoch: [50] [   9/  40] time: 515.9007, loss: 0.00001000\n",
      "Epoch: [50] [  10/  40] time: 516.1407, loss: 0.00000436\n",
      "Epoch: [50] [  11/  40] time: 516.3771, loss: 0.00000159\n",
      "Epoch: [50] [  12/  40] time: 516.6135, loss: 0.00000546\n",
      "Epoch: [50] [  13/  40] time: 516.8504, loss: 0.00000004\n",
      "Epoch: [50] [  14/  40] time: 517.0885, loss: 0.00000162\n",
      "Epoch: [50] [  15/  40] time: 517.3243, loss: 0.00000593\n",
      "Epoch: [50] [  16/  40] time: 517.5608, loss: 0.00000372\n",
      "Epoch: [50] [  17/  40] time: 517.7987, loss: 0.00001098\n",
      "Epoch: [50] [  18/  40] time: 518.0372, loss: 0.00000432\n",
      "Epoch: [50] [  19/  40] time: 518.2764, loss: 0.00000565\n",
      "Epoch: [50] [  20/  40] time: 518.5133, loss: 0.00000127\n",
      "Epoch: [50] [  21/  40] time: 518.7542, loss: 0.00000077\n",
      "Epoch: [50] [  22/  40] time: 518.9918, loss: 0.00000042\n",
      "Epoch: [50] [  23/  40] time: 519.2294, loss: 0.00000789\n",
      "Epoch: [50] [  24/  40] time: 519.4661, loss: 0.00020928\n",
      "Epoch: [50] [  25/  40] time: 519.7050, loss: 0.00000761\n",
      "Epoch: [50] [  26/  40] time: 519.9430, loss: 0.00001175\n",
      "Epoch: [50] [  27/  40] time: 520.1800, loss: 0.00000185\n",
      "Epoch: [50] [  28/  40] time: 520.4163, loss: 0.00002560\n",
      "Epoch: [50] [  29/  40] time: 520.6523, loss: 0.00000528\n",
      "Epoch: [50] [  30/  40] time: 520.8897, loss: 0.00000008\n",
      "Epoch: [50] [  31/  40] time: 521.1289, loss: 0.00000345\n",
      "Epoch: [50] [  32/  40] time: 521.3655, loss: 0.00000801\n",
      "Epoch: [50] [  33/  40] time: 521.6035, loss: 0.00002194\n",
      "Epoch: [50] [  34/  40] time: 521.8397, loss: 0.00000054\n",
      "Epoch: [50] [  35/  40] time: 522.0774, loss: 0.00007360\n",
      "Epoch: [50] [  36/  40] time: 522.3148, loss: 0.00000549\n",
      "Epoch: [50] [  37/  40] time: 522.5525, loss: 0.00000179\n",
      "Epoch: [50] [  38/  40] time: 522.7898, loss: 0.00000054\n",
      "Epoch: [50] [  39/  40] time: 523.0271, loss: 0.00000071\n",
      "[50/50] - ptime: 10.0280 loss: 0.00001208 acc: 0.79000\n",
      "Avg per epoch ptime: 10.05, total 50 epochs ptime: 523.65\n",
      " [*] Training finished!\n",
      " [*] Best Epoch:  3 , Accuracy:  0.8799999952316284\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/CNN_CANNY_C5_D1_Kernel(3,3)/CNN_CANNY_C5_D1_Kernel(3,3)-3\n",
      " [*] Finished testing Best Epoch: 3 , accuracy:  0.8799999952316284 !\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'CNN'\n",
    "dataset = '4_Flowers'\n",
    "epoch = 50\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "log_dir = 'logs'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    CNN = CNN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                log_dir=log_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    CNN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    CNN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    CNN.train()\n",
    "    \n",
    "#     CNN.test(epoch)\n",
    "        \n",
    "sess.close()\n",
    "#    Avg per epoch ptime: 10.05, total 50 epochs ptime: 523.65\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  3 , Accuracy:  0.8799999952316284\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_CANNY_C5_D1_Kernel(3,3)/CNN_CANNY_C5_D1_Kernel(3,3)-3\n",
    "#  [*] Finished testing Best Epoch: 3 , accuracy:  0.8799999952316284 !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "file='/home/huiqy/Music/CloudMusic/All_Time_Low.mp3' #文件名是完整路径名\n",
    "pygame.mixer.init() #初始化音频\n",
    "track = pygame.mixer.music.load(file)#载入音乐文件\n",
    "pygame.mixer.music.play()#开始播放\n",
    "time.sleep(60)#播放10秒\n",
    "pygame.mixer.music.stop()#停止播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
