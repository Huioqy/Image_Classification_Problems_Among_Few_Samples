{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def atoi(text):\n",
    "#     return int(text) if text.isdigit() else text\n",
    "\n",
    "# def natural_keys(text):\n",
    "#     return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "# def load_flower_data():\n",
    "#     # grab the list of images that we'll be describing\n",
    "#     print(\"[INFO] handling images...\")\n",
    "#     TRAIN_ORIGINAL_DIR = '../train/'\n",
    "#     TRAIN_SUB_DIR = '../subsample/'\n",
    "#     TEST_DIR = '../test/'\n",
    "\n",
    "#     # use this for full dataset\n",
    "#     train_images_original = [TRAIN_ORIGINAL_DIR + i for i in os.listdir(TRAIN_ORIGINAL_DIR)]\n",
    "#     train_images_sub = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "\n",
    "#     train_images = train_images_original + train_images_sub\n",
    "\n",
    "#     #print (train_images)\n",
    "#     train_images.sort(key=natural_keys)\n",
    "#     print (len(train_images))\n",
    "\n",
    "#     # initialize the features matrix and labels list\n",
    "#     trainImage = []\n",
    "#     trainLabels = []\n",
    "\n",
    "#     # loop over the input images\n",
    "#     for (i, imagePath) in enumerate(train_images):\n",
    "#         # extract the class label\n",
    "#         # get the labels from the name of the images by extract the string before \"_\"\n",
    "#         label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "#         # read and resize image\n",
    "#         img = cv2.imread(imagePath)\n",
    "#         img = cv2.resize(img, (128,128))\n",
    "\n",
    "#         # add the messages we got to features and labels matricies\n",
    "#         trainImage.append(img)\n",
    "#         trainLabels.append(label)\n",
    "\n",
    "#         # show an update every 100 images until the last image\n",
    "# #         if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "# #             print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "\n",
    "#     trainImage = np.array(trainImage,dtype = float32)\n",
    "#     trainLabels = np.array(trainLabels)\n",
    "#     print (trainImage.shape)\n",
    "#     trainImage = trainImage.astype(np.float32) / 255\n",
    "    \n",
    "#     le = preprocessing.LabelEncoder()\n",
    "#     le.fit(trainLabels)\n",
    "#     list(le.classes_)\n",
    "#     trainLabels = le.transform(trainLabels) \n",
    "    \n",
    "#     return trainImage, trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "4004\n",
      "(4004, 128, 128, 3)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[INFO] trainImage matrix: 768.77MB\n",
      "[INFO] trainLabels matrix: 0.0626MB\n"
     ]
    }
   ],
   "source": [
    "# trainImage,trainLabels = load_flower_data()\n",
    "\n",
    "# nb_classes = 2\n",
    "\n",
    "# # Convert class vectors to binary class matrices.\n",
    "# trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "# print (trainLabels)\n",
    "# np.save('./trainImage.npy', trainImage)\n",
    "# np.save('./trainLabels.npy', trainLabels)\n",
    "\n",
    "# print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "#     (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "# print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "#     (trainLabels.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu( X, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * X + f2 * tf.abs(X)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, result_dir, log_dir, \n",
    "                 test_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = \"cDCGAN\"     # name for checkpoint\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.output_height = 128\n",
    "        self.output_width = 128\n",
    "\n",
    "        self.z_dim = 100         # dimension of noise-vector\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay( 0.0002,\n",
    "                                             global_step=self.global_step,\n",
    "                                             decay_steps=20,\n",
    "                                             decay_rate=0.9,\n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # test\n",
    "        #visual results\n",
    "        self.onehot = np.eye(self.nb_class)\n",
    "        self.sample_num = 100  # number of generated images to be saved\n",
    "        self.visual_team = self.batch_size // self.nb_class  # number of generated images to be saved\n",
    "\n",
    "        #load_flower_data\n",
    "        self.data_x = np.load('./trainImage.npy')\n",
    "        self.data_y= np.load('./trainLabels.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches = len(self.data_x) // self.batch_size\n",
    "\n",
    "    def discriminator(self, x, y_fill, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"D:x\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            print(\"D:y_fill\",y_fill.get_shape())\n",
    "            # concat layer\n",
    "            \n",
    "            #卷积核为4*4 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(x, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            \n",
    "            print(\"D:\",net1_1.get_shape())\n",
    "            \n",
    "            net1_2 = tf.layers.conv2d(y_fill, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                         kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"D:\",net1_2.get_shape())\n",
    "    \n",
    "            #把数据和标签进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为128        \n",
    "            net = tf.layers.conv2d(net, 64, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "    \n",
    "            #卷积核为4*4 输出维度为128 \n",
    "            net = tf.layers.conv2d(net, 128, [4, 4], strides=(2, 2), padding='same', \n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为256\n",
    "            net = tf.layers.conv2d(net, 256, [4, 4], strides=(2, 2), padding='same', \n",
    "                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为512\n",
    "            net = tf.layers.conv2d(net, 512, [4, 4], strides=(2, 2), padding='same', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #output\n",
    "            out_logit = tf.layers.conv2d(net, 1, [4, 4], strides=(1, 1), padding='valid', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            print(\"D:out_logit\",out_logit.get_shape())\n",
    "            \n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:out\",out.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out, out_logit, net\n",
    "\n",
    "    def generator(self, z, y_label, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "            \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "            \n",
    "            print(\"G:z\",z.get_shape())\n",
    "            print(\"G:y_label\",y_label.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_1 = tf.layers.conv2d_transpose(z, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = tf.nn.relu(net1_1)\n",
    "            print(\"G:\",net1_1.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_2 = tf.layers.conv2d_transpose(y_label, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = tf.nn.relu(net1_2)\n",
    "            print(\"G:\",net1_2.get_shape())\n",
    "            \n",
    "            #把数据和标签进行连接\n",
    "            # concat layer\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度512\n",
    "            net = tf.layers.conv2d_transpose(net, 512, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = tf.nn.relu(net)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度128\n",
    "            net = tf.layers.conv2d_transpose(net, 128, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = tf.nn.relu(net)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度64\n",
    "            net = tf.layers.conv2d_transpose(net, 64, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = tf.nn.relu(net)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度32\n",
    "            net = tf.layers.conv2d_transpose(net, 32, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = tf.nn.relu(net)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度3\n",
    "            net = tf.layers.conv2d_transpose(net, 3, [4, 4], strides=(2, 2), padding='same',\n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            out = tf.nn.tanh(net)\n",
    "            print(\"G:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "            return out\n",
    "\n",
    "    def build_model(self):\n",
    "        #parameters\n",
    "        image_dims = [self.input_height, self.input_width, self.c_dim]\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=(self.batch_size,self.input_height, self.input_width, self.c_dim), \n",
    "                                name='real_images')\n",
    "\n",
    "        # noises\n",
    "        self.z = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.z_dim), name='z')\n",
    "        \n",
    "        self.y_label = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.nb_class), name='y_label')\n",
    "        self.y_fill = tf.placeholder(tf.float32, shape=(self.batch_size, self.output_width, \n",
    "                                                        self.output_height, self.nb_class), name='y_fill')\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of D for real images\n",
    "        D_real, D_real_logits, _ = self.discriminator(self.x, self.y_fill, is_training=True, reuse=False)\n",
    "            \n",
    "        #networks : generator\n",
    "        G = self.generator(self.z, self.y_label, is_training=True, reuse=False)\n",
    "\n",
    "        # output of D for fake images\n",
    "        D_fake, D_fake_logits, _ = self.discriminator(G, self.y_fill, is_training=True, reuse=True)\n",
    "\n",
    "        # get loss for discriminator\n",
    "        self.d_loss_real = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n",
    "        self.d_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n",
    "\n",
    "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
    "        \n",
    "        # get loss for generator\n",
    "        self.g_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # divide trainable variables into a group for D and a group for G\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        d_vars = [var for var in tf_vars if var.name.startswith('discriminator')]\n",
    "        g_vars = [var for var in tf_vars if var.name.startswith('generator')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)\n",
    "        \n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        self.fake_images = self.generator(self.z, self.y_label, is_training=False, reuse=True)\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", self.d_loss_real)\n",
    "        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", self.d_loss_fake)\n",
    "        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n",
    "\n",
    "        # final summary operations\n",
    "        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n",
    "        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # graph inputs for visualize training results\n",
    "        self.sample_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "\n",
    "        self.test_images = self.data_x[0:self.batch_size]\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep= self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            G_losses = []\n",
    "            D_losses = []\n",
    "    \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.data_x.shape[0]), self.data_x.shape[0])\n",
    "            shuffled_set = self.data_x[shuffle_idxs]\n",
    "            shuffled_label = self.data_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y_label = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill = batch_y_label * np.ones([self.batch_size, self.output_height, self.output_width, self.nb_class])\n",
    "                batch_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.z: batch_z,\n",
    "                                                          self.y_fill: batch_y_fill,\n",
    "                                                          self.y_label: batch_y_label}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                # update G network\n",
    "                batch_y = np.random.randint(0, self.nb_class, (self.batch_size, 1)) # <=  <\n",
    "                batch_y_label = self.onehot[batch_y.astype(np.int32)].reshape([self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill  = batch_y_label * np.ones([self.batch_size, self.input_height, self.input_width, self.nb_class])\n",
    "\n",
    "                # update G once\n",
    "                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss],\n",
    "                                                          feed_dict={self.x: batch_x,\n",
    "                                                                     self.z: batch_z, \n",
    "                                                                     self.y_fill: batch_y_fill,\n",
    "                                                                     self.y_label: batch_y_label})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                \n",
    "                D_losses.append(d_loss)\n",
    "                G_losses.append(g_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" % (epoch_loop, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss_d: %.8f, loss_g: %.8f, lf:  %.8f' % (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                        np.mean(D_losses), np.mean(G_losses), rate))\n",
    "            self.train_hist['D_losses'].append(np.mean(D_losses))\n",
    "            self.train_hist['G_losses'].append(np.mean(G_losses))\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "\n",
    "            # show temporal results\n",
    "            self.visualize_epoch_results(epoch_loop)\n",
    "            \n",
    "            # save trainhist for the initial train\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            \n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' + 'train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "    def visualize_img_to_gif(self, path, size, fps = 5):\n",
    "        print(\" [*] Generation Animation GIF start!\")\n",
    "        path_images = [path + '/'+ i for i in os.listdir(path)]\n",
    "        path_images.sort(key=natural_keys)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images start!\")\n",
    "        images = []\n",
    "        for p in tqdm(path_images):\n",
    "            img = imageio.imread(p)\n",
    "            img = cv2.resize(img, size)\n",
    "            images.append(img)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images finished!\")\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF start! FPS=\", fps)\n",
    "        path_gif = path + '/' + self.model_name + '_epoch%03d' % self.epoch + '_' + self.dataset_name + 'generation_animation.gif'\n",
    "        imageio.mimsave(path_gif, images, fps = fps)\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF finished! FPS=\", fps)\n",
    "\n",
    "    def visualize_test_image(self, epoch, num, times):\n",
    "        tot_num_samples = num #  100\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_dir + '/' + self.model_name + '/'+ self.model_name +'.model-'+ str(epoch)\n",
    "        \n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "            \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "        for j in range(times):\n",
    "            noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "            fixed_noise = noise \n",
    "            fixed_label = np.zeros((self.visual_team , 1))\n",
    "            #用于显示25组图像\n",
    "            for i in range(self.nb_class - 1):\n",
    "                fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "                temp_label = np.ones((self.visual_team, 1)) + i\n",
    "                fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "            fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "            samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "            self.save_cv2_img(samples[:tot_num_samples, :, :, :], tot_num_samples, epoch , j) \n",
    "        print(\" [*] Finished generating Epoch:\", epoch, \",\",times*num,\"new images!\")\n",
    "        \n",
    "                                    \n",
    "    def save_cv2_img(self, images, num, epoch, times):\n",
    "    # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(num):\n",
    "            classname = self.classname[idx // self.visual_team]\n",
    "            img_save = images[idx:idx+1, :, :, :][0, ...]*255\n",
    "            path = self.test_dir + '/' + classname + '_epoch%03d' % epoch + '_t%02d' % times+ '_%03d' % idx + '.png'\n",
    "            cv2.imwrite( path, img_save)\n",
    "              \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "        \n",
    "    def save_matplot_img(self, images, size, image_path):\n",
    "        # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(100):\n",
    "            vMin = np.amin(images[idx])\n",
    "            vMax = np.amax(images[idx])\n",
    "            img_arr = images[idx].reshape(128*128*3,1) # flatten\n",
    "            for i, v in enumerate(img_arr):\n",
    "                img_arr[i] = (v-vMin)/(vMax-vMin)\n",
    "            img_arr = img_arr.reshape(128,128,3) # M*N*3\n",
    "\n",
    "            # matplot display\n",
    "            plt.subplot(10,10,idx+1),plt.imshow(cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB), interpolation='nearest')\n",
    "            #plt.title(\"pred.:{}\".format(np.argmax(self.data_y[0]),fontsize=10))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.savefig(image_path, dpi = 400)\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}_{}\".format(\n",
    "            self.dataset_name, self.batch_size,\n",
    "            self.output_height, self.output_width)\n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['D_losses'])+1)\n",
    "\n",
    "        y1 = hist['D_losses']\n",
    "        y2 = hist['G_losses']\n",
    "\n",
    "        plt.plot(x, y1, label='D_loss')\n",
    "        plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.legend(loc=4)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "    def visualize_epoch_results(self, epoch):\n",
    "        tot_num_samples = min(self.sample_num, self.batch_size) # 100\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples))) # 10\n",
    "        \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "            \n",
    "        noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "        fixed_noise = noise \n",
    "        fixed_label = np.zeros((self.visual_team , 1))\n",
    "        \n",
    "        #用于显示25组图像\n",
    "        for i in range(self.nb_class - 1):\n",
    "            fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "            temp_label = np.ones((self.visual_team, 1)) + i\n",
    "            fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "        fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "    \n",
    "        samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "\n",
    "        self.save_matplot_img(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                    self.result_dir + '/' + self.model_name + '_epoch%03d' % epoch + '_' + self.dataset_name +'.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 2)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 2)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 2)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 2)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "discriminator/conv2d/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "discriminator/conv2d/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_1/kernel:0 (float32_ref 4x4x2x32) [1024, bytes: 4096]\n",
      "discriminator/conv2d_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_2/kernel:0 (float32_ref 4x4x64x64) [65536, bytes: 262144]\n",
      "discriminator/conv2d_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/conv2d_3/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "discriminator/conv2d_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/conv2d_4/kernel:0 (float32_ref 4x4x128x256) [524288, bytes: 2097152]\n",
      "discriminator/conv2d_4/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/conv2d_5/kernel:0 (float32_ref 4x4x256x512) [2097152, bytes: 8388608]\n",
      "discriminator/conv2d_5/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/conv2d_6/kernel:0 (float32_ref 4x4x512x1) [8192, bytes: 32768]\n",
      "discriminator/conv2d_6/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/conv2d_transpose/kernel:0 (float32_ref 4x4x256x100) [409600, bytes: 1638400]\n",
      "generator/conv2d_transpose/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_1/kernel:0 (float32_ref 4x4x256x2) [8192, bytes: 32768]\n",
      "generator/conv2d_transpose_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_2/kernel:0 (float32_ref 4x4x512x512) [4194304, bytes: 16777216]\n",
      "generator/conv2d_transpose_2/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/conv2d_transpose_3/kernel:0 (float32_ref 4x4x128x512) [1048576, bytes: 4194304]\n",
      "generator/conv2d_transpose_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/conv2d_transpose_4/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "generator/conv2d_transpose_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/conv2d_transpose_5/kernel:0 (float32_ref 4x4x32x64) [32768, bytes: 131072]\n",
      "generator/conv2d_transpose_5/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/conv2d_transpose_6/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "generator/conv2d_transpose_6/bias:0 (float32_ref 3) [3, bytes: 12]\n",
      "Total size of variables: 8660516\n",
      "Total bytes of variables: 34642064\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Success to read [cDCGAN.model-200], epoch [200]\n",
      " [*] Load SUCCESS\n",
      " [!] START_EPOCH is  201\n",
      "Avg per epoch ptime: 20.01, total 200 epochs ptime: 0.00\n",
      " [*] Training finished!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 1/40 [00:06<04:29,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 139 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 2/40 [00:12<03:54,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 137 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 3/40 [00:19<03:54,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 125 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 4/40 [00:26<03:59,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 155 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 5/40 [00:34<04:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 162 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 6/40 [00:41<03:53,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 163 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 7/40 [00:48<03:48,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 129 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 8/40 [00:56<03:45,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 171 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 9/40 [01:05<03:45,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 148 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 10/40 [01:13<03:40,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 181 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 11/40 [01:21<03:33,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 134 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-133\n",
      " [*] Finished generating Epoch: 133 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 12/40 [01:31<03:32,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-175\n",
      " [*] Finished generating Epoch: 175 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 13/40 [01:40<03:28,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 14/40 [01:49<03:23,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 189 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 15/40 [02:00<03:21,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 192 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 16/40 [02:10<03:15,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 143 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 17/40 [02:19<03:09,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 147 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-164\n",
      " [*] Finished generating Epoch: 164 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 18/40 [02:29<03:03,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-157\n",
      " [*] Finished generating Epoch: 157 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 19/40 [02:42<02:59,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 20/40 [02:53<02:53,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 173 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-174\n",
      " [*] Finished generating Epoch: 174 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 21/40 [03:03<02:45,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 22/40 [03:14<02:38,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 153 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 23/40 [03:25<02:32,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 151 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 24/40 [03:39<02:26,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 161 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-197\n",
      " [*] Finished generating Epoch: 197 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 25/40 [03:50<02:18,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-138\n",
      " [*] Finished generating Epoch: 138 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 26/40 [04:02<02:10,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 27/40 [04:14<02:02,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 168 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-190\n",
      " [*] Finished generating Epoch: 190 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 28/40 [04:26<01:54,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-188\n",
      " [*] Finished generating Epoch: 188 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▎  | 29/40 [04:38<01:45,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-149\n",
      " [*] Finished generating Epoch: 149 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 30/40 [04:55<01:38,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-142\n",
      " [*] Finished generating Epoch: 142 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 31/40 [05:08<01:29,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 32/40 [05:22<01:20, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 194 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-144\n",
      " [*] Finished generating Epoch: 144 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▎ | 33/40 [05:35<01:11, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-176\n",
      " [*] Finished generating Epoch: 176 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 34/40 [05:49<01:01, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 35/40 [06:04<00:52, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 167 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-165\n",
      " [*] Finished generating Epoch: 165 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 36/40 [06:18<00:42, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▎| 37/40 [06:33<00:31, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 145 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-184\n",
      " [*] Finished generating Epoch: 184 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 38/40 [06:53<00:21, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-146\n",
      " [*] Finished generating Epoch: 146 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 39/40 [07:10<00:11, 11.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample2_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 40/40 [07:25<00:00, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 193 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'cDCGAN'\n",
    "dataset = 'Class2_Sample2_test1_1_1000'\n",
    "epoch = 200\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "result_dir = 'results'\n",
    "log_dir = 'logs'\n",
    "test_dir = 'image_gan'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --test_dir\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    cDCGAN = cDCGAN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                    result_dir=result_dir, log_dir=log_dir, test_dir=test_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    cDCGAN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    cDCGAN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    cDCGAN.train()\n",
    "    \n",
    "    #visualize_img_to_gif\n",
    "#     cDCGAN.visualize_img_to_gif(path=result_dir, size=(900,600), fps=5)\n",
    "\n",
    "    vepoch = random.sample(range(120,200), 40)\n",
    "\n",
    "    for e in tqdm(vepoch):\n",
    "        cDCGAN.visualize_test_image( e, 100, 1)\n",
    "        \n",
    "sess.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
