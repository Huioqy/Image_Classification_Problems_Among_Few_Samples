{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "# def load_flower_data():\n",
    "#     # grab the list of images that we'll be describing\n",
    "#     print(\"[INFO] handling images...\")\n",
    "#     TRAIN_ORIGINAL_DIR = '../train/'\n",
    "#     TRAIN_SUB_DIR = '../subsample/'\n",
    "#     TEST_DIR = '../test/'\n",
    "\n",
    "#     # use this for full dataset\n",
    "#     train_images_original = [TRAIN_ORIGINAL_DIR + i for i in os.listdir(TRAIN_ORIGINAL_DIR)]\n",
    "#     train_images_sub = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "\n",
    "#     train_images = train_images_original + train_images_sub\n",
    "\n",
    "#     #print (train_images)\n",
    "#     train_images.sort(key=natural_keys)\n",
    "#     print (len(train_images))\n",
    "\n",
    "#     # initialize the features matrix and labels list\n",
    "#     trainImage = []\n",
    "#     trainLabels = []\n",
    "\n",
    "#     # loop over the input images\n",
    "#     for (i, imagePath) in enumerate(train_images):\n",
    "#         # extract the class label\n",
    "#         # get the labels from the name of the images by extract the string before \"_\"\n",
    "#         label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "#         # read and resize image\n",
    "#         img = cv2.imread(imagePath)\n",
    "#         img = cv2.resize(img, (128,128))\n",
    "\n",
    "#         # add the messages we got to features and labels matricies\n",
    "#         trainImage.append(img)\n",
    "#         trainLabels.append(label)\n",
    "\n",
    "#         # show an update every 100 images until the last image\n",
    "# #         if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "# #             print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "\n",
    "#     trainImage = np.array(trainImage,dtype = float32)\n",
    "#     trainLabels = np.array(trainLabels)\n",
    "#     print (trainImage.shape)\n",
    "#     trainImage = trainImage.astype(np.float32) / 255\n",
    "    \n",
    "#     le = preprocessing.LabelEncoder()\n",
    "#     le.fit(trainLabels)\n",
    "#     list(le.classes_)\n",
    "#     trainLabels = le.transform(trainLabels) \n",
    "    \n",
    "#     return trainImage, trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainImage,trainLabels = load_flower_data()\n",
    "\n",
    "# nb_classes = 4\n",
    "\n",
    "# # Convert class vectors to binary class matrices.\n",
    "# trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "# print (trainLabels)\n",
    "# np.save('./trainImage_4_1000.npy', trainImage)\n",
    "# np.save('./trainLabels_4_1000.npy', trainLabels)\n",
    "\n",
    "# print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "#     (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "# print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "#     (trainLabels.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu( X, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * X + f2 * tf.abs(X)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, result_dir, log_dir, \n",
    "                 test_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = \"cDCGAN\"     # name for checkpoint\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy', 'Sunflower', 'Windflower']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.output_height = 128\n",
    "        self.output_width = 128\n",
    "\n",
    "        self.z_dim = 100         # dimension of noise-vector\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 4\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(0.0002,  self.global_step, 500, 0.95, staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # test\n",
    "        #visual results\n",
    "        self.onehot = np.eye(self.nb_class)\n",
    "        self.sample_num = 100  # number of generated images to be saved\n",
    "        self.visual_team = self.batch_size // self.nb_class  # number of generated images to be saved\n",
    "\n",
    "        #load_flower_data\n",
    "        self.data_x = np.load('./trainImage_4_1000.npy')\n",
    "        self.data_y= np.load('./trainLabels_4_1000.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches = len(self.data_x) // self.batch_size\n",
    "\n",
    "    def discriminator(self, x, y_fill, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"D:x\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            print(\"D:y_fill\",y_fill.get_shape())\n",
    "            # concat layer\n",
    "            \n",
    "            #卷积核为4*4 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(x, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            \n",
    "            print(\"D:\",net1_1.get_shape())\n",
    "            \n",
    "            net1_2 = tf.layers.conv2d(y_fill, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                         kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"D:\",net1_2.get_shape())\n",
    "    \n",
    "            #把数据和标签进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为128        \n",
    "            net = tf.layers.conv2d(net, 64, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "    \n",
    "            #卷积核为4*4 输出维度为128 \n",
    "            net = tf.layers.conv2d(net, 128, [4, 4], strides=(2, 2), padding='same', \n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为256\n",
    "            net = tf.layers.conv2d(net, 256, [4, 4], strides=(2, 2), padding='same', \n",
    "                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为512\n",
    "            net = tf.layers.conv2d(net, 512, [4, 4], strides=(2, 2), padding='same', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #output\n",
    "            out_logit = tf.layers.conv2d(net, 1, [4, 4], strides=(1, 1), padding='valid', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            print(\"D:out_logit\",out_logit.get_shape())\n",
    "            \n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:out\",out.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out, out_logit, net\n",
    "\n",
    "    def generator(self, z, y_label, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "            \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "            \n",
    "            print(\"G:z\",z.get_shape())\n",
    "            print(\"G:y_label\",y_label.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_1 = tf.layers.conv2d_transpose(z, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            print(\"G:\",net1_1.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_2 = tf.layers.conv2d_transpose(y_label, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"G:\",net1_2.get_shape())\n",
    "            \n",
    "            #把数据和标签进行连接\n",
    "            # concat layer\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度512\n",
    "            net = tf.layers.conv2d_transpose(net, 512, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度128\n",
    "            net = tf.layers.conv2d_transpose(net, 128, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度64\n",
    "            net = tf.layers.conv2d_transpose(net, 64, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度32\n",
    "            net = tf.layers.conv2d_transpose(net, 32, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度3\n",
    "            net = tf.layers.conv2d_transpose(net, 3, [4, 4], strides=(2, 2), padding='same',\n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            out = tf.nn.tanh(net)\n",
    "            print(\"G:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "            return out\n",
    "\n",
    "    def build_model(self):\n",
    "        #parameters\n",
    "        image_dims = [self.input_height, self.input_width, self.c_dim]\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=(self.batch_size,self.input_height, self.input_width, self.c_dim), \n",
    "                                name='real_images')\n",
    "\n",
    "        # noises\n",
    "        self.z = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.z_dim), name='z')\n",
    "        \n",
    "        self.y_label = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.nb_class), name='y_label')\n",
    "        self.y_fill = tf.placeholder(tf.float32, shape=(self.batch_size, self.output_width, \n",
    "                                                        self.output_height, self.nb_class), name='y_fill')\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of D for real images\n",
    "        D_real, D_real_logits, _ = self.discriminator(self.x, self.y_fill, is_training=True, reuse=False)\n",
    "            \n",
    "        #networks : generator\n",
    "        G = self.generator(self.z, self.y_label, is_training=True, reuse=False)\n",
    "\n",
    "        # output of D for fake images\n",
    "        D_fake, D_fake_logits, _ = self.discriminator(G, self.y_fill, is_training=True, reuse=True)\n",
    "\n",
    "        # get loss for discriminator\n",
    "        self.d_loss_real = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n",
    "        self.d_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n",
    "\n",
    "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
    "        \n",
    "        # get loss for generator\n",
    "        self.g_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # divide trainable variables into a group for D and a group for G\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        d_vars = [var for var in tf_vars if var.name.startswith('discriminator')]\n",
    "        g_vars = [var for var in tf_vars if var.name.startswith('generator')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)\n",
    "        \n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        self.fake_images = self.generator(self.z, self.y_label, is_training=False, reuse=True)\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", self.d_loss_real)\n",
    "        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", self.d_loss_fake)\n",
    "        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n",
    "\n",
    "        # final summary operations\n",
    "        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n",
    "        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # graph inputs for visualize training results\n",
    "        self.sample_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "\n",
    "        self.test_images = self.data_x[0:self.batch_size]\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep= self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '\\\\' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            G_losses = []\n",
    "            D_losses = []\n",
    "    \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.data_x.shape[0]), self.data_x.shape[0])\n",
    "            shuffled_set = self.data_x[shuffle_idxs]\n",
    "            shuffled_label = self.data_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y_label = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill = batch_y_label * np.ones([self.batch_size, self.output_height, self.output_width, self.nb_class])\n",
    "                batch_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.z: batch_z,\n",
    "                                                          self.y_fill: batch_y_fill,\n",
    "                                                          self.y_label: batch_y_label}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                # update G network\n",
    "                batch_y = np.random.randint(0, self.nb_class, (self.batch_size, 1)) # <=  <\n",
    "                batch_y_label = self.onehot[batch_y.astype(np.int32)].reshape([self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill  = batch_y_label * np.ones([self.batch_size, self.input_height, self.input_width, self.nb_class])\n",
    "\n",
    "                # update G once\n",
    "                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss],\n",
    "                                                          feed_dict={self.x: batch_x,\n",
    "                                                                     self.z: batch_z, \n",
    "                                                                     self.y_fill: batch_y_fill,\n",
    "                                                                     self.y_label: batch_y_label})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                \n",
    "                D_losses.append(d_loss)\n",
    "                G_losses.append(g_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" % (epoch_loop, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss_d: %.8f, loss_g: %.8f' % (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                        np.mean(D_losses), np.mean(G_losses)))\n",
    "            self.train_hist['D_losses'].append(np.mean(D_losses))\n",
    "            self.train_hist['G_losses'].append(np.mean(G_losses))\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "\n",
    "            # show temporal results\n",
    "            self.visualize_epoch_results(epoch_loop)\n",
    "            \n",
    "            # save trainhist for the initial train\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            \n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' + 'train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "    def visualize_img_to_gif(self, path, size, fps = 5):\n",
    "        print(\" [*] Generation Animation GIF start!\")\n",
    "        path_images = [path + '/'+ i for i in os.listdir(path)]\n",
    "        path_images.sort(key=natural_keys)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images start!\")\n",
    "        images = []\n",
    "        for p in tqdm(path_images):\n",
    "            img = imageio.imread(p)\n",
    "            img = cv2.resize(img, size)\n",
    "            images.append(img)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images finished!\")\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF start! FPS=\", fps)\n",
    "        path_gif = path + '/' + self.model_name + '_epoch%03d' % self.epoch + '_' + self.dataset_name + 'generation_animation.gif'\n",
    "        imageio.mimsave(path_gif, images, fps = fps)\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF finished! FPS=\", fps)\n",
    "\n",
    "    def visualize_test_image(self, epoch, num, times):\n",
    "        tot_num_samples = num #  100\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_dir + '/' + self.model_name + '/'+ self.model_name +'.model-'+ str(epoch)\n",
    "        \n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "            \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "        for j in range(times):\n",
    "            noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "            fixed_noise = noise \n",
    "            fixed_label = np.zeros((self.visual_team , 1))\n",
    "            #用于显示25组图像\n",
    "            for i in range(self.nb_class - 1):\n",
    "                fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "                temp_label = np.ones((self.visual_team, 1)) + i\n",
    "                fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "            fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "            samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "            self.save_cv2_img(samples[:tot_num_samples, :, :, :], tot_num_samples, epoch , j) \n",
    "        print(\" [*] Finished generating Epoch:\", epoch, \",\",times*num,\"new images!\")\n",
    "        \n",
    "                                    \n",
    "    def save_cv2_img(self, images, num, epoch, times):\n",
    "    # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(num):\n",
    "            classname = self.classname[idx // self.visual_team]\n",
    "            img_save = images[idx:idx+1, :, :, :][0, ...]*255\n",
    "            path = self.test_dir + '/' + classname + '_epoch%03d' % epoch + '_t%02d' % times+ '_%03d' % idx + '.png'\n",
    "            cv2.imwrite( path, img_save)\n",
    "              \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "        \n",
    "    def save_matplot_img(self, images, size, image_path):\n",
    "        # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(100):\n",
    "            vMin = np.amin(images[idx])\n",
    "            vMax = np.amax(images[idx])\n",
    "            img_arr = images[idx].reshape(128*128*3,1) # flatten\n",
    "            for i, v in enumerate(img_arr):\n",
    "                img_arr[i] = (v-vMin)/(vMax-vMin)\n",
    "            img_arr = img_arr.reshape(128,128,3) # M*N*3\n",
    "\n",
    "            # matplot display\n",
    "            plt.subplot(10,10,idx+1),plt.imshow(cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB), interpolation='nearest')\n",
    "            #plt.title(\"pred.:{}\".format(np.argmax(self.data_y[0]),fontsize=10))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.savefig(image_path, dpi = 400)\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}_{}\".format(\n",
    "            self.dataset_name, self.batch_size,\n",
    "            self.output_height, self.output_width)\n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['D_losses'])+1)\n",
    "\n",
    "        y1 = hist['D_losses']\n",
    "        y2 = hist['G_losses']\n",
    "\n",
    "        plt.plot(x, y1, label='D_loss')\n",
    "        plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.legend(loc=4)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "    def visualize_epoch_results(self, epoch):\n",
    "        tot_num_samples = min(self.sample_num, self.batch_size) # 100\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples))) # 10\n",
    "        \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "            \n",
    "        noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "        fixed_noise = noise \n",
    "        fixed_label = np.zeros((self.visual_team , 1))\n",
    "        \n",
    "        #用于显示25组图像\n",
    "        for i in range(self.nb_class - 1):\n",
    "            fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "            temp_label = np.ones((self.visual_team, 1)) + i\n",
    "            fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "        fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "    \n",
    "        samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "\n",
    "        self.save_matplot_img(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                    self.result_dir + '/' + self.model_name + '_epoch%03d' % epoch + '_' + self.dataset_name +'.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 4)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 4)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 4)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 4)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "discriminator/conv2d/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "discriminator/conv2d/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_1/kernel:0 (float32_ref 4x4x4x32) [2048, bytes: 8192]\n",
      "discriminator/conv2d_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_2/kernel:0 (float32_ref 4x4x64x64) [65536, bytes: 262144]\n",
      "discriminator/conv2d_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/conv2d_3/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "discriminator/conv2d_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/conv2d_4/kernel:0 (float32_ref 4x4x128x256) [524288, bytes: 2097152]\n",
      "discriminator/conv2d_4/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/conv2d_5/kernel:0 (float32_ref 4x4x256x512) [2097152, bytes: 8388608]\n",
      "discriminator/conv2d_5/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/conv2d_6/kernel:0 (float32_ref 4x4x512x1) [8192, bytes: 32768]\n",
      "discriminator/conv2d_6/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/conv2d_transpose/kernel:0 (float32_ref 4x4x256x100) [409600, bytes: 1638400]\n",
      "generator/conv2d_transpose/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_1/kernel:0 (float32_ref 4x4x256x4) [16384, bytes: 65536]\n",
      "generator/conv2d_transpose_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_2/kernel:0 (float32_ref 4x4x512x512) [4194304, bytes: 16777216]\n",
      "generator/conv2d_transpose_2/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/conv2d_transpose_3/kernel:0 (float32_ref 4x4x128x512) [1048576, bytes: 4194304]\n",
      "generator/conv2d_transpose_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/conv2d_transpose_4/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "generator/conv2d_transpose_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/conv2d_transpose_5/kernel:0 (float32_ref 4x4x32x64) [32768, bytes: 131072]\n",
      "generator/conv2d_transpose_5/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/conv2d_transpose_6/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "generator/conv2d_transpose_6/bias:0 (float32_ref 3) [3, bytes: 12]\n",
      "Total size of variables: 8669732\n",
      "Total bytes of variables: 34678928\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Success to read [cDCGAN.model-300], epoch [300]\n",
      " [*] Load SUCCESS\n",
      " [!] START_EPOCH is  301\n",
      "Avg per epoch ptime: 63.81, total 300 epochs ptime: 0.00\n",
      " [*] Training finished!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/60 [00:04<04:23,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 143 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/60 [00:08<04:03,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 177 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 3/60 [00:12<03:59,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 144 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/60 [00:16<03:57,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 107 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 5/60 [00:21<03:56,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 101 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 6/60 [00:25<03:52,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 113 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 7/60 [00:30<03:51,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 168 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 8/60 [00:35<03:48,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 103 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 9/60 [00:40<03:47,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 134 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 10/60 [00:45<03:45,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 108 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 11/60 [00:50<03:44,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 100 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 12/60 [00:55<03:41,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 122 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 13/60 [01:00<03:38,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 127 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 14/60 [01:06<03:36,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 130 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 15/60 [01:11<03:33,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 159 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 16/60 [01:16<03:30,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 157 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 17/60 [01:21<03:27,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 145 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 18/60 [01:28<03:25,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 151 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 19/60 [01:33<03:22,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 170 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 20/60 [01:39<03:18,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 132 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 21/60 [01:45<03:15,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 158 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 22/60 [01:52<03:13,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 105 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 23/60 [01:58<03:09,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 140 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 24/60 [02:04<03:06,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 181 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 25/60 [02:10<03:02,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 154 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 26/60 [02:16<02:58,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 135 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 27/60 [02:23<02:55,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 148 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 28/60 [02:30<02:52,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 142 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 29/60 [02:37<02:48,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 109 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 30/60 [02:43<02:43,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 118 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 31/60 [02:50<02:39,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 117 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 32/60 [02:57<02:35,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 147 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 33/60 [03:04<02:31,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 112 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 34/60 [03:12<02:26,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 123 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 35/60 [03:20<02:23,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 119 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 36/60 [03:27<02:18,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 146 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 37/60 [03:34<02:13,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 121 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 38/60 [03:42<02:08,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 139 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 39/60 [03:50<02:03,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 169 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 40/60 [03:57<01:58,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 162 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 41/60 [04:05<01:53,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 166 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 42/60 [04:13<01:48,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 104 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 43/60 [04:21<01:43,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 171 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 44/60 [04:31<01:38,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 183 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 45/60 [04:39<01:33,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 124 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 46/60 [04:47<01:27,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 161 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 47/60 [04:56<01:21,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 156 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 48/60 [05:04<01:16,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 125 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 49/60 [05:13<01:10,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 116 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 50/60 [05:22<01:04,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 111 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 51/60 [05:30<00:58,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 128 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 52/60 [05:39<00:52,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 182 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/4_Flowers_100_128_128/cDCGAN/cDCGAN.model-133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 53/60 [05:48<00:46,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 133 , 100 new images!\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'cDCGAN'\n",
    "dataset = '4_Flowers'\n",
    "epoch = 300\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "result_dir = 'results'\n",
    "log_dir = 'logs'\n",
    "test_dir = 'image_gan'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "visual_epoch = 180\n",
    "nb_team = 40\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --test_dir\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    cDCGAN = cDCGAN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                    result_dir=result_dir, log_dir=log_dir, test_dir=test_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    cDCGAN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    cDCGAN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    cDCGAN.train()\n",
    "    \n",
    "    #visualize_img_to_gif\n",
    "#     cDCGAN.visualize_img_to_gif(path=result_dir, size=(900,600), fps=5)\n",
    "\n",
    "    #280 282    \n",
    "#     # Generate new images\n",
    "#     cDCGAN.visualize_test_image( visual_epoch, 100, nb_team)\n",
    "\n",
    "    vepoch = random.sample(range(100,185), 60)\n",
    "\n",
    "    for e in tqdm(vepoch):\n",
    "        cDCGAN.visualize_test_image( e, 100, 1)\n",
    "        \n",
    "sess.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
