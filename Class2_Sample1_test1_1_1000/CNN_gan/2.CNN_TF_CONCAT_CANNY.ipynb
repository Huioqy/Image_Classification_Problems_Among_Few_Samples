{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_canny(images):\n",
    "    canny_list = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "        canny_superposition = np.zeros(shape=(img.shape[0],img.shape[1]),dtype=np.uint16)\n",
    "        for channel in range(3):\n",
    "            img_ch = img[:,:,channel]\n",
    "            canny_ch = cv2.Canny(img_ch, 60, 150)\n",
    "            canny_superposition =  canny_superposition + (canny_ch).astype(np.uint16)\n",
    "        canny_superposition = cv2.normalize(canny_superposition, canny_superposition,0,255,cv2.NORM_MINMAX)\n",
    "        canny_list.append(np.array((canny_superposition).astype(np.uint8)).reshape([img.shape[0],img.shape[1],1]))\n",
    "    canny_list = np.array(canny_list,dtype = float32)/255.0\n",
    "    return canny_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "def load_flower_data():\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] handling images...\")\n",
    "    TRAIN_ORIGINAL_DIR = '../train/'\n",
    "    TRAIN_SUB_DIR = '../subsample/'\n",
    "    TRAIN_GAN = '../../image_gan/'\n",
    "    TEST_DIR = '../../test/'\n",
    "\n",
    "    # use this for full dataset\n",
    "#     train_images_original = [TRAIN_ORIGINAL_DIR + i for i in os.listdir(TRAIN_ORIGINAL_DIR)]\n",
    "#     train_images_sub = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "#     train_images = train_images_original + train_images_sub\n",
    "    train_images_gan = [TRAIN_GAN + i for i in os.listdir(TRAIN_GAN)]\n",
    "    test_images = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "    \n",
    "    train_images = train_images_gan\n",
    "    \n",
    "    train_images.sort(key=natural_keys)\n",
    "    test_images.sort(key=natural_keys)\n",
    "\n",
    "    # initialize the features matrix and labels list\n",
    "    trainImage = []\n",
    "    trainLabels = []\n",
    "    testImage = []\n",
    "    testLabels = []\n",
    "\n",
    "    # loop over the input images\n",
    "    for (i, imagePath) in enumerate(train_images):\n",
    "        # extract the class label\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # read and resize image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        trainImage.append(img)\n",
    "        trainLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "            \n",
    "      # loop over the input images\n",
    "    for (i, imagePath) in enumerate(test_images):\n",
    "        # extract the class label\n",
    "        # our images were named as labels.image_number.format\n",
    "        # get the labels from the name of the images by extract the string before \".\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # extract CNN features in the image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        testImage.append(img)\n",
    "        testLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(test_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(test_images)))\n",
    "\n",
    "\n",
    "    trainImage = np.array(trainImage,dtype = float32)\n",
    "    trainLabels = np.array(trainLabels)\n",
    "    testImage = np.array(testImage,dtype = float32)\n",
    "    testLabels = np.array(testLabels)\n",
    "    print (trainImage.shape)\n",
    "    \n",
    "    trainImage = trainImage.astype(np.float32) / 255.0\n",
    "    testImage = testImage.astype(np.float32) / 255.0\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainLabels)\n",
    "    list(le.classes_)\n",
    "    trainLabels = le.transform(trainLabels) \n",
    "    testLabels = le.transform(testLabels) \n",
    "    \n",
    "    return trainImage, trainLabels, testImage, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "[INFO] processed 1000/2000\n",
      "[INFO] processed 2000/2000\n",
      "[INFO] processed 158/158\n",
      "(2000, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [14:01<00:00,  2.38it/s]\n",
      "100%|██████████| 158/158 [00:03<00:00, 48.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(158, 2)\n",
      "[INFO] trainImage matrix: 384.00MB\n",
      "[INFO] trainLabels matrix: 0.0312MB\n",
      "[INFO] testImage matrix: 30.34MB\n",
      "[INFO] testLabels matrix: 0.0025MB\n",
      "[INFO] trainImage_canny matrix: 128.00MB\n",
      "[INFO] testImage_canny matrix: 10.1120MB\n"
     ]
    }
   ],
   "source": [
    "trainImage, trainLabels, testImage, testLabels = load_flower_data()\n",
    "\n",
    "trainImage_canny = batch_canny(trainImage)\n",
    "testImage_canny = batch_canny(testImage)\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "print (trainLabels)\n",
    "testLabels = keras.utils.to_categorical(testLabels, nb_classes)\n",
    "print (testLabels)\n",
    "print (testLabels.shape)\n",
    "\n",
    "np.save('../trainImage.npy', trainImage)\n",
    "np.save('../trainLabels.npy', trainLabels)\n",
    "np.save('../testImage.npy', testImage)\n",
    "np.save('../testLabels.npy', testLabels)\n",
    "np.save('../trainImage_canny.npy', trainImage_canny)\n",
    "np.save('../testImage_canny.npy', testImage_canny)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage matrix: {:.2f}MB\".format(\n",
    "    (testImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testLabels matrix: {:.4f}MB\".format(\n",
    "    (testLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainImage_canny matrix: {:.2f}MB\".format(\n",
    "    (trainImage_canny.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_canny matrix: {:.4f}MB\".format(\n",
    "    (testImage_canny.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, log_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "        \n",
    "        # number of convolutional filters to use  \n",
    "        self.nb_CNN = [32, 64, 64, 64, 128]  \n",
    "        # number of dense filters to use  \n",
    "        self.nb_Dense = [256] \n",
    "        # size of pooling area for max pooling  \n",
    "        self.pool_size = (2, 2)  \n",
    "        # convolution kernel size  \n",
    "        self.kernel_size = (3, 3)\n",
    "        self.batch_normalization_control = True\n",
    "        \n",
    "        # name for checkpoint\n",
    "        self.model_name = 'CNN_CANNY_C%d_D%d_Kernel(%d,%d)_lrdecay0.95' % (len(self.nb_CNN), len(self.nb_Dense),\n",
    "                                                          self.kernel_size[0], self.kernel_size[1])    \n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(0.001, \n",
    "                                             global_step=self.global_step, \n",
    "                                             decay_steps=10, \n",
    "                                             decay_rate=0.95, \n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # test\n",
    "\n",
    "        #load_flower_data\n",
    "        self.train_x = np.load('../trainImage.npy')\n",
    "        self.train_y= np.load('../trainLabels.npy')\n",
    "        self.test_x = np.load('../testImage.npy')\n",
    "        self.test_y= np.load('../testLabels.npy')\n",
    "        self.train_x_canny = np.load('../trainImage_canny.npy')\n",
    "        self.test_x_canny = np.load('../testImage_canny.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['losses'] = []\n",
    "        self.train_hist['accuracy'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches_train = len(self.train_x) // self.batch_size\n",
    "        self.num_batches_test= len(self.test_x) // self.batch_size\n",
    "\n",
    "    def cnn_model(self, x, x_canny, keep_prob, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"cnn\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            B = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"CNN:x\",x.get_shape()) # 128, 128, 3 \n",
    "            print(\"CNN:x_canny\",x_canny.get_shape()) # 128, 128, 1\n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(inputs = x,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_1'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_1.get_shape())\n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_2 = tf.layers.conv2d(inputs = x_canny,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_2'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_2.get_shape())\n",
    "\n",
    "            #把数据和边缘进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)\n",
    "            net = tf.nn.relu(net, name = 'relu_conv_1')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_1'\n",
    "                                             )\n",
    "            \n",
    "            for i in range(2,len(self.nb_CNN)+1):\n",
    "                net = tf.layers.conv2d(inputs = net,                 # 输入,\n",
    "                                       filters = self.nb_CNN[i-1],      # 卷积核个数,\n",
    "                                       kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                       strides = (1, 1),\n",
    "                                       padding = 'same',              # padding方法\n",
    "                                       kernel_initializer = W,\n",
    "                                       bias_initializer = B,\n",
    "                                       kernel_regularizer = None,\n",
    "                                       bias_regularizer = None,\n",
    "                                       activity_regularizer = None,\n",
    "                                       name = 'conv_'+ str(i)        # 命名用于获取变量\n",
    "                                       )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "                if self.batch_normalization_control:\n",
    "                    net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_conv_' + str(i))\n",
    "                net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_' + str(i)\n",
    "                                             )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #flatten\n",
    "            net = tf.reshape(net, [-1, int(net.get_shape()[1]*net.get_shape()[2]*net.get_shape()[3])],name='flatten')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #dense layer\n",
    "            for i in range(1,len(self.nb_Dense)+1):\n",
    "                net = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_Dense[i-1],\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_' + str(i)\n",
    "                                    )\n",
    "#                 net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_dense_' + str(i))\n",
    "                net = tf.layers.dropout(inputs = net,\n",
    "                                        rate=keep_prob,\n",
    "                                        noise_shape=None,\n",
    "                                        seed=None,\n",
    "                                        training = is_training,\n",
    "                                        name= 'dropout_dense_' + str(i)\n",
    "                                        )\n",
    "            #output\n",
    "            logit = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_class,\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_output'\n",
    "                                    )\n",
    "            out_logit = tf.nn.softmax(logit, name=\"softmax\")\n",
    "            print(\"CNN:out_logit\",out_logit.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out_logit, logit\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.c_dim], \n",
    "                                name='x_image')\n",
    "        \n",
    "        self.x_canny = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, 1], \n",
    "                                name='x_canny')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[self.batch_size, self.nb_class], name='y_label')\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of cnn_model\n",
    "        self.out_logit, self.logit = self.cnn_model(self.x, self.x_canny, self.keep_prob, is_training=True, reuse=False)\n",
    "        \n",
    "        self.loss_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,\n",
    "                                                                                         logits =self.logit))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # trainable variables into a group\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        cnn_vars = [var for var in tf_vars if var.name.startswith('cnn')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.cnn_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.loss_cross_entropy,\n",
    "                                                                                        var_list=cnn_vars)\n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        # output of cnn_model\n",
    "        self.out_logit_test, self.logit_test = self.cnn_model(self.x, self.x_canny, self.keep_prob, is_training=False, reuse=True)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logit_test, 1), tf.argmax(self.y, 1))\n",
    "        self.predict = tf.argmax(self.logit_test, 1)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        self.loss_sum = tf.summary.scalar(\"loss\", self.loss_cross_entropy)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep = self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name+'_train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            CNN_losses = []\n",
    "  \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.train_x.shape[0]), self.train_x.shape[0])\n",
    "            shuffled_set = self.train_x[shuffle_idxs]\n",
    "            shuffled_set_canny = self.train_x_canny[shuffle_idxs]\n",
    "            shuffled_label = self.train_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches_train):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_canny = shuffled_set_canny[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, cnn_loss = self.sess.run([self.cnn_optim, self.loss_sum, self.loss_cross_entropy],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.x_canny: batch_x_canny,\n",
    "                                                          self.y: batch_y,\n",
    "                                                          self.keep_prob: 0.5}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                CNN_losses.append(cnn_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" % (epoch_loop, idx, self.num_batches_train, \n",
    "                                                                          time.time() - start_time, cnn_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            # Evaluates accuracy on test set\n",
    "                    # Evaluates accuracy on test set\n",
    "            test_accuracy_list = []\n",
    "            for idx_test in range(self.num_batches_test):\n",
    "                batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_canny_test = self.test_x_canny[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                    self.x_canny: batch_x_canny_test,\n",
    "                                                                    self.y: batch_y_tes,\n",
    "                                                                    self.keep_prob: 1.0})\n",
    "                test_accuracy_list.append(accuracy)\n",
    "            test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        \n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss: %.8f acc: %.5f'% (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                    np.mean(CNN_losses), test_accuracy))\n",
    "            self.train_hist['losses'].append(np.mean(CNN_losses))\n",
    "            self.train_hist['accuracy'].append( test_accuracy)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "            \n",
    "            # save trainhist for train\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name + '_train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' \n",
    "                                 + self.model_name + '_train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "        \"\"\"test after train\"\"\"\n",
    "        best_acc = max(self.train_hist['accuracy'])\n",
    "        beat_epoch = self.train_hist['accuracy'].index(best_acc) + 1\n",
    "        print (\" [*] Best Epoch: \", beat_epoch, \", Accuracy: \", best_acc)\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(beat_epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "                # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_canny_test = self.test_x_canny[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_canny: batch_x_canny_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Best Epoch:\", beat_epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "\n",
    "    def test(self, epoch):\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_canny_test = self.test_x_canny[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_canny: batch_x_canny_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Epoch:\", epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True) \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['losses'])+1)\n",
    "\n",
    "        y1 = hist['losses']\n",
    "        y2 = hist['accuracy']\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "                            \n",
    "        ax2 = ax1.twinx()  \n",
    "\n",
    "        ax1.plot(x, y1, 'b')\n",
    "        ax2.plot(x, y2, 'r')\n",
    "                            \n",
    "        ax1.set_xlabel('Epoch')\n",
    "                            \n",
    "        ax1.set_ylabel('CNN_loss')    \n",
    "        ax2.set_ylabel('accuracy')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_canny (100, 128, 128, 1)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 64)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_canny (100, 128, 128, 1)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 64)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "cnn/conv_1_1/kernel:0 (float32_ref 3x3x3x32) [864, bytes: 3456]\n",
      "cnn/conv_1_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_2/kernel:0 (float32_ref 3x3x1x32) [288, bytes: 1152]\n",
      "cnn/conv_1_2/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_2/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_3/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_3/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_4/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_5/kernel:0 (float32_ref 3x3x64x128) [73728, bytes: 294912]\n",
      "cnn/conv_5/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_1/kernel:0 (float32_ref 2048x256) [524288, bytes: 2097152]\n",
      "cnn/dense_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "cnn/dense_output/kernel:0 (float32_ref 256x2) [512, bytes: 2048]\n",
      "cnn/dense_output/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 711682\n",
      "Total bytes of variables: 2846728\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 1] [   0/  20] time: 3.0422, loss: 0.71823227\n",
      "Epoch: [ 1] [   1/  20] time: 3.2863, loss: 0.61426532\n",
      "Epoch: [ 1] [   2/  20] time: 3.5313, loss: 0.78855836\n",
      "Epoch: [ 1] [   3/  20] time: 3.7802, loss: 0.09297362\n",
      "Epoch: [ 1] [   4/  20] time: 4.0320, loss: 0.17168278\n",
      "Epoch: [ 1] [   5/  20] time: 4.2935, loss: 0.07408733\n",
      "Epoch: [ 1] [   6/  20] time: 4.5374, loss: 0.07925440\n",
      "Epoch: [ 1] [   7/  20] time: 4.7852, loss: 0.03656322\n",
      "Epoch: [ 1] [   8/  20] time: 5.0327, loss: 0.05737457\n",
      "Epoch: [ 1] [   9/  20] time: 5.2957, loss: 0.06061869\n",
      "Epoch: [ 1] [  10/  20] time: 5.5384, loss: 0.01162877\n",
      "Epoch: [ 1] [  11/  20] time: 5.7843, loss: 0.02590505\n",
      "Epoch: [ 1] [  12/  20] time: 6.0342, loss: 0.04070725\n",
      "Epoch: [ 1] [  13/  20] time: 6.2809, loss: 0.08631304\n",
      "Epoch: [ 1] [  14/  20] time: 6.5231, loss: 0.05064804\n",
      "Epoch: [ 1] [  15/  20] time: 6.7695, loss: 0.07231186\n",
      "Epoch: [ 1] [  16/  20] time: 7.0216, loss: 0.07481426\n",
      "Epoch: [ 1] [  17/  20] time: 7.2630, loss: 0.01602238\n",
      "Epoch: [ 1] [  18/  20] time: 7.5077, loss: 0.05594134\n",
      "Epoch: [ 1] [  19/  20] time: 7.7529, loss: 0.04376722\n",
      "[1/80] - ptime: 7.8471 loss: 0.15858349 acc: 0.79000\n",
      "Epoch: [ 2] [   0/  20] time: 9.1169, loss: 0.03037190\n",
      "Epoch: [ 2] [   1/  20] time: 9.3615, loss: 0.02853358\n",
      "Epoch: [ 2] [   2/  20] time: 9.6125, loss: 0.04789044\n",
      "Epoch: [ 2] [   3/  20] time: 9.8632, loss: 0.01481046\n",
      "Epoch: [ 2] [   4/  20] time: 10.1159, loss: 0.02348188\n",
      "Epoch: [ 2] [   5/  20] time: 10.3692, loss: 0.11047620\n",
      "Epoch: [ 2] [   6/  20] time: 10.6160, loss: 0.01481948\n",
      "Epoch: [ 2] [   7/  20] time: 10.8633, loss: 0.05387943\n",
      "Epoch: [ 2] [   8/  20] time: 11.1137, loss: 0.06181031\n",
      "Epoch: [ 2] [   9/  20] time: 11.3765, loss: 0.06062915\n",
      "Epoch: [ 2] [  10/  20] time: 11.6212, loss: 0.02670097\n",
      "Epoch: [ 2] [  11/  20] time: 11.8709, loss: 0.01532174\n",
      "Epoch: [ 2] [  12/  20] time: 12.1238, loss: 0.07880450\n",
      "Epoch: [ 2] [  13/  20] time: 12.3766, loss: 0.03867265\n",
      "Epoch: [ 2] [  14/  20] time: 12.6206, loss: 0.02297645\n",
      "Epoch: [ 2] [  15/  20] time: 12.8624, loss: 0.03935742\n",
      "Epoch: [ 2] [  16/  20] time: 13.1158, loss: 0.03668460\n",
      "Epoch: [ 2] [  17/  20] time: 13.3683, loss: 0.02548563\n",
      "Epoch: [ 2] [  18/  20] time: 13.6130, loss: 0.02739271\n",
      "Epoch: [ 2] [  19/  20] time: 13.8608, loss: 0.03715058\n",
      "[2/80] - ptime: 5.4971 loss: 0.03976250 acc: 0.79000\n",
      "Epoch: [ 3] [   0/  20] time: 15.0422, loss: 0.03103452\n",
      "Epoch: [ 3] [   1/  20] time: 15.2953, loss: 0.03592916\n",
      "Epoch: [ 3] [   2/  20] time: 15.5407, loss: 0.03509831\n",
      "Epoch: [ 3] [   3/  20] time: 15.7864, loss: 0.00197527\n",
      "Epoch: [ 3] [   4/  20] time: 16.0333, loss: 0.02473694\n",
      "Epoch: [ 3] [   5/  20] time: 16.2996, loss: 0.02929403\n",
      "Epoch: [ 3] [   6/  20] time: 16.5427, loss: 0.06481002\n",
      "Epoch: [ 3] [   7/  20] time: 16.7902, loss: 0.02987470\n",
      "Epoch: [ 3] [   8/  20] time: 17.0400, loss: 0.06874865\n",
      "Epoch: [ 3] [   9/  20] time: 17.2968, loss: 0.00627151\n",
      "Epoch: [ 3] [  10/  20] time: 17.5607, loss: 0.02357438\n",
      "Epoch: [ 3] [  11/  20] time: 17.8061, loss: 0.05643464\n",
      "Epoch: [ 3] [  12/  20] time: 18.0545, loss: 0.02871065\n",
      "Epoch: [ 3] [  13/  20] time: 18.3180, loss: 0.01054072\n",
      "Epoch: [ 3] [  14/  20] time: 18.5677, loss: 0.04099635\n",
      "Epoch: [ 3] [  15/  20] time: 18.8232, loss: 0.01552553\n",
      "Epoch: [ 3] [  16/  20] time: 19.0722, loss: 0.01765601\n",
      "Epoch: [ 3] [  17/  20] time: 19.3312, loss: 0.06983958\n",
      "Epoch: [ 3] [  18/  20] time: 19.5889, loss: 0.01918982\n",
      "Epoch: [ 3] [  19/  20] time: 19.8360, loss: 0.02698100\n",
      "[3/80] - ptime: 5.4758 loss: 0.03186109 acc: 0.79000\n",
      "Epoch: [ 4] [   0/  20] time: 21.0439, loss: 0.01572634\n",
      "Epoch: [ 4] [   1/  20] time: 21.2962, loss: 0.03514621\n",
      "Epoch: [ 4] [   2/  20] time: 21.5493, loss: 0.10026740\n",
      "Epoch: [ 4] [   3/  20] time: 21.7990, loss: 0.01325259\n",
      "Epoch: [ 4] [   4/  20] time: 22.0425, loss: 0.04796818\n",
      "Epoch: [ 4] [   5/  20] time: 22.2994, loss: 0.01140680\n",
      "Epoch: [ 4] [   6/  20] time: 22.5513, loss: 0.02223439\n",
      "Epoch: [ 4] [   7/  20] time: 22.7976, loss: 0.03996939\n",
      "Epoch: [ 4] [   8/  20] time: 23.0406, loss: 0.03523871\n",
      "Epoch: [ 4] [   9/  20] time: 23.2902, loss: 0.02852141\n",
      "Epoch: [ 4] [  10/  20] time: 23.5451, loss: 0.03518116\n",
      "Epoch: [ 4] [  11/  20] time: 23.7896, loss: 0.26428643\n",
      "Epoch: [ 4] [  12/  20] time: 24.0352, loss: 0.28580621\n",
      "Epoch: [ 4] [  13/  20] time: 24.2869, loss: 0.10941019\n",
      "Epoch: [ 4] [  14/  20] time: 24.5359, loss: 0.03217267\n",
      "Epoch: [ 4] [  15/  20] time: 24.7821, loss: 0.02497602\n",
      "Epoch: [ 4] [  16/  20] time: 25.0252, loss: 0.02417421\n",
      "Epoch: [ 4] [  17/  20] time: 25.2764, loss: 0.01428586\n",
      "Epoch: [ 4] [  18/  20] time: 25.5264, loss: 0.00904300\n",
      "Epoch: [ 4] [  19/  20] time: 25.7706, loss: 0.02027012\n",
      "[4/80] - ptime: 5.3615 loss: 0.05846686 acc: 0.79000\n",
      "Epoch: [ 5] [   0/  20] time: 26.9908, loss: 0.03226875\n",
      "Epoch: [ 5] [   1/  20] time: 27.2389, loss: 0.01720426\n",
      "Epoch: [ 5] [   2/  20] time: 27.4834, loss: 0.03291949\n",
      "Epoch: [ 5] [   3/  20] time: 27.7277, loss: 0.10127092\n",
      "Epoch: [ 5] [   4/  20] time: 27.9732, loss: 0.02112415\n",
      "Epoch: [ 5] [   5/  20] time: 28.2209, loss: 0.17619315\n",
      "Epoch: [ 5] [   6/  20] time: 28.4792, loss: 0.02522491\n",
      "Epoch: [ 5] [   7/  20] time: 28.7237, loss: 0.03360779\n",
      "Epoch: [ 5] [   8/  20] time: 28.9677, loss: 0.02190619\n",
      "Epoch: [ 5] [   9/  20] time: 29.2147, loss: 0.02270929\n",
      "Epoch: [ 5] [  10/  20] time: 29.4755, loss: 0.10284539\n",
      "Epoch: [ 5] [  11/  20] time: 29.7205, loss: 0.00691105\n",
      "Epoch: [ 5] [  12/  20] time: 29.9660, loss: 0.02505738\n",
      "Epoch: [ 5] [  13/  20] time: 30.2131, loss: 0.01429682\n",
      "Epoch: [ 5] [  14/  20] time: 30.4728, loss: 0.01312251\n",
      "Epoch: [ 5] [  15/  20] time: 30.7253, loss: 0.01163874\n",
      "Epoch: [ 5] [  16/  20] time: 30.9704, loss: 0.03362496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 5] [  17/  20] time: 31.2190, loss: 0.01636663\n",
      "Epoch: [ 5] [  18/  20] time: 31.4762, loss: 0.03469323\n",
      "Epoch: [ 5] [  19/  20] time: 31.7186, loss: 0.04057778\n",
      "[5/80] - ptime: 5.3529 loss: 0.03917817 acc: 0.79000\n",
      "Epoch: [ 6] [   0/  20] time: 33.1316, loss: 0.00800829\n",
      "Epoch: [ 6] [   1/  20] time: 33.3801, loss: 0.01926140\n",
      "Epoch: [ 6] [   2/  20] time: 33.6309, loss: 0.04586631\n",
      "Epoch: [ 6] [   3/  20] time: 33.8779, loss: 0.04716146\n",
      "Epoch: [ 6] [   4/  20] time: 34.1215, loss: 0.01610855\n",
      "Epoch: [ 6] [   5/  20] time: 34.3693, loss: 0.01079348\n",
      "Epoch: [ 6] [   6/  20] time: 34.6199, loss: 0.02488069\n",
      "Epoch: [ 6] [   7/  20] time: 34.8680, loss: 0.01360999\n",
      "Epoch: [ 6] [   8/  20] time: 35.1126, loss: 0.03039996\n",
      "Epoch: [ 6] [   9/  20] time: 35.3636, loss: 0.18675193\n",
      "Epoch: [ 6] [  10/  20] time: 35.6169, loss: 0.07736140\n",
      "Epoch: [ 6] [  11/  20] time: 35.8628, loss: 0.02892289\n",
      "Epoch: [ 6] [  12/  20] time: 36.1042, loss: 0.02623400\n",
      "Epoch: [ 6] [  13/  20] time: 36.3586, loss: 0.05489842\n",
      "Epoch: [ 6] [  14/  20] time: 36.6124, loss: 0.02487027\n",
      "Epoch: [ 6] [  15/  20] time: 36.8584, loss: 0.01325024\n",
      "Epoch: [ 6] [  16/  20] time: 37.1027, loss: 0.01689736\n",
      "Epoch: [ 6] [  17/  20] time: 37.3472, loss: 0.01110880\n",
      "Epoch: [ 6] [  18/  20] time: 37.5984, loss: 0.02207709\n",
      "Epoch: [ 6] [  19/  20] time: 37.8463, loss: 0.02092160\n",
      "[6/80] - ptime: 5.3402 loss: 0.03496921 acc: 0.79000\n",
      "Epoch: [ 7] [   0/  20] time: 39.0535, loss: 0.03215648\n",
      "Epoch: [ 7] [   1/  20] time: 39.3020, loss: 0.01064750\n",
      "Epoch: [ 7] [   2/  20] time: 39.5629, loss: 0.02423274\n",
      "Epoch: [ 7] [   3/  20] time: 39.8263, loss: 0.01513498\n",
      "Epoch: [ 7] [   4/  20] time: 40.0819, loss: 0.02410197\n",
      "Epoch: [ 7] [   5/  20] time: 40.3331, loss: 0.03316262\n",
      "Epoch: [ 7] [   6/  20] time: 40.5851, loss: 0.00789199\n",
      "Epoch: [ 7] [   7/  20] time: 40.8469, loss: 0.00481412\n",
      "Epoch: [ 7] [   8/  20] time: 41.0928, loss: 0.01405320\n",
      "Epoch: [ 7] [   9/  20] time: 41.3454, loss: 0.00472165\n",
      "Epoch: [ 7] [  10/  20] time: 41.6009, loss: 0.01214564\n",
      "Epoch: [ 7] [  11/  20] time: 41.8559, loss: 0.02866360\n",
      "Epoch: [ 7] [  12/  20] time: 42.1009, loss: 0.00904905\n",
      "Epoch: [ 7] [  13/  20] time: 42.3539, loss: 0.04525056\n",
      "Epoch: [ 7] [  14/  20] time: 42.6096, loss: 0.05724250\n",
      "Epoch: [ 7] [  15/  20] time: 42.8726, loss: 0.01371623\n",
      "Epoch: [ 7] [  16/  20] time: 43.1173, loss: 0.01120343\n",
      "Epoch: [ 7] [  17/  20] time: 43.3678, loss: 0.07920881\n",
      "Epoch: [ 7] [  18/  20] time: 43.6274, loss: 0.02014496\n",
      "Epoch: [ 7] [  19/  20] time: 43.8927, loss: 0.05974182\n",
      "[7/80] - ptime: 5.4655 loss: 0.02536420 acc: 0.77000\n",
      "Epoch: [ 8] [   0/  20] time: 45.1152, loss: 0.06583376\n",
      "Epoch: [ 8] [   1/  20] time: 45.3621, loss: 0.02997791\n",
      "Epoch: [ 8] [   2/  20] time: 45.6179, loss: 0.05931549\n",
      "Epoch: [ 8] [   3/  20] time: 45.8727, loss: 0.02684111\n",
      "Epoch: [ 8] [   4/  20] time: 46.1185, loss: 0.03130380\n",
      "Epoch: [ 8] [   5/  20] time: 46.3709, loss: 0.04610269\n",
      "Epoch: [ 8] [   6/  20] time: 46.6250, loss: 0.01555215\n",
      "Epoch: [ 8] [   7/  20] time: 46.8813, loss: 0.01790507\n",
      "Epoch: [ 8] [   8/  20] time: 47.1268, loss: 0.01505355\n",
      "Epoch: [ 8] [   9/  20] time: 47.3768, loss: 0.03673797\n",
      "Epoch: [ 8] [  10/  20] time: 47.6308, loss: 0.02177829\n",
      "Epoch: [ 8] [  11/  20] time: 47.8870, loss: 0.01776615\n",
      "Epoch: [ 8] [  12/  20] time: 48.1334, loss: 0.01330765\n",
      "Epoch: [ 8] [  13/  20] time: 48.3818, loss: 0.02483432\n",
      "Epoch: [ 8] [  14/  20] time: 48.6346, loss: 0.02171496\n",
      "Epoch: [ 8] [  15/  20] time: 48.8931, loss: 0.00534211\n",
      "Epoch: [ 8] [  16/  20] time: 49.1378, loss: 0.00898057\n",
      "Epoch: [ 8] [  17/  20] time: 49.3846, loss: 0.01404004\n",
      "Epoch: [ 8] [  18/  20] time: 49.6396, loss: 0.05000539\n",
      "Epoch: [ 8] [  19/  20] time: 49.9007, loss: 0.00563329\n",
      "[8/80] - ptime: 5.4151 loss: 0.02640131 acc: 0.77000\n",
      "Epoch: [ 9] [   0/  20] time: 51.1130, loss: 0.03261445\n",
      "Epoch: [ 9] [   1/  20] time: 51.3586, loss: 0.01451055\n",
      "Epoch: [ 9] [   2/  20] time: 51.6066, loss: 0.01796596\n",
      "Epoch: [ 9] [   3/  20] time: 51.8689, loss: 0.01618499\n",
      "Epoch: [ 9] [   4/  20] time: 52.1123, loss: 0.00989843\n",
      "Epoch: [ 9] [   5/  20] time: 52.3570, loss: 0.00288989\n",
      "Epoch: [ 9] [   6/  20] time: 52.6071, loss: 0.01893056\n",
      "Epoch: [ 9] [   7/  20] time: 52.8638, loss: 0.00504061\n",
      "Epoch: [ 9] [   8/  20] time: 53.1075, loss: 0.01521689\n",
      "Epoch: [ 9] [   9/  20] time: 53.3551, loss: 0.02106629\n",
      "Epoch: [ 9] [  10/  20] time: 53.6050, loss: 0.02433339\n",
      "Epoch: [ 9] [  11/  20] time: 53.8700, loss: 0.00797397\n",
      "Epoch: [ 9] [  12/  20] time: 54.1168, loss: 0.06031749\n",
      "Epoch: [ 9] [  13/  20] time: 54.3625, loss: 0.02860201\n",
      "Epoch: [ 9] [  14/  20] time: 54.6103, loss: 0.01137398\n",
      "Epoch: [ 9] [  15/  20] time: 54.8613, loss: 0.01061251\n",
      "Epoch: [ 9] [  16/  20] time: 55.1060, loss: 0.02341969\n",
      "Epoch: [ 9] [  17/  20] time: 55.3511, loss: 0.00581420\n",
      "Epoch: [ 9] [  18/  20] time: 55.6003, loss: 0.06399182\n",
      "Epoch: [ 9] [  19/  20] time: 55.8577, loss: 0.01305279\n",
      "[9/80] - ptime: 5.3772 loss: 0.02019052 acc: 0.80000\n",
      "Epoch: [10] [   0/  20] time: 57.0541, loss: 0.00544085\n",
      "Epoch: [10] [   1/  20] time: 57.2984, loss: 0.01702450\n",
      "Epoch: [10] [   2/  20] time: 57.5455, loss: 0.01027941\n",
      "Epoch: [10] [   3/  20] time: 57.8014, loss: 0.03652225\n",
      "Epoch: [10] [   4/  20] time: 58.0471, loss: 0.01373003\n",
      "Epoch: [10] [   5/  20] time: 58.2935, loss: 0.01206793\n",
      "Epoch: [10] [   6/  20] time: 58.5405, loss: 0.01084598\n",
      "Epoch: [10] [   7/  20] time: 58.7980, loss: 0.03498835\n",
      "Epoch: [10] [   8/  20] time: 59.0411, loss: 0.02399271\n",
      "Epoch: [10] [   9/  20] time: 59.2862, loss: 0.02339914\n",
      "Epoch: [10] [  10/  20] time: 59.5344, loss: 0.00243139\n",
      "Epoch: [10] [  11/  20] time: 59.7944, loss: 0.00431240\n",
      "Epoch: [10] [  12/  20] time: 60.0393, loss: 0.00383199\n",
      "Epoch: [10] [  13/  20] time: 60.2865, loss: 0.00145996\n",
      "Epoch: [10] [  14/  20] time: 60.5370, loss: 0.13416544\n",
      "Epoch: [10] [  15/  20] time: 60.7934, loss: 0.16759963\n",
      "Epoch: [10] [  16/  20] time: 61.0411, loss: 0.02703526\n",
      "Epoch: [10] [  17/  20] time: 61.2883, loss: 0.05180474\n",
      "Epoch: [10] [  18/  20] time: 61.5346, loss: 0.03205493\n",
      "Epoch: [10] [  19/  20] time: 61.7963, loss: 0.02005347\n",
      "[10/80] - ptime: 5.3930 loss: 0.03165202 acc: 0.78000\n",
      "Epoch: [11] [   0/  20] time: 63.0570, loss: 0.02687400\n",
      "Epoch: [11] [   1/  20] time: 63.3004, loss: 0.00964513\n",
      "Epoch: [11] [   2/  20] time: 63.5480, loss: 0.00592885\n",
      "Epoch: [11] [   3/  20] time: 63.8106, loss: 0.05503928\n",
      "Epoch: [11] [   4/  20] time: 64.0527, loss: 0.10877112\n",
      "Epoch: [11] [   5/  20] time: 64.2983, loss: 0.03402452\n",
      "Epoch: [11] [   6/  20] time: 64.5463, loss: 0.01460153\n",
      "Epoch: [11] [   7/  20] time: 64.7943, loss: 0.01779345\n",
      "Epoch: [11] [   8/  20] time: 65.0378, loss: 0.01146448\n",
      "Epoch: [11] [   9/  20] time: 65.2837, loss: 0.06013861\n",
      "Epoch: [11] [  10/  20] time: 65.5349, loss: 0.01625547\n",
      "Epoch: [11] [  11/  20] time: 65.7856, loss: 0.03292111\n",
      "Epoch: [11] [  12/  20] time: 66.0302, loss: 0.02036439\n",
      "Epoch: [11] [  13/  20] time: 66.2753, loss: 0.06380450\n",
      "Epoch: [11] [  14/  20] time: 66.5252, loss: 0.01509973\n",
      "Epoch: [11] [  15/  20] time: 66.7809, loss: 0.02112931\n",
      "Epoch: [11] [  16/  20] time: 67.0276, loss: 0.02020704\n",
      "Epoch: [11] [  17/  20] time: 67.2750, loss: 0.00953866\n",
      "Epoch: [11] [  18/  20] time: 67.5224, loss: 0.01020235\n",
      "Epoch: [11] [  19/  20] time: 67.7784, loss: 0.01720211\n",
      "[11/80] - ptime: 5.3969 loss: 0.02855028 acc: 0.79000\n",
      "Epoch: [12] [   0/  20] time: 69.0484, loss: 0.04064861\n",
      "Epoch: [12] [   1/  20] time: 69.2929, loss: 0.01177141\n",
      "Epoch: [12] [   2/  20] time: 69.5405, loss: 0.01850606\n",
      "Epoch: [12] [   3/  20] time: 69.8002, loss: 0.00587153\n",
      "Epoch: [12] [   4/  20] time: 70.0466, loss: 0.01001289\n",
      "Epoch: [12] [   5/  20] time: 70.2936, loss: 0.02575307\n",
      "Epoch: [12] [   6/  20] time: 70.5410, loss: 0.04222702\n",
      "Epoch: [12] [   7/  20] time: 70.8036, loss: 0.03611148\n",
      "Epoch: [12] [   8/  20] time: 71.0488, loss: 0.01468455\n",
      "Epoch: [12] [   9/  20] time: 71.2972, loss: 0.01469651\n",
      "Epoch: [12] [  10/  20] time: 71.5480, loss: 0.01201827\n",
      "Epoch: [12] [  11/  20] time: 71.8107, loss: 0.00624327\n",
      "Epoch: [12] [  12/  20] time: 72.0575, loss: 0.01712073\n",
      "Epoch: [12] [  13/  20] time: 72.3029, loss: 0.01187103\n",
      "Epoch: [12] [  14/  20] time: 72.5494, loss: 0.01425474\n",
      "Epoch: [12] [  15/  20] time: 72.8078, loss: 0.00177992\n",
      "Epoch: [12] [  16/  20] time: 73.0529, loss: 0.00330815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12] [  17/  20] time: 73.2993, loss: 0.01751679\n",
      "Epoch: [12] [  18/  20] time: 73.5474, loss: 0.01105223\n",
      "Epoch: [12] [  19/  20] time: 73.8081, loss: 0.01405674\n",
      "[12/80] - ptime: 5.4578 loss: 0.01647525 acc: 0.66000\n",
      "Epoch: [13] [   0/  20] time: 75.0136, loss: 0.00556115\n",
      "Epoch: [13] [   1/  20] time: 75.2570, loss: 0.01049671\n",
      "Epoch: [13] [   2/  20] time: 75.5049, loss: 0.02753647\n",
      "Epoch: [13] [   3/  20] time: 75.7622, loss: 0.01194715\n",
      "Epoch: [13] [   4/  20] time: 76.0250, loss: 0.00166341\n",
      "Epoch: [13] [   5/  20] time: 76.2711, loss: 0.01247774\n",
      "Epoch: [13] [   6/  20] time: 76.5185, loss: 0.01837321\n",
      "Epoch: [13] [   7/  20] time: 76.7765, loss: 0.00486453\n",
      "Epoch: [13] [   8/  20] time: 77.0299, loss: 0.04732073\n",
      "Epoch: [13] [   9/  20] time: 77.2798, loss: 0.00599907\n",
      "Epoch: [13] [  10/  20] time: 77.5304, loss: 0.00404183\n",
      "Epoch: [13] [  11/  20] time: 77.7886, loss: 0.00829322\n",
      "Epoch: [13] [  12/  20] time: 78.0522, loss: 0.01808547\n",
      "Epoch: [13] [  13/  20] time: 78.2981, loss: 0.00530912\n",
      "Epoch: [13] [  14/  20] time: 78.5469, loss: 0.01407044\n",
      "Epoch: [13] [  15/  20] time: 78.8035, loss: 0.01704107\n",
      "Epoch: [13] [  16/  20] time: 79.0613, loss: 0.01747214\n",
      "Epoch: [13] [  17/  20] time: 79.3070, loss: 0.00926616\n",
      "Epoch: [13] [  18/  20] time: 79.5558, loss: 0.00769843\n",
      "Epoch: [13] [  19/  20] time: 79.8146, loss: 0.01961681\n",
      "[13/80] - ptime: 5.5069 loss: 0.01335674 acc: 0.64000\n",
      "Epoch: [14] [   0/  20] time: 81.0295, loss: 0.00710556\n",
      "Epoch: [14] [   1/  20] time: 81.2727, loss: 0.00164798\n",
      "Epoch: [14] [   2/  20] time: 81.5196, loss: 0.01681541\n",
      "Epoch: [14] [   3/  20] time: 81.7750, loss: 0.00049104\n",
      "Epoch: [14] [   4/  20] time: 82.0391, loss: 0.00541481\n",
      "Epoch: [14] [   5/  20] time: 82.2878, loss: 0.00214580\n",
      "Epoch: [14] [   6/  20] time: 82.5366, loss: 0.01442329\n",
      "Epoch: [14] [   7/  20] time: 82.7880, loss: 0.00168109\n",
      "Epoch: [14] [   8/  20] time: 83.0499, loss: 0.01552941\n",
      "Epoch: [14] [   9/  20] time: 83.2902, loss: 0.00914138\n",
      "Epoch: [14] [  10/  20] time: 83.5385, loss: 0.02380055\n",
      "Epoch: [14] [  11/  20] time: 83.7874, loss: 0.01185344\n",
      "Epoch: [14] [  12/  20] time: 84.0441, loss: 0.01203292\n",
      "Epoch: [14] [  13/  20] time: 84.2926, loss: 0.00877552\n",
      "Epoch: [14] [  14/  20] time: 84.5417, loss: 0.01391153\n",
      "Epoch: [14] [  15/  20] time: 84.7951, loss: 0.01505424\n",
      "Epoch: [14] [  16/  20] time: 85.0536, loss: 0.01241975\n",
      "Epoch: [14] [  17/  20] time: 85.3000, loss: 0.01833096\n",
      "Epoch: [14] [  18/  20] time: 85.5464, loss: 0.00420527\n",
      "Epoch: [14] [  19/  20] time: 85.7981, loss: 0.00109879\n",
      "[14/80] - ptime: 5.4883 loss: 0.00979394 acc: 0.64000\n",
      "Epoch: [15] [   0/  20] time: 87.0248, loss: 0.00404360\n",
      "Epoch: [15] [   1/  20] time: 87.2688, loss: 0.01790114\n",
      "Epoch: [15] [   2/  20] time: 87.5122, loss: 0.01050857\n",
      "Epoch: [15] [   3/  20] time: 87.7601, loss: 0.01742301\n",
      "Epoch: [15] [   4/  20] time: 88.0198, loss: 0.00634384\n",
      "Epoch: [15] [   5/  20] time: 88.2669, loss: 0.00032874\n",
      "Epoch: [15] [   6/  20] time: 88.5105, loss: 0.00187346\n",
      "Epoch: [15] [   7/  20] time: 88.7566, loss: 0.00275316\n",
      "Epoch: [15] [   8/  20] time: 89.0104, loss: 0.00254244\n",
      "Epoch: [15] [   9/  20] time: 89.2553, loss: 0.01016635\n",
      "Epoch: [15] [  10/  20] time: 89.4999, loss: 0.00790893\n",
      "Epoch: [15] [  11/  20] time: 89.7506, loss: 0.00454253\n",
      "Epoch: [15] [  12/  20] time: 90.0141, loss: 0.00913889\n",
      "Epoch: [15] [  13/  20] time: 90.2633, loss: 0.01054055\n",
      "Epoch: [15] [  14/  20] time: 90.5073, loss: 0.00173379\n",
      "Epoch: [15] [  15/  20] time: 90.7549, loss: 0.01468743\n",
      "Epoch: [15] [  16/  20] time: 91.0123, loss: 0.00651107\n",
      "Epoch: [15] [  17/  20] time: 91.2583, loss: 0.00001224\n",
      "Epoch: [15] [  18/  20] time: 91.5062, loss: 0.00634995\n",
      "Epoch: [15] [  19/  20] time: 91.7557, loss: 0.00006729\n",
      "[15/80] - ptime: 5.4850 loss: 0.00676885 acc: 0.63000\n",
      "Epoch: [16] [   0/  20] time: 92.9922, loss: 0.00988514\n",
      "Epoch: [16] [   1/  20] time: 93.2374, loss: 0.00253195\n",
      "Epoch: [16] [   2/  20] time: 93.4827, loss: 0.03591206\n",
      "Epoch: [16] [   3/  20] time: 93.7353, loss: 0.00598856\n",
      "Epoch: [16] [   4/  20] time: 93.9951, loss: 0.00963271\n",
      "Epoch: [16] [   5/  20] time: 94.2567, loss: 0.03088917\n",
      "Epoch: [16] [   6/  20] time: 94.5003, loss: 0.00968562\n",
      "Epoch: [16] [   7/  20] time: 94.7495, loss: 0.00677895\n",
      "Epoch: [16] [   8/  20] time: 95.0102, loss: 0.01249561\n",
      "Epoch: [16] [   9/  20] time: 95.2596, loss: 0.00755310\n",
      "Epoch: [16] [  10/  20] time: 95.5053, loss: 0.01390907\n",
      "Epoch: [16] [  11/  20] time: 95.7540, loss: 0.00527206\n",
      "Epoch: [16] [  12/  20] time: 96.0115, loss: 0.00399185\n",
      "Epoch: [16] [  13/  20] time: 96.2705, loss: 0.00018088\n",
      "Epoch: [16] [  14/  20] time: 96.5159, loss: 0.01154208\n",
      "Epoch: [16] [  15/  20] time: 96.7643, loss: 0.01445590\n",
      "Epoch: [16] [  16/  20] time: 97.0238, loss: 0.00129459\n",
      "Epoch: [16] [  17/  20] time: 97.2753, loss: 0.00467967\n",
      "Epoch: [16] [  18/  20] time: 97.5157, loss: 0.00260226\n",
      "Epoch: [16] [  19/  20] time: 97.7657, loss: 0.00650307\n",
      "[16/80] - ptime: 5.5457 loss: 0.00978922 acc: 0.62000\n",
      "Epoch: [17] [   0/  20] time: 98.9646, loss: 0.00020338\n",
      "Epoch: [17] [   1/  20] time: 99.2084, loss: 0.00456077\n",
      "Epoch: [17] [   2/  20] time: 99.4545, loss: 0.00112002\n",
      "Epoch: [17] [   3/  20] time: 99.6979, loss: 0.00525702\n",
      "Epoch: [17] [   4/  20] time: 99.9477, loss: 0.00690114\n",
      "Epoch: [17] [   5/  20] time: 100.1919, loss: 0.00019857\n",
      "Epoch: [17] [   6/  20] time: 100.4383, loss: 0.00442491\n",
      "Epoch: [17] [   7/  20] time: 100.6818, loss: 0.01036556\n",
      "Epoch: [17] [   8/  20] time: 100.9323, loss: 0.01323844\n",
      "Epoch: [17] [   9/  20] time: 101.1917, loss: 0.02233493\n",
      "Epoch: [17] [  10/  20] time: 101.4399, loss: 0.00119037\n",
      "Epoch: [17] [  11/  20] time: 101.6869, loss: 0.00878028\n",
      "Epoch: [17] [  12/  20] time: 101.9396, loss: 0.00039782\n",
      "Epoch: [17] [  13/  20] time: 102.2008, loss: 0.00010749\n",
      "Epoch: [17] [  14/  20] time: 102.4476, loss: 0.00347137\n",
      "Epoch: [17] [  15/  20] time: 102.6983, loss: 0.00881987\n",
      "Epoch: [17] [  16/  20] time: 102.9450, loss: 0.00182802\n",
      "Epoch: [17] [  17/  20] time: 103.2038, loss: 0.00490915\n",
      "Epoch: [17] [  18/  20] time: 103.4510, loss: 0.00215257\n",
      "Epoch: [17] [  19/  20] time: 103.6975, loss: 0.00061342\n",
      "[17/80] - ptime: 5.4443 loss: 0.00504376 acc: 0.60000\n",
      "Epoch: [18] [   0/  20] time: 104.9267, loss: 0.00216266\n",
      "Epoch: [18] [   1/  20] time: 105.1806, loss: 0.00162192\n",
      "Epoch: [18] [   2/  20] time: 105.4257, loss: 0.00757560\n",
      "Epoch: [18] [   3/  20] time: 105.6736, loss: 0.00022255\n",
      "Epoch: [18] [   4/  20] time: 105.9372, loss: 0.00015873\n",
      "Epoch: [18] [   5/  20] time: 106.1785, loss: 0.00328164\n",
      "Epoch: [18] [   6/  20] time: 106.4256, loss: 0.00469340\n",
      "Epoch: [18] [   7/  20] time: 106.6699, loss: 0.00063103\n",
      "Epoch: [18] [   8/  20] time: 106.9181, loss: 0.00008033\n",
      "Epoch: [18] [   9/  20] time: 107.1703, loss: 0.00192810\n",
      "Epoch: [18] [  10/  20] time: 107.4181, loss: 0.00137209\n",
      "Epoch: [18] [  11/  20] time: 107.6658, loss: 0.00025547\n",
      "Epoch: [18] [  12/  20] time: 107.9159, loss: 0.00046028\n",
      "Epoch: [18] [  13/  20] time: 108.1729, loss: 0.00043304\n",
      "Epoch: [18] [  14/  20] time: 108.4205, loss: 0.02144940\n",
      "Epoch: [18] [  15/  20] time: 108.6649, loss: 0.00001520\n",
      "Epoch: [18] [  16/  20] time: 108.9202, loss: 0.03751685\n",
      "Epoch: [18] [  17/  20] time: 109.1768, loss: 0.03168633\n",
      "Epoch: [18] [  18/  20] time: 109.4227, loss: 0.01885154\n",
      "Epoch: [18] [  19/  20] time: 109.6677, loss: 0.00862127\n",
      "[18/80] - ptime: 5.4292 loss: 0.00715087 acc: 0.62000\n",
      "Epoch: [19] [   0/  20] time: 111.1950, loss: 0.00486992\n",
      "Epoch: [19] [   1/  20] time: 111.4384, loss: 0.02706004\n",
      "Epoch: [19] [   2/  20] time: 111.6826, loss: 0.03779851\n",
      "Epoch: [19] [   3/  20] time: 111.9359, loss: 0.00290653\n",
      "Epoch: [19] [   4/  20] time: 112.1935, loss: 0.00523740\n",
      "Epoch: [19] [   5/  20] time: 112.4587, loss: 0.02004893\n",
      "Epoch: [19] [   6/  20] time: 112.7021, loss: 0.00029852\n",
      "Epoch: [19] [   7/  20] time: 112.9497, loss: 0.00855936\n",
      "Epoch: [19] [   8/  20] time: 113.2085, loss: 0.00211220\n",
      "Epoch: [19] [   9/  20] time: 113.4709, loss: 0.00354793\n",
      "Epoch: [19] [  10/  20] time: 113.7156, loss: 0.00352896\n",
      "Epoch: [19] [  11/  20] time: 113.9647, loss: 0.00293553\n",
      "Epoch: [19] [  12/  20] time: 114.2216, loss: 0.00724208\n",
      "Epoch: [19] [  13/  20] time: 114.4882, loss: 0.00406250\n",
      "Epoch: [19] [  14/  20] time: 114.7332, loss: 0.00801300\n",
      "Epoch: [19] [  15/  20] time: 114.9821, loss: 0.00195411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19] [  16/  20] time: 115.2434, loss: 0.00090155\n",
      "Epoch: [19] [  17/  20] time: 115.4944, loss: 0.01603347\n",
      "Epoch: [19] [  18/  20] time: 115.7401, loss: 0.02258901\n",
      "Epoch: [19] [  19/  20] time: 115.9928, loss: 0.00924097\n",
      "[19/80] - ptime: 5.5552 loss: 0.00944703 acc: 0.59000\n",
      "Epoch: [20] [   0/  20] time: 117.2867, loss: 0.01513486\n",
      "Epoch: [20] [   1/  20] time: 117.5322, loss: 0.00366119\n",
      "Epoch: [20] [   2/  20] time: 117.7788, loss: 0.00370290\n",
      "Epoch: [20] [   3/  20] time: 118.0314, loss: 0.00026200\n",
      "Epoch: [20] [   4/  20] time: 118.2929, loss: 0.00155962\n",
      "Epoch: [20] [   5/  20] time: 118.5367, loss: 0.00248996\n",
      "Epoch: [20] [   6/  20] time: 118.7821, loss: 0.00490251\n",
      "Epoch: [20] [   7/  20] time: 119.0365, loss: 0.00164497\n",
      "Epoch: [20] [   8/  20] time: 119.2965, loss: 0.00040871\n",
      "Epoch: [20] [   9/  20] time: 119.5625, loss: 0.01051712\n",
      "Epoch: [20] [  10/  20] time: 119.8075, loss: 0.00001184\n",
      "Epoch: [20] [  11/  20] time: 120.0569, loss: 0.00076759\n",
      "Epoch: [20] [  12/  20] time: 120.3185, loss: 0.00503146\n",
      "Epoch: [20] [  13/  20] time: 120.5653, loss: 0.00808298\n",
      "Epoch: [20] [  14/  20] time: 120.8107, loss: 0.00355982\n",
      "Epoch: [20] [  15/  20] time: 121.0617, loss: 0.00053952\n",
      "Epoch: [20] [  16/  20] time: 121.3221, loss: 0.00000670\n",
      "Epoch: [20] [  17/  20] time: 121.5815, loss: 0.01430634\n",
      "Epoch: [20] [  18/  20] time: 121.8308, loss: 0.00907136\n",
      "Epoch: [20] [  19/  20] time: 122.0842, loss: 0.00107508\n",
      "[20/80] - ptime: 5.5584 loss: 0.00433683 acc: 0.64000\n",
      "Epoch: [21] [   0/  20] time: 123.2766, loss: 0.00042300\n",
      "Epoch: [21] [   1/  20] time: 123.5201, loss: 0.00134005\n",
      "Epoch: [21] [   2/  20] time: 123.7657, loss: 0.01064254\n",
      "Epoch: [21] [   3/  20] time: 124.0137, loss: 0.00137448\n",
      "Epoch: [21] [   4/  20] time: 124.2661, loss: 0.00001546\n",
      "Epoch: [21] [   5/  20] time: 124.5243, loss: 0.00089278\n",
      "Epoch: [21] [   6/  20] time: 124.7637, loss: 0.00089402\n",
      "Epoch: [21] [   7/  20] time: 125.0133, loss: 0.00004458\n",
      "Epoch: [21] [   8/  20] time: 125.2618, loss: 0.00789919\n",
      "Epoch: [21] [   9/  20] time: 125.5193, loss: 0.00059852\n",
      "Epoch: [21] [  10/  20] time: 125.7634, loss: 0.00693371\n",
      "Epoch: [21] [  11/  20] time: 126.0108, loss: 0.00618754\n",
      "Epoch: [21] [  12/  20] time: 126.2658, loss: 0.00272211\n",
      "Epoch: [21] [  13/  20] time: 126.5205, loss: 0.00174719\n",
      "Epoch: [21] [  14/  20] time: 126.7656, loss: 0.00090955\n",
      "Epoch: [21] [  15/  20] time: 127.0128, loss: 0.00849484\n",
      "Epoch: [21] [  16/  20] time: 127.2666, loss: 0.00193592\n",
      "Epoch: [21] [  17/  20] time: 127.5211, loss: 0.00013039\n",
      "Epoch: [21] [  18/  20] time: 127.7685, loss: 0.00094292\n",
      "Epoch: [21] [  19/  20] time: 128.0155, loss: 0.00189322\n",
      "[21/80] - ptime: 5.4548 loss: 0.00280110 acc: 0.65000\n",
      "Epoch: [22] [   0/  20] time: 129.1009, loss: 0.00132084\n",
      "Epoch: [22] [   1/  20] time: 129.3536, loss: 0.00043402\n",
      "Epoch: [22] [   2/  20] time: 129.6124, loss: 0.00420034\n",
      "Epoch: [22] [   3/  20] time: 129.8535, loss: 0.00082560\n",
      "Epoch: [22] [   4/  20] time: 130.1033, loss: 0.00335847\n",
      "Epoch: [22] [   5/  20] time: 130.3578, loss: 0.00048887\n",
      "Epoch: [22] [   6/  20] time: 130.6183, loss: 0.00056239\n",
      "Epoch: [22] [   7/  20] time: 130.8622, loss: 0.00047004\n",
      "Epoch: [22] [   8/  20] time: 131.1142, loss: 0.00124086\n",
      "Epoch: [22] [   9/  20] time: 131.3682, loss: 0.00024862\n",
      "Epoch: [22] [  10/  20] time: 131.6348, loss: 0.00095318\n",
      "Epoch: [22] [  11/  20] time: 131.8812, loss: 0.00117216\n",
      "Epoch: [22] [  12/  20] time: 132.1296, loss: 0.00024497\n",
      "Epoch: [22] [  13/  20] time: 132.3846, loss: 0.00003131\n",
      "Epoch: [22] [  14/  20] time: 132.6439, loss: 0.00094521\n",
      "Epoch: [22] [  15/  20] time: 132.8887, loss: 0.00011397\n",
      "Epoch: [22] [  16/  20] time: 133.1428, loss: 0.00346672\n",
      "Epoch: [22] [  17/  20] time: 133.3987, loss: 0.00000259\n",
      "Epoch: [22] [  18/  20] time: 133.6610, loss: 0.00471051\n",
      "Epoch: [22] [  19/  20] time: 133.9062, loss: 0.00034715\n",
      "[22/80] - ptime: 5.4341 loss: 0.00125689 acc: 0.63000\n",
      "Epoch: [23] [   0/  20] time: 135.0958, loss: 0.00006196\n",
      "Epoch: [23] [   1/  20] time: 135.3483, loss: 0.00031854\n",
      "Epoch: [23] [   2/  20] time: 135.6006, loss: 0.00006143\n",
      "Epoch: [23] [   3/  20] time: 135.8473, loss: 0.00012386\n",
      "Epoch: [23] [   4/  20] time: 136.0967, loss: 0.00014895\n",
      "Epoch: [23] [   5/  20] time: 136.3500, loss: 0.00332976\n",
      "Epoch: [23] [   6/  20] time: 136.6108, loss: 0.00102815\n",
      "Epoch: [23] [   7/  20] time: 136.8561, loss: 0.00071827\n",
      "Epoch: [23] [   8/  20] time: 137.1036, loss: 0.00451848\n",
      "Epoch: [23] [   9/  20] time: 137.3615, loss: 0.00191734\n",
      "Epoch: [23] [  10/  20] time: 137.6149, loss: 0.00020327\n",
      "Epoch: [23] [  11/  20] time: 137.8639, loss: 0.00110035\n",
      "Epoch: [23] [  12/  20] time: 138.1097, loss: 0.00022963\n",
      "Epoch: [23] [  13/  20] time: 138.3595, loss: 0.00013397\n",
      "Epoch: [23] [  14/  20] time: 138.6132, loss: 0.00004408\n",
      "Epoch: [23] [  15/  20] time: 138.8751, loss: 0.00002853\n",
      "Epoch: [23] [  16/  20] time: 139.1205, loss: 0.00031090\n",
      "Epoch: [23] [  17/  20] time: 139.3709, loss: 0.00024845\n",
      "Epoch: [23] [  18/  20] time: 139.6271, loss: 0.00060955\n",
      "Epoch: [23] [  19/  20] time: 139.8715, loss: 0.00030023\n",
      "[23/80] - ptime: 5.4011 loss: 0.00077178 acc: 0.62000\n",
      "Epoch: [24] [   0/  20] time: 141.0992, loss: 0.00009607\n",
      "Epoch: [24] [   1/  20] time: 141.3477, loss: 0.00022449\n",
      "Epoch: [24] [   2/  20] time: 141.6029, loss: 0.00005058\n",
      "Epoch: [24] [   3/  20] time: 141.8496, loss: 0.00000622\n",
      "Epoch: [24] [   4/  20] time: 142.0965, loss: 0.00054745\n",
      "Epoch: [24] [   5/  20] time: 142.3478, loss: 0.00029759\n",
      "Epoch: [24] [   6/  20] time: 142.6049, loss: 0.00000266\n",
      "Epoch: [24] [   7/  20] time: 142.8508, loss: 0.00012325\n",
      "Epoch: [24] [   8/  20] time: 143.0970, loss: 0.00000741\n",
      "Epoch: [24] [   9/  20] time: 143.3495, loss: 0.00289748\n",
      "Epoch: [24] [  10/  20] time: 143.6031, loss: 0.00127473\n",
      "Epoch: [24] [  11/  20] time: 143.8498, loss: 0.00000530\n",
      "Epoch: [24] [  12/  20] time: 144.0989, loss: 0.00027984\n",
      "Epoch: [24] [  13/  20] time: 144.3555, loss: 0.00000941\n",
      "Epoch: [24] [  14/  20] time: 144.6110, loss: 0.00008752\n",
      "Epoch: [24] [  15/  20] time: 144.8563, loss: 0.00087262\n",
      "Epoch: [24] [  16/  20] time: 145.1029, loss: 0.00012675\n",
      "Epoch: [24] [  17/  20] time: 145.3555, loss: 0.00047338\n",
      "Epoch: [24] [  18/  20] time: 145.6085, loss: 0.00002310\n",
      "Epoch: [24] [  19/  20] time: 145.8538, loss: 0.00000932\n",
      "[24/80] - ptime: 5.3835 loss: 0.00037076 acc: 0.62000\n",
      "Epoch: [25] [   0/  20] time: 147.1112, loss: 0.00112159\n",
      "Epoch: [25] [   1/  20] time: 147.3618, loss: 0.00004286\n",
      "Epoch: [25] [   2/  20] time: 147.6185, loss: 0.00000612\n",
      "Epoch: [25] [   3/  20] time: 147.8625, loss: 0.00019513\n",
      "Epoch: [25] [   4/  20] time: 148.1071, loss: 0.00003230\n",
      "Epoch: [25] [   5/  20] time: 148.3593, loss: 0.00041205\n",
      "Epoch: [25] [   6/  20] time: 148.6078, loss: 0.00016226\n",
      "Epoch: [25] [   7/  20] time: 148.8533, loss: 0.00005075\n",
      "Epoch: [25] [   8/  20] time: 149.1023, loss: 0.00019856\n",
      "Epoch: [25] [   9/  20] time: 149.3551, loss: 0.00006209\n",
      "Epoch: [25] [  10/  20] time: 149.6144, loss: 0.00029424\n",
      "Epoch: [25] [  11/  20] time: 149.8609, loss: 0.00003235\n",
      "Epoch: [25] [  12/  20] time: 150.1068, loss: 0.00000349\n",
      "Epoch: [25] [  13/  20] time: 150.3591, loss: 0.00018855\n",
      "Epoch: [25] [  14/  20] time: 150.6168, loss: 0.00000593\n",
      "Epoch: [25] [  15/  20] time: 150.8602, loss: 0.00006282\n",
      "Epoch: [25] [  16/  20] time: 151.1049, loss: 0.00003102\n",
      "Epoch: [25] [  17/  20] time: 151.3597, loss: 0.00004400\n",
      "Epoch: [25] [  18/  20] time: 151.6243, loss: 0.00005233\n",
      "Epoch: [25] [  19/  20] time: 151.8691, loss: 0.00000366\n",
      "[25/80] - ptime: 5.3808 loss: 0.00015010 acc: 0.60000\n",
      "Epoch: [26] [   0/  20] time: 153.0980, loss: 0.00001955\n",
      "Epoch: [26] [   1/  20] time: 153.3486, loss: 0.00034083\n",
      "Epoch: [26] [   2/  20] time: 153.6061, loss: 0.00039809\n",
      "Epoch: [26] [   3/  20] time: 153.8695, loss: 0.00015018\n",
      "Epoch: [26] [   4/  20] time: 154.1160, loss: 0.00009495\n",
      "Epoch: [26] [   5/  20] time: 154.3682, loss: 0.00008029\n",
      "Epoch: [26] [   6/  20] time: 154.6257, loss: 0.00001165\n",
      "Epoch: [26] [   7/  20] time: 154.8710, loss: 0.00012722\n",
      "Epoch: [26] [   8/  20] time: 155.1192, loss: 0.00003011\n",
      "Epoch: [26] [   9/  20] time: 155.3701, loss: 0.00031808\n",
      "Epoch: [26] [  10/  20] time: 155.6334, loss: 0.00010461\n",
      "Epoch: [26] [  11/  20] time: 155.8772, loss: 0.00001158\n",
      "Epoch: [26] [  12/  20] time: 156.1231, loss: 0.00054775\n",
      "Epoch: [26] [  13/  20] time: 156.3766, loss: 0.00000946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [26] [  14/  20] time: 156.6380, loss: 0.00012145\n",
      "Epoch: [26] [  15/  20] time: 156.8829, loss: 0.00000252\n",
      "Epoch: [26] [  16/  20] time: 157.1235, loss: 0.00001797\n",
      "Epoch: [26] [  17/  20] time: 157.3797, loss: 0.00000177\n",
      "Epoch: [26] [  18/  20] time: 157.6378, loss: 0.00007596\n",
      "Epoch: [26] [  19/  20] time: 157.8828, loss: 0.00005842\n",
      "[26/80] - ptime: 5.4107 loss: 0.00012612 acc: 0.60000\n",
      "Epoch: [27] [   0/  20] time: 159.0956, loss: 0.00007041\n",
      "Epoch: [27] [   1/  20] time: 159.3479, loss: 0.00005011\n",
      "Epoch: [27] [   2/  20] time: 159.6115, loss: 0.00010358\n",
      "Epoch: [27] [   3/  20] time: 159.8582, loss: 0.00000665\n",
      "Epoch: [27] [   4/  20] time: 160.1042, loss: 0.00009915\n",
      "Epoch: [27] [   5/  20] time: 160.3554, loss: 0.00000673\n",
      "Epoch: [27] [   6/  20] time: 160.6167, loss: 0.00006047\n",
      "Epoch: [27] [   7/  20] time: 160.8614, loss: 0.00054746\n",
      "Epoch: [27] [   8/  20] time: 161.1079, loss: 0.00003459\n",
      "Epoch: [27] [   9/  20] time: 161.3580, loss: 0.00000996\n",
      "Epoch: [27] [  10/  20] time: 161.6174, loss: 0.00000193\n",
      "Epoch: [27] [  11/  20] time: 161.8642, loss: 0.00016938\n",
      "Epoch: [27] [  12/  20] time: 162.1132, loss: 0.00001492\n",
      "Epoch: [27] [  13/  20] time: 162.3655, loss: 0.00004224\n",
      "Epoch: [27] [  14/  20] time: 162.6248, loss: 0.00003727\n",
      "Epoch: [27] [  15/  20] time: 162.8701, loss: 0.00008821\n",
      "Epoch: [27] [  16/  20] time: 163.1118, loss: 0.00003149\n",
      "Epoch: [27] [  17/  20] time: 163.3627, loss: 0.00001281\n",
      "Epoch: [27] [  18/  20] time: 163.6248, loss: 0.00000913\n",
      "Epoch: [27] [  19/  20] time: 163.8698, loss: 0.00004292\n",
      "[27/80] - ptime: 5.4028 loss: 0.00007197 acc: 0.59000\n",
      "Epoch: [28] [   0/  20] time: 165.1196, loss: 0.00008052\n",
      "Epoch: [28] [   1/  20] time: 165.3706, loss: 0.00000610\n",
      "Epoch: [28] [   2/  20] time: 165.6286, loss: 0.00007933\n",
      "Epoch: [28] [   3/  20] time: 165.8743, loss: 0.00002717\n",
      "Epoch: [28] [   4/  20] time: 166.1246, loss: 0.00072257\n",
      "Epoch: [28] [   5/  20] time: 166.3773, loss: 0.00005328\n",
      "Epoch: [28] [   6/  20] time: 166.6349, loss: 0.00011219\n",
      "Epoch: [28] [   7/  20] time: 166.8798, loss: 0.00001403\n",
      "Epoch: [28] [   8/  20] time: 167.1269, loss: 0.00014427\n",
      "Epoch: [28] [   9/  20] time: 167.3768, loss: 0.00006715\n",
      "Epoch: [28] [  10/  20] time: 167.6398, loss: 0.00000019\n",
      "Epoch: [28] [  11/  20] time: 167.8863, loss: 0.00002943\n",
      "Epoch: [28] [  12/  20] time: 168.1346, loss: 0.00002413\n",
      "Epoch: [28] [  13/  20] time: 168.3899, loss: 0.00048881\n",
      "Epoch: [28] [  14/  20] time: 168.6434, loss: 0.00002502\n",
      "Epoch: [28] [  15/  20] time: 168.8903, loss: 0.00006152\n",
      "Epoch: [28] [  16/  20] time: 169.1385, loss: 0.00001542\n",
      "Epoch: [28] [  17/  20] time: 169.3906, loss: 0.00015278\n",
      "Epoch: [28] [  18/  20] time: 169.6442, loss: 0.00001276\n",
      "Epoch: [28] [  19/  20] time: 169.8901, loss: 0.00020299\n",
      "[28/80] - ptime: 5.4002 loss: 0.00011598 acc: 0.59000\n",
      "Epoch: [29] [   0/  20] time: 171.2099, loss: 0.00001975\n",
      "Epoch: [29] [   1/  20] time: 171.4603, loss: 0.00004549\n",
      "Epoch: [29] [   2/  20] time: 171.7189, loss: 0.00005635\n",
      "Epoch: [29] [   3/  20] time: 171.9636, loss: 0.00009346\n",
      "Epoch: [29] [   4/  20] time: 172.2102, loss: 0.00002336\n",
      "Epoch: [29] [   5/  20] time: 172.4626, loss: 0.00007750\n",
      "Epoch: [29] [   6/  20] time: 172.7256, loss: 0.00010996\n",
      "Epoch: [29] [   7/  20] time: 172.9702, loss: 0.00013956\n",
      "Epoch: [29] [   8/  20] time: 173.2174, loss: 0.00001635\n",
      "Epoch: [29] [   9/  20] time: 173.4678, loss: 0.00008191\n",
      "Epoch: [29] [  10/  20] time: 173.7234, loss: 0.00005836\n",
      "Epoch: [29] [  11/  20] time: 173.9682, loss: 0.00140183\n",
      "Epoch: [29] [  12/  20] time: 174.2151, loss: 0.00005038\n",
      "Epoch: [29] [  13/  20] time: 174.4678, loss: 0.00006990\n",
      "Epoch: [29] [  14/  20] time: 174.7230, loss: 0.00000759\n",
      "Epoch: [29] [  15/  20] time: 174.9687, loss: 0.00171099\n",
      "Epoch: [29] [  16/  20] time: 175.2167, loss: 0.00019336\n",
      "Epoch: [29] [  17/  20] time: 175.4691, loss: 0.00002042\n",
      "Epoch: [29] [  18/  20] time: 175.7229, loss: 0.00001503\n",
      "Epoch: [29] [  19/  20] time: 175.9710, loss: 0.00002824\n",
      "[29/80] - ptime: 5.3903 loss: 0.00021099 acc: 0.59000\n",
      "Epoch: [30] [   0/  20] time: 177.2929, loss: 0.00001806\n",
      "Epoch: [30] [   1/  20] time: 177.5415, loss: 0.00003312\n",
      "Epoch: [30] [   2/  20] time: 177.8031, loss: 0.00006850\n",
      "Epoch: [30] [   3/  20] time: 178.0500, loss: 0.00014091\n",
      "Epoch: [30] [   4/  20] time: 178.3000, loss: 0.00005979\n",
      "Epoch: [30] [   5/  20] time: 178.5510, loss: 0.00002817\n",
      "Epoch: [30] [   6/  20] time: 178.8098, loss: 0.00000912\n",
      "Epoch: [30] [   7/  20] time: 179.0542, loss: 0.00002585\n",
      "Epoch: [30] [   8/  20] time: 179.3017, loss: 0.00001749\n",
      "Epoch: [30] [   9/  20] time: 179.5555, loss: 0.00003273\n",
      "Epoch: [30] [  10/  20] time: 179.8069, loss: 0.00005463\n",
      "Epoch: [30] [  11/  20] time: 180.0521, loss: 0.00003052\n",
      "Epoch: [30] [  12/  20] time: 180.2953, loss: 0.00008254\n",
      "Epoch: [30] [  13/  20] time: 180.5442, loss: 0.00002647\n",
      "Epoch: [30] [  14/  20] time: 180.7913, loss: 0.00000386\n",
      "Epoch: [30] [  15/  20] time: 181.0353, loss: 0.00038137\n",
      "Epoch: [30] [  16/  20] time: 181.2828, loss: 0.00001744\n",
      "Epoch: [30] [  17/  20] time: 181.5330, loss: 0.00001714\n",
      "Epoch: [30] [  18/  20] time: 181.7913, loss: 0.00002040\n",
      "Epoch: [30] [  19/  20] time: 182.0376, loss: 0.00000243\n",
      "[30/80] - ptime: 5.4148 loss: 0.00005353 acc: 0.60000\n",
      "Epoch: [31] [   0/  20] time: 183.3221, loss: 0.00000626\n",
      "Epoch: [31] [   1/  20] time: 183.5708, loss: 0.00003199\n",
      "Epoch: [31] [   2/  20] time: 183.8246, loss: 0.00000850\n",
      "Epoch: [31] [   3/  20] time: 184.0722, loss: 0.00001510\n",
      "Epoch: [31] [   4/  20] time: 184.3237, loss: 0.00014774\n",
      "Epoch: [31] [   5/  20] time: 184.5729, loss: 0.00019472\n",
      "Epoch: [31] [   6/  20] time: 184.8284, loss: 0.00004755\n",
      "Epoch: [31] [   7/  20] time: 185.0774, loss: 0.00001332\n",
      "Epoch: [31] [   8/  20] time: 185.3236, loss: 0.00000224\n",
      "Epoch: [31] [   9/  20] time: 185.5725, loss: 0.00009843\n",
      "Epoch: [31] [  10/  20] time: 185.8287, loss: 0.00000877\n",
      "Epoch: [31] [  11/  20] time: 186.0748, loss: 0.00000751\n",
      "Epoch: [31] [  12/  20] time: 186.3215, loss: 0.00015468\n",
      "Epoch: [31] [  13/  20] time: 186.5705, loss: 0.00004600\n",
      "Epoch: [31] [  14/  20] time: 186.8244, loss: 0.00002465\n",
      "Epoch: [31] [  15/  20] time: 187.0714, loss: 0.00001501\n",
      "Epoch: [31] [  16/  20] time: 187.3181, loss: 0.00000015\n",
      "Epoch: [31] [  17/  20] time: 187.5684, loss: 0.00010078\n",
      "Epoch: [31] [  18/  20] time: 187.8158, loss: 0.00000959\n",
      "Epoch: [31] [  19/  20] time: 188.0604, loss: 0.00002447\n",
      "[31/80] - ptime: 5.4043 loss: 0.00004787 acc: 0.58000\n",
      "Epoch: [32] [   0/  20] time: 189.3684, loss: 0.00008910\n",
      "Epoch: [32] [   1/  20] time: 189.6203, loss: 0.00001504\n",
      "Epoch: [32] [   2/  20] time: 189.8855, loss: 0.00005639\n",
      "Epoch: [32] [   3/  20] time: 190.1319, loss: 0.00004267\n",
      "Epoch: [32] [   4/  20] time: 190.3818, loss: 0.00002788\n",
      "Epoch: [32] [   5/  20] time: 190.6312, loss: 0.00003952\n",
      "Epoch: [32] [   6/  20] time: 190.8776, loss: 0.00001027\n",
      "Epoch: [32] [   7/  20] time: 191.1265, loss: 0.00012087\n",
      "Epoch: [32] [   8/  20] time: 191.3733, loss: 0.00005785\n",
      "Epoch: [32] [   9/  20] time: 191.6243, loss: 0.00004509\n",
      "Epoch: [32] [  10/  20] time: 191.8816, loss: 0.00022839\n",
      "Epoch: [32] [  11/  20] time: 192.1280, loss: 0.00000793\n",
      "Epoch: [32] [  12/  20] time: 192.3764, loss: 0.00027537\n",
      "Epoch: [32] [  13/  20] time: 192.6265, loss: 0.00000266\n",
      "Epoch: [32] [  14/  20] time: 192.8743, loss: 0.00001362\n",
      "Epoch: [32] [  15/  20] time: 193.1228, loss: 0.00001090\n",
      "Epoch: [32] [  16/  20] time: 193.3703, loss: 0.00098561\n",
      "Epoch: [32] [  17/  20] time: 193.6205, loss: 0.00034437\n",
      "Epoch: [32] [  18/  20] time: 193.8768, loss: 0.00000851\n",
      "Epoch: [32] [  19/  20] time: 194.1252, loss: 0.00005704\n",
      "[32/80] - ptime: 5.4162 loss: 0.00012195 acc: 0.59000\n",
      "Epoch: [33] [   0/  20] time: 195.3662, loss: 0.00009551\n",
      "Epoch: [33] [   1/  20] time: 195.6133, loss: 0.00005690\n",
      "Epoch: [33] [   2/  20] time: 195.8623, loss: 0.00003820\n",
      "Epoch: [33] [   3/  20] time: 196.1100, loss: 0.00000783\n",
      "Epoch: [33] [   4/  20] time: 196.3560, loss: 0.00003753\n",
      "Epoch: [33] [   5/  20] time: 196.6045, loss: 0.00001477\n",
      "Epoch: [33] [   6/  20] time: 196.8608, loss: 0.00000704\n",
      "Epoch: [33] [   7/  20] time: 197.1076, loss: 0.00000031\n",
      "Epoch: [33] [   8/  20] time: 197.3532, loss: 0.00000153\n",
      "Epoch: [33] [   9/  20] time: 197.6033, loss: 0.00007425\n",
      "Epoch: [33] [  10/  20] time: 197.8634, loss: 0.00009681\n",
      "Epoch: [33] [  11/  20] time: 198.1082, loss: 0.00001659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [33] [  12/  20] time: 198.3550, loss: 0.00007685\n",
      "Epoch: [33] [  13/  20] time: 198.6044, loss: 0.00001548\n",
      "Epoch: [33] [  14/  20] time: 198.8621, loss: 0.00001951\n",
      "Epoch: [33] [  15/  20] time: 199.1095, loss: 0.00002802\n",
      "Epoch: [33] [  16/  20] time: 199.3565, loss: 0.00000118\n",
      "Epoch: [33] [  17/  20] time: 199.5999, loss: 0.00040528\n",
      "Epoch: [33] [  18/  20] time: 199.8552, loss: 0.00042599\n",
      "Epoch: [33] [  19/  20] time: 200.1016, loss: 0.00004050\n",
      "[33/80] - ptime: 5.3669 loss: 0.00007300 acc: 0.59000\n",
      "Epoch: [34] [   0/  20] time: 201.6346, loss: 0.00003625\n",
      "Epoch: [34] [   1/  20] time: 201.8929, loss: 0.00003035\n",
      "Epoch: [34] [   2/  20] time: 202.1390, loss: 0.00008585\n",
      "Epoch: [34] [   3/  20] time: 202.3863, loss: 0.00002580\n",
      "Epoch: [34] [   4/  20] time: 202.6346, loss: 0.00000692\n",
      "Epoch: [34] [   5/  20] time: 202.8976, loss: 0.00000014\n",
      "Epoch: [34] [   6/  20] time: 203.1458, loss: 0.00000789\n",
      "Epoch: [34] [   7/  20] time: 203.3919, loss: 0.00003740\n",
      "Epoch: [34] [   8/  20] time: 203.6423, loss: 0.00004405\n",
      "Epoch: [34] [   9/  20] time: 203.9030, loss: 0.00000284\n",
      "Epoch: [34] [  10/  20] time: 204.1465, loss: 0.00008566\n",
      "Epoch: [34] [  11/  20] time: 204.3939, loss: 0.00000292\n",
      "Epoch: [34] [  12/  20] time: 204.6425, loss: 0.00000734\n",
      "Epoch: [34] [  13/  20] time: 204.9036, loss: 0.00008435\n",
      "Epoch: [34] [  14/  20] time: 205.1494, loss: 0.00006061\n",
      "Epoch: [34] [  15/  20] time: 205.3981, loss: 0.00001165\n",
      "Epoch: [34] [  16/  20] time: 205.6557, loss: 0.00002919\n",
      "Epoch: [34] [  17/  20] time: 205.9133, loss: 0.00000740\n",
      "Epoch: [34] [  18/  20] time: 206.1613, loss: 0.00000088\n",
      "Epoch: [34] [  19/  20] time: 206.4064, loss: 0.00001474\n",
      "[34/80] - ptime: 5.4564 loss: 0.00002911 acc: 0.57000\n",
      "Epoch: [35] [   0/  20] time: 207.6159, loss: 0.00000200\n",
      "Epoch: [35] [   1/  20] time: 207.8657, loss: 0.00000212\n",
      "Epoch: [35] [   2/  20] time: 208.1306, loss: 0.00000161\n",
      "Epoch: [35] [   3/  20] time: 208.3780, loss: 0.00001950\n",
      "Epoch: [35] [   4/  20] time: 208.6267, loss: 0.00000155\n",
      "Epoch: [35] [   5/  20] time: 208.8797, loss: 0.00000100\n",
      "Epoch: [35] [   6/  20] time: 209.1406, loss: 0.00000765\n",
      "Epoch: [35] [   7/  20] time: 209.3875, loss: 0.00000503\n",
      "Epoch: [35] [   8/  20] time: 209.6359, loss: 0.00002662\n",
      "Epoch: [35] [   9/  20] time: 209.8940, loss: 0.00005905\n",
      "Epoch: [35] [  10/  20] time: 210.1497, loss: 0.00001377\n",
      "Epoch: [35] [  11/  20] time: 210.3979, loss: 0.00019366\n",
      "Epoch: [35] [  12/  20] time: 210.6483, loss: 0.00008278\n",
      "Epoch: [35] [  13/  20] time: 210.9060, loss: 0.00018379\n",
      "Epoch: [35] [  14/  20] time: 211.1617, loss: 0.00002909\n",
      "Epoch: [35] [  15/  20] time: 211.4098, loss: 0.00001437\n",
      "Epoch: [35] [  16/  20] time: 211.6583, loss: 0.00004913\n",
      "Epoch: [35] [  17/  20] time: 211.9162, loss: 0.00000431\n",
      "Epoch: [35] [  18/  20] time: 212.1812, loss: 0.00000546\n",
      "Epoch: [35] [  19/  20] time: 212.4326, loss: 0.00000631\n",
      "[35/80] - ptime: 5.4519 loss: 0.00003544 acc: 0.57000\n",
      "Epoch: [36] [   0/  20] time: 213.7499, loss: 0.00001770\n",
      "Epoch: [36] [   1/  20] time: 214.0048, loss: 0.00003079\n",
      "Epoch: [36] [   2/  20] time: 214.2575, loss: 0.00003059\n",
      "Epoch: [36] [   3/  20] time: 214.5020, loss: 0.00000683\n",
      "Epoch: [36] [   4/  20] time: 214.7504, loss: 0.00002231\n",
      "Epoch: [36] [   5/  20] time: 215.0114, loss: 0.00000317\n",
      "Epoch: [36] [   6/  20] time: 215.2637, loss: 0.00000198\n",
      "Epoch: [36] [   7/  20] time: 215.5106, loss: 0.00002937\n",
      "Epoch: [36] [   8/  20] time: 215.7582, loss: 0.00000686\n",
      "Epoch: [36] [   9/  20] time: 216.0194, loss: 0.00005898\n",
      "Epoch: [36] [  10/  20] time: 216.2787, loss: 0.00000838\n",
      "Epoch: [36] [  11/  20] time: 216.5240, loss: 0.00000293\n",
      "Epoch: [36] [  12/  20] time: 216.7736, loss: 0.00001880\n",
      "Epoch: [36] [  13/  20] time: 217.0344, loss: 0.00011788\n",
      "Epoch: [36] [  14/  20] time: 217.2814, loss: 0.00002660\n",
      "Epoch: [36] [  15/  20] time: 217.5269, loss: 0.00000149\n",
      "Epoch: [36] [  16/  20] time: 217.7776, loss: 0.00000084\n",
      "Epoch: [36] [  17/  20] time: 218.0341, loss: 0.00000439\n",
      "Epoch: [36] [  18/  20] time: 218.2816, loss: 0.00002118\n",
      "Epoch: [36] [  19/  20] time: 218.5262, loss: 0.00000202\n",
      "[36/80] - ptime: 5.4399 loss: 0.00002065 acc: 0.57000\n",
      "Epoch: [37] [   0/  20] time: 219.7174, loss: 0.00018506\n",
      "Epoch: [37] [   1/  20] time: 219.9664, loss: 0.00000070\n",
      "Epoch: [37] [   2/  20] time: 220.2291, loss: 0.00004067\n",
      "Epoch: [37] [   3/  20] time: 220.4746, loss: 0.00000488\n",
      "Epoch: [37] [   4/  20] time: 220.7225, loss: 0.00001496\n",
      "Epoch: [37] [   5/  20] time: 220.9758, loss: 0.00002192\n",
      "Epoch: [37] [   6/  20] time: 221.2309, loss: 0.00001108\n",
      "Epoch: [37] [   7/  20] time: 221.4757, loss: 0.00000010\n",
      "Epoch: [37] [   8/  20] time: 221.7210, loss: 0.00004037\n",
      "Epoch: [37] [   9/  20] time: 221.9715, loss: 0.00000195\n",
      "Epoch: [37] [  10/  20] time: 222.2201, loss: 0.00000417\n",
      "Epoch: [37] [  11/  20] time: 222.4653, loss: 0.00001408\n",
      "Epoch: [37] [  12/  20] time: 222.7124, loss: 0.00003571\n",
      "Epoch: [37] [  13/  20] time: 222.9638, loss: 0.00014001\n",
      "Epoch: [37] [  14/  20] time: 223.2146, loss: 0.00000327\n",
      "Epoch: [37] [  15/  20] time: 223.4617, loss: 0.00002011\n",
      "Epoch: [37] [  16/  20] time: 223.7062, loss: 0.00000246\n",
      "Epoch: [37] [  17/  20] time: 223.9544, loss: 0.00003201\n",
      "Epoch: [37] [  18/  20] time: 224.2031, loss: 0.00003243\n",
      "Epoch: [37] [  19/  20] time: 224.4480, loss: 0.00006034\n",
      "[37/80] - ptime: 5.3572 loss: 0.00003331 acc: 0.57000\n",
      "Epoch: [38] [   0/  20] time: 225.6541, loss: 0.00000306\n",
      "Epoch: [38] [   1/  20] time: 225.9003, loss: 0.00010260\n",
      "Epoch: [38] [   2/  20] time: 226.1662, loss: 0.00004380\n",
      "Epoch: [38] [   3/  20] time: 226.4154, loss: 0.00001003\n",
      "Epoch: [38] [   4/  20] time: 226.6604, loss: 0.00000279\n",
      "Epoch: [38] [   5/  20] time: 226.9109, loss: 0.00005135\n",
      "Epoch: [38] [   6/  20] time: 227.1701, loss: 0.00000030\n",
      "Epoch: [38] [   7/  20] time: 227.4186, loss: 0.00003075\n",
      "Epoch: [38] [   8/  20] time: 227.6633, loss: 0.00000653\n",
      "Epoch: [38] [   9/  20] time: 227.9112, loss: 0.00012671\n",
      "Epoch: [38] [  10/  20] time: 228.1694, loss: 0.00000289\n",
      "Epoch: [38] [  11/  20] time: 228.4189, loss: 0.00022859\n",
      "Epoch: [38] [  12/  20] time: 228.6636, loss: 0.00001374\n",
      "Epoch: [38] [  13/  20] time: 228.9126, loss: 0.00002219\n",
      "Epoch: [38] [  14/  20] time: 229.1672, loss: 0.00005993\n",
      "Epoch: [38] [  15/  20] time: 229.4146, loss: 0.00009512\n",
      "Epoch: [38] [  16/  20] time: 229.6595, loss: 0.00000671\n",
      "Epoch: [38] [  17/  20] time: 229.9097, loss: 0.00000389\n",
      "Epoch: [38] [  18/  20] time: 230.1663, loss: 0.00000538\n",
      "Epoch: [38] [  19/  20] time: 230.4141, loss: 0.00000109\n",
      "[38/80] - ptime: 5.3854 loss: 0.00004087 acc: 0.57000\n",
      "Epoch: [39] [   0/  20] time: 231.6147, loss: 0.00000242\n",
      "Epoch: [39] [   1/  20] time: 231.8604, loss: 0.00000383\n",
      "Epoch: [39] [   2/  20] time: 232.1176, loss: 0.00000434\n",
      "Epoch: [39] [   3/  20] time: 232.3765, loss: 0.00000560\n",
      "Epoch: [39] [   4/  20] time: 232.6224, loss: 0.00002219\n",
      "Epoch: [39] [   5/  20] time: 232.8724, loss: 0.00000434\n",
      "Epoch: [39] [   6/  20] time: 233.1260, loss: 0.00019327\n",
      "Epoch: [39] [   7/  20] time: 233.3830, loss: 0.00002420\n",
      "Epoch: [39] [   8/  20] time: 233.6292, loss: 0.00000150\n",
      "Epoch: [39] [   9/  20] time: 233.8791, loss: 0.00000233\n",
      "Epoch: [39] [  10/  20] time: 234.1295, loss: 0.00000530\n",
      "Epoch: [39] [  11/  20] time: 234.3891, loss: 0.00043970\n",
      "Epoch: [39] [  12/  20] time: 234.6337, loss: 0.00008087\n",
      "Epoch: [39] [  13/  20] time: 234.8827, loss: 0.00000669\n",
      "Epoch: [39] [  14/  20] time: 235.1366, loss: 0.00001493\n",
      "Epoch: [39] [  15/  20] time: 235.3932, loss: 0.00001147\n",
      "Epoch: [39] [  16/  20] time: 235.6382, loss: 0.00000903\n",
      "Epoch: [39] [  17/  20] time: 235.8816, loss: 0.00007200\n",
      "Epoch: [39] [  18/  20] time: 236.1351, loss: 0.00002172\n",
      "Epoch: [39] [  19/  20] time: 236.3925, loss: 0.00003484\n",
      "[39/80] - ptime: 5.4068 loss: 0.00004803 acc: 0.57000\n",
      "Epoch: [40] [   0/  20] time: 237.7466, loss: 0.00000893\n",
      "Epoch: [40] [   1/  20] time: 237.9964, loss: 0.00001511\n",
      "Epoch: [40] [   2/  20] time: 238.2526, loss: 0.00000019\n",
      "Epoch: [40] [   3/  20] time: 238.4982, loss: 0.00001372\n",
      "Epoch: [40] [   4/  20] time: 238.7440, loss: 0.00001623\n",
      "Epoch: [40] [   5/  20] time: 238.9939, loss: 0.00000111\n",
      "Epoch: [40] [   6/  20] time: 239.2539, loss: 0.00000109\n",
      "Epoch: [40] [   7/  20] time: 239.5001, loss: 0.00006808\n",
      "Epoch: [40] [   8/  20] time: 239.7441, loss: 0.00000559\n",
      "Epoch: [40] [   9/  20] time: 239.9946, loss: 0.00006948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [40] [  10/  20] time: 240.2560, loss: 0.00002042\n",
      "Epoch: [40] [  11/  20] time: 240.5011, loss: 0.00000775\n",
      "Epoch: [40] [  12/  20] time: 240.7479, loss: 0.00003204\n",
      "Epoch: [40] [  13/  20] time: 240.9928, loss: 0.00004216\n",
      "Epoch: [40] [  14/  20] time: 241.2506, loss: 0.00000299\n",
      "Epoch: [40] [  15/  20] time: 241.4958, loss: 0.00002393\n",
      "Epoch: [40] [  16/  20] time: 241.7423, loss: 0.00000302\n",
      "Epoch: [40] [  17/  20] time: 241.9925, loss: 0.00000228\n",
      "Epoch: [40] [  18/  20] time: 242.2526, loss: 0.00000263\n",
      "Epoch: [40] [  19/  20] time: 242.4984, loss: 0.00000200\n",
      "[40/80] - ptime: 5.3818 loss: 0.00001694 acc: 0.57000\n",
      "Epoch: [41] [   0/  20] time: 243.7647, loss: 0.00000262\n",
      "Epoch: [41] [   1/  20] time: 244.0130, loss: 0.00002390\n",
      "Epoch: [41] [   2/  20] time: 244.2724, loss: 0.00000063\n",
      "Epoch: [41] [   3/  20] time: 244.5207, loss: 0.00003737\n",
      "Epoch: [41] [   4/  20] time: 244.7679, loss: 0.00001030\n",
      "Epoch: [41] [   5/  20] time: 245.0204, loss: 0.00000834\n",
      "Epoch: [41] [   6/  20] time: 245.2797, loss: 0.00003616\n",
      "Epoch: [41] [   7/  20] time: 245.5376, loss: 0.00000666\n",
      "Epoch: [41] [   8/  20] time: 245.7837, loss: 0.00000689\n",
      "Epoch: [41] [   9/  20] time: 246.0358, loss: 0.00000224\n",
      "Epoch: [41] [  10/  20] time: 246.2980, loss: 0.00000466\n",
      "Epoch: [41] [  11/  20] time: 246.5438, loss: 0.00002258\n",
      "Epoch: [41] [  12/  20] time: 246.7928, loss: 0.00059407\n",
      "Epoch: [41] [  13/  20] time: 247.0411, loss: 0.00002127\n",
      "Epoch: [41] [  14/  20] time: 247.3034, loss: 0.00003169\n",
      "Epoch: [41] [  15/  20] time: 247.5482, loss: 0.00001716\n",
      "Epoch: [41] [  16/  20] time: 247.7968, loss: 0.00000360\n",
      "Epoch: [41] [  17/  20] time: 248.0453, loss: 0.00001292\n",
      "Epoch: [41] [  18/  20] time: 248.3049, loss: 0.00000139\n",
      "Epoch: [41] [  19/  20] time: 248.5515, loss: 0.00000167\n",
      "[41/80] - ptime: 5.4139 loss: 0.00004231 acc: 0.57000\n",
      "Epoch: [42] [   0/  20] time: 249.8085, loss: 0.00000200\n",
      "Epoch: [42] [   1/  20] time: 250.0585, loss: 0.00002044\n",
      "Epoch: [42] [   2/  20] time: 250.3196, loss: 0.00000314\n",
      "Epoch: [42] [   3/  20] time: 250.5675, loss: 0.00013668\n",
      "Epoch: [42] [   4/  20] time: 250.8127, loss: 0.00000404\n",
      "Epoch: [42] [   5/  20] time: 251.0634, loss: 0.00001320\n",
      "Epoch: [42] [   6/  20] time: 251.3260, loss: 0.00000145\n",
      "Epoch: [42] [   7/  20] time: 251.5713, loss: 0.00000074\n",
      "Epoch: [42] [   8/  20] time: 251.8172, loss: 0.00003655\n",
      "Epoch: [42] [   9/  20] time: 252.0649, loss: 0.00001982\n",
      "Epoch: [42] [  10/  20] time: 252.3231, loss: 0.00002515\n",
      "Epoch: [42] [  11/  20] time: 252.5824, loss: 0.00000402\n",
      "Epoch: [42] [  12/  20] time: 252.8330, loss: 0.00003360\n",
      "Epoch: [42] [  13/  20] time: 253.0812, loss: 0.00010418\n",
      "Epoch: [42] [  14/  20] time: 253.3407, loss: 0.00000012\n",
      "Epoch: [42] [  15/  20] time: 253.5864, loss: 0.00000084\n",
      "Epoch: [42] [  16/  20] time: 253.8331, loss: 0.00002653\n",
      "Epoch: [42] [  17/  20] time: 254.0811, loss: 0.00003883\n",
      "Epoch: [42] [  18/  20] time: 254.3455, loss: 0.00002582\n",
      "Epoch: [42] [  19/  20] time: 254.5905, loss: 0.00018997\n",
      "[42/80] - ptime: 5.4075 loss: 0.00003436 acc: 0.57000\n",
      "Epoch: [43] [   0/  20] time: 255.7956, loss: 0.00000463\n",
      "Epoch: [43] [   1/  20] time: 256.0434, loss: 0.00001580\n",
      "Epoch: [43] [   2/  20] time: 256.3024, loss: 0.00002240\n",
      "Epoch: [43] [   3/  20] time: 256.5675, loss: 0.00004885\n",
      "Epoch: [43] [   4/  20] time: 256.8150, loss: 0.00000149\n",
      "Epoch: [43] [   5/  20] time: 257.0639, loss: 0.00000832\n",
      "Epoch: [43] [   6/  20] time: 257.3242, loss: 0.00000816\n",
      "Epoch: [43] [   7/  20] time: 257.5869, loss: 0.00000584\n",
      "Epoch: [43] [   8/  20] time: 257.8322, loss: 0.00011145\n",
      "Epoch: [43] [   9/  20] time: 258.0800, loss: 0.00004173\n",
      "Epoch: [43] [  10/  20] time: 258.3398, loss: 0.00000087\n",
      "Epoch: [43] [  11/  20] time: 258.5928, loss: 0.00002843\n",
      "Epoch: [43] [  12/  20] time: 258.8483, loss: 0.00000290\n",
      "Epoch: [43] [  13/  20] time: 259.0978, loss: 0.00001784\n",
      "Epoch: [43] [  14/  20] time: 259.3605, loss: 0.00009335\n",
      "Epoch: [43] [  15/  20] time: 259.6153, loss: 0.00000412\n",
      "Epoch: [43] [  16/  20] time: 259.8600, loss: 0.00001186\n",
      "Epoch: [43] [  17/  20] time: 260.1106, loss: 0.00000384\n",
      "Epoch: [43] [  18/  20] time: 260.3746, loss: 0.00000788\n",
      "Epoch: [43] [  19/  20] time: 260.6448, loss: 0.00004165\n",
      "[43/80] - ptime: 5.4713 loss: 0.00002407 acc: 0.57000\n",
      "Epoch: [44] [   0/  20] time: 261.8652, loss: 0.00002194\n",
      "Epoch: [44] [   1/  20] time: 262.1202, loss: 0.00004571\n",
      "Epoch: [44] [   2/  20] time: 262.3815, loss: 0.00000010\n",
      "Epoch: [44] [   3/  20] time: 262.6476, loss: 0.00000034\n",
      "Epoch: [44] [   4/  20] time: 262.8947, loss: 0.00001289\n",
      "Epoch: [44] [   5/  20] time: 263.1448, loss: 0.00000012\n",
      "Epoch: [44] [   6/  20] time: 263.4075, loss: 0.00002323\n",
      "Epoch: [44] [   7/  20] time: 263.6667, loss: 0.00000096\n",
      "Epoch: [44] [   8/  20] time: 263.9099, loss: 0.00000041\n",
      "Epoch: [44] [   9/  20] time: 264.1611, loss: 0.00000976\n",
      "Epoch: [44] [  10/  20] time: 264.4228, loss: 0.00001086\n",
      "Epoch: [44] [  11/  20] time: 264.6899, loss: 0.00005043\n",
      "Epoch: [44] [  12/  20] time: 264.9336, loss: 0.00001107\n",
      "Epoch: [44] [  13/  20] time: 265.1832, loss: 0.00000929\n",
      "Epoch: [44] [  14/  20] time: 265.4462, loss: 0.00000183\n",
      "Epoch: [44] [  15/  20] time: 265.6912, loss: 0.00000762\n",
      "Epoch: [44] [  16/  20] time: 265.9358, loss: 0.00000034\n",
      "Epoch: [44] [  17/  20] time: 266.1847, loss: 0.00002693\n",
      "Epoch: [44] [  18/  20] time: 266.4459, loss: 0.00001622\n",
      "Epoch: [44] [  19/  20] time: 266.6922, loss: 0.00002468\n",
      "[44/80] - ptime: 5.4655 loss: 0.00001374 acc: 0.57000\n",
      "Epoch: [45] [   0/  20] time: 267.9770, loss: 0.00001154\n",
      "Epoch: [45] [   1/  20] time: 268.2252, loss: 0.00000362\n",
      "Epoch: [45] [   2/  20] time: 268.4827, loss: 0.00000270\n",
      "Epoch: [45] [   3/  20] time: 268.7278, loss: 0.00001740\n",
      "Epoch: [45] [   4/  20] time: 268.9738, loss: 0.00000717\n",
      "Epoch: [45] [   5/  20] time: 269.2250, loss: 0.00010588\n",
      "Epoch: [45] [   6/  20] time: 269.4892, loss: 0.00001273\n",
      "Epoch: [45] [   7/  20] time: 269.7367, loss: 0.00000380\n",
      "Epoch: [45] [   8/  20] time: 269.9788, loss: 0.00014364\n",
      "Epoch: [45] [   9/  20] time: 270.2302, loss: 0.00001090\n",
      "Epoch: [45] [  10/  20] time: 270.4929, loss: 0.00001287\n",
      "Epoch: [45] [  11/  20] time: 270.7392, loss: 0.00000394\n",
      "Epoch: [45] [  12/  20] time: 270.9848, loss: 0.00000117\n",
      "Epoch: [45] [  13/  20] time: 271.2364, loss: 0.00000069\n",
      "Epoch: [45] [  14/  20] time: 271.4864, loss: 0.00000211\n",
      "Epoch: [45] [  15/  20] time: 271.7336, loss: 0.00000642\n",
      "Epoch: [45] [  16/  20] time: 271.9773, loss: 0.00000032\n",
      "Epoch: [45] [  17/  20] time: 272.2272, loss: 0.00000280\n",
      "Epoch: [45] [  18/  20] time: 272.4926, loss: 0.00005882\n",
      "Epoch: [45] [  19/  20] time: 272.7398, loss: 0.00000658\n",
      "[45/80] - ptime: 5.3923 loss: 0.00002075 acc: 0.57000\n",
      "Epoch: [46] [   0/  20] time: 273.9434, loss: 0.00005203\n",
      "Epoch: [46] [   1/  20] time: 274.1904, loss: 0.00000518\n",
      "Epoch: [46] [   2/  20] time: 274.4538, loss: 0.00000009\n",
      "Epoch: [46] [   3/  20] time: 274.7201, loss: 0.00001715\n",
      "Epoch: [46] [   4/  20] time: 274.9660, loss: 0.00000201\n",
      "Epoch: [46] [   5/  20] time: 275.2171, loss: 0.00001038\n",
      "Epoch: [46] [   6/  20] time: 275.4742, loss: 0.00003750\n",
      "Epoch: [46] [   7/  20] time: 275.7332, loss: 0.00000151\n",
      "Epoch: [46] [   8/  20] time: 275.9785, loss: 0.00002059\n",
      "Epoch: [46] [   9/  20] time: 276.2280, loss: 0.00001786\n",
      "Epoch: [46] [  10/  20] time: 276.4939, loss: 0.00000044\n",
      "Epoch: [46] [  11/  20] time: 276.7555, loss: 0.00000009\n",
      "Epoch: [46] [  12/  20] time: 277.0013, loss: 0.00002718\n",
      "Epoch: [46] [  13/  20] time: 277.2518, loss: 0.00014272\n",
      "Epoch: [46] [  14/  20] time: 277.5129, loss: 0.00002652\n",
      "Epoch: [46] [  15/  20] time: 277.7616, loss: 0.00000077\n",
      "Epoch: [46] [  16/  20] time: 278.0074, loss: 0.00003115\n",
      "Epoch: [46] [  17/  20] time: 278.2586, loss: 0.00000171\n",
      "Epoch: [46] [  18/  20] time: 278.5201, loss: 0.00000269\n",
      "Epoch: [46] [  19/  20] time: 278.7674, loss: 0.00000378\n",
      "[46/80] - ptime: 5.4520 loss: 0.00002007 acc: 0.57000\n",
      "Epoch: [47] [   0/  20] time: 280.0413, loss: 0.00001103\n",
      "Epoch: [47] [   1/  20] time: 280.2933, loss: 0.00000381\n",
      "Epoch: [47] [   2/  20] time: 280.5518, loss: 0.00004685\n",
      "Epoch: [47] [   3/  20] time: 280.8119, loss: 0.00012544\n",
      "Epoch: [47] [   4/  20] time: 281.0584, loss: 0.00000181\n",
      "Epoch: [47] [   5/  20] time: 281.3163, loss: 0.00001025\n",
      "Epoch: [47] [   6/  20] time: 281.5782, loss: 0.00002445\n",
      "Epoch: [47] [   7/  20] time: 281.8375, loss: 0.00000223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [47] [   8/  20] time: 282.0837, loss: 0.00001570\n",
      "Epoch: [47] [   9/  20] time: 282.3364, loss: 0.00000718\n",
      "Epoch: [47] [  10/  20] time: 282.5975, loss: 0.00000190\n",
      "Epoch: [47] [  11/  20] time: 282.8431, loss: 0.00001768\n",
      "Epoch: [47] [  12/  20] time: 283.0890, loss: 0.00001552\n",
      "Epoch: [47] [  13/  20] time: 283.3431, loss: 0.00001791\n",
      "Epoch: [47] [  14/  20] time: 283.6051, loss: 0.00000496\n",
      "Epoch: [47] [  15/  20] time: 283.8509, loss: 0.00004185\n",
      "Epoch: [47] [  16/  20] time: 284.0981, loss: 0.00000125\n",
      "Epoch: [47] [  17/  20] time: 284.3557, loss: 0.00005991\n",
      "Epoch: [47] [  18/  20] time: 284.6138, loss: 0.00000725\n",
      "Epoch: [47] [  19/  20] time: 284.8611, loss: 0.00000411\n",
      "[47/80] - ptime: 5.4555 loss: 0.00002105 acc: 0.57000\n",
      "Epoch: [48] [   0/  20] time: 286.0808, loss: 0.00000053\n",
      "Epoch: [48] [   1/  20] time: 286.3333, loss: 0.00000265\n",
      "Epoch: [48] [   2/  20] time: 286.5921, loss: 0.00000249\n",
      "Epoch: [48] [   3/  20] time: 286.8511, loss: 0.00001058\n",
      "Epoch: [48] [   4/  20] time: 287.0992, loss: 0.00000283\n",
      "Epoch: [48] [   5/  20] time: 287.3515, loss: 0.00001268\n",
      "Epoch: [48] [   6/  20] time: 287.6132, loss: 0.00000196\n",
      "Epoch: [48] [   7/  20] time: 287.8771, loss: 0.00000459\n",
      "Epoch: [48] [   8/  20] time: 288.1221, loss: 0.00000547\n",
      "Epoch: [48] [   9/  20] time: 288.3696, loss: 0.00001096\n",
      "Epoch: [48] [  10/  20] time: 288.6269, loss: 0.00000340\n",
      "Epoch: [48] [  11/  20] time: 288.8717, loss: 0.00000647\n",
      "Epoch: [48] [  12/  20] time: 289.1177, loss: 0.00000273\n",
      "Epoch: [48] [  13/  20] time: 289.3725, loss: 0.00000397\n",
      "Epoch: [48] [  14/  20] time: 289.6303, loss: 0.00002287\n",
      "Epoch: [48] [  15/  20] time: 289.8770, loss: 0.00000354\n",
      "Epoch: [48] [  16/  20] time: 290.1233, loss: 0.00000014\n",
      "Epoch: [48] [  17/  20] time: 290.3775, loss: 0.00001677\n",
      "Epoch: [48] [  18/  20] time: 290.6386, loss: 0.00000269\n",
      "Epoch: [48] [  19/  20] time: 290.8844, loss: 0.00002757\n",
      "[48/80] - ptime: 5.4294 loss: 0.00000724 acc: 0.58000\n",
      "Epoch: [49] [   0/  20] time: 292.0950, loss: 0.00001159\n",
      "Epoch: [49] [   1/  20] time: 292.3478, loss: 0.00002095\n",
      "Epoch: [49] [   2/  20] time: 292.6071, loss: 0.00001699\n",
      "Epoch: [49] [   3/  20] time: 292.8651, loss: 0.00000569\n",
      "Epoch: [49] [   4/  20] time: 293.1093, loss: 0.00000571\n",
      "Epoch: [49] [   5/  20] time: 293.3663, loss: 0.00000006\n",
      "Epoch: [49] [   6/  20] time: 293.6241, loss: 0.00000864\n",
      "Epoch: [49] [   7/  20] time: 293.8709, loss: 0.00000382\n",
      "Epoch: [49] [   8/  20] time: 294.1221, loss: 0.00002194\n",
      "Epoch: [49] [   9/  20] time: 294.3738, loss: 0.00002430\n",
      "Epoch: [49] [  10/  20] time: 294.6307, loss: 0.00005474\n",
      "Epoch: [49] [  11/  20] time: 294.8769, loss: 0.00000190\n",
      "Epoch: [49] [  12/  20] time: 295.1241, loss: 0.00000534\n",
      "Epoch: [49] [  13/  20] time: 295.3769, loss: 0.00000743\n",
      "Epoch: [49] [  14/  20] time: 295.6405, loss: 0.00000010\n",
      "Epoch: [49] [  15/  20] time: 295.8874, loss: 0.00004802\n",
      "Epoch: [49] [  16/  20] time: 296.1354, loss: 0.00002993\n",
      "Epoch: [49] [  17/  20] time: 296.3862, loss: 0.00000544\n",
      "Epoch: [49] [  18/  20] time: 296.6463, loss: 0.00000020\n",
      "Epoch: [49] [  19/  20] time: 296.8919, loss: 0.00000363\n",
      "[49/80] - ptime: 5.4315 loss: 0.00001382 acc: 0.57000\n",
      "Epoch: [50] [   0/  20] time: 298.0911, loss: 0.00000631\n",
      "Epoch: [50] [   1/  20] time: 298.3408, loss: 0.00001733\n",
      "Epoch: [50] [   2/  20] time: 298.5960, loss: 0.00000268\n",
      "Epoch: [50] [   3/  20] time: 298.8494, loss: 0.00000081\n",
      "Epoch: [50] [   4/  20] time: 299.0956, loss: 0.00003724\n",
      "Epoch: [50] [   5/  20] time: 299.3471, loss: 0.00000467\n",
      "Epoch: [50] [   6/  20] time: 299.6007, loss: 0.00001634\n",
      "Epoch: [50] [   7/  20] time: 299.8600, loss: 0.00000403\n",
      "Epoch: [50] [   8/  20] time: 300.1082, loss: 0.00000296\n",
      "Epoch: [50] [   9/  20] time: 300.3663, loss: 0.00005478\n",
      "Epoch: [50] [  10/  20] time: 300.6218, loss: 0.00000258\n",
      "Epoch: [50] [  11/  20] time: 300.8858, loss: 0.00000415\n",
      "Epoch: [50] [  12/  20] time: 301.1322, loss: 0.00002499\n",
      "Epoch: [50] [  13/  20] time: 301.3843, loss: 0.00000756\n",
      "Epoch: [50] [  14/  20] time: 301.6375, loss: 0.00001761\n",
      "Epoch: [50] [  15/  20] time: 301.8917, loss: 0.00000408\n",
      "Epoch: [50] [  16/  20] time: 302.1375, loss: 0.00002693\n",
      "Epoch: [50] [  17/  20] time: 302.3852, loss: 0.00000364\n",
      "Epoch: [50] [  18/  20] time: 302.6400, loss: 0.00000120\n",
      "Epoch: [50] [  19/  20] time: 302.9010, loss: 0.00001816\n",
      "[50/80] - ptime: 5.4377 loss: 0.00001290 acc: 0.57000\n",
      "Epoch: [51] [   0/  20] time: 304.0400, loss: 0.00000020\n",
      "Epoch: [51] [   1/  20] time: 304.2841, loss: 0.00000126\n",
      "Epoch: [51] [   2/  20] time: 304.5353, loss: 0.00024255\n",
      "Epoch: [51] [   3/  20] time: 304.7838, loss: 0.00000409\n",
      "Epoch: [51] [   4/  20] time: 305.0308, loss: 0.00000180\n",
      "Epoch: [51] [   5/  20] time: 305.2810, loss: 0.00002765\n",
      "Epoch: [51] [   6/  20] time: 305.5346, loss: 0.00000312\n",
      "Epoch: [51] [   7/  20] time: 305.7908, loss: 0.00000150\n",
      "Epoch: [51] [   8/  20] time: 306.0386, loss: 0.00000683\n",
      "Epoch: [51] [   9/  20] time: 306.2852, loss: 0.00001704\n",
      "Epoch: [51] [  10/  20] time: 306.5394, loss: 0.00000612\n",
      "Epoch: [51] [  11/  20] time: 306.7930, loss: 0.00000316\n",
      "Epoch: [51] [  12/  20] time: 307.0377, loss: 0.00000309\n",
      "Epoch: [51] [  13/  20] time: 307.2877, loss: 0.00000005\n",
      "Epoch: [51] [  14/  20] time: 307.5395, loss: 0.00000472\n",
      "Epoch: [51] [  15/  20] time: 307.7922, loss: 0.00011888\n",
      "Epoch: [51] [  16/  20] time: 308.0366, loss: 0.00001019\n",
      "Epoch: [51] [  17/  20] time: 308.2815, loss: 0.00000365\n",
      "Epoch: [51] [  18/  20] time: 308.5309, loss: 0.00000001\n",
      "Epoch: [51] [  19/  20] time: 308.7874, loss: 0.00001315\n",
      "[51/80] - ptime: 5.3710 loss: 0.00002345 acc: 0.58000\n",
      "Epoch: [52] [   0/  20] time: 310.2233, loss: 0.00004048\n",
      "Epoch: [52] [   1/  20] time: 310.4752, loss: 0.00000074\n",
      "Epoch: [52] [   2/  20] time: 310.7255, loss: 0.00001156\n",
      "Epoch: [52] [   3/  20] time: 310.9935, loss: 0.00000932\n",
      "Epoch: [52] [   4/  20] time: 311.2390, loss: 0.00000492\n",
      "Epoch: [52] [   5/  20] time: 311.4886, loss: 0.00000474\n",
      "Epoch: [52] [   6/  20] time: 311.7464, loss: 0.00000053\n",
      "Epoch: [52] [   7/  20] time: 312.0005, loss: 0.00000357\n",
      "Epoch: [52] [   8/  20] time: 312.2503, loss: 0.00000911\n",
      "Epoch: [52] [   9/  20] time: 312.4998, loss: 0.00010047\n",
      "Epoch: [52] [  10/  20] time: 312.7559, loss: 0.00000448\n",
      "Epoch: [52] [  11/  20] time: 313.0143, loss: 0.00023514\n",
      "Epoch: [52] [  12/  20] time: 313.2645, loss: 0.00000008\n",
      "Epoch: [52] [  13/  20] time: 313.5172, loss: 0.00003850\n",
      "Epoch: [52] [  14/  20] time: 313.7734, loss: 0.00000769\n",
      "Epoch: [52] [  15/  20] time: 314.0270, loss: 0.00001209\n",
      "Epoch: [52] [  16/  20] time: 314.2747, loss: 0.00000354\n",
      "Epoch: [52] [  17/  20] time: 314.5283, loss: 0.00000651\n",
      "Epoch: [52] [  18/  20] time: 314.7825, loss: 0.00000571\n",
      "Epoch: [52] [  19/  20] time: 315.0419, loss: 0.00000214\n",
      "[52/80] - ptime: 5.4429 loss: 0.00002507 acc: 0.57000\n",
      "Epoch: [53] [   0/  20] time: 316.2739, loss: 0.00010094\n",
      "Epoch: [53] [   1/  20] time: 316.5236, loss: 0.00000861\n",
      "Epoch: [53] [   2/  20] time: 316.7775, loss: 0.00001399\n",
      "Epoch: [53] [   3/  20] time: 317.0293, loss: 0.00001420\n",
      "Epoch: [53] [   4/  20] time: 317.2759, loss: 0.00000445\n",
      "Epoch: [53] [   5/  20] time: 317.5290, loss: 0.00002083\n",
      "Epoch: [53] [   6/  20] time: 317.7819, loss: 0.00071693\n",
      "Epoch: [53] [   7/  20] time: 318.0439, loss: 0.00009086\n",
      "Epoch: [53] [   8/  20] time: 318.2901, loss: 0.00000611\n",
      "Epoch: [53] [   9/  20] time: 318.5391, loss: 0.00000854\n",
      "Epoch: [53] [  10/  20] time: 318.7884, loss: 0.00000420\n",
      "Epoch: [53] [  11/  20] time: 319.0507, loss: 0.00001047\n",
      "Epoch: [53] [  12/  20] time: 319.2990, loss: 0.00000552\n",
      "Epoch: [53] [  13/  20] time: 319.5500, loss: 0.00000827\n",
      "Epoch: [53] [  14/  20] time: 319.8055, loss: 0.00000822\n",
      "Epoch: [53] [  15/  20] time: 320.0610, loss: 0.00000210\n",
      "Epoch: [53] [  16/  20] time: 320.3024, loss: 0.00000104\n",
      "Epoch: [53] [  17/  20] time: 320.5546, loss: 0.00000222\n",
      "Epoch: [53] [  18/  20] time: 320.8131, loss: 0.00000086\n",
      "Epoch: [53] [  19/  20] time: 321.0720, loss: 0.00002202\n",
      "[53/80] - ptime: 5.4283 loss: 0.00005252 acc: 0.58000\n",
      "Epoch: [54] [   0/  20] time: 322.3217, loss: 0.00000346\n",
      "Epoch: [54] [   1/  20] time: 322.5695, loss: 0.00000403\n",
      "Epoch: [54] [   2/  20] time: 322.8229, loss: 0.00000004\n",
      "Epoch: [54] [   3/  20] time: 323.0893, loss: 0.00001477\n",
      "Epoch: [54] [   4/  20] time: 323.3373, loss: 0.00000514\n",
      "Epoch: [54] [   5/  20] time: 323.5871, loss: 0.00001925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [54] [   6/  20] time: 323.8405, loss: 0.00006332\n",
      "Epoch: [54] [   7/  20] time: 324.1033, loss: 0.00000324\n",
      "Epoch: [54] [   8/  20] time: 324.3499, loss: 0.00000018\n",
      "Epoch: [54] [   9/  20] time: 324.6012, loss: 0.00000463\n",
      "Epoch: [54] [  10/  20] time: 324.8547, loss: 0.00003492\n",
      "Epoch: [54] [  11/  20] time: 325.1103, loss: 0.00000393\n",
      "Epoch: [54] [  12/  20] time: 325.3581, loss: 0.00001993\n",
      "Epoch: [54] [  13/  20] time: 325.6090, loss: 0.00001999\n",
      "Epoch: [54] [  14/  20] time: 325.8660, loss: 0.00000397\n",
      "Epoch: [54] [  15/  20] time: 326.1205, loss: 0.00000198\n",
      "Epoch: [54] [  16/  20] time: 326.3682, loss: 0.00000010\n",
      "Epoch: [54] [  17/  20] time: 326.6329, loss: 0.00002997\n",
      "Epoch: [54] [  18/  20] time: 326.8962, loss: 0.00001308\n",
      "Epoch: [54] [  19/  20] time: 327.1611, loss: 0.00000387\n",
      "[54/80] - ptime: 5.4732 loss: 0.00001249 acc: 0.58000\n",
      "Epoch: [55] [   0/  20] time: 328.4178, loss: 0.00031145\n",
      "Epoch: [55] [   1/  20] time: 328.6662, loss: 0.00001449\n",
      "Epoch: [55] [   2/  20] time: 328.9213, loss: 0.00000129\n",
      "Epoch: [55] [   3/  20] time: 329.1810, loss: 0.00000101\n",
      "Epoch: [55] [   4/  20] time: 329.4281, loss: 0.00002464\n",
      "Epoch: [55] [   5/  20] time: 329.6768, loss: 0.00001223\n",
      "Epoch: [55] [   6/  20] time: 329.9342, loss: 0.00002374\n",
      "Epoch: [55] [   7/  20] time: 330.1932, loss: 0.00000097\n",
      "Epoch: [55] [   8/  20] time: 330.4430, loss: 0.00011569\n",
      "Epoch: [55] [   9/  20] time: 330.6924, loss: 0.00001606\n",
      "Epoch: [55] [  10/  20] time: 330.9498, loss: 0.00002518\n",
      "Epoch: [55] [  11/  20] time: 331.2073, loss: 0.00000177\n",
      "Epoch: [55] [  12/  20] time: 331.4570, loss: 0.00001241\n",
      "Epoch: [55] [  13/  20] time: 331.7054, loss: 0.00000626\n",
      "Epoch: [55] [  14/  20] time: 331.9643, loss: 0.00000158\n",
      "Epoch: [55] [  15/  20] time: 332.2228, loss: 0.00001686\n",
      "Epoch: [55] [  16/  20] time: 332.4700, loss: 0.00000145\n",
      "Epoch: [55] [  17/  20] time: 332.7212, loss: 0.00000757\n",
      "Epoch: [55] [  18/  20] time: 332.9793, loss: 0.00000427\n",
      "Epoch: [55] [  19/  20] time: 333.2308, loss: 0.00001022\n",
      "[55/80] - ptime: 5.4554 loss: 0.00003046 acc: 0.58000\n",
      "Epoch: [56] [   0/  20] time: 334.4921, loss: 0.00002581\n",
      "Epoch: [56] [   1/  20] time: 334.7399, loss: 0.00000287\n",
      "Epoch: [56] [   2/  20] time: 335.0019, loss: 0.00000065\n",
      "Epoch: [56] [   3/  20] time: 335.2497, loss: 0.00001008\n",
      "Epoch: [56] [   4/  20] time: 335.4966, loss: 0.00000064\n",
      "Epoch: [56] [   5/  20] time: 335.7526, loss: 0.00001116\n",
      "Epoch: [56] [   6/  20] time: 336.0179, loss: 0.00000230\n",
      "Epoch: [56] [   7/  20] time: 336.2638, loss: 0.00001048\n",
      "Epoch: [56] [   8/  20] time: 336.5164, loss: 0.00000044\n",
      "Epoch: [56] [   9/  20] time: 336.7656, loss: 0.00001851\n",
      "Epoch: [56] [  10/  20] time: 337.0279, loss: 0.00000657\n",
      "Epoch: [56] [  11/  20] time: 337.2783, loss: 0.00000103\n",
      "Epoch: [56] [  12/  20] time: 337.5265, loss: 0.00001072\n",
      "Epoch: [56] [  13/  20] time: 337.7766, loss: 0.00000312\n",
      "Epoch: [56] [  14/  20] time: 338.0357, loss: 0.00003592\n",
      "Epoch: [56] [  15/  20] time: 338.2839, loss: 0.00003644\n",
      "Epoch: [56] [  16/  20] time: 338.5326, loss: 0.00000775\n",
      "Epoch: [56] [  17/  20] time: 338.7836, loss: 0.00000355\n",
      "Epoch: [56] [  18/  20] time: 339.0441, loss: 0.00000373\n",
      "Epoch: [56] [  19/  20] time: 339.2937, loss: 0.00000206\n",
      "[56/80] - ptime: 5.4337 loss: 0.00000969 acc: 0.58000\n",
      "Epoch: [57] [   0/  20] time: 340.5612, loss: 0.00000770\n",
      "Epoch: [57] [   1/  20] time: 340.8073, loss: 0.00000442\n",
      "Epoch: [57] [   2/  20] time: 341.0685, loss: 0.00000638\n",
      "Epoch: [57] [   3/  20] time: 341.3134, loss: 0.00000307\n",
      "Epoch: [57] [   4/  20] time: 341.5618, loss: 0.00000112\n",
      "Epoch: [57] [   5/  20] time: 341.8137, loss: 0.00000032\n",
      "Epoch: [57] [   6/  20] time: 342.0628, loss: 0.00000186\n",
      "Epoch: [57] [   7/  20] time: 342.3094, loss: 0.00000577\n",
      "Epoch: [57] [   8/  20] time: 342.5567, loss: 0.00000667\n",
      "Epoch: [57] [   9/  20] time: 342.8062, loss: 0.00000096\n",
      "Epoch: [57] [  10/  20] time: 343.0669, loss: 0.00011835\n",
      "Epoch: [57] [  11/  20] time: 343.3075, loss: 0.00000772\n",
      "Epoch: [57] [  12/  20] time: 343.5548, loss: 0.00002216\n",
      "Epoch: [57] [  13/  20] time: 343.8069, loss: 0.00001514\n",
      "Epoch: [57] [  14/  20] time: 344.0690, loss: 0.00000130\n",
      "Epoch: [57] [  15/  20] time: 344.3147, loss: 0.00000047\n",
      "Epoch: [57] [  16/  20] time: 344.5623, loss: 0.00000493\n",
      "Epoch: [57] [  17/  20] time: 344.8111, loss: 0.00000509\n",
      "Epoch: [57] [  18/  20] time: 345.0730, loss: 0.00000010\n",
      "Epoch: [57] [  19/  20] time: 345.3183, loss: 0.00000422\n",
      "[57/80] - ptime: 5.3882 loss: 0.00001089 acc: 0.59000\n",
      "Epoch: [58] [   0/  20] time: 346.6107, loss: 0.00000183\n",
      "Epoch: [58] [   1/  20] time: 346.8584, loss: 0.00001826\n",
      "Epoch: [58] [   2/  20] time: 347.1114, loss: 0.00000674\n",
      "Epoch: [58] [   3/  20] time: 347.3606, loss: 0.00000069\n",
      "Epoch: [58] [   4/  20] time: 347.6051, loss: 0.00001860\n",
      "Epoch: [58] [   5/  20] time: 347.8562, loss: 0.00000420\n",
      "Epoch: [58] [   6/  20] time: 348.1106, loss: 0.00006059\n",
      "Epoch: [58] [   7/  20] time: 348.3590, loss: 0.00000829\n",
      "Epoch: [58] [   8/  20] time: 348.6106, loss: 0.00000079\n",
      "Epoch: [58] [   9/  20] time: 348.8611, loss: 0.00003679\n",
      "Epoch: [58] [  10/  20] time: 349.1171, loss: 0.00012536\n",
      "Epoch: [58] [  11/  20] time: 349.3655, loss: 0.00000150\n",
      "Epoch: [58] [  12/  20] time: 349.6125, loss: 0.00004033\n",
      "Epoch: [58] [  13/  20] time: 349.8639, loss: 0.00000224\n",
      "Epoch: [58] [  14/  20] time: 350.1164, loss: 0.00001873\n",
      "Epoch: [58] [  15/  20] time: 350.3640, loss: 0.00000489\n",
      "Epoch: [58] [  16/  20] time: 350.6119, loss: 0.00000121\n",
      "Epoch: [58] [  17/  20] time: 350.8619, loss: 0.00000010\n",
      "Epoch: [58] [  18/  20] time: 351.1178, loss: 0.00009484\n",
      "Epoch: [58] [  19/  20] time: 351.3647, loss: 0.00003125\n",
      "[58/80] - ptime: 5.3957 loss: 0.00002386 acc: 0.58000\n",
      "Epoch: [59] [   0/  20] time: 352.6180, loss: 0.00000045\n",
      "Epoch: [59] [   1/  20] time: 352.8663, loss: 0.00006436\n",
      "Epoch: [59] [   2/  20] time: 353.1242, loss: 0.00002142\n",
      "Epoch: [59] [   3/  20] time: 353.3722, loss: 0.00000026\n",
      "Epoch: [59] [   4/  20] time: 353.6213, loss: 0.00000174\n",
      "Epoch: [59] [   5/  20] time: 353.8730, loss: 0.00001784\n",
      "Epoch: [59] [   6/  20] time: 354.1172, loss: 0.00001657\n",
      "Epoch: [59] [   7/  20] time: 354.3794, loss: 0.00000524\n",
      "Epoch: [59] [   8/  20] time: 354.6290, loss: 0.00000393\n",
      "Epoch: [59] [   9/  20] time: 354.8778, loss: 0.00002175\n",
      "Epoch: [59] [  10/  20] time: 355.1353, loss: 0.00001320\n",
      "Epoch: [59] [  11/  20] time: 355.3793, loss: 0.00000145\n",
      "Epoch: [59] [  12/  20] time: 355.6268, loss: 0.00000004\n",
      "Epoch: [59] [  13/  20] time: 355.8783, loss: 0.00000219\n",
      "Epoch: [59] [  14/  20] time: 356.1259, loss: 0.00000144\n",
      "Epoch: [59] [  15/  20] time: 356.3844, loss: 0.00000167\n",
      "Epoch: [59] [  16/  20] time: 356.6317, loss: 0.00002095\n",
      "Epoch: [59] [  17/  20] time: 356.8817, loss: 0.00000956\n",
      "Epoch: [59] [  18/  20] time: 357.1408, loss: 0.00000297\n",
      "Epoch: [59] [  19/  20] time: 357.3860, loss: 0.00000004\n",
      "[59/80] - ptime: 5.3982 loss: 0.00001035 acc: 0.58000\n",
      "Epoch: [60] [   0/  20] time: 358.7074, loss: 0.00000407\n",
      "Epoch: [60] [   1/  20] time: 358.9543, loss: 0.00001226\n",
      "Epoch: [60] [   2/  20] time: 359.2105, loss: 0.00000260\n",
      "Epoch: [60] [   3/  20] time: 359.4577, loss: 0.00000476\n",
      "Epoch: [60] [   4/  20] time: 359.7035, loss: 0.00001131\n",
      "Epoch: [60] [   5/  20] time: 359.9526, loss: 0.00000819\n",
      "Epoch: [60] [   6/  20] time: 360.2050, loss: 0.00000121\n",
      "Epoch: [60] [   7/  20] time: 360.4507, loss: 0.00000426\n",
      "Epoch: [60] [   8/  20] time: 360.6973, loss: 0.00000023\n",
      "Epoch: [60] [   9/  20] time: 360.9496, loss: 0.00000136\n",
      "Epoch: [60] [  10/  20] time: 361.2066, loss: 0.00026562\n",
      "Epoch: [60] [  11/  20] time: 361.4546, loss: 0.00000028\n",
      "Epoch: [60] [  12/  20] time: 361.7001, loss: 0.00000031\n",
      "Epoch: [60] [  13/  20] time: 361.9505, loss: 0.00000316\n",
      "Epoch: [60] [  14/  20] time: 362.2092, loss: 0.00000751\n",
      "Epoch: [60] [  15/  20] time: 362.4572, loss: 0.00008252\n",
      "Epoch: [60] [  16/  20] time: 362.7051, loss: 0.00000043\n",
      "Epoch: [60] [  17/  20] time: 362.9543, loss: 0.00002332\n",
      "Epoch: [60] [  18/  20] time: 363.2062, loss: 0.00000069\n",
      "Epoch: [60] [  19/  20] time: 363.4548, loss: 0.00000122\n",
      "[60/80] - ptime: 5.4001 loss: 0.00002177 acc: 0.59000\n",
      "Epoch: [61] [   0/  20] time: 364.7071, loss: 0.00000360\n",
      "Epoch: [61] [   1/  20] time: 364.9537, loss: 0.00002060\n",
      "Epoch: [61] [   2/  20] time: 365.2115, loss: 0.00002271\n",
      "Epoch: [61] [   3/  20] time: 365.4582, loss: 0.00000008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [61] [   4/  20] time: 365.7035, loss: 0.00000346\n",
      "Epoch: [61] [   5/  20] time: 365.9529, loss: 0.00002846\n",
      "Epoch: [61] [   6/  20] time: 366.2154, loss: 0.00003646\n",
      "Epoch: [61] [   7/  20] time: 366.4622, loss: 0.00000690\n",
      "Epoch: [61] [   8/  20] time: 366.7087, loss: 0.00000180\n",
      "Epoch: [61] [   9/  20] time: 366.9586, loss: 0.00000419\n",
      "Epoch: [61] [  10/  20] time: 367.2177, loss: 0.00000080\n",
      "Epoch: [61] [  11/  20] time: 367.4648, loss: 0.00000037\n",
      "Epoch: [61] [  12/  20] time: 367.7121, loss: 0.00000654\n",
      "Epoch: [61] [  13/  20] time: 367.9636, loss: 0.00001932\n",
      "Epoch: [61] [  14/  20] time: 368.2155, loss: 0.00000045\n",
      "Epoch: [61] [  15/  20] time: 368.4617, loss: 0.00000033\n",
      "Epoch: [61] [  16/  20] time: 368.7124, loss: 0.00000127\n",
      "Epoch: [61] [  17/  20] time: 368.9600, loss: 0.00001895\n",
      "Epoch: [61] [  18/  20] time: 369.2200, loss: 0.00000126\n",
      "Epoch: [61] [  19/  20] time: 369.4668, loss: 0.00000084\n",
      "[61/80] - ptime: 5.3915 loss: 0.00000892 acc: 0.59000\n",
      "Epoch: [62] [   0/  20] time: 370.6852, loss: 0.00004938\n",
      "Epoch: [62] [   1/  20] time: 370.9359, loss: 0.00000603\n",
      "Epoch: [62] [   2/  20] time: 371.1972, loss: 0.00000810\n",
      "Epoch: [62] [   3/  20] time: 371.4563, loss: 0.00000260\n",
      "Epoch: [62] [   4/  20] time: 371.7058, loss: 0.00000252\n",
      "Epoch: [62] [   5/  20] time: 371.9558, loss: 0.00000333\n",
      "Epoch: [62] [   6/  20] time: 372.2130, loss: 0.00002278\n",
      "Epoch: [62] [   7/  20] time: 372.4705, loss: 0.00000478\n",
      "Epoch: [62] [   8/  20] time: 372.7165, loss: 0.00000311\n",
      "Epoch: [62] [   9/  20] time: 372.9680, loss: 0.00000038\n",
      "Epoch: [62] [  10/  20] time: 373.2291, loss: 0.00000152\n",
      "Epoch: [62] [  11/  20] time: 373.4925, loss: 0.00051504\n",
      "Epoch: [62] [  12/  20] time: 373.7409, loss: 0.00000534\n",
      "Epoch: [62] [  13/  20] time: 373.9903, loss: 0.00000158\n",
      "Epoch: [62] [  14/  20] time: 374.2499, loss: 0.00003625\n",
      "Epoch: [62] [  15/  20] time: 374.4943, loss: 0.00000677\n",
      "Epoch: [62] [  16/  20] time: 374.7411, loss: 0.00000016\n",
      "Epoch: [62] [  17/  20] time: 374.9894, loss: 0.00000491\n",
      "Epoch: [62] [  18/  20] time: 375.2485, loss: 0.00005137\n",
      "Epoch: [62] [  19/  20] time: 375.4938, loss: 0.00000121\n",
      "[62/80] - ptime: 5.4412 loss: 0.00003636 acc: 0.59000\n",
      "Epoch: [63] [   0/  20] time: 376.6945, loss: 0.00000229\n",
      "Epoch: [63] [   1/  20] time: 376.9415, loss: 0.00003322\n",
      "Epoch: [63] [   2/  20] time: 377.1956, loss: 0.00000051\n",
      "Epoch: [63] [   3/  20] time: 377.4541, loss: 0.00000636\n",
      "Epoch: [63] [   4/  20] time: 377.7026, loss: 0.00004039\n",
      "Epoch: [63] [   5/  20] time: 377.9472, loss: 0.00001924\n",
      "Epoch: [63] [   6/  20] time: 378.2028, loss: 0.00000080\n",
      "Epoch: [63] [   7/  20] time: 378.4683, loss: 0.00000116\n",
      "Epoch: [63] [   8/  20] time: 378.7242, loss: 0.00002515\n",
      "Epoch: [63] [   9/  20] time: 378.9715, loss: 0.00000169\n",
      "Epoch: [63] [  10/  20] time: 379.2278, loss: 0.00001316\n",
      "Epoch: [63] [  11/  20] time: 379.4902, loss: 0.00000149\n",
      "Epoch: [63] [  12/  20] time: 379.7382, loss: 0.00002871\n",
      "Epoch: [63] [  13/  20] time: 379.9872, loss: 0.00000635\n",
      "Epoch: [63] [  14/  20] time: 380.2451, loss: 0.00000064\n",
      "Epoch: [63] [  15/  20] time: 380.5077, loss: 0.00000898\n",
      "Epoch: [63] [  16/  20] time: 380.7640, loss: 0.00000153\n",
      "Epoch: [63] [  17/  20] time: 381.0163, loss: 0.00001553\n",
      "Epoch: [63] [  18/  20] time: 381.2748, loss: 0.00000383\n",
      "Epoch: [63] [  19/  20] time: 381.5270, loss: 0.00001093\n",
      "[63/80] - ptime: 5.4623 loss: 0.00001110 acc: 0.59000\n",
      "Epoch: [64] [   0/  20] time: 382.8295, loss: 0.00000056\n",
      "Epoch: [64] [   1/  20] time: 383.0758, loss: 0.00000059\n",
      "Epoch: [64] [   2/  20] time: 383.3377, loss: 0.00000039\n",
      "Epoch: [64] [   3/  20] time: 383.5846, loss: 0.00000043\n",
      "Epoch: [64] [   4/  20] time: 383.8305, loss: 0.00000183\n",
      "Epoch: [64] [   5/  20] time: 384.0809, loss: 0.00000113\n",
      "Epoch: [64] [   6/  20] time: 384.3380, loss: 0.00001174\n",
      "Epoch: [64] [   7/  20] time: 384.5853, loss: 0.00000185\n",
      "Epoch: [64] [   8/  20] time: 384.8315, loss: 0.00001661\n",
      "Epoch: [64] [   9/  20] time: 385.0815, loss: 0.00000099\n",
      "Epoch: [64] [  10/  20] time: 385.3364, loss: 0.00000137\n",
      "Epoch: [64] [  11/  20] time: 385.5833, loss: 0.00000016\n",
      "Epoch: [64] [  12/  20] time: 385.8305, loss: 0.00005072\n",
      "Epoch: [64] [  13/  20] time: 386.0774, loss: 0.00000049\n",
      "Epoch: [64] [  14/  20] time: 386.3286, loss: 0.00002968\n",
      "Epoch: [64] [  15/  20] time: 386.5756, loss: 0.00000239\n",
      "Epoch: [64] [  16/  20] time: 386.8211, loss: 0.00000463\n",
      "Epoch: [64] [  17/  20] time: 387.0705, loss: 0.00000545\n",
      "Epoch: [64] [  18/  20] time: 387.3283, loss: 0.00000401\n",
      "Epoch: [64] [  19/  20] time: 387.5758, loss: 0.00012937\n",
      "[64/80] - ptime: 5.4158 loss: 0.00001322 acc: 0.59000\n",
      "Epoch: [65] [   0/  20] time: 388.7860, loss: 0.00000246\n",
      "Epoch: [65] [   1/  20] time: 389.0322, loss: 0.00000353\n",
      "Epoch: [65] [   2/  20] time: 389.2926, loss: 0.00000395\n",
      "Epoch: [65] [   3/  20] time: 389.5397, loss: 0.00000125\n",
      "Epoch: [65] [   4/  20] time: 389.7925, loss: 0.00000129\n",
      "Epoch: [65] [   5/  20] time: 390.0413, loss: 0.00000137\n",
      "Epoch: [65] [   6/  20] time: 390.2993, loss: 0.00000203\n",
      "Epoch: [65] [   7/  20] time: 390.5426, loss: 0.00001662\n",
      "Epoch: [65] [   8/  20] time: 390.7920, loss: 0.00001789\n",
      "Epoch: [65] [   9/  20] time: 391.0411, loss: 0.00001868\n",
      "Epoch: [65] [  10/  20] time: 391.3014, loss: 0.00000488\n",
      "Epoch: [65] [  11/  20] time: 391.5460, loss: 0.00003168\n",
      "Epoch: [65] [  12/  20] time: 391.7942, loss: 0.00001483\n",
      "Epoch: [65] [  13/  20] time: 392.0429, loss: 0.00000065\n",
      "Epoch: [65] [  14/  20] time: 392.2997, loss: 0.00000117\n",
      "Epoch: [65] [  15/  20] time: 392.5458, loss: 0.00000215\n",
      "Epoch: [65] [  16/  20] time: 392.7927, loss: 0.00000520\n",
      "Epoch: [65] [  17/  20] time: 393.0425, loss: 0.00000508\n",
      "Epoch: [65] [  18/  20] time: 393.3025, loss: 0.00000871\n",
      "Epoch: [65] [  19/  20] time: 393.5579, loss: 0.00000348\n",
      "[65/80] - ptime: 5.4062 loss: 0.00000734 acc: 0.58000\n",
      "Epoch: [66] [   0/  20] time: 394.7760, loss: 0.00001255\n",
      "Epoch: [66] [   1/  20] time: 395.0232, loss: 0.00000688\n",
      "Epoch: [66] [   2/  20] time: 395.2818, loss: 0.00000267\n",
      "Epoch: [66] [   3/  20] time: 395.5517, loss: 0.00000016\n",
      "Epoch: [66] [   4/  20] time: 395.7995, loss: 0.00003195\n",
      "Epoch: [66] [   5/  20] time: 396.0487, loss: 0.00000128\n",
      "Epoch: [66] [   6/  20] time: 396.3039, loss: 0.00013379\n",
      "Epoch: [66] [   7/  20] time: 396.5581, loss: 0.00001237\n",
      "Epoch: [66] [   8/  20] time: 396.8065, loss: 0.00001469\n",
      "Epoch: [66] [   9/  20] time: 397.0541, loss: 0.00000120\n",
      "Epoch: [66] [  10/  20] time: 397.3110, loss: 0.00000804\n",
      "Epoch: [66] [  11/  20] time: 397.5656, loss: 0.00000064\n",
      "Epoch: [66] [  12/  20] time: 397.8153, loss: 0.00000104\n",
      "Epoch: [66] [  13/  20] time: 398.0638, loss: 0.00000219\n",
      "Epoch: [66] [  14/  20] time: 398.3238, loss: 0.00000156\n",
      "Epoch: [66] [  15/  20] time: 398.5858, loss: 0.00000820\n",
      "Epoch: [66] [  16/  20] time: 398.8322, loss: 0.00000181\n",
      "Epoch: [66] [  17/  20] time: 399.0818, loss: 0.00000177\n",
      "Epoch: [66] [  18/  20] time: 399.3397, loss: 0.00006842\n",
      "Epoch: [66] [  19/  20] time: 399.5988, loss: 0.00002834\n",
      "[66/80] - ptime: 5.4629 loss: 0.00001698 acc: 0.58000\n",
      "Epoch: [67] [   0/  20] time: 400.7843, loss: 0.00000094\n",
      "Epoch: [67] [   1/  20] time: 401.0281, loss: 0.00002279\n",
      "Epoch: [67] [   2/  20] time: 401.2809, loss: 0.00001988\n",
      "Epoch: [67] [   3/  20] time: 401.5415, loss: 0.00000028\n",
      "Epoch: [67] [   4/  20] time: 401.7876, loss: 0.00001744\n",
      "Epoch: [67] [   5/  20] time: 402.0344, loss: 0.00001071\n",
      "Epoch: [67] [   6/  20] time: 402.2841, loss: 0.00002984\n",
      "Epoch: [67] [   7/  20] time: 402.5440, loss: 0.00000219\n",
      "Epoch: [67] [   8/  20] time: 402.7994, loss: 0.00000078\n",
      "Epoch: [67] [   9/  20] time: 403.0457, loss: 0.00000587\n",
      "Epoch: [67] [  10/  20] time: 403.2967, loss: 0.00000186\n",
      "Epoch: [67] [  11/  20] time: 403.5495, loss: 0.00000202\n",
      "Epoch: [67] [  12/  20] time: 403.7981, loss: 0.00000616\n",
      "Epoch: [67] [  13/  20] time: 404.0454, loss: 0.00000742\n",
      "Epoch: [67] [  14/  20] time: 404.2953, loss: 0.00001408\n",
      "Epoch: [67] [  15/  20] time: 404.5552, loss: 0.00000090\n",
      "Epoch: [67] [  16/  20] time: 404.8014, loss: 0.00000606\n",
      "Epoch: [67] [  17/  20] time: 405.0500, loss: 0.00000976\n",
      "Epoch: [67] [  18/  20] time: 405.3001, loss: 0.00000994\n",
      "Epoch: [67] [  19/  20] time: 405.5525, loss: 0.00000072\n",
      "[67/80] - ptime: 5.4106 loss: 0.00000848 acc: 0.58000\n",
      "Epoch: [68] [   0/  20] time: 406.7401, loss: 0.00000335\n",
      "Epoch: [68] [   1/  20] time: 406.9813, loss: 0.00004159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [68] [   2/  20] time: 407.2333, loss: 0.00002845\n",
      "Epoch: [68] [   3/  20] time: 407.4897, loss: 0.00000020\n",
      "Epoch: [68] [   4/  20] time: 407.7428, loss: 0.00002109\n",
      "Epoch: [68] [   5/  20] time: 407.9900, loss: 0.00000096\n",
      "Epoch: [68] [   6/  20] time: 408.2405, loss: 0.00000001\n",
      "Epoch: [68] [   7/  20] time: 408.4998, loss: 0.00000264\n",
      "Epoch: [68] [   8/  20] time: 408.7493, loss: 0.00000968\n",
      "Epoch: [68] [   9/  20] time: 408.9957, loss: 0.00000026\n",
      "Epoch: [68] [  10/  20] time: 409.2455, loss: 0.00000499\n",
      "Epoch: [68] [  11/  20] time: 409.5079, loss: 0.00002972\n",
      "Epoch: [68] [  12/  20] time: 409.7555, loss: 0.00000045\n",
      "Epoch: [68] [  13/  20] time: 410.0017, loss: 0.00000021\n",
      "Epoch: [68] [  14/  20] time: 410.2549, loss: 0.00000855\n",
      "Epoch: [68] [  15/  20] time: 410.5113, loss: 0.00000069\n",
      "Epoch: [68] [  16/  20] time: 410.7604, loss: 0.00000008\n",
      "Epoch: [68] [  17/  20] time: 411.0075, loss: 0.00000159\n",
      "Epoch: [68] [  18/  20] time: 411.2569, loss: 0.00000372\n",
      "Epoch: [68] [  19/  20] time: 411.5054, loss: 0.00000016\n",
      "[68/80] - ptime: 5.4137 loss: 0.00000792 acc: 0.57000\n",
      "Epoch: [69] [   0/  20] time: 412.7054, loss: 0.00000627\n",
      "Epoch: [69] [   1/  20] time: 412.9496, loss: 0.00000542\n",
      "Epoch: [69] [   2/  20] time: 413.1995, loss: 0.00000140\n",
      "Epoch: [69] [   3/  20] time: 413.4603, loss: 0.00000324\n",
      "Epoch: [69] [   4/  20] time: 413.7196, loss: 0.00000469\n",
      "Epoch: [69] [   5/  20] time: 413.9655, loss: 0.00000072\n",
      "Epoch: [69] [   6/  20] time: 414.2167, loss: 0.00001246\n",
      "Epoch: [69] [   7/  20] time: 414.4748, loss: 0.00001035\n",
      "Epoch: [69] [   8/  20] time: 414.7226, loss: 0.00000049\n",
      "Epoch: [69] [   9/  20] time: 414.9664, loss: 0.00000213\n",
      "Epoch: [69] [  10/  20] time: 415.2169, loss: 0.00000072\n",
      "Epoch: [69] [  11/  20] time: 415.4763, loss: 0.00055547\n",
      "Epoch: [69] [  12/  20] time: 415.7275, loss: 0.00000105\n",
      "Epoch: [69] [  13/  20] time: 415.9725, loss: 0.00000188\n",
      "Epoch: [69] [  14/  20] time: 416.2239, loss: 0.00000180\n",
      "Epoch: [69] [  15/  20] time: 416.4808, loss: 0.00006731\n",
      "Epoch: [69] [  16/  20] time: 416.7235, loss: 0.00001033\n",
      "Epoch: [69] [  17/  20] time: 416.9689, loss: 0.00002687\n",
      "Epoch: [69] [  18/  20] time: 417.2187, loss: 0.00000118\n",
      "Epoch: [69] [  19/  20] time: 417.4766, loss: 0.00000468\n",
      "[69/80] - ptime: 5.4642 loss: 0.00003592 acc: 0.58000\n",
      "Epoch: [70] [   0/  20] time: 418.6902, loss: 0.00002887\n",
      "Epoch: [70] [   1/  20] time: 418.9336, loss: 0.00000384\n",
      "Epoch: [70] [   2/  20] time: 419.1803, loss: 0.00000536\n",
      "Epoch: [70] [   3/  20] time: 419.4412, loss: 0.00000076\n",
      "Epoch: [70] [   4/  20] time: 419.7014, loss: 0.00000087\n",
      "Epoch: [70] [   5/  20] time: 419.9478, loss: 0.00000063\n",
      "Epoch: [70] [   6/  20] time: 420.1957, loss: 0.00000003\n",
      "Epoch: [70] [   7/  20] time: 420.4553, loss: 0.00000047\n",
      "Epoch: [70] [   8/  20] time: 420.7215, loss: 0.00002332\n",
      "Epoch: [70] [   9/  20] time: 420.9683, loss: 0.00001784\n",
      "Epoch: [70] [  10/  20] time: 421.2188, loss: 0.00000716\n",
      "Epoch: [70] [  11/  20] time: 421.4768, loss: 0.00000020\n",
      "Epoch: [70] [  12/  20] time: 421.7378, loss: 0.00006192\n",
      "Epoch: [70] [  13/  20] time: 421.9828, loss: 0.00000623\n",
      "Epoch: [70] [  14/  20] time: 422.2317, loss: 0.00000008\n",
      "Epoch: [70] [  15/  20] time: 422.4887, loss: 0.00000972\n",
      "Epoch: [70] [  16/  20] time: 422.7505, loss: 0.00000115\n",
      "Epoch: [70] [  17/  20] time: 422.9979, loss: 0.00008193\n",
      "Epoch: [70] [  18/  20] time: 423.2490, loss: 0.00012269\n",
      "Epoch: [70] [  19/  20] time: 423.5080, loss: 0.00001321\n",
      "[70/80] - ptime: 5.5565 loss: 0.00001931 acc: 0.58000\n",
      "Epoch: [71] [   0/  20] time: 424.7344, loss: 0.00000866\n",
      "Epoch: [71] [   1/  20] time: 424.9820, loss: 0.00000436\n",
      "Epoch: [71] [   2/  20] time: 425.2300, loss: 0.00000157\n",
      "Epoch: [71] [   3/  20] time: 425.4878, loss: 0.00001578\n",
      "Epoch: [71] [   4/  20] time: 425.7509, loss: 0.00000283\n",
      "Epoch: [71] [   5/  20] time: 425.9971, loss: 0.00002339\n",
      "Epoch: [71] [   6/  20] time: 426.2492, loss: 0.00000367\n",
      "Epoch: [71] [   7/  20] time: 426.5077, loss: 0.00001120\n",
      "Epoch: [71] [   8/  20] time: 426.7699, loss: 0.00000147\n",
      "Epoch: [71] [   9/  20] time: 427.0147, loss: 0.00000013\n",
      "Epoch: [71] [  10/  20] time: 427.2658, loss: 0.00000334\n",
      "Epoch: [71] [  11/  20] time: 427.5238, loss: 0.00000288\n",
      "Epoch: [71] [  12/  20] time: 427.7783, loss: 0.00003075\n",
      "Epoch: [71] [  13/  20] time: 428.0241, loss: 0.00001890\n",
      "Epoch: [71] [  14/  20] time: 428.2757, loss: 0.00000751\n",
      "Epoch: [71] [  15/  20] time: 428.5302, loss: 0.00004299\n",
      "Epoch: [71] [  16/  20] time: 428.7876, loss: 0.00000169\n",
      "Epoch: [71] [  17/  20] time: 429.0348, loss: 0.00000511\n",
      "Epoch: [71] [  18/  20] time: 429.2867, loss: 0.00003353\n",
      "Epoch: [71] [  19/  20] time: 429.5440, loss: 0.00000216\n",
      "[71/80] - ptime: 5.5222 loss: 0.00001110 acc: 0.58000\n",
      "Epoch: [72] [   0/  20] time: 430.7614, loss: 0.00000082\n",
      "Epoch: [72] [   1/  20] time: 431.0050, loss: 0.00000560\n",
      "Epoch: [72] [   2/  20] time: 431.2554, loss: 0.00001465\n",
      "Epoch: [72] [   3/  20] time: 431.5092, loss: 0.00000005\n",
      "Epoch: [72] [   4/  20] time: 431.7613, loss: 0.00000660\n",
      "Epoch: [72] [   5/  20] time: 432.0080, loss: 0.00000187\n",
      "Epoch: [72] [   6/  20] time: 432.2588, loss: 0.00000721\n",
      "Epoch: [72] [   7/  20] time: 432.5097, loss: 0.00000108\n",
      "Epoch: [72] [   8/  20] time: 432.7762, loss: 0.00007087\n",
      "Epoch: [72] [   9/  20] time: 433.0244, loss: 0.00000369\n",
      "Epoch: [72] [  10/  20] time: 433.2745, loss: 0.00000015\n",
      "Epoch: [72] [  11/  20] time: 433.5274, loss: 0.00000073\n",
      "Epoch: [72] [  12/  20] time: 433.7847, loss: 0.00000328\n",
      "Epoch: [72] [  13/  20] time: 434.0293, loss: 0.00004172\n",
      "Epoch: [72] [  14/  20] time: 434.2767, loss: 0.00003859\n",
      "Epoch: [72] [  15/  20] time: 434.5270, loss: 0.00001291\n",
      "Epoch: [72] [  16/  20] time: 434.7859, loss: 0.00000067\n",
      "Epoch: [72] [  17/  20] time: 435.0320, loss: 0.00000991\n",
      "Epoch: [72] [  18/  20] time: 435.2816, loss: 0.00000813\n",
      "Epoch: [72] [  19/  20] time: 435.5338, loss: 0.00000232\n",
      "[72/80] - ptime: 5.4736 loss: 0.00001154 acc: 0.58000\n",
      "Epoch: [73] [   0/  20] time: 437.0961, loss: 0.00001041\n",
      "Epoch: [73] [   1/  20] time: 437.3440, loss: 0.00000001\n",
      "Epoch: [73] [   2/  20] time: 437.5937, loss: 0.00000060\n",
      "Epoch: [73] [   3/  20] time: 437.8545, loss: 0.00000030\n",
      "Epoch: [73] [   4/  20] time: 438.0989, loss: 0.00000625\n",
      "Epoch: [73] [   5/  20] time: 438.3445, loss: 0.00000249\n",
      "Epoch: [73] [   6/  20] time: 438.5954, loss: 0.00004333\n",
      "Epoch: [73] [   7/  20] time: 438.8444, loss: 0.00000151\n",
      "Epoch: [73] [   8/  20] time: 439.0864, loss: 0.00000053\n",
      "Epoch: [73] [   9/  20] time: 439.3321, loss: 0.00005330\n",
      "Epoch: [73] [  10/  20] time: 439.5820, loss: 0.00000155\n",
      "Epoch: [73] [  11/  20] time: 439.8342, loss: 0.00000201\n",
      "Epoch: [73] [  12/  20] time: 440.0817, loss: 0.00000152\n",
      "Epoch: [73] [  13/  20] time: 440.3291, loss: 0.00000487\n",
      "Epoch: [73] [  14/  20] time: 440.5811, loss: 0.00001117\n",
      "Epoch: [73] [  15/  20] time: 440.8358, loss: 0.00000256\n",
      "Epoch: [73] [  16/  20] time: 441.0812, loss: 0.00000412\n",
      "Epoch: [73] [  17/  20] time: 441.3278, loss: 0.00000190\n",
      "Epoch: [73] [  18/  20] time: 441.5787, loss: 0.00000010\n",
      "Epoch: [73] [  19/  20] time: 441.8337, loss: 0.00000154\n",
      "[73/80] - ptime: 5.3694 loss: 0.00000750 acc: 0.58000\n",
      "Epoch: [74] [   0/  20] time: 443.0043, loss: 0.00001161\n",
      "Epoch: [74] [   1/  20] time: 443.2583, loss: 0.00000129\n",
      "Epoch: [74] [   2/  20] time: 443.5071, loss: 0.00000403\n",
      "Epoch: [74] [   3/  20] time: 443.7642, loss: 0.00000861\n",
      "Epoch: [74] [   4/  20] time: 444.0201, loss: 0.00000043\n",
      "Epoch: [74] [   5/  20] time: 444.2686, loss: 0.00000352\n",
      "Epoch: [74] [   6/  20] time: 444.5172, loss: 0.00000153\n",
      "Epoch: [74] [   7/  20] time: 444.7730, loss: 0.00003237\n",
      "Epoch: [74] [   8/  20] time: 445.0274, loss: 0.00000996\n",
      "Epoch: [74] [   9/  20] time: 445.2744, loss: 0.00005953\n",
      "Epoch: [74] [  10/  20] time: 445.5238, loss: 0.00000057\n",
      "Epoch: [74] [  11/  20] time: 445.7819, loss: 0.00000164\n",
      "Epoch: [74] [  12/  20] time: 446.0398, loss: 0.00001071\n",
      "Epoch: [74] [  13/  20] time: 446.2860, loss: 0.00004680\n",
      "Epoch: [74] [  14/  20] time: 446.5444, loss: 0.00000189\n",
      "Epoch: [74] [  15/  20] time: 446.8177, loss: 0.00001477\n",
      "Epoch: [74] [  16/  20] time: 447.0818, loss: 0.00000532\n",
      "Epoch: [74] [  17/  20] time: 447.3291, loss: 0.00000085\n",
      "Epoch: [74] [  18/  20] time: 447.5787, loss: 0.00000676\n",
      "Epoch: [74] [  19/  20] time: 447.8429, loss: 0.00001030\n",
      "[74/80] - ptime: 5.5390 loss: 0.00001162 acc: 0.58000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75] [   0/  20] time: 449.1733, loss: 0.00000057\n",
      "Epoch: [75] [   1/  20] time: 449.4242, loss: 0.00000756\n",
      "Epoch: [75] [   2/  20] time: 449.6742, loss: 0.00000761\n",
      "Epoch: [75] [   3/  20] time: 449.9291, loss: 0.00000176\n",
      "Epoch: [75] [   4/  20] time: 450.1762, loss: 0.00001429\n",
      "Epoch: [75] [   5/  20] time: 450.4232, loss: 0.00000011\n",
      "Epoch: [75] [   6/  20] time: 450.6753, loss: 0.00000726\n",
      "Epoch: [75] [   7/  20] time: 450.9330, loss: 0.00000214\n",
      "Epoch: [75] [   8/  20] time: 451.1801, loss: 0.00000010\n",
      "Epoch: [75] [   9/  20] time: 451.4270, loss: 0.00000219\n",
      "Epoch: [75] [  10/  20] time: 451.6772, loss: 0.00000074\n",
      "Epoch: [75] [  11/  20] time: 451.9347, loss: 0.00001433\n",
      "Epoch: [75] [  12/  20] time: 452.1813, loss: 0.00000019\n",
      "Epoch: [75] [  13/  20] time: 452.4247, loss: 0.00000519\n",
      "Epoch: [75] [  14/  20] time: 452.6775, loss: 0.00000146\n",
      "Epoch: [75] [  15/  20] time: 452.9415, loss: 0.00000245\n",
      "Epoch: [75] [  16/  20] time: 453.1869, loss: 0.00000303\n",
      "Epoch: [75] [  17/  20] time: 453.4359, loss: 0.00000626\n",
      "Epoch: [75] [  18/  20] time: 453.6892, loss: 0.00000247\n",
      "Epoch: [75] [  19/  20] time: 453.9435, loss: 0.00000032\n",
      "[75/80] - ptime: 5.4407 loss: 0.00000400 acc: 0.57000\n",
      "Epoch: [76] [   0/  20] time: 455.1405, loss: 0.00020906\n",
      "Epoch: [76] [   1/  20] time: 455.3850, loss: 0.00000189\n",
      "Epoch: [76] [   2/  20] time: 455.6363, loss: 0.00000313\n",
      "Epoch: [76] [   3/  20] time: 455.8961, loss: 0.00000001\n",
      "Epoch: [76] [   4/  20] time: 456.1412, loss: 0.00001549\n",
      "Epoch: [76] [   5/  20] time: 456.3882, loss: 0.00002451\n",
      "Epoch: [76] [   6/  20] time: 456.6385, loss: 0.00000466\n",
      "Epoch: [76] [   7/  20] time: 456.8951, loss: 0.00000100\n",
      "Epoch: [76] [   8/  20] time: 457.1399, loss: 0.00000007\n",
      "Epoch: [76] [   9/  20] time: 457.3879, loss: 0.00000044\n",
      "Epoch: [76] [  10/  20] time: 457.6361, loss: 0.00001323\n",
      "Epoch: [76] [  11/  20] time: 457.8871, loss: 0.00000022\n",
      "Epoch: [76] [  12/  20] time: 458.1332, loss: 0.00000010\n",
      "Epoch: [76] [  13/  20] time: 458.3815, loss: 0.00000028\n",
      "Epoch: [76] [  14/  20] time: 458.6313, loss: 0.00000302\n",
      "Epoch: [76] [  15/  20] time: 458.8846, loss: 0.00001283\n",
      "Epoch: [76] [  16/  20] time: 459.1308, loss: 0.00000113\n",
      "Epoch: [76] [  17/  20] time: 459.3799, loss: 0.00000249\n",
      "Epoch: [76] [  18/  20] time: 459.6305, loss: 0.00000482\n",
      "Epoch: [76] [  19/  20] time: 459.8895, loss: 0.00006061\n",
      "[76/80] - ptime: 5.3919 loss: 0.00001795 acc: 0.57000\n",
      "Epoch: [77] [   0/  20] time: 461.0789, loss: 0.00000438\n",
      "Epoch: [77] [   1/  20] time: 461.3247, loss: 0.00000772\n",
      "Epoch: [77] [   2/  20] time: 461.5753, loss: 0.00000034\n",
      "Epoch: [77] [   3/  20] time: 461.8332, loss: 0.00000314\n",
      "Epoch: [77] [   4/  20] time: 462.0929, loss: 0.00001605\n",
      "Epoch: [77] [   5/  20] time: 462.3465, loss: 0.00000422\n",
      "Epoch: [77] [   6/  20] time: 462.5964, loss: 0.00000004\n",
      "Epoch: [77] [   7/  20] time: 462.8575, loss: 0.00000129\n",
      "Epoch: [77] [   8/  20] time: 463.1160, loss: 0.00000053\n",
      "Epoch: [77] [   9/  20] time: 463.3624, loss: 0.00000329\n",
      "Epoch: [77] [  10/  20] time: 463.6115, loss: 0.00000017\n",
      "Epoch: [77] [  11/  20] time: 463.8742, loss: 0.00002496\n",
      "Epoch: [77] [  12/  20] time: 464.1238, loss: 0.00000234\n",
      "Epoch: [77] [  13/  20] time: 464.3703, loss: 0.00000007\n",
      "Epoch: [77] [  14/  20] time: 464.6212, loss: 0.00000563\n",
      "Epoch: [77] [  15/  20] time: 464.8815, loss: 0.00000026\n",
      "Epoch: [77] [  16/  20] time: 465.1244, loss: 0.00000078\n",
      "Epoch: [77] [  17/  20] time: 465.3717, loss: 0.00000032\n",
      "Epoch: [77] [  18/  20] time: 465.6223, loss: 0.00000063\n",
      "Epoch: [77] [  19/  20] time: 465.8814, loss: 0.00002978\n",
      "[77/80] - ptime: 5.4876 loss: 0.00000530 acc: 0.59000\n",
      "Epoch: [78] [   0/  20] time: 467.1364, loss: 0.00000427\n",
      "Epoch: [78] [   1/  20] time: 467.3819, loss: 0.00000056\n",
      "Epoch: [78] [   2/  20] time: 467.6324, loss: 0.00000138\n",
      "Epoch: [78] [   3/  20] time: 467.8910, loss: 0.00000563\n",
      "Epoch: [78] [   4/  20] time: 468.1566, loss: 0.00000048\n",
      "Epoch: [78] [   5/  20] time: 468.4016, loss: 0.00000046\n",
      "Epoch: [78] [   6/  20] time: 468.6533, loss: 0.00002619\n",
      "Epoch: [78] [   7/  20] time: 468.9124, loss: 0.00000160\n",
      "Epoch: [78] [   8/  20] time: 469.1713, loss: 0.00000080\n",
      "Epoch: [78] [   9/  20] time: 469.4157, loss: 0.00000237\n",
      "Epoch: [78] [  10/  20] time: 469.6637, loss: 0.00000118\n",
      "Epoch: [78] [  11/  20] time: 469.9240, loss: 0.00000515\n",
      "Epoch: [78] [  12/  20] time: 470.1707, loss: 0.00000007\n",
      "Epoch: [78] [  13/  20] time: 470.4177, loss: 0.00017429\n",
      "Epoch: [78] [  14/  20] time: 470.6679, loss: 0.00001089\n",
      "Epoch: [78] [  15/  20] time: 470.9311, loss: 0.00000075\n",
      "Epoch: [78] [  16/  20] time: 471.1805, loss: 0.00006377\n",
      "Epoch: [78] [  17/  20] time: 471.4284, loss: 0.00000033\n",
      "Epoch: [78] [  18/  20] time: 471.6766, loss: 0.00000064\n",
      "Epoch: [78] [  19/  20] time: 471.9373, loss: 0.00000029\n",
      "[78/80] - ptime: 5.4884 loss: 0.00001506 acc: 0.57000\n",
      "Epoch: [79] [   0/  20] time: 473.1946, loss: 0.00000092\n",
      "Epoch: [79] [   1/  20] time: 473.4395, loss: 0.00000015\n",
      "Epoch: [79] [   2/  20] time: 473.6887, loss: 0.00000291\n",
      "Epoch: [79] [   3/  20] time: 473.9494, loss: 0.00000051\n",
      "Epoch: [79] [   4/  20] time: 474.1970, loss: 0.00000199\n",
      "Epoch: [79] [   5/  20] time: 474.4498, loss: 0.00000124\n",
      "Epoch: [79] [   6/  20] time: 474.7020, loss: 0.00001331\n",
      "Epoch: [79] [   7/  20] time: 474.9576, loss: 0.00003034\n",
      "Epoch: [79] [   8/  20] time: 475.2031, loss: 0.00000153\n",
      "Epoch: [79] [   9/  20] time: 475.4516, loss: 0.00000055\n",
      "Epoch: [79] [  10/  20] time: 475.7013, loss: 0.00000134\n",
      "Epoch: [79] [  11/  20] time: 475.9585, loss: 0.00003369\n",
      "Epoch: [79] [  12/  20] time: 476.2062, loss: 0.00000177\n",
      "Epoch: [79] [  13/  20] time: 476.4619, loss: 0.00000053\n",
      "Epoch: [79] [  14/  20] time: 476.7111, loss: 0.00000113\n",
      "Epoch: [79] [  15/  20] time: 476.9772, loss: 0.00001359\n",
      "Epoch: [79] [  16/  20] time: 477.2242, loss: 0.00000026\n",
      "Epoch: [79] [  17/  20] time: 477.4686, loss: 0.00000045\n",
      "Epoch: [79] [  18/  20] time: 477.7183, loss: 0.00000060\n",
      "Epoch: [79] [  19/  20] time: 477.9765, loss: 0.00000115\n",
      "[79/80] - ptime: 5.4505 loss: 0.00000540 acc: 0.58000\n",
      "Epoch: [80] [   0/  20] time: 479.2163, loss: 0.00000168\n",
      "Epoch: [80] [   1/  20] time: 479.4593, loss: 0.00000204\n",
      "Epoch: [80] [   2/  20] time: 479.7056, loss: 0.00000018\n",
      "Epoch: [80] [   3/  20] time: 479.9686, loss: 0.00000769\n",
      "Epoch: [80] [   4/  20] time: 480.2147, loss: 0.00000300\n",
      "Epoch: [80] [   5/  20] time: 480.4614, loss: 0.00000871\n",
      "Epoch: [80] [   6/  20] time: 480.7108, loss: 0.00002676\n",
      "Epoch: [80] [   7/  20] time: 480.9769, loss: 0.00000438\n",
      "Epoch: [80] [   8/  20] time: 481.2229, loss: 0.00000685\n",
      "Epoch: [80] [   9/  20] time: 481.4666, loss: 0.00001347\n",
      "Epoch: [80] [  10/  20] time: 481.7170, loss: 0.00001346\n",
      "Epoch: [80] [  11/  20] time: 481.9798, loss: 0.00000525\n",
      "Epoch: [80] [  12/  20] time: 482.2257, loss: 0.00000334\n",
      "Epoch: [80] [  13/  20] time: 482.4691, loss: 0.00000097\n",
      "Epoch: [80] [  14/  20] time: 482.7206, loss: 0.00000369\n",
      "Epoch: [80] [  15/  20] time: 482.9833, loss: 0.00001685\n",
      "Epoch: [80] [  16/  20] time: 483.2253, loss: 0.00000034\n",
      "Epoch: [80] [  17/  20] time: 483.4692, loss: 0.00000017\n",
      "Epoch: [80] [  18/  20] time: 483.7374, loss: 0.00000100\n",
      "Epoch: [80] [  19/  20] time: 483.9967, loss: 0.00000184\n",
      "[80/80] - ptime: 5.4444 loss: 0.00000608 acc: 0.58000\n",
      "Avg per epoch ptime: 5.46, total 80 epochs ptime: 484.56\n",
      " [*] Training finished!\n",
      " [*] Best Epoch:  9 , Accuracy:  0.800000011920929\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/CNN_CANNY_C5_D1_Kernel(3,3)_lrdecay0.95/CNN_CANNY_C5_D1_Kernel(3,3)_lrdecay0.95-9\n",
      " [*] Finished testing Best Epoch: 9 , accuracy:  0.800000011920929 !\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'CNN'\n",
    "dataset = '4_Flowers'\n",
    "epoch = 80\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "log_dir = 'logs'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    CNN = CNN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                log_dir=log_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    CNN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    CNN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    CNN.train()\n",
    "    \n",
    "#     CNN.test(epoch)\n",
    "        \n",
    "sess.close()\n",
    "# Avg per epoch ptime: 11.34, total 80 epochs ptime: 967.46\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  68 , Accuracy:  0.7400000095367432\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_CANNY_C5_D1_Kernel(3,3)_lrdecay0.95/CNN_CANNY_C5_D1_Kernel(3,3)_lrdecay0.95-68\n",
    "#  [*] Finished testing Best Epoch: 68 , accuracy:  0.7400000095367432 !\n",
    "\n",
    "# Avg per epoch ptime: 5.46, total 80 epochs ptime: 484.56\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  9 , Accuracy:  0.800000011920929\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_CANNY_C5_D1_Kernel(3,3)_lrdecay0.95/CNN_CANNY_C5_D1_Kernel(3,3)_lrdecay0.95-9\n",
    "#  [*] Finished testing Best Epoch: 9 , accuracy:  0.800000011920929 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "file='/home/huiqy/Music/CloudMusic/All_Time_Low.mp3' #文件名是完整路径名\n",
    "pygame.mixer.init() #初始化音频\n",
    "track = pygame.mixer.music.load(file)#载入音乐文件\n",
    "pygame.mixer.music.play()#开始播放\n",
    "time.sleep(60)#播放10秒\n",
    "pygame.mixer.music.stop()#停止播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
