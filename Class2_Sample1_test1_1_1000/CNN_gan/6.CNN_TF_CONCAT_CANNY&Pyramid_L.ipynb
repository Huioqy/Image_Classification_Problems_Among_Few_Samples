{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, log_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "        \n",
    "        # number of convolutional filters to use  \n",
    "        self.nb_CNN = [32, 64, 64, 64, 128]  \n",
    "        # number of dense filters to use  \n",
    "        self.nb_Dense = [256] \n",
    "        # size of pooling area for max pooling  \n",
    "        self.pool_size = (2, 2)  \n",
    "        # convolution kernel size  \n",
    "        self.kernel_size = (3, 3)\n",
    "        self.batch_normalization_control = True\n",
    "        \n",
    "        # name for checkpoint\n",
    "        self.model_name = 'CNN_Canny&Pyramid_L_C%d_D%d_Kernel(%d,%d)_%d_lrdecay' % (len(self.nb_CNN), len(self.nb_Dense),\n",
    "                                                          self.kernel_size[0], self.kernel_size[1], max(self.nb_CNN))\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(0.001, \n",
    "                                             global_step=self.global_step, \n",
    "                                             decay_steps=10, \n",
    "                                             decay_rate=0.9, \n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "        \n",
    "        # test\n",
    "\n",
    "        #load_flower_data\n",
    "        self.train_x = np.load('../trainImage.npy')\n",
    "        self.train_y = np.load('../trainLabels.npy')\n",
    "        self.test_x = np.load('../testImage.npy')\n",
    "        self.test_y = np.load('../testLabels.npy')\n",
    "        self.train_x_f1 = np.load('../trainImage_canny.npy')/255.0\n",
    "        self.test_x_f1 = np.load('../testImage_canny.npy')/255.0\n",
    "        self.train_x_f2 = np.load('../trainImage_pyramid_L.npy')/255.0\n",
    "        self.test_x_f2 = np.load('../testImage_pyramid_L.npy')/255.0\n",
    "\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['losses'] = []\n",
    "        self.train_hist['accuracy'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches_train = len(self.train_x) // self.batch_size\n",
    "        self.num_batches_test= len(self.test_x) // self.batch_size\n",
    "\n",
    "    def cnn_model(self, x, x_f1, x_f2, keep_prob, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"cnn\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            B = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"CNN:x\",x.get_shape()) # 128, 128, 3 \n",
    "            print(\"CNN:x_f1\",x_f1.get_shape()) \n",
    "            print(\"CNN:x_f2\",x_f2.get_shape())  \n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(inputs = x,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_1'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_1.get_shape())\n",
    "            \n",
    "            #输入x_f1,卷积核为3*3 输出维度为32\n",
    "            net1_2 = tf.layers.conv2d(inputs = x_f1,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_2'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_2.get_shape())\n",
    "            \n",
    "            #输入x_f2,卷积核为3*3 输出维度为32\n",
    "            net1_3 = tf.layers.conv2d(inputs = x_f2,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_3'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_3.get_shape())\n",
    "\n",
    "            #把数据和边缘进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            net = tf.concat([net, net1_3], 3)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)\n",
    "            net = tf.nn.relu(net, name = 'relu_conv_1')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_1'\n",
    "                                             )\n",
    "            \n",
    "            for i in range(2,len(self.nb_CNN)+1):\n",
    "                net = tf.layers.conv2d(inputs = net,                 # 输入,\n",
    "                                       filters = self.nb_CNN[i-1],      # 卷积核个数,\n",
    "                                       kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                       strides = (1, 1),\n",
    "                                       padding = 'same',              # padding方法\n",
    "                                       kernel_initializer = W,\n",
    "                                       bias_initializer = B,\n",
    "                                       kernel_regularizer = None,\n",
    "                                       bias_regularizer = None,\n",
    "                                       activity_regularizer = None,\n",
    "                                       name = 'conv_'+ str(i)        # 命名用于获取变量\n",
    "                                       )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "                if self.batch_normalization_control:\n",
    "                    net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_conv_' + str(i))\n",
    "                net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_' + str(i)\n",
    "                                             )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #flatten\n",
    "            net = tf.reshape(net, [-1, int(net.get_shape()[1]*net.get_shape()[2]*net.get_shape()[3])],name='flatten')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #dense layer\n",
    "            for i in range(1,len(self.nb_Dense)+1):\n",
    "                net = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_Dense[i-1],\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_' + str(i)\n",
    "                                    )\n",
    "#                 net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_dense_' + str(i))\n",
    "                net = tf.layers.dropout(inputs = net,\n",
    "                                        rate=keep_prob,\n",
    "                                        noise_shape=None,\n",
    "                                        seed=None,\n",
    "                                        training = is_training,\n",
    "                                        name= 'dropout_dense_' + str(i)\n",
    "                                        )\n",
    "            #output\n",
    "            logit = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_class,\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_output'\n",
    "                                    )\n",
    "            out_logit = tf.nn.softmax(logit, name=\"softmax\")\n",
    "            print(\"CNN:out_logit\",out_logit.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out_logit, logit\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.c_dim], \n",
    "                                name='x_image')\n",
    "        \n",
    "        self.x_f1= tf.placeholder(tf.float32, shape=[self.batch_size,self.train_x_f1.shape[1], \n",
    "                                                     self.train_x_f1.shape[2], self.train_x_f1.shape[3]],\n",
    "                                  name='x_f1')\n",
    "        self.x_f2= tf.placeholder(tf.float32, shape=[self.batch_size,self.train_x_f2.shape[1], \n",
    "                                                     self.train_x_f2.shape[2], self.train_x_f2.shape[3]],\n",
    "                                  name='x_f2')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[self.batch_size, self.nb_class], name='y_label')\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of cnn_model\n",
    "        self.out_logit, self.logit = self.cnn_model(self.x, self.x_f1, self.x_f2, self.keep_prob, is_training=True, reuse=False)\n",
    "        \n",
    "        self.loss_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,\n",
    "                                                                                         logits =self.logit))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # trainable variables into a group\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        cnn_vars = [var for var in tf_vars if var.name.startswith('cnn')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.cnn_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.loss_cross_entropy,\n",
    "                                                                                        var_list=cnn_vars)\n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        # output of cnn_model\n",
    "        self.out_logit_test, self.logit_test = self.cnn_model(self.x,  self.x_f1, self.x_f2, self.keep_prob, is_training=False, reuse=True)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logit_test, 1), tf.argmax(self.y, 1))\n",
    "        self.predict = tf.argmax(self.logit_test, 1)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        self.loss_sum = tf.summary.scalar(\"loss\", self.loss_cross_entropy)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep = self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name+'.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            CNN_losses = []\n",
    "  \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.train_x.shape[0]), self.train_x.shape[0])\n",
    "            shuffled_set = self.train_x[shuffle_idxs]\n",
    "            shuffled_set_f1 = self.train_x_f1[shuffle_idxs]\n",
    "            shuffled_set_f2 = self.train_x_f2[shuffle_idxs]\n",
    "            shuffled_label = self.train_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches_train):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_f1 = shuffled_set_f1[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_f2 = shuffled_set_f2[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, cnn_loss = self.sess.run([self.cnn_optim, self.loss_sum, self.loss_cross_entropy],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.x_f1: batch_x_f1,\n",
    "                                                          self.x_f2: batch_x_f2,\n",
    "                                                          self.y: batch_y,\n",
    "                                                          self.keep_prob: 0.5}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                CNN_losses.append(cnn_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" % (epoch_loop, idx, self.num_batches_train, \n",
    "                                                                          time.time() - start_time, cnn_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            # Evaluates accuracy on test set\n",
    "            test_accuracy_list = []\n",
    "            for idx_test in range(self.num_batches_test):\n",
    "                batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_f1_test =self.test_x_f1[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_f2_test =self.test_x_f2[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                   self.x_f1: batch_x_f1_test,\n",
    "                                                                   self.x_f2: batch_x_f2_test,\n",
    "                                                                    self.y: batch_y_tes,\n",
    "                                                                    self.keep_prob: 1.0})\n",
    "                test_accuracy_list.append(accuracy)\n",
    "            test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        \n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss: %.8f acc: %.5f lr: %.8f'% (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                    np.mean(CNN_losses), test_accuracy, rate))\n",
    "            \n",
    "            self.train_hist['losses'].append(np.mean(CNN_losses))\n",
    "            self.train_hist['accuracy'].append( test_accuracy)\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "            \n",
    "            # save trainhist for train\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name + '.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' \n",
    "                                 + self.model_name + '.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "        \"\"\"test after train\"\"\"\n",
    "        best_acc = max(self.train_hist['accuracy'])\n",
    "        beat_epoch = self.train_hist['accuracy'].index(best_acc) + 1\n",
    "        print (\" [*] Best Epoch: \", beat_epoch, \", Accuracy: \", best_acc)\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(beat_epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f1_test =self.test_x_f1[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f2_test =self.test_x_f2[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_f1: batch_x_f1_test,\n",
    "                                                                self.x_f2: batch_x_f2_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Best Epoch:\", beat_epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "\n",
    "    def test(self, epoch):\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f1_test =self.test_x_f1[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f2_test =self.test_x_f2[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_f1: batch_x_f1_test,\n",
    "                                                                self.x_f2: batch_x_f2_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Epoch:\", epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True) \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['losses'])+1)\n",
    "\n",
    "        y1 = hist['losses']\n",
    "        y2 = hist['accuracy']\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "                            \n",
    "        ax2 = ax1.twinx()  \n",
    "\n",
    "        ax1.plot(x, y1, 'b')\n",
    "        ax2.plot(x, y2, 'r')\n",
    "                            \n",
    "        ax1.set_xlabel('Epoch')\n",
    "                            \n",
    "        ax1.set_ylabel('CNN_loss')    \n",
    "        ax2.set_ylabel('accuracy')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_f1 (100, 128, 128, 1)\n",
      "CNN:x_f2 (100, 128, 128, 2)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 96)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_f1 (100, 128, 128, 1)\n",
      "CNN:x_f2 (100, 128, 128, 2)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 96)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "cnn/conv_1_1/kernel:0 (float32_ref 3x3x3x32) [864, bytes: 3456]\n",
      "cnn/conv_1_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_2/kernel:0 (float32_ref 3x3x1x32) [288, bytes: 1152]\n",
      "cnn/conv_1_2/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_3/kernel:0 (float32_ref 3x3x2x32) [576, bytes: 2304]\n",
      "cnn/conv_1_3/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/beta:0 (float32_ref 96) [96, bytes: 384]\n",
      "cnn/batch_normalization/gamma:0 (float32_ref 96) [96, bytes: 384]\n",
      "cnn/conv_2/kernel:0 (float32_ref 3x3x96x64) [55296, bytes: 221184]\n",
      "cnn/conv_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_3/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_3/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_4/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_5/kernel:0 (float32_ref 3x3x64x128) [73728, bytes: 294912]\n",
      "cnn/conv_5/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_1/kernel:0 (float32_ref 2048x256) [524288, bytes: 2097152]\n",
      "cnn/dense_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "cnn/dense_output/kernel:0 (float32_ref 256x2) [512, bytes: 2048]\n",
      "cnn/dense_output/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 730786\n",
      "Total bytes of variables: 2923144\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 1] [   0/  20] time: 3.1390, loss: 0.67436647\n",
      "Epoch: [ 1] [   1/  20] time: 3.4848, loss: 0.44242904\n",
      "Epoch: [ 1] [   2/  20] time: 3.8215, loss: 0.36804533\n",
      "Epoch: [ 1] [   3/  20] time: 4.1607, loss: 0.07805366\n",
      "Epoch: [ 1] [   4/  20] time: 4.5068, loss: 0.20626169\n",
      "Epoch: [ 1] [   5/  20] time: 4.8603, loss: 0.13963328\n",
      "Epoch: [ 1] [   6/  20] time: 5.2051, loss: 0.06180633\n",
      "Epoch: [ 1] [   7/  20] time: 5.5400, loss: 0.04355201\n",
      "Epoch: [ 1] [   8/  20] time: 5.8746, loss: 0.06915149\n",
      "Epoch: [ 1] [   9/  20] time: 6.2090, loss: 0.04919838\n",
      "Epoch: [ 1] [  10/  20] time: 6.5427, loss: 0.02146881\n",
      "Epoch: [ 1] [  11/  20] time: 6.8771, loss: 0.04849893\n",
      "Epoch: [ 1] [  12/  20] time: 7.2135, loss: 0.07486933\n",
      "Epoch: [ 1] [  13/  20] time: 7.5485, loss: 0.04440416\n",
      "Epoch: [ 1] [  14/  20] time: 7.8816, loss: 0.04360624\n",
      "Epoch: [ 1] [  15/  20] time: 8.2173, loss: 0.01889358\n",
      "Epoch: [ 1] [  16/  20] time: 8.5649, loss: 0.02763892\n",
      "Epoch: [ 1] [  17/  20] time: 8.9156, loss: 0.02650515\n",
      "Epoch: [ 1] [  18/  20] time: 9.2735, loss: 0.05587833\n",
      "Epoch: [ 1] [  19/  20] time: 9.6244, loss: 0.02966860\n",
      "[1/50] - ptime: 9.8061 loss: 0.12619649 acc: 0.79000 lr: 0.00100000\n",
      "Epoch: [ 2] [   0/  20] time: 11.1624, loss: 0.07345204\n",
      "Epoch: [ 2] [   1/  20] time: 11.5137, loss: 0.05006026\n",
      "Epoch: [ 2] [   2/  20] time: 11.8612, loss: 0.03524914\n",
      "Epoch: [ 2] [   3/  20] time: 12.2079, loss: 0.01997914\n",
      "Epoch: [ 2] [   4/  20] time: 12.5423, loss: 0.00585732\n",
      "Epoch: [ 2] [   5/  20] time: 12.8770, loss: 0.04122170\n",
      "Epoch: [ 2] [   6/  20] time: 13.2097, loss: 0.02097268\n",
      "Epoch: [ 2] [   7/  20] time: 13.5438, loss: 0.00494967\n",
      "Epoch: [ 2] [   8/  20] time: 13.8798, loss: 0.03448292\n",
      "Epoch: [ 2] [   9/  20] time: 14.2135, loss: 0.02130833\n",
      "Epoch: [ 2] [  10/  20] time: 14.5488, loss: 0.01153422\n",
      "Epoch: [ 2] [  11/  20] time: 14.8837, loss: 0.02783950\n",
      "Epoch: [ 2] [  12/  20] time: 15.2176, loss: 0.02174195\n",
      "Epoch: [ 2] [  13/  20] time: 15.5510, loss: 0.04989465\n",
      "Epoch: [ 2] [  14/  20] time: 15.8857, loss: 0.00337419\n",
      "Epoch: [ 2] [  15/  20] time: 16.2430, loss: 0.03694497\n",
      "Epoch: [ 2] [  16/  20] time: 16.5865, loss: 0.04639901\n",
      "Epoch: [ 2] [  17/  20] time: 16.9283, loss: 0.03543187\n",
      "Epoch: [ 2] [  18/  20] time: 17.2748, loss: 0.04363326\n",
      "Epoch: [ 2] [  19/  20] time: 17.6077, loss: 0.05373824\n",
      "[2/50] - ptime: 7.1683 loss: 0.03190326 acc: 0.79000 lr: 0.00100000\n",
      "Epoch: [ 3] [   0/  20] time: 18.6767, loss: 0.04003124\n",
      "Epoch: [ 3] [   1/  20] time: 19.0117, loss: 0.01761549\n",
      "Epoch: [ 3] [   2/  20] time: 19.3466, loss: 0.03589788\n",
      "Epoch: [ 3] [   3/  20] time: 19.6790, loss: 0.02351382\n",
      "Epoch: [ 3] [   4/  20] time: 20.0126, loss: 0.02793727\n",
      "Epoch: [ 3] [   5/  20] time: 20.3473, loss: 0.04532688\n",
      "Epoch: [ 3] [   6/  20] time: 20.6797, loss: 0.00835109\n",
      "Epoch: [ 3] [   7/  20] time: 21.0142, loss: 0.06729652\n",
      "Epoch: [ 3] [   8/  20] time: 21.3481, loss: 0.04310502\n",
      "Epoch: [ 3] [   9/  20] time: 21.6809, loss: 0.02204331\n",
      "Epoch: [ 3] [  10/  20] time: 22.0160, loss: 0.00438918\n",
      "Epoch: [ 3] [  11/  20] time: 22.3535, loss: 0.02541905\n",
      "Epoch: [ 3] [  12/  20] time: 22.6873, loss: 0.01356170\n",
      "Epoch: [ 3] [  13/  20] time: 23.0217, loss: 0.04090312\n",
      "Epoch: [ 3] [  14/  20] time: 23.3515, loss: 0.01497417\n",
      "Epoch: [ 3] [  15/  20] time: 23.6859, loss: 0.04059396\n",
      "Epoch: [ 3] [  16/  20] time: 24.0199, loss: 0.03263414\n",
      "Epoch: [ 3] [  17/  20] time: 24.3551, loss: 0.04954816\n",
      "Epoch: [ 3] [  18/  20] time: 24.6887, loss: 0.02896451\n",
      "Epoch: [ 3] [  19/  20] time: 25.0228, loss: 0.09085868\n",
      "[3/50] - ptime: 7.0426 loss: 0.03364826 acc: 0.79000 lr: 0.00100000\n",
      "Epoch: [ 4] [   0/  20] time: 26.1270, loss: 0.10061681\n",
      "Epoch: [ 4] [   1/  20] time: 26.4616, loss: 0.01310531\n",
      "Epoch: [ 4] [   2/  20] time: 26.7992, loss: 0.01648286\n",
      "Epoch: [ 4] [   3/  20] time: 27.1345, loss: 0.05469308\n",
      "Epoch: [ 4] [   4/  20] time: 27.4712, loss: 0.02170964\n",
      "Epoch: [ 4] [   5/  20] time: 27.8046, loss: 0.02657059\n",
      "Epoch: [ 4] [   6/  20] time: 28.1389, loss: 0.02788730\n",
      "Epoch: [ 4] [   7/  20] time: 28.4764, loss: 0.01020110\n",
      "Epoch: [ 4] [   8/  20] time: 28.8117, loss: 0.01874030\n",
      "Epoch: [ 4] [   9/  20] time: 29.1464, loss: 0.00114920\n",
      "Epoch: [ 4] [  10/  20] time: 29.4841, loss: 0.03549570\n",
      "Epoch: [ 4] [  11/  20] time: 29.8195, loss: 0.03535988\n",
      "Epoch: [ 4] [  12/  20] time: 30.1537, loss: 0.05649569\n",
      "Epoch: [ 4] [  13/  20] time: 30.4878, loss: 0.03741497\n",
      "Epoch: [ 4] [  14/  20] time: 30.8227, loss: 0.02713393\n",
      "Epoch: [ 4] [  15/  20] time: 31.1615, loss: 0.01777977\n",
      "Epoch: [ 4] [  16/  20] time: 31.4938, loss: 0.05185719\n",
      "Epoch: [ 4] [  17/  20] time: 31.8295, loss: 0.02100847\n",
      "Epoch: [ 4] [  18/  20] time: 32.1643, loss: 0.02679508\n",
      "Epoch: [ 4] [  19/  20] time: 32.4958, loss: 0.00799279\n",
      "[4/50] - ptime: 7.0770 loss: 0.03042448 acc: 0.79000 lr: 0.00100000\n",
      "Epoch: [ 5] [   0/  20] time: 33.6486, loss: 0.00802741\n",
      "Epoch: [ 5] [   1/  20] time: 33.9832, loss: 0.03517037\n",
      "Epoch: [ 5] [   2/  20] time: 34.3191, loss: 0.02500906\n",
      "Epoch: [ 5] [   3/  20] time: 34.6560, loss: 0.01064081\n",
      "Epoch: [ 5] [   4/  20] time: 34.9926, loss: 0.02421334\n",
      "Epoch: [ 5] [   5/  20] time: 35.3284, loss: 0.01540563\n",
      "Epoch: [ 5] [   6/  20] time: 35.6735, loss: 0.01806106\n",
      "Epoch: [ 5] [   7/  20] time: 36.0108, loss: 0.03410434\n",
      "Epoch: [ 5] [   8/  20] time: 36.3471, loss: 0.00409467\n",
      "Epoch: [ 5] [   9/  20] time: 36.6817, loss: 0.13589638\n",
      "Epoch: [ 5] [  10/  20] time: 37.0200, loss: 0.03272924\n",
      "Epoch: [ 5] [  11/  20] time: 37.3557, loss: 0.01745934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 5] [  12/  20] time: 37.6889, loss: 0.00453151\n",
      "Epoch: [ 5] [  13/  20] time: 38.0250, loss: 0.03966414\n",
      "Epoch: [ 5] [  14/  20] time: 38.3604, loss: 0.02931387\n",
      "Epoch: [ 5] [  15/  20] time: 38.6958, loss: 0.03004435\n",
      "Epoch: [ 5] [  16/  20] time: 39.0319, loss: 0.08508901\n",
      "Epoch: [ 5] [  17/  20] time: 39.3694, loss: 0.03179241\n",
      "Epoch: [ 5] [  18/  20] time: 39.7081, loss: 0.02818531\n",
      "Epoch: [ 5] [  19/  20] time: 40.0422, loss: 0.04777849\n",
      "[5/50] - ptime: 7.1125 loss: 0.03286054 acc: 0.77000 lr: 0.00100000\n",
      "Epoch: [ 6] [   0/  20] time: 41.1564, loss: 0.01692673\n",
      "Epoch: [ 6] [   1/  20] time: 41.4901, loss: 0.04090896\n",
      "Epoch: [ 6] [   2/  20] time: 41.8233, loss: 0.03011173\n",
      "Epoch: [ 6] [   3/  20] time: 42.1575, loss: 0.00601389\n",
      "Epoch: [ 6] [   4/  20] time: 42.4950, loss: 0.02554172\n",
      "Epoch: [ 6] [   5/  20] time: 42.8285, loss: 0.00733499\n",
      "Epoch: [ 6] [   6/  20] time: 43.1621, loss: 0.02366106\n",
      "Epoch: [ 6] [   7/  20] time: 43.4977, loss: 0.01493681\n",
      "Epoch: [ 6] [   8/  20] time: 43.8379, loss: 0.00841961\n",
      "Epoch: [ 6] [   9/  20] time: 44.1711, loss: 0.01119836\n",
      "Epoch: [ 6] [  10/  20] time: 44.5072, loss: 0.01209598\n",
      "Epoch: [ 6] [  11/  20] time: 44.8426, loss: 0.01174911\n",
      "Epoch: [ 6] [  12/  20] time: 45.1797, loss: 0.01176521\n",
      "Epoch: [ 6] [  13/  20] time: 45.5156, loss: 0.01630135\n",
      "Epoch: [ 6] [  14/  20] time: 45.8504, loss: 0.02913062\n",
      "Epoch: [ 6] [  15/  20] time: 46.1841, loss: 0.01820271\n",
      "Epoch: [ 6] [  16/  20] time: 46.5195, loss: 0.06432344\n",
      "Epoch: [ 6] [  17/  20] time: 46.8550, loss: 0.01727047\n",
      "Epoch: [ 6] [  18/  20] time: 47.1895, loss: 0.03331078\n",
      "Epoch: [ 6] [  19/  20] time: 47.5271, loss: 0.01113351\n",
      "[6/50] - ptime: 7.0736 loss: 0.02051685 acc: 0.77000 lr: 0.00100000\n",
      "Epoch: [ 7] [   0/  20] time: 48.6129, loss: 0.04037571\n",
      "Epoch: [ 7] [   1/  20] time: 48.9493, loss: 0.02064400\n",
      "Epoch: [ 7] [   2/  20] time: 49.2838, loss: 0.05812150\n",
      "Epoch: [ 7] [   3/  20] time: 49.6178, loss: 0.03548769\n",
      "Epoch: [ 7] [   4/  20] time: 49.9539, loss: 0.00645979\n",
      "Epoch: [ 7] [   5/  20] time: 50.2892, loss: 0.03103369\n",
      "Epoch: [ 7] [   6/  20] time: 50.6235, loss: 0.01027748\n",
      "Epoch: [ 7] [   7/  20] time: 50.9589, loss: 0.02375843\n",
      "Epoch: [ 7] [   8/  20] time: 51.2923, loss: 0.00205176\n",
      "Epoch: [ 7] [   9/  20] time: 51.6265, loss: 0.00031862\n",
      "Epoch: [ 7] [  10/  20] time: 51.9648, loss: 0.01281570\n",
      "Epoch: [ 7] [  11/  20] time: 52.2985, loss: 0.00779090\n",
      "Epoch: [ 7] [  12/  20] time: 52.6349, loss: 0.00640105\n",
      "Epoch: [ 7] [  13/  20] time: 52.9704, loss: 0.00964943\n",
      "Epoch: [ 7] [  14/  20] time: 53.3045, loss: 0.01526083\n",
      "Epoch: [ 7] [  15/  20] time: 53.6382, loss: 0.03343371\n",
      "Epoch: [ 7] [  16/  20] time: 53.9744, loss: 0.02824518\n",
      "Epoch: [ 7] [  17/  20] time: 54.3080, loss: 0.01406579\n",
      "Epoch: [ 7] [  18/  20] time: 54.6417, loss: 0.01557276\n",
      "Epoch: [ 7] [  19/  20] time: 54.9782, loss: 0.01627918\n",
      "[7/50] - ptime: 7.0797 loss: 0.01940216 acc: 0.81000 lr: 0.00100000\n",
      "Epoch: [ 8] [   0/  20] time: 56.0548, loss: 0.00639930\n",
      "Epoch: [ 8] [   1/  20] time: 56.3908, loss: 0.01000668\n",
      "Epoch: [ 8] [   2/  20] time: 56.7251, loss: 0.00967350\n",
      "Epoch: [ 8] [   3/  20] time: 57.0601, loss: 0.00953899\n",
      "Epoch: [ 8] [   4/  20] time: 57.3946, loss: 0.01621335\n",
      "Epoch: [ 8] [   5/  20] time: 57.7280, loss: 0.02374672\n",
      "Epoch: [ 8] [   6/  20] time: 58.0646, loss: 0.02735718\n",
      "Epoch: [ 8] [   7/  20] time: 58.4000, loss: 0.00755332\n",
      "Epoch: [ 8] [   8/  20] time: 58.7346, loss: 0.00559296\n",
      "Epoch: [ 8] [   9/  20] time: 59.0686, loss: 0.00176642\n",
      "Epoch: [ 8] [  10/  20] time: 59.4050, loss: 0.00791379\n",
      "Epoch: [ 8] [  11/  20] time: 59.7387, loss: 0.03008196\n",
      "Epoch: [ 8] [  12/  20] time: 60.0734, loss: 0.00359651\n",
      "Epoch: [ 8] [  13/  20] time: 60.4093, loss: 0.01168809\n",
      "Epoch: [ 8] [  14/  20] time: 60.7429, loss: 0.05979419\n",
      "Epoch: [ 8] [  15/  20] time: 61.0795, loss: 0.02420912\n",
      "Epoch: [ 8] [  16/  20] time: 61.4147, loss: 0.02579853\n",
      "Epoch: [ 8] [  17/  20] time: 61.7482, loss: 0.04048886\n",
      "Epoch: [ 8] [  18/  20] time: 62.0825, loss: 0.03494047\n",
      "Epoch: [ 8] [  19/  20] time: 62.4183, loss: 0.04189187\n",
      "[8/50] - ptime: 7.0686 loss: 0.01991259 acc: 0.68000 lr: 0.00100000\n",
      "Epoch: [ 9] [   0/  20] time: 63.5154, loss: 0.02704630\n",
      "Epoch: [ 9] [   1/  20] time: 63.8496, loss: 0.02043714\n",
      "Epoch: [ 9] [   2/  20] time: 64.1833, loss: 0.00480391\n",
      "Epoch: [ 9] [   3/  20] time: 64.5182, loss: 0.00717185\n",
      "Epoch: [ 9] [   4/  20] time: 64.8532, loss: 0.14567286\n",
      "Epoch: [ 9] [   5/  20] time: 65.1881, loss: 0.02590289\n",
      "Epoch: [ 9] [   6/  20] time: 65.5257, loss: 0.00317258\n",
      "Epoch: [ 9] [   7/  20] time: 65.8614, loss: 0.00362806\n",
      "Epoch: [ 9] [   8/  20] time: 66.1957, loss: 0.04211033\n",
      "Epoch: [ 9] [   9/  20] time: 66.5275, loss: 0.00592603\n",
      "Epoch: [ 9] [  10/  20] time: 66.8629, loss: 0.01607269\n",
      "Epoch: [ 9] [  11/  20] time: 67.1983, loss: 0.02757834\n",
      "Epoch: [ 9] [  12/  20] time: 67.5342, loss: 0.02261421\n",
      "Epoch: [ 9] [  13/  20] time: 67.8745, loss: 0.01408054\n",
      "Epoch: [ 9] [  14/  20] time: 68.2073, loss: 0.01017204\n",
      "Epoch: [ 9] [  15/  20] time: 68.5422, loss: 0.01754707\n",
      "Epoch: [ 9] [  16/  20] time: 68.8773, loss: 0.01065741\n",
      "Epoch: [ 9] [  17/  20] time: 69.2109, loss: 0.03391708\n",
      "Epoch: [ 9] [  18/  20] time: 69.5472, loss: 0.05666561\n",
      "Epoch: [ 9] [  19/  20] time: 69.8828, loss: 0.02566509\n",
      "[9/50] - ptime: 7.0841 loss: 0.02604210 acc: 0.61000 lr: 0.00100000\n",
      "Epoch: [10] [   0/  20] time: 70.9830, loss: 0.03209722\n",
      "Epoch: [10] [   1/  20] time: 71.3177, loss: 0.07954572\n",
      "Epoch: [10] [   2/  20] time: 71.6554, loss: 0.00664226\n",
      "Epoch: [10] [   3/  20] time: 71.9911, loss: 0.06803690\n",
      "Epoch: [10] [   4/  20] time: 72.3253, loss: 0.01659102\n",
      "Epoch: [10] [   5/  20] time: 72.6604, loss: 0.01979978\n",
      "Epoch: [10] [   6/  20] time: 72.9974, loss: 0.00185113\n",
      "Epoch: [10] [   7/  20] time: 73.3332, loss: 0.00164607\n",
      "Epoch: [10] [   8/  20] time: 73.6678, loss: 0.01223348\n",
      "Epoch: [10] [   9/  20] time: 74.0073, loss: 0.00817306\n",
      "Epoch: [10] [  10/  20] time: 74.3425, loss: 0.00145344\n",
      "Epoch: [10] [  11/  20] time: 74.6791, loss: 0.02267361\n",
      "Epoch: [10] [  12/  20] time: 75.0181, loss: 0.03277875\n",
      "Epoch: [10] [  13/  20] time: 75.3534, loss: 0.02366943\n",
      "Epoch: [10] [  14/  20] time: 75.6905, loss: 0.03069291\n",
      "Epoch: [10] [  15/  20] time: 76.0273, loss: 0.01374220\n",
      "Epoch: [10] [  16/  20] time: 76.3661, loss: 0.00377796\n",
      "Epoch: [10] [  17/  20] time: 76.7011, loss: 0.02277659\n",
      "Epoch: [10] [  18/  20] time: 77.0370, loss: 0.06100846\n",
      "Epoch: [10] [  19/  20] time: 77.3736, loss: 0.00441646\n",
      "[10/50] - ptime: 7.0934 loss: 0.02318032 acc: 0.51000 lr: 0.00090000\n",
      "Epoch: [11] [   0/  20] time: 78.4332, loss: 0.01319715\n",
      "Epoch: [11] [   1/  20] time: 78.7673, loss: 0.01632691\n",
      "Epoch: [11] [   2/  20] time: 79.1009, loss: 0.03279546\n",
      "Epoch: [11] [   3/  20] time: 79.4373, loss: 0.01437443\n",
      "Epoch: [11] [   4/  20] time: 79.7711, loss: 0.01225025\n",
      "Epoch: [11] [   5/  20] time: 80.1131, loss: 0.01881704\n",
      "Epoch: [11] [   6/  20] time: 80.4546, loss: 0.00598480\n",
      "Epoch: [11] [   7/  20] time: 80.7905, loss: 0.01122260\n",
      "Epoch: [11] [   8/  20] time: 81.1245, loss: 0.00465981\n",
      "Epoch: [11] [   9/  20] time: 81.4602, loss: 0.01845199\n",
      "Epoch: [11] [  10/  20] time: 81.7948, loss: 0.01153262\n",
      "Epoch: [11] [  11/  20] time: 82.1286, loss: 0.00050157\n",
      "Epoch: [11] [  12/  20] time: 82.4638, loss: 0.02746444\n",
      "Epoch: [11] [  13/  20] time: 82.7981, loss: 0.02122726\n",
      "Epoch: [11] [  14/  20] time: 83.1320, loss: 0.01124598\n",
      "Epoch: [11] [  15/  20] time: 83.4701, loss: 0.00341761\n",
      "Epoch: [11] [  16/  20] time: 83.8042, loss: 0.00026216\n",
      "Epoch: [11] [  17/  20] time: 84.1414, loss: 0.01172561\n",
      "Epoch: [11] [  18/  20] time: 84.4759, loss: 0.00767866\n",
      "Epoch: [11] [  19/  20] time: 84.8105, loss: 0.00990868\n",
      "[11/50] - ptime: 7.0740 loss: 0.01265225 acc: 0.70000 lr: 0.00090000\n",
      "Epoch: [12] [   0/  20] time: 85.8898, loss: 0.00771278\n",
      "Epoch: [12] [   1/  20] time: 86.2248, loss: 0.01077171\n",
      "Epoch: [12] [   2/  20] time: 86.5607, loss: 0.00203203\n",
      "Epoch: [12] [   3/  20] time: 86.8978, loss: 0.00363768\n",
      "Epoch: [12] [   4/  20] time: 87.2385, loss: 0.00707345\n",
      "Epoch: [12] [   5/  20] time: 87.5798, loss: 0.01408297\n",
      "Epoch: [12] [   6/  20] time: 87.9158, loss: 0.00248088\n",
      "Epoch: [12] [   7/  20] time: 88.2514, loss: 0.01503568\n",
      "Epoch: [12] [   8/  20] time: 88.5870, loss: 0.00136627\n",
      "Epoch: [12] [   9/  20] time: 88.9260, loss: 0.00204946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12] [  10/  20] time: 89.2617, loss: 0.00281210\n",
      "Epoch: [12] [  11/  20] time: 89.5986, loss: 0.00801758\n",
      "Epoch: [12] [  12/  20] time: 89.9357, loss: 0.00355978\n",
      "Epoch: [12] [  13/  20] time: 90.2715, loss: 0.00188788\n",
      "Epoch: [12] [  14/  20] time: 90.6080, loss: 0.00197522\n",
      "Epoch: [12] [  15/  20] time: 90.9447, loss: 0.00642548\n",
      "Epoch: [12] [  16/  20] time: 91.2799, loss: 0.00914538\n",
      "Epoch: [12] [  17/  20] time: 91.6149, loss: 0.01293946\n",
      "Epoch: [12] [  18/  20] time: 91.9541, loss: 0.00634168\n",
      "Epoch: [12] [  19/  20] time: 92.2907, loss: 0.00096497\n",
      "[12/50] - ptime: 7.0986 loss: 0.00601562 acc: 0.74000 lr: 0.00090000\n",
      "Epoch: [13] [   0/  20] time: 93.4831, loss: 0.00040206\n",
      "Epoch: [13] [   1/  20] time: 93.8185, loss: 0.00068967\n",
      "Epoch: [13] [   2/  20] time: 94.1549, loss: 0.00683210\n",
      "Epoch: [13] [   3/  20] time: 94.4927, loss: 0.01050522\n",
      "Epoch: [13] [   4/  20] time: 94.8282, loss: 0.00130877\n",
      "Epoch: [13] [   5/  20] time: 95.1626, loss: 0.00008885\n",
      "Epoch: [13] [   6/  20] time: 95.5022, loss: 0.00086015\n",
      "Epoch: [13] [   7/  20] time: 95.8381, loss: 0.00614349\n",
      "Epoch: [13] [   8/  20] time: 96.1736, loss: 0.00524320\n",
      "Epoch: [13] [   9/  20] time: 96.5083, loss: 0.00584776\n",
      "Epoch: [13] [  10/  20] time: 96.8434, loss: 0.00763595\n",
      "Epoch: [13] [  11/  20] time: 97.1770, loss: 0.00199309\n",
      "Epoch: [13] [  12/  20] time: 97.5141, loss: 0.00179198\n",
      "Epoch: [13] [  13/  20] time: 97.8533, loss: 0.01299054\n",
      "Epoch: [13] [  14/  20] time: 98.1878, loss: 0.01221209\n",
      "Epoch: [13] [  15/  20] time: 98.5255, loss: 0.00087876\n",
      "Epoch: [13] [  16/  20] time: 98.8659, loss: 0.00006099\n",
      "Epoch: [13] [  17/  20] time: 99.2001, loss: 0.00061870\n",
      "Epoch: [13] [  18/  20] time: 99.5366, loss: 0.02119798\n",
      "Epoch: [13] [  19/  20] time: 99.8744, loss: 0.00059330\n",
      "[13/50] - ptime: 7.0916 loss: 0.00489473 acc: 0.72000 lr: 0.00090000\n",
      "Epoch: [14] [   0/  20] time: 100.9484, loss: 0.02494488\n",
      "Epoch: [14] [   1/  20] time: 101.2835, loss: 0.00404100\n",
      "Epoch: [14] [   2/  20] time: 101.6189, loss: 0.00030194\n",
      "Epoch: [14] [   3/  20] time: 101.9552, loss: 0.00432295\n",
      "Epoch: [14] [   4/  20] time: 102.2910, loss: 0.00468943\n",
      "Epoch: [14] [   5/  20] time: 102.6274, loss: 0.00575970\n",
      "Epoch: [14] [   6/  20] time: 102.9636, loss: 0.00943804\n",
      "Epoch: [14] [   7/  20] time: 103.2991, loss: 0.00208455\n",
      "Epoch: [14] [   8/  20] time: 103.6377, loss: 0.00911311\n",
      "Epoch: [14] [   9/  20] time: 103.9750, loss: 0.00187550\n",
      "Epoch: [14] [  10/  20] time: 104.3107, loss: 0.00204940\n",
      "Epoch: [14] [  11/  20] time: 104.6467, loss: 0.00136058\n",
      "Epoch: [14] [  12/  20] time: 104.9837, loss: 0.00798592\n",
      "Epoch: [14] [  13/  20] time: 105.3198, loss: 0.00537890\n",
      "Epoch: [14] [  14/  20] time: 105.6564, loss: 0.00330051\n",
      "Epoch: [14] [  15/  20] time: 105.9933, loss: 0.00562994\n",
      "Epoch: [14] [  16/  20] time: 106.3289, loss: 0.01570598\n",
      "Epoch: [14] [  17/  20] time: 106.6662, loss: 0.00852179\n",
      "Epoch: [14] [  18/  20] time: 107.0039, loss: 0.01927136\n",
      "Epoch: [14] [  19/  20] time: 107.3420, loss: 0.00312292\n",
      "[14/50] - ptime: 7.0865 loss: 0.00694492 acc: 0.61000 lr: 0.00090000\n",
      "Epoch: [15] [   0/  20] time: 108.4193, loss: 0.02220247\n",
      "Epoch: [15] [   1/  20] time: 108.7548, loss: 0.01639624\n",
      "Epoch: [15] [   2/  20] time: 109.0911, loss: 0.00162670\n",
      "Epoch: [15] [   3/  20] time: 109.4316, loss: 0.02584951\n",
      "Epoch: [15] [   4/  20] time: 109.7660, loss: 0.00747909\n",
      "Epoch: [15] [   5/  20] time: 110.1009, loss: 0.02918042\n",
      "Epoch: [15] [   6/  20] time: 110.4370, loss: 0.01155871\n",
      "Epoch: [15] [   7/  20] time: 110.7727, loss: 0.00121566\n",
      "Epoch: [15] [   8/  20] time: 111.1069, loss: 0.00954298\n",
      "Epoch: [15] [   9/  20] time: 111.4422, loss: 0.00184416\n",
      "Epoch: [15] [  10/  20] time: 111.7774, loss: 0.01994067\n",
      "Epoch: [15] [  11/  20] time: 112.1139, loss: 0.00304596\n",
      "Epoch: [15] [  12/  20] time: 112.4488, loss: 0.00757343\n",
      "Epoch: [15] [  13/  20] time: 112.7828, loss: 0.00571729\n",
      "Epoch: [15] [  14/  20] time: 113.1186, loss: 0.00127817\n",
      "Epoch: [15] [  15/  20] time: 113.4538, loss: 0.01956873\n",
      "Epoch: [15] [  16/  20] time: 113.7882, loss: 0.00602424\n",
      "Epoch: [15] [  17/  20] time: 114.1233, loss: 0.00215837\n",
      "Epoch: [15] [  18/  20] time: 114.4620, loss: 0.00135388\n",
      "Epoch: [15] [  19/  20] time: 114.7985, loss: 0.00152116\n",
      "[15/50] - ptime: 7.0767 loss: 0.00975389 acc: 0.73000 lr: 0.00090000\n",
      "Epoch: [16] [   0/  20] time: 115.8911, loss: 0.00249995\n",
      "Epoch: [16] [   1/  20] time: 116.2274, loss: 0.00056221\n",
      "Epoch: [16] [   2/  20] time: 116.5636, loss: 0.01005985\n",
      "Epoch: [16] [   3/  20] time: 116.8990, loss: 0.00196471\n",
      "Epoch: [16] [   4/  20] time: 117.2366, loss: 0.00426900\n",
      "Epoch: [16] [   5/  20] time: 117.5740, loss: 0.00072613\n",
      "Epoch: [16] [   6/  20] time: 117.9102, loss: 0.00011405\n",
      "Epoch: [16] [   7/  20] time: 118.2442, loss: 0.00001604\n",
      "Epoch: [16] [   8/  20] time: 118.5814, loss: 0.00154186\n",
      "Epoch: [16] [   9/  20] time: 118.9205, loss: 0.00076502\n",
      "Epoch: [16] [  10/  20] time: 119.2557, loss: 0.00169584\n",
      "Epoch: [16] [  11/  20] time: 119.5919, loss: 0.00411527\n",
      "Epoch: [16] [  12/  20] time: 119.9278, loss: 0.00061123\n",
      "Epoch: [16] [  13/  20] time: 120.2651, loss: 0.06372586\n",
      "Epoch: [16] [  14/  20] time: 120.6022, loss: 0.00465316\n",
      "Epoch: [16] [  15/  20] time: 120.9377, loss: 0.02393245\n",
      "Epoch: [16] [  16/  20] time: 121.2735, loss: 0.00505943\n",
      "Epoch: [16] [  17/  20] time: 121.6113, loss: 0.00598830\n",
      "Epoch: [16] [  18/  20] time: 121.9495, loss: 0.01438614\n",
      "Epoch: [16] [  19/  20] time: 122.2852, loss: 0.00298517\n",
      "[16/50] - ptime: 7.0995 loss: 0.00748358 acc: 0.76000 lr: 0.00090000\n",
      "Epoch: [17] [   0/  20] time: 123.3636, loss: 0.00233374\n",
      "Epoch: [17] [   1/  20] time: 123.6971, loss: 0.00051825\n",
      "Epoch: [17] [   2/  20] time: 124.0329, loss: 0.00203665\n",
      "Epoch: [17] [   3/  20] time: 124.3681, loss: 0.00254223\n",
      "Epoch: [17] [   4/  20] time: 124.7027, loss: 0.00073805\n",
      "Epoch: [17] [   5/  20] time: 125.0327, loss: 0.00009881\n",
      "Epoch: [17] [   6/  20] time: 125.3671, loss: 0.00098250\n",
      "Epoch: [17] [   7/  20] time: 125.7025, loss: 0.00231857\n",
      "Epoch: [17] [   8/  20] time: 126.0384, loss: 0.06285989\n",
      "Epoch: [17] [   9/  20] time: 126.3726, loss: 0.03042966\n",
      "Epoch: [17] [  10/  20] time: 126.7071, loss: 0.01259103\n",
      "Epoch: [17] [  11/  20] time: 127.0428, loss: 0.02390516\n",
      "Epoch: [17] [  12/  20] time: 127.3784, loss: 0.00246592\n",
      "Epoch: [17] [  13/  20] time: 127.7139, loss: 0.00625494\n",
      "Epoch: [17] [  14/  20] time: 128.0505, loss: 0.06692702\n",
      "Epoch: [17] [  15/  20] time: 128.3858, loss: 0.00508252\n",
      "Epoch: [17] [  16/  20] time: 128.7208, loss: 0.00181159\n",
      "Epoch: [17] [  17/  20] time: 129.0573, loss: 0.01659904\n",
      "Epoch: [17] [  18/  20] time: 129.3915, loss: 0.01480698\n",
      "Epoch: [17] [  19/  20] time: 129.7265, loss: 0.00209695\n",
      "[17/50] - ptime: 7.0636 loss: 0.01286997 acc: 0.71000 lr: 0.00090000\n",
      "Epoch: [18] [   0/  20] time: 130.8934, loss: 0.00022744\n",
      "Epoch: [18] [   1/  20] time: 131.2267, loss: 0.01593737\n",
      "Epoch: [18] [   2/  20] time: 131.5616, loss: 0.00739642\n",
      "Epoch: [18] [   3/  20] time: 131.9001, loss: 0.00069383\n",
      "Epoch: [18] [   4/  20] time: 132.2344, loss: 0.02995192\n",
      "Epoch: [18] [   5/  20] time: 132.5699, loss: 0.01653513\n",
      "Epoch: [18] [   6/  20] time: 132.9068, loss: 0.00869588\n",
      "Epoch: [18] [   7/  20] time: 133.2411, loss: 0.01947133\n",
      "Epoch: [18] [   8/  20] time: 133.5749, loss: 0.00065922\n",
      "Epoch: [18] [   9/  20] time: 133.9110, loss: 0.00030754\n",
      "Epoch: [18] [  10/  20] time: 134.2464, loss: 0.00067962\n",
      "Epoch: [18] [  11/  20] time: 134.5828, loss: 0.00113990\n",
      "Epoch: [18] [  12/  20] time: 134.9181, loss: 0.00880134\n",
      "Epoch: [18] [  13/  20] time: 135.2523, loss: 0.00336278\n",
      "Epoch: [18] [  14/  20] time: 135.5875, loss: 0.00105863\n",
      "Epoch: [18] [  15/  20] time: 135.9233, loss: 0.02701813\n",
      "Epoch: [18] [  16/  20] time: 136.2588, loss: 0.00509169\n",
      "Epoch: [18] [  17/  20] time: 136.5943, loss: 0.00578568\n",
      "Epoch: [18] [  18/  20] time: 136.9300, loss: 0.00547779\n",
      "Epoch: [18] [  19/  20] time: 137.2657, loss: 0.00344786\n",
      "[18/50] - ptime: 7.0826 loss: 0.00808698 acc: 0.73000 lr: 0.00090000\n",
      "Epoch: [19] [   0/  20] time: 138.3940, loss: 0.00756755\n",
      "Epoch: [19] [   1/  20] time: 138.7286, loss: 0.00207614\n",
      "Epoch: [19] [   2/  20] time: 139.0656, loss: 0.01818624\n",
      "Epoch: [19] [   3/  20] time: 139.4043, loss: 0.00108201\n",
      "Epoch: [19] [   4/  20] time: 139.7401, loss: 0.00218857\n",
      "Epoch: [19] [   5/  20] time: 140.0741, loss: 0.00055020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19] [   6/  20] time: 140.4102, loss: 0.00077214\n",
      "Epoch: [19] [   7/  20] time: 140.7453, loss: 0.00983752\n",
      "Epoch: [19] [   8/  20] time: 141.0790, loss: 0.00001053\n",
      "Epoch: [19] [   9/  20] time: 141.4168, loss: 0.00006146\n",
      "Epoch: [19] [  10/  20] time: 141.7522, loss: 0.00615398\n",
      "Epoch: [19] [  11/  20] time: 142.0867, loss: 0.00011059\n",
      "Epoch: [19] [  12/  20] time: 142.4224, loss: 0.00467236\n",
      "Epoch: [19] [  13/  20] time: 142.7573, loss: 0.00635715\n",
      "Epoch: [19] [  14/  20] time: 143.0914, loss: 0.00030420\n",
      "Epoch: [19] [  15/  20] time: 143.4270, loss: 0.00012844\n",
      "Epoch: [19] [  16/  20] time: 143.7628, loss: 0.00491975\n",
      "Epoch: [19] [  17/  20] time: 144.1000, loss: 0.00048010\n",
      "Epoch: [19] [  18/  20] time: 144.4352, loss: 0.00732113\n",
      "Epoch: [19] [  19/  20] time: 144.7699, loss: 0.00002232\n",
      "[19/50] - ptime: 7.0895 loss: 0.00364012 acc: 0.73000 lr: 0.00090000\n",
      "Epoch: [20] [   0/  20] time: 145.8866, loss: 0.00057597\n",
      "Epoch: [20] [   1/  20] time: 146.2213, loss: 0.00000169\n",
      "Epoch: [20] [   2/  20] time: 146.5593, loss: 0.00127612\n",
      "Epoch: [20] [   3/  20] time: 146.8964, loss: 0.00214127\n",
      "Epoch: [20] [   4/  20] time: 147.2321, loss: 0.00014745\n",
      "Epoch: [20] [   5/  20] time: 147.5694, loss: 0.00048035\n",
      "Epoch: [20] [   6/  20] time: 147.9051, loss: 0.00111852\n",
      "Epoch: [20] [   7/  20] time: 148.2405, loss: 0.00016098\n",
      "Epoch: [20] [   8/  20] time: 148.5787, loss: 0.00098182\n",
      "Epoch: [20] [   9/  20] time: 148.9153, loss: 0.00039594\n",
      "Epoch: [20] [  10/  20] time: 149.2512, loss: 0.00324799\n",
      "Epoch: [20] [  11/  20] time: 149.5866, loss: 0.00011666\n",
      "Epoch: [20] [  12/  20] time: 149.9231, loss: 0.00068497\n",
      "Epoch: [20] [  13/  20] time: 150.2578, loss: 0.00006998\n",
      "Epoch: [20] [  14/  20] time: 150.5924, loss: 0.00072023\n",
      "Epoch: [20] [  15/  20] time: 150.9281, loss: 0.01106815\n",
      "Epoch: [20] [  16/  20] time: 151.2633, loss: 0.00037792\n",
      "Epoch: [20] [  17/  20] time: 151.5992, loss: 0.00039135\n",
      "Epoch: [20] [  18/  20] time: 151.9350, loss: 0.00589696\n",
      "Epoch: [20] [  19/  20] time: 152.2700, loss: 0.00200397\n",
      "[20/50] - ptime: 7.0960 loss: 0.00159291 acc: 0.83000 lr: 0.00081000\n",
      "Epoch: [21] [   0/  20] time: 153.3785, loss: 0.00060323\n",
      "Epoch: [21] [   1/  20] time: 153.7285, loss: 0.00824474\n",
      "Epoch: [21] [   2/  20] time: 154.0652, loss: 0.00156470\n",
      "Epoch: [21] [   3/  20] time: 154.4038, loss: 0.00022713\n",
      "Epoch: [21] [   4/  20] time: 154.7417, loss: 0.00001737\n",
      "Epoch: [21] [   5/  20] time: 155.0802, loss: 0.00005492\n",
      "Epoch: [21] [   6/  20] time: 155.4177, loss: 0.00004819\n",
      "Epoch: [21] [   7/  20] time: 155.7656, loss: 0.00107591\n",
      "Epoch: [21] [   8/  20] time: 156.1020, loss: 0.00156020\n",
      "Epoch: [21] [   9/  20] time: 156.4392, loss: 0.00005782\n",
      "Epoch: [21] [  10/  20] time: 156.7768, loss: 0.00014606\n",
      "Epoch: [21] [  11/  20] time: 157.1133, loss: 0.00025554\n",
      "Epoch: [21] [  12/  20] time: 157.4510, loss: 0.00042950\n",
      "Epoch: [21] [  13/  20] time: 157.7896, loss: 0.00007853\n",
      "Epoch: [21] [  14/  20] time: 158.1265, loss: 0.00001844\n",
      "Epoch: [21] [  15/  20] time: 158.4637, loss: 0.00171696\n",
      "Epoch: [21] [  16/  20] time: 158.8016, loss: 0.00184156\n",
      "Epoch: [21] [  17/  20] time: 159.1366, loss: 0.00034426\n",
      "Epoch: [21] [  18/  20] time: 159.4735, loss: 0.00002907\n",
      "Epoch: [21] [  19/  20] time: 159.8108, loss: 0.00173022\n",
      "[21/50] - ptime: 7.1356 loss: 0.00100222 acc: 0.80000 lr: 0.00081000\n",
      "Epoch: [22] [   0/  20] time: 160.9267, loss: 0.00001122\n",
      "Epoch: [22] [   1/  20] time: 161.2657, loss: 0.00008838\n",
      "Epoch: [22] [   2/  20] time: 161.6039, loss: 0.00015017\n",
      "Epoch: [22] [   3/  20] time: 161.9444, loss: 0.00094049\n",
      "Epoch: [22] [   4/  20] time: 162.2815, loss: 0.00132863\n",
      "Epoch: [22] [   5/  20] time: 162.6229, loss: 0.00000870\n",
      "Epoch: [22] [   6/  20] time: 162.9608, loss: 0.00013750\n",
      "Epoch: [22] [   7/  20] time: 163.2987, loss: 0.00004937\n",
      "Epoch: [22] [   8/  20] time: 163.6347, loss: 0.00006229\n",
      "Epoch: [22] [   9/  20] time: 163.9689, loss: 0.00004028\n",
      "Epoch: [22] [  10/  20] time: 164.3062, loss: 0.01170658\n",
      "Epoch: [22] [  11/  20] time: 164.6437, loss: 0.00037525\n",
      "Epoch: [22] [  12/  20] time: 164.9817, loss: 0.00079503\n",
      "Epoch: [22] [  13/  20] time: 165.3160, loss: 0.00033308\n",
      "Epoch: [22] [  14/  20] time: 165.6523, loss: 0.00208814\n",
      "Epoch: [22] [  15/  20] time: 165.9931, loss: 0.00000231\n",
      "Epoch: [22] [  16/  20] time: 166.3294, loss: 0.00116122\n",
      "Epoch: [22] [  17/  20] time: 166.6663, loss: 0.00000463\n",
      "Epoch: [22] [  18/  20] time: 167.0023, loss: 0.00100658\n",
      "Epoch: [22] [  19/  20] time: 167.3406, loss: 0.00096980\n",
      "[22/50] - ptime: 7.1218 loss: 0.00106298 acc: 0.76000 lr: 0.00081000\n",
      "Epoch: [23] [   0/  20] time: 168.4277, loss: 0.00023853\n",
      "Epoch: [23] [   1/  20] time: 168.7633, loss: 0.00006499\n",
      "Epoch: [23] [   2/  20] time: 169.0994, loss: 0.00000300\n",
      "Epoch: [23] [   3/  20] time: 169.4357, loss: 0.00007454\n",
      "Epoch: [23] [   4/  20] time: 169.7725, loss: 0.00010217\n",
      "Epoch: [23] [   5/  20] time: 170.1085, loss: 0.00022074\n",
      "Epoch: [23] [   6/  20] time: 170.4444, loss: 0.00059974\n",
      "Epoch: [23] [   7/  20] time: 170.7807, loss: 0.00002717\n",
      "Epoch: [23] [   8/  20] time: 171.1163, loss: 0.00010382\n",
      "Epoch: [23] [   9/  20] time: 171.4544, loss: 0.00001877\n",
      "Epoch: [23] [  10/  20] time: 171.7918, loss: 0.00025313\n",
      "Epoch: [23] [  11/  20] time: 172.1276, loss: 0.00032814\n",
      "Epoch: [23] [  12/  20] time: 172.4640, loss: 0.00130871\n",
      "Epoch: [23] [  13/  20] time: 172.7998, loss: 0.00039325\n",
      "Epoch: [23] [  14/  20] time: 173.1357, loss: 0.00029694\n",
      "Epoch: [23] [  15/  20] time: 173.4742, loss: 0.00000060\n",
      "Epoch: [23] [  16/  20] time: 173.8109, loss: 0.00028521\n",
      "Epoch: [23] [  17/  20] time: 174.1523, loss: 0.00007617\n",
      "Epoch: [23] [  18/  20] time: 174.4904, loss: 0.00003433\n",
      "Epoch: [23] [  19/  20] time: 174.8267, loss: 0.00025624\n",
      "[23/50] - ptime: 7.1067 loss: 0.00023431 acc: 0.76000 lr: 0.00081000\n",
      "Epoch: [24] [   0/  20] time: 175.9080, loss: 0.00199651\n",
      "Epoch: [24] [   1/  20] time: 176.2430, loss: 0.00003866\n",
      "Epoch: [24] [   2/  20] time: 176.5814, loss: 0.00143384\n",
      "Epoch: [24] [   3/  20] time: 176.9180, loss: 0.00010806\n",
      "Epoch: [24] [   4/  20] time: 177.2526, loss: 0.00007264\n",
      "Epoch: [24] [   5/  20] time: 177.5883, loss: 0.00000769\n",
      "Epoch: [24] [   6/  20] time: 177.9257, loss: 0.00002652\n",
      "Epoch: [24] [   7/  20] time: 178.2607, loss: 0.00000380\n",
      "Epoch: [24] [   8/  20] time: 178.5972, loss: 0.00002356\n",
      "Epoch: [24] [   9/  20] time: 178.9373, loss: 0.00030726\n",
      "Epoch: [24] [  10/  20] time: 179.2725, loss: 0.00020303\n",
      "Epoch: [24] [  11/  20] time: 179.6102, loss: 0.00000771\n",
      "Epoch: [24] [  12/  20] time: 179.9476, loss: 0.00024180\n",
      "Epoch: [24] [  13/  20] time: 180.2836, loss: 0.00008986\n",
      "Epoch: [24] [  14/  20] time: 180.6192, loss: 0.00003363\n",
      "Epoch: [24] [  15/  20] time: 180.9568, loss: 0.00001339\n",
      "Epoch: [24] [  16/  20] time: 181.2931, loss: 0.00000553\n",
      "Epoch: [24] [  17/  20] time: 181.6282, loss: 0.00002217\n",
      "Epoch: [24] [  18/  20] time: 181.9641, loss: 0.00013529\n",
      "Epoch: [24] [  19/  20] time: 182.3001, loss: 0.00000543\n",
      "[24/50] - ptime: 7.1011 loss: 0.00023882 acc: 0.71000 lr: 0.00081000\n",
      "Epoch: [25] [   0/  20] time: 183.4023, loss: 0.00035580\n",
      "Epoch: [25] [   1/  20] time: 183.7385, loss: 0.00000143\n",
      "Epoch: [25] [   2/  20] time: 184.0733, loss: 0.00023865\n",
      "Epoch: [25] [   3/  20] time: 184.4096, loss: 0.00038740\n",
      "Epoch: [25] [   4/  20] time: 184.7450, loss: 0.00000452\n",
      "Epoch: [25] [   5/  20] time: 185.0813, loss: 0.00004620\n",
      "Epoch: [25] [   6/  20] time: 185.4175, loss: 0.00001644\n",
      "Epoch: [25] [   7/  20] time: 185.7573, loss: 0.00019482\n",
      "Epoch: [25] [   8/  20] time: 186.0957, loss: 0.00002983\n",
      "Epoch: [25] [   9/  20] time: 186.4302, loss: 0.00003782\n",
      "Epoch: [25] [  10/  20] time: 186.7666, loss: 0.00010339\n",
      "Epoch: [25] [  11/  20] time: 187.1012, loss: 0.00002819\n",
      "Epoch: [25] [  12/  20] time: 187.4372, loss: 0.00005660\n",
      "Epoch: [25] [  13/  20] time: 187.7756, loss: 0.00005398\n",
      "Epoch: [25] [  14/  20] time: 188.1106, loss: 0.00010873\n",
      "Epoch: [25] [  15/  20] time: 188.4464, loss: 0.00001314\n",
      "Epoch: [25] [  16/  20] time: 188.7828, loss: 0.00003398\n",
      "Epoch: [25] [  17/  20] time: 189.1183, loss: 0.00000197\n",
      "Epoch: [25] [  18/  20] time: 189.4545, loss: 0.00005091\n",
      "Epoch: [25] [  19/  20] time: 189.7915, loss: 0.00000103\n",
      "[25/50] - ptime: 7.1014 loss: 0.00008824 acc: 0.71000 lr: 0.00081000\n",
      "Epoch: [26] [   0/  20] time: 190.8782, loss: 0.00001264\n",
      "Epoch: [26] [   1/  20] time: 191.2132, loss: 0.00000359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [26] [   2/  20] time: 191.5484, loss: 0.00017027\n",
      "Epoch: [26] [   3/  20] time: 191.8894, loss: 0.00000808\n",
      "Epoch: [26] [   4/  20] time: 192.2256, loss: 0.00007737\n",
      "Epoch: [26] [   5/  20] time: 192.5629, loss: 0.00000529\n",
      "Epoch: [26] [   6/  20] time: 192.9036, loss: 0.00006404\n",
      "Epoch: [26] [   7/  20] time: 193.2419, loss: 0.00000975\n",
      "Epoch: [26] [   8/  20] time: 193.5821, loss: 0.00002714\n",
      "Epoch: [26] [   9/  20] time: 193.9213, loss: 0.00680270\n",
      "Epoch: [26] [  10/  20] time: 194.2569, loss: 0.00001658\n",
      "Epoch: [26] [  11/  20] time: 194.5938, loss: 0.00010682\n",
      "Epoch: [26] [  12/  20] time: 194.9330, loss: 0.00018072\n",
      "Epoch: [26] [  13/  20] time: 195.2708, loss: 0.00004112\n",
      "Epoch: [26] [  14/  20] time: 195.6086, loss: 0.00004043\n",
      "Epoch: [26] [  15/  20] time: 195.9471, loss: 0.00017414\n",
      "Epoch: [26] [  16/  20] time: 196.2828, loss: 0.00000790\n",
      "Epoch: [26] [  17/  20] time: 196.6178, loss: 0.00051876\n",
      "Epoch: [26] [  18/  20] time: 196.9567, loss: 0.00002327\n",
      "Epoch: [26] [  19/  20] time: 197.2961, loss: 0.00018097\n",
      "[26/50] - ptime: 7.1231 loss: 0.00042358 acc: 0.74000 lr: 0.00081000\n",
      "Epoch: [27] [   0/  20] time: 198.3967, loss: 0.00170685\n",
      "Epoch: [27] [   1/  20] time: 198.7336, loss: 0.00002188\n",
      "Epoch: [27] [   2/  20] time: 199.0685, loss: 0.00004780\n",
      "Epoch: [27] [   3/  20] time: 199.4048, loss: 0.00002206\n",
      "Epoch: [27] [   4/  20] time: 199.7418, loss: 0.00009727\n",
      "Epoch: [27] [   5/  20] time: 200.0776, loss: 0.00010872\n",
      "Epoch: [27] [   6/  20] time: 200.4141, loss: 0.00000318\n",
      "Epoch: [27] [   7/  20] time: 200.7506, loss: 0.00000678\n",
      "Epoch: [27] [   8/  20] time: 201.0864, loss: 0.00018123\n",
      "Epoch: [27] [   9/  20] time: 201.4226, loss: 0.00000956\n",
      "Epoch: [27] [  10/  20] time: 201.7592, loss: 0.00000381\n",
      "Epoch: [27] [  11/  20] time: 202.0941, loss: 0.00020343\n",
      "Epoch: [27] [  12/  20] time: 202.4294, loss: 0.00004348\n",
      "Epoch: [27] [  13/  20] time: 202.7673, loss: 0.00001081\n",
      "Epoch: [27] [  14/  20] time: 203.1039, loss: 0.00029129\n",
      "Epoch: [27] [  15/  20] time: 203.4394, loss: 0.00000912\n",
      "Epoch: [27] [  16/  20] time: 203.7759, loss: 0.00000634\n",
      "Epoch: [27] [  17/  20] time: 204.1134, loss: 0.00016652\n",
      "Epoch: [27] [  18/  20] time: 204.4538, loss: 0.00002601\n",
      "Epoch: [27] [  19/  20] time: 204.7933, loss: 0.00011293\n",
      "[27/50] - ptime: 7.1200 loss: 0.00015395 acc: 0.72000 lr: 0.00081000\n",
      "Epoch: [28] [   0/  20] time: 205.9164, loss: 0.00000282\n",
      "Epoch: [28] [   1/  20] time: 206.2515, loss: 0.00036105\n",
      "Epoch: [28] [   2/  20] time: 206.5869, loss: 0.00003915\n",
      "Epoch: [28] [   3/  20] time: 206.9233, loss: 0.00000539\n",
      "Epoch: [28] [   4/  20] time: 207.2581, loss: 0.00000085\n",
      "Epoch: [28] [   5/  20] time: 207.5944, loss: 0.00006202\n",
      "Epoch: [28] [   6/  20] time: 207.9302, loss: 0.00004813\n",
      "Epoch: [28] [   7/  20] time: 208.2669, loss: 0.00915589\n",
      "Epoch: [28] [   8/  20] time: 208.6029, loss: 0.00073027\n",
      "Epoch: [28] [   9/  20] time: 208.9401, loss: 0.00713101\n",
      "Epoch: [28] [  10/  20] time: 209.2755, loss: 0.00425935\n",
      "Epoch: [28] [  11/  20] time: 209.6115, loss: 0.00759693\n",
      "Epoch: [28] [  12/  20] time: 209.9483, loss: 0.00020270\n",
      "Epoch: [28] [  13/  20] time: 210.2835, loss: 0.00018885\n",
      "Epoch: [28] [  14/  20] time: 210.6203, loss: 0.00000083\n",
      "Epoch: [28] [  15/  20] time: 210.9563, loss: 0.00000074\n",
      "Epoch: [28] [  16/  20] time: 211.2909, loss: 0.00020635\n",
      "Epoch: [28] [  17/  20] time: 211.6264, loss: 0.00154978\n",
      "Epoch: [28] [  18/  20] time: 211.9626, loss: 0.00004571\n",
      "Epoch: [28] [  19/  20] time: 212.2977, loss: 0.00260213\n",
      "[28/50] - ptime: 7.0888 loss: 0.00170950 acc: 0.70000 lr: 0.00081000\n",
      "Epoch: [29] [   0/  20] time: 213.3854, loss: 0.00015818\n",
      "Epoch: [29] [   1/  20] time: 213.7222, loss: 0.00086906\n",
      "Epoch: [29] [   2/  20] time: 214.0591, loss: 0.00002738\n",
      "Epoch: [29] [   3/  20] time: 214.3977, loss: 0.00009243\n",
      "Epoch: [29] [   4/  20] time: 214.7359, loss: 0.00003553\n",
      "Epoch: [29] [   5/  20] time: 215.0719, loss: 0.00003833\n",
      "Epoch: [29] [   6/  20] time: 215.4093, loss: 0.00001228\n",
      "Epoch: [29] [   7/  20] time: 215.7501, loss: 0.00006713\n",
      "Epoch: [29] [   8/  20] time: 216.0865, loss: 0.00001914\n",
      "Epoch: [29] [   9/  20] time: 216.4245, loss: 0.00512893\n",
      "Epoch: [29] [  10/  20] time: 216.7619, loss: 0.00559476\n",
      "Epoch: [29] [  11/  20] time: 217.0991, loss: 0.00157214\n",
      "Epoch: [29] [  12/  20] time: 217.4445, loss: 0.00000135\n",
      "Epoch: [29] [  13/  20] time: 217.7814, loss: 0.00003956\n",
      "Epoch: [29] [  14/  20] time: 218.1182, loss: 0.00005547\n",
      "Epoch: [29] [  15/  20] time: 218.4556, loss: 0.00002820\n",
      "Epoch: [29] [  16/  20] time: 218.7968, loss: 0.00019876\n",
      "Epoch: [29] [  17/  20] time: 219.1325, loss: 0.00006295\n",
      "Epoch: [29] [  18/  20] time: 219.4699, loss: 0.00003807\n",
      "Epoch: [29] [  19/  20] time: 219.8072, loss: 0.00004618\n",
      "[29/50] - ptime: 7.1330 loss: 0.00070429 acc: 0.67000 lr: 0.00081000\n",
      "Epoch: [30] [   0/  20] time: 220.9112, loss: 0.00079112\n",
      "Epoch: [30] [   1/  20] time: 221.2493, loss: 0.00000606\n",
      "Epoch: [30] [   2/  20] time: 221.5853, loss: 0.00033676\n",
      "Epoch: [30] [   3/  20] time: 221.9226, loss: 0.00006754\n",
      "Epoch: [30] [   4/  20] time: 222.2599, loss: 0.00009715\n",
      "Epoch: [30] [   5/  20] time: 222.5989, loss: 0.00007663\n",
      "Epoch: [30] [   6/  20] time: 222.9360, loss: 0.00017045\n",
      "Epoch: [30] [   7/  20] time: 223.2733, loss: 0.00004208\n",
      "Epoch: [30] [   8/  20] time: 223.6096, loss: 0.00536743\n",
      "Epoch: [30] [   9/  20] time: 223.9477, loss: 0.00193476\n",
      "Epoch: [30] [  10/  20] time: 224.2849, loss: 0.00124673\n",
      "Epoch: [30] [  11/  20] time: 224.6214, loss: 0.00057450\n",
      "Epoch: [30] [  12/  20] time: 224.9638, loss: 0.00000561\n",
      "Epoch: [30] [  13/  20] time: 225.2989, loss: 0.00004200\n",
      "Epoch: [30] [  14/  20] time: 225.6365, loss: 0.00000771\n",
      "Epoch: [30] [  15/  20] time: 225.9728, loss: 0.00000625\n",
      "Epoch: [30] [  16/  20] time: 226.3096, loss: 0.00014546\n",
      "Epoch: [30] [  17/  20] time: 226.6473, loss: 0.00003742\n",
      "Epoch: [30] [  18/  20] time: 226.9839, loss: 0.00151394\n",
      "Epoch: [30] [  19/  20] time: 227.3214, loss: 0.00003676\n",
      "[30/50] - ptime: 7.1233 loss: 0.00062532 acc: 0.68000 lr: 0.00072900\n",
      "Epoch: [31] [   0/  20] time: 228.4253, loss: 0.00006914\n",
      "Epoch: [31] [   1/  20] time: 228.7635, loss: 0.00001583\n",
      "Epoch: [31] [   2/  20] time: 229.1014, loss: 0.00148929\n",
      "Epoch: [31] [   3/  20] time: 229.4422, loss: 0.00008032\n",
      "Epoch: [31] [   4/  20] time: 229.7854, loss: 0.00012469\n",
      "Epoch: [31] [   5/  20] time: 230.1234, loss: 0.00002335\n",
      "Epoch: [31] [   6/  20] time: 230.4617, loss: 0.00015390\n",
      "Epoch: [31] [   7/  20] time: 230.8030, loss: 0.00000905\n",
      "Epoch: [31] [   8/  20] time: 231.1421, loss: 0.00001324\n",
      "Epoch: [31] [   9/  20] time: 231.4827, loss: 0.00016830\n",
      "Epoch: [31] [  10/  20] time: 231.8193, loss: 0.00002824\n",
      "Epoch: [31] [  11/  20] time: 232.1554, loss: 0.00005075\n",
      "Epoch: [31] [  12/  20] time: 232.4943, loss: 0.00002542\n",
      "Epoch: [31] [  13/  20] time: 232.8323, loss: 0.00074953\n",
      "Epoch: [31] [  14/  20] time: 233.1704, loss: 0.00002196\n",
      "Epoch: [31] [  15/  20] time: 233.5079, loss: 0.00001294\n",
      "Epoch: [31] [  16/  20] time: 233.8489, loss: 0.00000849\n",
      "Epoch: [31] [  17/  20] time: 234.1841, loss: 0.00001590\n",
      "Epoch: [31] [  18/  20] time: 234.5198, loss: 0.00002263\n",
      "Epoch: [31] [  19/  20] time: 234.8588, loss: 0.00005363\n",
      "[31/50] - ptime: 7.1391 loss: 0.00015683 acc: 0.68000 lr: 0.00072900\n",
      "Epoch: [32] [   0/  20] time: 235.9393, loss: 0.00003593\n",
      "Epoch: [32] [   1/  20] time: 236.2755, loss: 0.00024781\n",
      "Epoch: [32] [   2/  20] time: 236.6138, loss: 0.00000682\n",
      "Epoch: [32] [   3/  20] time: 236.9527, loss: 0.00001341\n",
      "Epoch: [32] [   4/  20] time: 237.2960, loss: 0.00001413\n",
      "Epoch: [32] [   5/  20] time: 237.6335, loss: 0.00000003\n",
      "Epoch: [32] [   6/  20] time: 237.9711, loss: 0.00078410\n",
      "Epoch: [32] [   7/  20] time: 238.3100, loss: 0.00001774\n",
      "Epoch: [32] [   8/  20] time: 238.6495, loss: 0.00002507\n",
      "Epoch: [32] [   9/  20] time: 238.9882, loss: 0.00000090\n",
      "Epoch: [32] [  10/  20] time: 239.3297, loss: 0.00000144\n",
      "Epoch: [32] [  11/  20] time: 239.6666, loss: 0.00004357\n",
      "Epoch: [32] [  12/  20] time: 240.0053, loss: 0.00008284\n",
      "Epoch: [32] [  13/  20] time: 240.3424, loss: 0.00002309\n",
      "Epoch: [32] [  14/  20] time: 240.6808, loss: 0.00000222\n",
      "Epoch: [32] [  15/  20] time: 241.0196, loss: 0.00011707\n",
      "Epoch: [32] [  16/  20] time: 241.3576, loss: 0.00000073\n",
      "Epoch: [32] [  17/  20] time: 241.6945, loss: 0.00001129\n",
      "Epoch: [32] [  18/  20] time: 242.0329, loss: 0.00000090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32] [  19/  20] time: 242.3711, loss: 0.00003057\n",
      "[32/50] - ptime: 7.1383 loss: 0.00007298 acc: 0.66000 lr: 0.00072900\n",
      "Epoch: [33] [   0/  20] time: 243.6000, loss: 0.00019698\n",
      "Epoch: [33] [   1/  20] time: 243.9369, loss: 0.00000246\n",
      "Epoch: [33] [   2/  20] time: 244.2733, loss: 0.00000248\n",
      "Epoch: [33] [   3/  20] time: 244.6105, loss: 0.00000226\n",
      "Epoch: [33] [   4/  20] time: 244.9488, loss: 0.00001718\n",
      "Epoch: [33] [   5/  20] time: 245.2856, loss: 0.00000725\n",
      "Epoch: [33] [   6/  20] time: 245.6212, loss: 0.00010228\n",
      "Epoch: [33] [   7/  20] time: 245.9587, loss: 0.00003822\n",
      "Epoch: [33] [   8/  20] time: 246.2971, loss: 0.00007250\n",
      "Epoch: [33] [   9/  20] time: 246.6346, loss: 0.00003213\n",
      "Epoch: [33] [  10/  20] time: 246.9726, loss: 0.00007955\n",
      "Epoch: [33] [  11/  20] time: 247.3142, loss: 0.00001702\n",
      "Epoch: [33] [  12/  20] time: 247.6533, loss: 0.00002714\n",
      "Epoch: [33] [  13/  20] time: 247.9922, loss: 0.00005580\n",
      "Epoch: [33] [  14/  20] time: 248.3290, loss: 0.00000810\n",
      "Epoch: [33] [  15/  20] time: 248.6667, loss: 0.00004071\n",
      "Epoch: [33] [  16/  20] time: 249.0040, loss: 0.00000562\n",
      "Epoch: [33] [  17/  20] time: 249.3428, loss: 0.00001635\n",
      "Epoch: [33] [  18/  20] time: 249.6806, loss: 0.00001004\n",
      "Epoch: [33] [  19/  20] time: 250.0197, loss: 0.00000602\n",
      "[33/50] - ptime: 7.1642 loss: 0.00003700 acc: 0.68000 lr: 0.00072900\n",
      "Epoch: [34] [   0/  20] time: 251.1269, loss: 0.00000236\n",
      "Epoch: [34] [   1/  20] time: 251.4623, loss: 0.00001541\n",
      "Epoch: [34] [   2/  20] time: 251.7989, loss: 0.00000161\n",
      "Epoch: [34] [   3/  20] time: 252.1358, loss: 0.00000505\n",
      "Epoch: [34] [   4/  20] time: 252.4712, loss: 0.00012805\n",
      "Epoch: [34] [   5/  20] time: 252.8068, loss: 0.00007233\n",
      "Epoch: [34] [   6/  20] time: 253.1419, loss: 0.00001031\n",
      "Epoch: [34] [   7/  20] time: 253.4795, loss: 0.00001675\n",
      "Epoch: [34] [   8/  20] time: 253.8160, loss: 0.00000168\n",
      "Epoch: [34] [   9/  20] time: 254.1511, loss: 0.00006460\n",
      "Epoch: [34] [  10/  20] time: 254.4859, loss: 0.00000729\n",
      "Epoch: [34] [  11/  20] time: 254.8241, loss: 0.00010490\n",
      "Epoch: [34] [  12/  20] time: 255.1590, loss: 0.00007212\n",
      "Epoch: [34] [  13/  20] time: 255.4950, loss: 0.00002764\n",
      "Epoch: [34] [  14/  20] time: 255.8325, loss: 0.00001120\n",
      "Epoch: [34] [  15/  20] time: 256.1679, loss: 0.00002692\n",
      "Epoch: [34] [  16/  20] time: 256.5032, loss: 0.00001837\n",
      "Epoch: [34] [  17/  20] time: 256.8417, loss: 0.00008647\n",
      "Epoch: [34] [  18/  20] time: 257.1780, loss: 0.00001995\n",
      "Epoch: [34] [  19/  20] time: 257.5144, loss: 0.00000565\n",
      "[34/50] - ptime: 7.1002 loss: 0.00003493 acc: 0.69000 lr: 0.00072900\n",
      "Epoch: [35] [   0/  20] time: 258.6046, loss: 0.00007351\n",
      "Epoch: [35] [   1/  20] time: 258.9432, loss: 0.00000403\n",
      "Epoch: [35] [   2/  20] time: 259.2802, loss: 0.00000480\n",
      "Epoch: [35] [   3/  20] time: 259.6169, loss: 0.00001650\n",
      "Epoch: [35] [   4/  20] time: 259.9547, loss: 0.00004438\n",
      "Epoch: [35] [   5/  20] time: 260.2947, loss: 0.00001132\n",
      "Epoch: [35] [   6/  20] time: 260.6293, loss: 0.00000077\n",
      "Epoch: [35] [   7/  20] time: 260.9664, loss: 0.00003332\n",
      "Epoch: [35] [   8/  20] time: 261.3043, loss: 0.00002493\n",
      "Epoch: [35] [   9/  20] time: 261.6409, loss: 0.00000417\n",
      "Epoch: [35] [  10/  20] time: 261.9805, loss: 0.00001921\n",
      "Epoch: [35] [  11/  20] time: 262.3166, loss: 0.00005723\n",
      "Epoch: [35] [  12/  20] time: 262.6517, loss: 0.00001433\n",
      "Epoch: [35] [  13/  20] time: 262.9880, loss: 0.00000960\n",
      "Epoch: [35] [  14/  20] time: 263.3242, loss: 0.00008818\n",
      "Epoch: [35] [  15/  20] time: 263.6590, loss: 0.00000270\n",
      "Epoch: [35] [  16/  20] time: 263.9949, loss: 0.00002152\n",
      "Epoch: [35] [  17/  20] time: 264.3307, loss: 0.00002181\n",
      "Epoch: [35] [  18/  20] time: 264.6663, loss: 0.00007836\n",
      "Epoch: [35] [  19/  20] time: 265.0039, loss: 0.00005342\n",
      "[35/50] - ptime: 7.1076 loss: 0.00002921 acc: 0.69000 lr: 0.00072900\n",
      "Epoch: [36] [   0/  20] time: 266.0874, loss: 0.00000591\n",
      "Epoch: [36] [   1/  20] time: 266.4262, loss: 0.00000141\n",
      "Epoch: [36] [   2/  20] time: 266.7658, loss: 0.00000878\n",
      "Epoch: [36] [   3/  20] time: 267.1043, loss: 0.00004335\n",
      "Epoch: [36] [   4/  20] time: 267.4444, loss: 0.00000897\n",
      "Epoch: [36] [   5/  20] time: 267.7818, loss: 0.00005039\n",
      "Epoch: [36] [   6/  20] time: 268.1181, loss: 0.00000506\n",
      "Epoch: [36] [   7/  20] time: 268.4572, loss: 0.00001020\n",
      "Epoch: [36] [   8/  20] time: 268.7944, loss: 0.00000038\n",
      "Epoch: [36] [   9/  20] time: 269.1323, loss: 0.00000462\n",
      "Epoch: [36] [  10/  20] time: 269.4713, loss: 0.00002122\n",
      "Epoch: [36] [  11/  20] time: 269.8135, loss: 0.00001368\n",
      "Epoch: [36] [  12/  20] time: 270.1506, loss: 0.00000241\n",
      "Epoch: [36] [  13/  20] time: 270.4882, loss: 0.00004007\n",
      "Epoch: [36] [  14/  20] time: 270.8301, loss: 0.00003164\n",
      "Epoch: [36] [  15/  20] time: 271.1664, loss: 0.00001257\n",
      "Epoch: [36] [  16/  20] time: 271.5019, loss: 0.00000402\n",
      "Epoch: [36] [  17/  20] time: 271.8405, loss: 0.00000751\n",
      "Epoch: [36] [  18/  20] time: 272.1786, loss: 0.00001298\n",
      "Epoch: [36] [  19/  20] time: 272.5189, loss: 0.00000648\n",
      "[36/50] - ptime: 7.1457 loss: 0.00001458 acc: 0.69000 lr: 0.00072900\n",
      "Epoch: [37] [   0/  20] time: 273.6677, loss: 0.00000327\n",
      "Epoch: [37] [   1/  20] time: 274.0055, loss: 0.00000788\n",
      "Epoch: [37] [   2/  20] time: 274.3418, loss: 0.00002888\n",
      "Epoch: [37] [   3/  20] time: 274.6769, loss: 0.00000425\n",
      "Epoch: [37] [   4/  20] time: 275.0146, loss: 0.00001567\n",
      "Epoch: [37] [   5/  20] time: 275.3516, loss: 0.00000868\n",
      "Epoch: [37] [   6/  20] time: 275.6964, loss: 0.00000596\n",
      "Epoch: [37] [   7/  20] time: 276.0338, loss: 0.00001546\n",
      "Epoch: [37] [   8/  20] time: 276.3700, loss: 0.00000922\n",
      "Epoch: [37] [   9/  20] time: 276.7049, loss: 0.00000590\n",
      "Epoch: [37] [  10/  20] time: 277.0406, loss: 0.00000082\n",
      "Epoch: [37] [  11/  20] time: 277.3766, loss: 0.00000101\n",
      "Epoch: [37] [  12/  20] time: 277.7136, loss: 0.00000652\n",
      "Epoch: [37] [  13/  20] time: 278.0510, loss: 0.00002140\n",
      "Epoch: [37] [  14/  20] time: 278.3878, loss: 0.00000590\n",
      "Epoch: [37] [  15/  20] time: 278.7239, loss: 0.00002430\n",
      "Epoch: [37] [  16/  20] time: 279.0595, loss: 0.00000320\n",
      "Epoch: [37] [  17/  20] time: 279.3951, loss: 0.00000068\n",
      "Epoch: [37] [  18/  20] time: 279.7323, loss: 0.00000938\n",
      "Epoch: [37] [  19/  20] time: 280.0681, loss: 0.00000486\n",
      "[37/50] - ptime: 7.1287 loss: 0.00000916 acc: 0.69000 lr: 0.00072900\n",
      "Epoch: [38] [   0/  20] time: 281.1393, loss: 0.00002134\n",
      "Epoch: [38] [   1/  20] time: 281.4752, loss: 0.00008165\n",
      "Epoch: [38] [   2/  20] time: 281.8130, loss: 0.00000685\n",
      "Epoch: [38] [   3/  20] time: 282.1483, loss: 0.00000019\n",
      "Epoch: [38] [   4/  20] time: 282.4827, loss: 0.00001036\n",
      "Epoch: [38] [   5/  20] time: 282.8191, loss: 0.00002003\n",
      "Epoch: [38] [   6/  20] time: 283.1551, loss: 0.00000641\n",
      "Epoch: [38] [   7/  20] time: 283.4927, loss: 0.00002940\n",
      "Epoch: [38] [   8/  20] time: 283.8289, loss: 0.00001851\n",
      "Epoch: [38] [   9/  20] time: 284.1646, loss: 0.00013925\n",
      "Epoch: [38] [  10/  20] time: 284.5005, loss: 0.00001892\n",
      "Epoch: [38] [  11/  20] time: 284.8367, loss: 0.00000023\n",
      "Epoch: [38] [  12/  20] time: 285.1721, loss: 0.00000130\n",
      "Epoch: [38] [  13/  20] time: 285.5109, loss: 0.00001172\n",
      "Epoch: [38] [  14/  20] time: 285.8485, loss: 0.00001619\n",
      "Epoch: [38] [  15/  20] time: 286.1847, loss: 0.00000171\n",
      "Epoch: [38] [  16/  20] time: 286.5206, loss: 0.00002131\n",
      "Epoch: [38] [  17/  20] time: 286.8607, loss: 0.00001636\n",
      "Epoch: [38] [  18/  20] time: 287.1979, loss: 0.00001454\n",
      "Epoch: [38] [  19/  20] time: 287.5360, loss: 0.00001795\n",
      "[38/50] - ptime: 7.0948 loss: 0.00002271 acc: 0.69000 lr: 0.00072900\n",
      "Epoch: [39] [   0/  20] time: 288.6066, loss: 0.00000031\n",
      "Epoch: [39] [   1/  20] time: 288.9454, loss: 0.00001875\n",
      "Epoch: [39] [   2/  20] time: 289.2809, loss: 0.00002267\n",
      "Epoch: [39] [   3/  20] time: 289.6157, loss: 0.00000242\n",
      "Epoch: [39] [   4/  20] time: 289.9528, loss: 0.00000133\n",
      "Epoch: [39] [   5/  20] time: 290.2880, loss: 0.00004730\n",
      "Epoch: [39] [   6/  20] time: 290.6240, loss: 0.00001497\n",
      "Epoch: [39] [   7/  20] time: 290.9629, loss: 0.00000284\n",
      "Epoch: [39] [   8/  20] time: 291.2987, loss: 0.00000677\n",
      "Epoch: [39] [   9/  20] time: 291.6331, loss: 0.00002070\n",
      "Epoch: [39] [  10/  20] time: 291.9719, loss: 0.00001774\n",
      "Epoch: [39] [  11/  20] time: 292.3074, loss: 0.00000097\n",
      "Epoch: [39] [  12/  20] time: 292.6450, loss: 0.00002815\n",
      "Epoch: [39] [  13/  20] time: 292.9828, loss: 0.00000131\n",
      "Epoch: [39] [  14/  20] time: 293.3205, loss: 0.00001711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [39] [  15/  20] time: 293.6551, loss: 0.00000944\n",
      "Epoch: [39] [  16/  20] time: 293.9921, loss: 0.00000265\n",
      "Epoch: [39] [  17/  20] time: 294.3278, loss: 0.00005959\n",
      "Epoch: [39] [  18/  20] time: 294.6630, loss: 0.00000393\n",
      "Epoch: [39] [  19/  20] time: 295.0009, loss: 0.00002201\n",
      "[39/50] - ptime: 7.0890 loss: 0.00001505 acc: 0.69000 lr: 0.00072900\n",
      "Epoch: [40] [   0/  20] time: 296.0611, loss: 0.00000362\n",
      "Epoch: [40] [   1/  20] time: 296.3964, loss: 0.00001472\n",
      "Epoch: [40] [   2/  20] time: 296.7342, loss: 0.00000062\n",
      "Epoch: [40] [   3/  20] time: 297.0693, loss: 0.00000064\n",
      "Epoch: [40] [   4/  20] time: 297.4062, loss: 0.00000066\n",
      "Epoch: [40] [   5/  20] time: 297.7454, loss: 0.00000101\n",
      "Epoch: [40] [   6/  20] time: 298.0840, loss: 0.00001406\n",
      "Epoch: [40] [   7/  20] time: 298.4216, loss: 0.00000018\n",
      "Epoch: [40] [   8/  20] time: 298.7581, loss: 0.00000256\n",
      "Epoch: [40] [   9/  20] time: 299.0941, loss: 0.00005298\n",
      "Epoch: [40] [  10/  20] time: 299.4335, loss: 0.00002630\n",
      "Epoch: [40] [  11/  20] time: 299.7712, loss: 0.00000772\n",
      "Epoch: [40] [  12/  20] time: 300.1108, loss: 0.00000147\n",
      "Epoch: [40] [  13/  20] time: 300.4483, loss: 0.00000770\n",
      "Epoch: [40] [  14/  20] time: 300.7851, loss: 0.00008951\n",
      "Epoch: [40] [  15/  20] time: 301.1214, loss: 0.00000234\n",
      "Epoch: [40] [  16/  20] time: 301.4630, loss: 0.00001062\n",
      "Epoch: [40] [  17/  20] time: 301.8002, loss: 0.00011476\n",
      "Epoch: [40] [  18/  20] time: 302.1331, loss: 0.00000457\n",
      "Epoch: [40] [  19/  20] time: 302.4699, loss: 0.00000587\n",
      "[40/50] - ptime: 7.1029 loss: 0.00001810 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [41] [   0/  20] time: 303.5431, loss: 0.00001082\n",
      "Epoch: [41] [   1/  20] time: 303.8804, loss: 0.00000960\n",
      "Epoch: [41] [   2/  20] time: 304.2153, loss: 0.00003338\n",
      "Epoch: [41] [   3/  20] time: 304.5507, loss: 0.00005228\n",
      "Epoch: [41] [   4/  20] time: 304.8890, loss: 0.00000227\n",
      "Epoch: [41] [   5/  20] time: 305.2243, loss: 0.00000912\n",
      "Epoch: [41] [   6/  20] time: 305.5593, loss: 0.00002146\n",
      "Epoch: [41] [   7/  20] time: 305.8984, loss: 0.00004406\n",
      "Epoch: [41] [   8/  20] time: 306.2346, loss: 0.00000061\n",
      "Epoch: [41] [   9/  20] time: 306.5695, loss: 0.00000124\n",
      "Epoch: [41] [  10/  20] time: 306.9068, loss: 0.00000118\n",
      "Epoch: [41] [  11/  20] time: 307.2427, loss: 0.00000105\n",
      "Epoch: [41] [  12/  20] time: 307.5785, loss: 0.00003390\n",
      "Epoch: [41] [  13/  20] time: 307.9170, loss: 0.00000013\n",
      "Epoch: [41] [  14/  20] time: 308.2541, loss: 0.00002172\n",
      "Epoch: [41] [  15/  20] time: 308.5894, loss: 0.00000791\n",
      "Epoch: [41] [  16/  20] time: 308.9256, loss: 0.00003665\n",
      "Epoch: [41] [  17/  20] time: 309.2618, loss: 0.00002581\n",
      "Epoch: [41] [  18/  20] time: 309.5988, loss: 0.00001301\n",
      "Epoch: [41] [  19/  20] time: 309.9358, loss: 0.00004139\n",
      "[41/50] - ptime: 7.0904 loss: 0.00001838 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [42] [   0/  20] time: 311.0467, loss: 0.00000318\n",
      "Epoch: [42] [   1/  20] time: 311.3821, loss: 0.00002945\n",
      "Epoch: [42] [   2/  20] time: 311.7193, loss: 0.00000063\n",
      "Epoch: [42] [   3/  20] time: 312.0572, loss: 0.00000417\n",
      "Epoch: [42] [   4/  20] time: 312.3940, loss: 0.00000979\n",
      "Epoch: [42] [   5/  20] time: 312.7306, loss: 0.00000091\n",
      "Epoch: [42] [   6/  20] time: 313.0675, loss: 0.00006326\n",
      "Epoch: [42] [   7/  20] time: 313.4046, loss: 0.00001023\n",
      "Epoch: [42] [   8/  20] time: 313.7411, loss: 0.00000328\n",
      "Epoch: [42] [   9/  20] time: 314.0786, loss: 0.00000737\n",
      "Epoch: [42] [  10/  20] time: 314.4158, loss: 0.00000439\n",
      "Epoch: [42] [  11/  20] time: 314.7510, loss: 0.00000622\n",
      "Epoch: [42] [  12/  20] time: 315.0958, loss: 0.00000062\n",
      "Epoch: [42] [  13/  20] time: 315.4327, loss: 0.00002272\n",
      "Epoch: [42] [  14/  20] time: 315.7661, loss: 0.00001273\n",
      "Epoch: [42] [  15/  20] time: 316.1075, loss: 0.00000866\n",
      "Epoch: [42] [  16/  20] time: 316.4442, loss: 0.00001050\n",
      "Epoch: [42] [  17/  20] time: 316.7817, loss: 0.00000094\n",
      "Epoch: [42] [  18/  20] time: 317.1167, loss: 0.00000367\n",
      "Epoch: [42] [  19/  20] time: 317.4521, loss: 0.00001470\n",
      "[42/50] - ptime: 7.1163 loss: 0.00001087 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [43] [   0/  20] time: 318.5665, loss: 0.00000840\n",
      "Epoch: [43] [   1/  20] time: 318.9032, loss: 0.00000346\n",
      "Epoch: [43] [   2/  20] time: 319.2386, loss: 0.00000030\n",
      "Epoch: [43] [   3/  20] time: 319.5750, loss: 0.00000524\n",
      "Epoch: [43] [   4/  20] time: 319.9137, loss: 0.00053411\n",
      "Epoch: [43] [   5/  20] time: 320.2507, loss: 0.00000648\n",
      "Epoch: [43] [   6/  20] time: 320.5873, loss: 0.00000671\n",
      "Epoch: [43] [   7/  20] time: 320.9252, loss: 0.00000715\n",
      "Epoch: [43] [   8/  20] time: 321.2634, loss: 0.00002303\n",
      "Epoch: [43] [   9/  20] time: 321.6016, loss: 0.00000604\n",
      "Epoch: [43] [  10/  20] time: 321.9419, loss: 0.00000217\n",
      "Epoch: [43] [  11/  20] time: 322.2772, loss: 0.00012286\n",
      "Epoch: [43] [  12/  20] time: 322.6152, loss: 0.00000057\n",
      "Epoch: [43] [  13/  20] time: 322.9568, loss: 0.00000825\n",
      "Epoch: [43] [  14/  20] time: 323.2932, loss: 0.00000681\n",
      "Epoch: [43] [  15/  20] time: 323.6333, loss: 0.00000092\n",
      "Epoch: [43] [  16/  20] time: 323.9728, loss: 0.00002520\n",
      "Epoch: [43] [  17/  20] time: 324.3133, loss: 0.00000452\n",
      "Epoch: [43] [  18/  20] time: 324.6506, loss: 0.00001042\n",
      "Epoch: [43] [  19/  20] time: 324.9908, loss: 0.00000029\n",
      "[43/50] - ptime: 7.1398 loss: 0.00003915 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [44] [   0/  20] time: 326.1491, loss: 0.00000126\n",
      "Epoch: [44] [   1/  20] time: 326.4875, loss: 0.00001012\n",
      "Epoch: [44] [   2/  20] time: 326.8256, loss: 0.00012151\n",
      "Epoch: [44] [   3/  20] time: 327.1620, loss: 0.00003222\n",
      "Epoch: [44] [   4/  20] time: 327.4986, loss: 0.00000120\n",
      "Epoch: [44] [   5/  20] time: 327.8366, loss: 0.00000038\n",
      "Epoch: [44] [   6/  20] time: 328.1737, loss: 0.00000366\n",
      "Epoch: [44] [   7/  20] time: 328.5102, loss: 0.00000032\n",
      "Epoch: [44] [   8/  20] time: 328.8476, loss: 0.00001748\n",
      "Epoch: [44] [   9/  20] time: 329.1855, loss: 0.00001385\n",
      "Epoch: [44] [  10/  20] time: 329.5234, loss: 0.00000221\n",
      "Epoch: [44] [  11/  20] time: 329.8608, loss: 0.00000901\n",
      "Epoch: [44] [  12/  20] time: 330.1975, loss: 0.00000112\n",
      "Epoch: [44] [  13/  20] time: 330.5359, loss: 0.00000055\n",
      "Epoch: [44] [  14/  20] time: 330.8756, loss: 0.00003396\n",
      "Epoch: [44] [  15/  20] time: 331.2108, loss: 0.00001303\n",
      "Epoch: [44] [  16/  20] time: 331.5507, loss: 0.00000007\n",
      "Epoch: [44] [  17/  20] time: 331.8892, loss: 0.00000296\n",
      "Epoch: [44] [  18/  20] time: 332.2252, loss: 0.00000051\n",
      "Epoch: [44] [  19/  20] time: 332.5619, loss: 0.00002011\n",
      "[44/50] - ptime: 7.1645 loss: 0.00001428 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [45] [   0/  20] time: 333.6612, loss: 0.00001091\n",
      "Epoch: [45] [   1/  20] time: 334.0026, loss: 0.00000128\n",
      "Epoch: [45] [   2/  20] time: 334.3416, loss: 0.00000073\n",
      "Epoch: [45] [   3/  20] time: 334.6821, loss: 0.00001180\n",
      "Epoch: [45] [   4/  20] time: 335.0215, loss: 0.00002721\n",
      "Epoch: [45] [   5/  20] time: 335.3579, loss: 0.00001161\n",
      "Epoch: [45] [   6/  20] time: 335.6978, loss: 0.00000473\n",
      "Epoch: [45] [   7/  20] time: 336.0349, loss: 0.00004029\n",
      "Epoch: [45] [   8/  20] time: 336.3708, loss: 0.00000461\n",
      "Epoch: [45] [   9/  20] time: 336.7079, loss: 0.00000072\n",
      "Epoch: [45] [  10/  20] time: 337.0443, loss: 0.00000398\n",
      "Epoch: [45] [  11/  20] time: 337.3822, loss: 0.00000315\n",
      "Epoch: [45] [  12/  20] time: 337.7208, loss: 0.00000641\n",
      "Epoch: [45] [  13/  20] time: 338.0601, loss: 0.00000754\n",
      "Epoch: [45] [  14/  20] time: 338.3976, loss: 0.00000095\n",
      "Epoch: [45] [  15/  20] time: 338.7332, loss: 0.00000078\n",
      "Epoch: [45] [  16/  20] time: 339.0695, loss: 0.00000856\n",
      "Epoch: [45] [  17/  20] time: 339.4061, loss: 0.00000077\n",
      "Epoch: [45] [  18/  20] time: 339.7432, loss: 0.00000469\n",
      "Epoch: [45] [  19/  20] time: 340.0822, loss: 0.00000257\n",
      "[45/50] - ptime: 7.1501 loss: 0.00000767 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [46] [   0/  20] time: 341.2856, loss: 0.00000315\n",
      "Epoch: [46] [   1/  20] time: 341.6225, loss: 0.00000650\n",
      "Epoch: [46] [   2/  20] time: 341.9652, loss: 0.00001535\n",
      "Epoch: [46] [   3/  20] time: 342.2989, loss: 0.00001195\n",
      "Epoch: [46] [   4/  20] time: 342.6365, loss: 0.00001155\n",
      "Epoch: [46] [   5/  20] time: 342.9769, loss: 0.00000094\n",
      "Epoch: [46] [   6/  20] time: 343.3176, loss: 0.00002060\n",
      "Epoch: [46] [   7/  20] time: 343.6570, loss: 0.00000859\n",
      "Epoch: [46] [   8/  20] time: 343.9966, loss: 0.00000951\n",
      "Epoch: [46] [   9/  20] time: 344.3348, loss: 0.00000274\n",
      "Epoch: [46] [  10/  20] time: 344.6727, loss: 0.00000639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46] [  11/  20] time: 345.0155, loss: 0.00000364\n",
      "Epoch: [46] [  12/  20] time: 345.3536, loss: 0.00000120\n",
      "Epoch: [46] [  13/  20] time: 345.6908, loss: 0.00002526\n",
      "Epoch: [46] [  14/  20] time: 346.0299, loss: 0.00002295\n",
      "Epoch: [46] [  15/  20] time: 346.3672, loss: 0.00000071\n",
      "Epoch: [46] [  16/  20] time: 346.7046, loss: 0.00001324\n",
      "Epoch: [46] [  17/  20] time: 347.0440, loss: 0.00000455\n",
      "Epoch: [46] [  18/  20] time: 347.3838, loss: 0.00000098\n",
      "Epoch: [46] [  19/  20] time: 347.7201, loss: 0.00000138\n",
      "[46/50] - ptime: 7.1978 loss: 0.00000856 acc: 0.69000 lr: 0.00065610\n",
      "Epoch: [47] [   0/  20] time: 348.8535, loss: 0.00000197\n",
      "Epoch: [47] [   1/  20] time: 349.1903, loss: 0.00000904\n",
      "Epoch: [47] [   2/  20] time: 349.5299, loss: 0.00000220\n",
      "Epoch: [47] [   3/  20] time: 349.8700, loss: 0.00001244\n",
      "Epoch: [47] [   4/  20] time: 350.2076, loss: 0.00000063\n",
      "Epoch: [47] [   5/  20] time: 350.5480, loss: 0.00061438\n",
      "Epoch: [47] [   6/  20] time: 350.8864, loss: 0.00000111\n",
      "Epoch: [47] [   7/  20] time: 351.2256, loss: 0.00001537\n",
      "Epoch: [47] [   8/  20] time: 351.5628, loss: 0.00004730\n",
      "Epoch: [47] [   9/  20] time: 351.9022, loss: 0.00001613\n",
      "Epoch: [47] [  10/  20] time: 352.2420, loss: 0.00002068\n",
      "Epoch: [47] [  11/  20] time: 352.5814, loss: 0.00001591\n",
      "Epoch: [47] [  12/  20] time: 352.9203, loss: 0.00002880\n",
      "Epoch: [47] [  13/  20] time: 353.2585, loss: 0.00000164\n",
      "Epoch: [47] [  14/  20] time: 353.5908, loss: 0.00001259\n",
      "Epoch: [47] [  15/  20] time: 353.9295, loss: 0.00006950\n",
      "Epoch: [47] [  16/  20] time: 354.2673, loss: 0.00000662\n",
      "Epoch: [47] [  17/  20] time: 354.6039, loss: 0.00000334\n",
      "Epoch: [47] [  18/  20] time: 354.9447, loss: 0.00000274\n",
      "Epoch: [47] [  19/  20] time: 355.2820, loss: 0.00000906\n",
      "[47/50] - ptime: 7.1923 loss: 0.00004457 acc: 0.67000 lr: 0.00065610\n",
      "Epoch: [48] [   0/  20] time: 356.4209, loss: 0.00000101\n",
      "Epoch: [48] [   1/  20] time: 356.7591, loss: 0.00000566\n",
      "Epoch: [48] [   2/  20] time: 357.1004, loss: 0.00001370\n",
      "Epoch: [48] [   3/  20] time: 357.4404, loss: 0.00000730\n",
      "Epoch: [48] [   4/  20] time: 357.7790, loss: 0.00000036\n",
      "Epoch: [48] [   5/  20] time: 358.1178, loss: 0.00000104\n",
      "Epoch: [48] [   6/  20] time: 358.4596, loss: 0.00000655\n",
      "Epoch: [48] [   7/  20] time: 358.7976, loss: 0.00002753\n",
      "Epoch: [48] [   8/  20] time: 359.1381, loss: 0.00000518\n",
      "Epoch: [48] [   9/  20] time: 359.4766, loss: 0.00000249\n",
      "Epoch: [48] [  10/  20] time: 359.8173, loss: 0.00000050\n",
      "Epoch: [48] [  11/  20] time: 360.1540, loss: 0.00000030\n",
      "Epoch: [48] [  12/  20] time: 360.4908, loss: 0.00000090\n",
      "Epoch: [48] [  13/  20] time: 360.8285, loss: 0.00002949\n",
      "Epoch: [48] [  14/  20] time: 361.1663, loss: 0.00000922\n",
      "Epoch: [48] [  15/  20] time: 361.5035, loss: 0.00006718\n",
      "Epoch: [48] [  16/  20] time: 361.8432, loss: 0.00000099\n",
      "Epoch: [48] [  17/  20] time: 362.1801, loss: 0.00000031\n",
      "Epoch: [48] [  18/  20] time: 362.5182, loss: 0.00001081\n",
      "Epoch: [48] [  19/  20] time: 362.8565, loss: 0.00000515\n",
      "[48/50] - ptime: 7.2045 loss: 0.00000978 acc: 0.67000 lr: 0.00065610\n",
      "Epoch: [49] [   0/  20] time: 363.9410, loss: 0.00000145\n",
      "Epoch: [49] [   1/  20] time: 364.2777, loss: 0.00000099\n",
      "Epoch: [49] [   2/  20] time: 364.6140, loss: 0.00000357\n",
      "Epoch: [49] [   3/  20] time: 364.9541, loss: 0.00000187\n",
      "Epoch: [49] [   4/  20] time: 365.2964, loss: 0.00000731\n",
      "Epoch: [49] [   5/  20] time: 365.6345, loss: 0.00000001\n",
      "Epoch: [49] [   6/  20] time: 365.9780, loss: 0.00000410\n",
      "Epoch: [49] [   7/  20] time: 366.3167, loss: 0.00002539\n",
      "Epoch: [49] [   8/  20] time: 366.6548, loss: 0.00000080\n",
      "Epoch: [49] [   9/  20] time: 366.9937, loss: 0.00000057\n",
      "Epoch: [49] [  10/  20] time: 367.3322, loss: 0.00000024\n",
      "Epoch: [49] [  11/  20] time: 367.6674, loss: 0.00000262\n",
      "Epoch: [49] [  12/  20] time: 368.0102, loss: 0.00000010\n",
      "Epoch: [49] [  13/  20] time: 368.3479, loss: 0.00000855\n",
      "Epoch: [49] [  14/  20] time: 368.6854, loss: 0.00000178\n",
      "Epoch: [49] [  15/  20] time: 369.0257, loss: 0.00000308\n",
      "Epoch: [49] [  16/  20] time: 369.3626, loss: 0.00001319\n",
      "Epoch: [49] [  17/  20] time: 369.7020, loss: 0.00006693\n",
      "Epoch: [49] [  18/  20] time: 370.0394, loss: 0.00001377\n",
      "Epoch: [49] [  19/  20] time: 370.3763, loss: 0.00001114\n",
      "[49/50] - ptime: 7.1566 loss: 0.00000837 acc: 0.67000 lr: 0.00065610\n",
      "Epoch: [50] [   0/  20] time: 371.4725, loss: 0.00000226\n",
      "Epoch: [50] [   1/  20] time: 371.8093, loss: 0.00000232\n",
      "Epoch: [50] [   2/  20] time: 372.1484, loss: 0.00000017\n",
      "Epoch: [50] [   3/  20] time: 372.4852, loss: 0.00000826\n",
      "Epoch: [50] [   4/  20] time: 372.8237, loss: 0.00001464\n",
      "Epoch: [50] [   5/  20] time: 373.1644, loss: 0.00000363\n",
      "Epoch: [50] [   6/  20] time: 373.5020, loss: 0.00004103\n",
      "Epoch: [50] [   7/  20] time: 373.8412, loss: 0.00000198\n",
      "Epoch: [50] [   8/  20] time: 374.1794, loss: 0.00000976\n",
      "Epoch: [50] [   9/  20] time: 374.5135, loss: 0.00000050\n",
      "Epoch: [50] [  10/  20] time: 374.8524, loss: 0.00000916\n",
      "Epoch: [50] [  11/  20] time: 375.1898, loss: 0.00000399\n",
      "Epoch: [50] [  12/  20] time: 375.5302, loss: 0.00000390\n",
      "Epoch: [50] [  13/  20] time: 375.8690, loss: 0.00003979\n",
      "Epoch: [50] [  14/  20] time: 376.2077, loss: 0.00000400\n",
      "Epoch: [50] [  15/  20] time: 376.5452, loss: 0.00001246\n",
      "Epoch: [50] [  16/  20] time: 376.8867, loss: 0.00001805\n",
      "Epoch: [50] [  17/  20] time: 377.2252, loss: 0.00000067\n",
      "Epoch: [50] [  18/  20] time: 377.5597, loss: 0.00000069\n",
      "Epoch: [50] [  19/  20] time: 377.8969, loss: 0.00000136\n",
      "[50/50] - ptime: 7.1536 loss: 0.00000893 acc: 0.69000 lr: 0.00059049\n",
      "Avg per epoch ptime: 7.17, total 50 epochs ptime: 378.63\n",
      " [*] Training finished!\n",
      " [*] Best Epoch:  20 , Accuracy:  0.8299999833106995\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay-20\n",
      " [*] Finished testing Best Epoch: 20 , accuracy:  0.8300000429153442 !\n"
     ]
    }
   ],
   "source": [
    "dataset = '4_Flowers_1s'\n",
    "epoch = 50\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "log_dir = 'logs'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    CNN = CNN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                log_dir=log_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    CNN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    CNN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    CNN.train()\n",
    "    \n",
    "#     CNN.test(epoch)\n",
    "        \n",
    "sess.close()\n",
    "        \n",
    "# lrdecay\n",
    "# Avg per epoch ptime: 7.17, total 50 epochs ptime: 378.63\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  20 , Accuracy:  0.8299999833106995\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay-20\n",
    "#  [*] Finished testing Best Epoch: 20 , accuracy:  0.8300000429153442 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "file='/home/huiqy/Music/CloudMusic/All_Time_Low.mp3' #文件名是完整路径名\n",
    "pygame.mixer.init() #初始化音频\n",
    "track = pygame.mixer.music.load(file)#载入音乐文件\n",
    "pygame.mixer.music.play()#开始播放\n",
    "time.sleep(60)#播放10秒\n",
    "pygame.mixer.music.stop()#停止播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
