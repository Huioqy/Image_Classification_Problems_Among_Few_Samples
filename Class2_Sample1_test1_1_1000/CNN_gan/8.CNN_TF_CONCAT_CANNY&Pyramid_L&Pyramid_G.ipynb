{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, log_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "        \n",
    "        # number of convolutional filters to use  \n",
    "        self.nb_CNN = [32, 64, 64, 64, 128]  \n",
    "        # number of dense filters to use  \n",
    "        self.nb_Dense = [256] \n",
    "        # size of pooling area for max pooling  \n",
    "        self.pool_size = (2, 2)  \n",
    "        # convolution kernel size  \n",
    "        self.kernel_size = (3, 3)\n",
    "        self.batch_normalization_control = True\n",
    "        \n",
    "        # name for checkpoint\n",
    "        self.model_name = 'CNN_Canny&Pyramid_L_C%d_D%d_Kernel(%d,%d)_%d_lrdecay' % (len(self.nb_CNN), len(self.nb_Dense),\n",
    "                                                          self.kernel_size[0], self.kernel_size[1], max(self.nb_CNN))\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay(0.001, \n",
    "                                             global_step=self.global_step, \n",
    "                                             decay_steps=10, \n",
    "                                             decay_rate=0.9, \n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "        \n",
    "        # test\n",
    "\n",
    "        #load_flower_data\n",
    "        self.train_x = np.load('../trainImage.npy')\n",
    "        self.train_y = np.load('../trainLabels.npy')\n",
    "        self.test_x = np.load('../testImage.npy')\n",
    "        self.test_y = np.load('../testLabels.npy')\n",
    "        self.train_x_f1 = np.load('../trainImage_canny.npy')\n",
    "        self.test_x_f1 = np.load('../testImage_canny.npy')\n",
    "        self.train_x_f2 = np.load('../trainImage_pyramid_L.npy')/255.0\n",
    "        self.test_x_f2 = np.load('../testImage_pyramid_L.npy')/255.0\n",
    "        self.train_x_f3 = np.load('../trainImage_pyramid_G.npy')/255.0\n",
    "        self.test_x_f3 = np.load('../testImage_pyramid_G.npy')/255.0\n",
    "\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['losses'] = []\n",
    "        self.train_hist['accuracy'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches_train = len(self.train_x) // self.batch_size\n",
    "        self.num_batches_test= len(self.test_x) // self.batch_size\n",
    "\n",
    "    def cnn_model(self, x, x_f1, x_f2, x_f3, keep_prob, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"cnn\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            B = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"CNN:x\",x.get_shape()) # 128, 128, 3 \n",
    "            print(\"CNN:x_f1\",x_f1.get_shape()) \n",
    "            print(\"CNN:x_f2\",x_f2.get_shape())  \n",
    "            print(\"CNN:x_f3\",x_f3.get_shape())  \n",
    "            \n",
    "            #输入x,卷积核为3*3 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(inputs = x,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_1'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_1.get_shape())\n",
    "            \n",
    "            #输入x_f1,卷积核为3*3 输出维度为32\n",
    "            net1_2 = tf.layers.conv2d(inputs = x_f1,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_2'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_2.get_shape())\n",
    "            \n",
    "            #输入x_f2,卷积核为3*3 输出维度为32\n",
    "            net1_3 = tf.layers.conv2d(inputs = x_f2,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_3'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_3.get_shape())\n",
    "            \n",
    "            #输入x_f3,卷积核为3*3 输出维度为32\n",
    "            net1_4 = tf.layers.conv2d(inputs = x_f3,                 # 输入,\n",
    "                                    filters = self.nb_CNN[0],      # 卷积核个数,\n",
    "                                    kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                    strides = (1, 1),\n",
    "                                    padding = 'same',              # padding方法\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer = None,\n",
    "                                    bias_regularizer = None,\n",
    "                                    activity_regularizer = None,\n",
    "                                    name = 'conv_1_4'               # 命名用于获取变量\n",
    "                                    )\n",
    "            print(\"CNN:\",net1_4.get_shape())\n",
    "\n",
    "            #把数据和边缘进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            net = tf.concat([net, net1_3], 3)\n",
    "            net = tf.concat([net, net1_4], 3)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)\n",
    "            net = tf.nn.relu(net, name = 'relu_conv_1')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_1'\n",
    "                                             )\n",
    "            \n",
    "            for i in range(2,len(self.nb_CNN)+1):\n",
    "                net = tf.layers.conv2d(inputs = net,                 # 输入,\n",
    "                                       filters = self.nb_CNN[i-1],      # 卷积核个数,\n",
    "                                       kernel_size = self.kernel_size,          # 卷积核尺寸\n",
    "                                       strides = (1, 1),\n",
    "                                       padding = 'same',              # padding方法\n",
    "                                       kernel_initializer = W,\n",
    "                                       bias_initializer = B,\n",
    "                                       kernel_regularizer = None,\n",
    "                                       bias_regularizer = None,\n",
    "                                       activity_regularizer = None,\n",
    "                                       name = 'conv_'+ str(i)        # 命名用于获取变量\n",
    "                                       )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "                if self.batch_normalization_control:\n",
    "                    net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_conv_' + str(i))\n",
    "                net = tf.layers.max_pooling2d(inputs = net,\n",
    "                                              pool_size = self.pool_size,\n",
    "                                              strides = (2, 2),\n",
    "                                              padding = 'same',\n",
    "                                              name = 'pool_conv_' + str(i)\n",
    "                                             )\n",
    "                print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #flatten\n",
    "            net = tf.reshape(net, [-1, int(net.get_shape()[1]*net.get_shape()[2]*net.get_shape()[3])],name='flatten')\n",
    "            print(\"CNN:\",net.get_shape())\n",
    "            \n",
    "            #dense layer\n",
    "            for i in range(1,len(self.nb_Dense)+1):\n",
    "                net = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_Dense[i-1],\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_' + str(i)\n",
    "                                    )\n",
    "#                 net = tf.layers.batch_normalization(net, training=is_training)\n",
    "                net = tf.nn.relu( net, name = 'relu_dense_' + str(i))\n",
    "                net = tf.layers.dropout(inputs = net,\n",
    "                                        rate=keep_prob,\n",
    "                                        noise_shape=None,\n",
    "                                        seed=None,\n",
    "                                        training = is_training,\n",
    "                                        name= 'dropout_dense_' + str(i)\n",
    "                                        )\n",
    "            #output\n",
    "            logit = tf.layers.dense(inputs = net,\n",
    "                                    units = self.nb_class,\n",
    "                                    kernel_initializer = W,\n",
    "                                    bias_initializer = B,\n",
    "                                    kernel_regularizer=None,\n",
    "                                    bias_regularizer=None,\n",
    "                                    activity_regularizer=None,\n",
    "                                    name = 'dense_output'\n",
    "                                    )\n",
    "            out_logit = tf.nn.softmax(logit, name=\"softmax\")\n",
    "            print(\"CNN:out_logit\",out_logit.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out_logit, logit\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=[self.batch_size,self.input_height, self.input_width, self.c_dim], \n",
    "                                name='x_image')\n",
    "        \n",
    "        self.x_f1 = tf.placeholder(tf.float32, shape=[self.batch_size,self.train_x_f1.shape[1], \n",
    "                                                     self.train_x_f1.shape[2], self.train_x_f1.shape[3]],\n",
    "                                  name='x_f1')\n",
    "        self.x_f2 = tf.placeholder(tf.float32, shape=[self.batch_size,self.train_x_f2.shape[1], \n",
    "                                                     self.train_x_f2.shape[2], self.train_x_f2.shape[3]],\n",
    "                                  name='x_f2')\n",
    "        self.x_f3 = tf.placeholder(tf.float32, shape=[self.batch_size,self.train_x_f3.shape[1], \n",
    "                                             self.train_x_f3.shape[2], self.train_x_f3.shape[3]],\n",
    "                          name='x_f3')\n",
    "\n",
    "        self.y = tf.placeholder(tf.float32, shape=[self.batch_size, self.nb_class], name='y_label')\n",
    "        \n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of cnn_model\n",
    "        self.out_logit, self.logit = self.cnn_model(self.x, self.x_f1, self.x_f2, self.x_f3, self.keep_prob, is_training=True, reuse=False)\n",
    "        \n",
    "        self.loss_cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y,\n",
    "                                                                                         logits =self.logit))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # trainable variables into a group\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        cnn_vars = [var for var in tf_vars if var.name.startswith('cnn')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.cnn_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.loss_cross_entropy,\n",
    "                                                                                        var_list=cnn_vars)\n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        # output of cnn_model\n",
    "        self.out_logit_test, self.logit_test = self.cnn_model(self.x,  self.x_f1, self.x_f2, self.x_f3, self.keep_prob, is_training=False, reuse=True)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.logit_test, 1), tf.argmax(self.y, 1))\n",
    "        self.predict = tf.argmax(self.logit_test, 1)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        self.loss_sum = tf.summary.scalar(\"loss\", self.loss_cross_entropy)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep = self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name+'.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            CNN_losses = []\n",
    "  \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.train_x.shape[0]), self.train_x.shape[0])\n",
    "            shuffled_set = self.train_x[shuffle_idxs]\n",
    "            shuffled_set_f1 = self.train_x_f1[shuffle_idxs]\n",
    "            shuffled_set_f2 = self.train_x_f2[shuffle_idxs]\n",
    "            shuffled_set_f3 = self.train_x_f3[shuffle_idxs]\n",
    "            shuffled_label = self.train_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches_train):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_f1 = shuffled_set_f1[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_f2 = shuffled_set_f2[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_x_f3 = shuffled_set_f3[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, cnn_loss = self.sess.run([self.cnn_optim, self.loss_sum, self.loss_cross_entropy],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.x_f1: batch_x_f1,\n",
    "                                                          self.x_f2: batch_x_f2,\n",
    "                                                          self.x_f3: batch_x_f3,\n",
    "                                                          self.y: batch_y,\n",
    "                                                          self.keep_prob: 0.5}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                CNN_losses.append(cnn_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" % (epoch_loop, idx, self.num_batches_train, \n",
    "                                                                          time.time() - start_time, cnn_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            # Evaluates accuracy on test set\n",
    "            test_accuracy_list = []\n",
    "            for idx_test in range(self.num_batches_test):\n",
    "                batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_f1_test =self.test_x_f1[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_f2_test =self.test_x_f2[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_x_f3_test =self.test_x_f3[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "                batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, self.nb_class])\n",
    "                accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                    self.x_f1: batch_x_f1_test,\n",
    "                                                                    self.x_f2: batch_x_f2_test,\n",
    "                                                                    self.x_f3: batch_x_f3_test,\n",
    "                                                                    self.y: batch_y_tes,\n",
    "                                                                    self.keep_prob: 1.0})\n",
    "                test_accuracy_list.append(accuracy)\n",
    "            test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        \n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            \n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss: %.8f acc: %.5f lr: %.8f'% (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                    np.mean(CNN_losses), test_accuracy, rate))\n",
    "            \n",
    "            self.train_hist['losses'].append(np.mean(CNN_losses))\n",
    "            self.train_hist['accuracy'].append( test_accuracy)\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "            \n",
    "            # save trainhist for train\n",
    "            f = open(self.trainhist_dir + '/' + self.model_name + '.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' \n",
    "                                 + self.model_name + '.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "        \"\"\"test after train\"\"\"\n",
    "        best_acc = max(self.train_hist['accuracy'])\n",
    "        beat_epoch = self.train_hist['accuracy'].index(best_acc) + 1\n",
    "        print (\" [*] Best Epoch: \", beat_epoch, \", Accuracy: \", best_acc)\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(beat_epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f1_test =self.test_x_f1[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f2_test =self.test_x_f2[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f3_test =self.test_x_f3[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_f1: batch_x_f1_test,\n",
    "                                                                self.x_f2: batch_x_f2_test,\n",
    "                                                                self.x_f3: batch_x_f3_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Best Epoch:\", beat_epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "\n",
    "    def test(self, epoch):\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_name + '/'+ self.model_name +'-'+ str(epoch)\n",
    "\n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "\n",
    "        # Evaluates accuracy on test set\n",
    "        test_accuracy_list = []\n",
    "        for idx_test in range(self.num_batches_test):\n",
    "            batch_x_test = self.test_x[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f1_test =self.test_x_f1[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_x_f2_test =self.test_x_f2[idx_test*self.batch_size:(idx_test+1)*self.batch_size]\n",
    "            batch_y_tes = self.test_y[idx_test*self.batch_size:(idx_test+1)*self.batch_size].reshape(\n",
    "                                    [self.batch_size, self.nb_class])\n",
    "            accuracy = self.sess.run([self.accuracy],feed_dict={self.x: batch_x_test, \n",
    "                                                                self.x_f1: batch_x_f1_test,\n",
    "                                                                self.x_f2: batch_x_f2_test,\n",
    "                                                                self.y: batch_y_tes,\n",
    "                                                                self.keep_prob: 1.0})\n",
    "            test_accuracy_list.append(accuracy)\n",
    "        test_accuracy = np.sum(test_accuracy_list)/self.num_batches_test\n",
    "        print(\" [*] Finished testing Epoch:\", epoch, \", accuracy: \",test_accuracy, \"!\")\n",
    "        \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True) \n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['losses'])+1)\n",
    "\n",
    "        y1 = hist['losses']\n",
    "        y2 = hist['accuracy']\n",
    "        \n",
    "        fig, ax1 = plt.subplots()\n",
    "                            \n",
    "        ax2 = ax1.twinx()  \n",
    "\n",
    "        ax1.plot(x, y1, 'b')\n",
    "        ax2.plot(x, y2, 'r')\n",
    "                            \n",
    "        ax1.set_xlabel('Epoch')\n",
    "                            \n",
    "        ax1.set_ylabel('CNN_loss')    \n",
    "        ax2.set_ylabel('accuracy')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_f1 (100, 128, 128, 1)\n",
      "CNN:x_f2 (100, 128, 128, 2)\n",
      "CNN:x_f3 (100, 128, 128, 2)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 128)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "CNN:x (100, 128, 128, 3)\n",
      "CNN:x_f1 (100, 128, 128, 1)\n",
      "CNN:x_f2 (100, 128, 128, 2)\n",
      "CNN:x_f3 (100, 128, 128, 2)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 32)\n",
      "CNN: (100, 128, 128, 128)\n",
      "CNN: (100, 64, 64, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 32, 32, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 16, 16, 64)\n",
      "CNN: (100, 8, 8, 64)\n",
      "CNN: (100, 8, 8, 128)\n",
      "CNN: (100, 4, 4, 128)\n",
      "CNN: (100, 2048)\n",
      "CNN:out_logit (100, 2)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "cnn/conv_1_1/kernel:0 (float32_ref 3x3x3x32) [864, bytes: 3456]\n",
      "cnn/conv_1_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_2/kernel:0 (float32_ref 3x3x1x32) [288, bytes: 1152]\n",
      "cnn/conv_1_2/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_3/kernel:0 (float32_ref 3x3x2x32) [576, bytes: 2304]\n",
      "cnn/conv_1_3/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/conv_1_4/kernel:0 (float32_ref 3x3x2x32) [576, bytes: 2304]\n",
      "cnn/conv_1_4/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "cnn/batch_normalization/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/conv_2/kernel:0 (float32_ref 3x3x128x64) [73728, bytes: 294912]\n",
      "cnn/conv_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_1/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_3/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_3/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_4/kernel:0 (float32_ref 3x3x64x64) [36864, bytes: 147456]\n",
      "cnn/conv_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/batch_normalization_3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "cnn/conv_5/kernel:0 (float32_ref 3x3x64x128) [73728, bytes: 294912]\n",
      "cnn/conv_5/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/batch_normalization_4/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "cnn/dense_1/kernel:0 (float32_ref 2048x256) [524288, bytes: 2097152]\n",
      "cnn/dense_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "cnn/dense_output/kernel:0 (float32_ref 256x2) [512, bytes: 2048]\n",
      "cnn/dense_output/bias:0 (float32_ref 2) [2, bytes: 8]\n",
      "Total size of variables: 749890\n",
      "Total bytes of variables: 2999560\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 1] [   0/  20] time: 3.3587, loss: 0.77839762\n",
      "Epoch: [ 1] [   1/  20] time: 3.8039, loss: 0.50535560\n",
      "Epoch: [ 1] [   2/  20] time: 4.2652, loss: 0.30478147\n",
      "Epoch: [ 1] [   3/  20] time: 4.7142, loss: 0.08435714\n",
      "Epoch: [ 1] [   4/  20] time: 5.1772, loss: 0.10033067\n",
      "Epoch: [ 1] [   5/  20] time: 5.6210, loss: 0.07998028\n",
      "Epoch: [ 1] [   6/  20] time: 6.0860, loss: 0.06798125\n",
      "Epoch: [ 1] [   7/  20] time: 6.5345, loss: 0.06389507\n",
      "Epoch: [ 1] [   8/  20] time: 6.9899, loss: 0.08501853\n",
      "Epoch: [ 1] [   9/  20] time: 7.4361, loss: 0.08266064\n",
      "Epoch: [ 1] [  10/  20] time: 7.8830, loss: 0.03845173\n",
      "Epoch: [ 1] [  11/  20] time: 8.3277, loss: 0.07587235\n",
      "Epoch: [ 1] [  12/  20] time: 8.7753, loss: 0.13492773\n",
      "Epoch: [ 1] [  13/  20] time: 9.2317, loss: 0.01126458\n",
      "Epoch: [ 1] [  14/  20] time: 9.6760, loss: 0.02130107\n",
      "Epoch: [ 1] [  15/  20] time: 10.1321, loss: 0.06009273\n",
      "Epoch: [ 1] [  16/  20] time: 10.5794, loss: 0.03958954\n",
      "Epoch: [ 1] [  17/  20] time: 11.0362, loss: 0.10779763\n",
      "Epoch: [ 1] [  18/  20] time: 11.4810, loss: 0.03822725\n",
      "Epoch: [ 1] [  19/  20] time: 11.9317, loss: 0.05155319\n",
      "[1/80] - ptime: 12.0717 loss: 0.13659182 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 2] [   0/  20] time: 13.7228, loss: 0.03058628\n",
      "Epoch: [ 2] [   1/  20] time: 14.1857, loss: 0.01674363\n",
      "Epoch: [ 2] [   2/  20] time: 14.6330, loss: 0.00715752\n",
      "Epoch: [ 2] [   3/  20] time: 15.0828, loss: 0.16966014\n",
      "Epoch: [ 2] [   4/  20] time: 15.5302, loss: 0.02691429\n",
      "Epoch: [ 2] [   5/  20] time: 15.9746, loss: 0.09162677\n",
      "Epoch: [ 2] [   6/  20] time: 16.4353, loss: 0.05690064\n",
      "Epoch: [ 2] [   7/  20] time: 16.8799, loss: 0.02829102\n",
      "Epoch: [ 2] [   8/  20] time: 17.3371, loss: 0.12167946\n",
      "Epoch: [ 2] [   9/  20] time: 17.7819, loss: 0.03996655\n",
      "Epoch: [ 2] [  10/  20] time: 18.2383, loss: 0.03990595\n",
      "Epoch: [ 2] [  11/  20] time: 18.6837, loss: 0.09225659\n",
      "Epoch: [ 2] [  12/  20] time: 19.1390, loss: 0.02131098\n",
      "Epoch: [ 2] [  13/  20] time: 19.5848, loss: 0.01984537\n",
      "Epoch: [ 2] [  14/  20] time: 20.0366, loss: 0.08137707\n",
      "Epoch: [ 2] [  15/  20] time: 20.4874, loss: 0.02528864\n",
      "Epoch: [ 2] [  16/  20] time: 20.9354, loss: 0.02707430\n",
      "Epoch: [ 2] [  17/  20] time: 21.3923, loss: 0.02780475\n",
      "Epoch: [ 2] [  18/  20] time: 21.8371, loss: 0.02178612\n",
      "Epoch: [ 2] [  19/  20] time: 22.2854, loss: 0.02840197\n",
      "[2/80] - ptime: 9.8338 loss: 0.04872890 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 3] [   0/  20] time: 24.2056, loss: 0.01263383\n",
      "Epoch: [ 3] [   1/  20] time: 24.6524, loss: 0.01561622\n",
      "Epoch: [ 3] [   2/  20] time: 25.1002, loss: 0.03736204\n",
      "Epoch: [ 3] [   3/  20] time: 25.5529, loss: 0.01455494\n",
      "Epoch: [ 3] [   4/  20] time: 26.0000, loss: 0.06055857\n",
      "Epoch: [ 3] [   5/  20] time: 26.4592, loss: 0.05319136\n",
      "Epoch: [ 3] [   6/  20] time: 26.9059, loss: 0.01723065\n",
      "Epoch: [ 3] [   7/  20] time: 27.3630, loss: 0.02028775\n",
      "Epoch: [ 3] [   8/  20] time: 27.8083, loss: 0.08946554\n",
      "Epoch: [ 3] [   9/  20] time: 28.2663, loss: 0.02963713\n",
      "Epoch: [ 3] [  10/  20] time: 28.7137, loss: 0.02228356\n",
      "Epoch: [ 3] [  11/  20] time: 29.1631, loss: 0.02768539\n",
      "Epoch: [ 3] [  12/  20] time: 29.6093, loss: 0.03668272\n",
      "Epoch: [ 3] [  13/  20] time: 30.0577, loss: 0.01877773\n",
      "Epoch: [ 3] [  14/  20] time: 30.5209, loss: 0.03392799\n",
      "Epoch: [ 3] [  15/  20] time: 30.9665, loss: 0.04192515\n",
      "Epoch: [ 3] [  16/  20] time: 31.4220, loss: 0.02400284\n",
      "Epoch: [ 3] [  17/  20] time: 31.8636, loss: 0.01247473\n",
      "Epoch: [ 3] [  18/  20] time: 32.3168, loss: 0.05095855\n",
      "Epoch: [ 3] [  19/  20] time: 32.7626, loss: 0.02360274\n",
      "[3/80] - ptime: 9.7672 loss: 0.03214297 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 4] [   0/  20] time: 34.6830, loss: 0.09262884\n",
      "Epoch: [ 4] [   1/  20] time: 35.1324, loss: 0.01767467\n",
      "Epoch: [ 4] [   2/  20] time: 35.5932, loss: 0.06718460\n",
      "Epoch: [ 4] [   3/  20] time: 36.0350, loss: 0.05180069\n",
      "Epoch: [ 4] [   4/  20] time: 36.4972, loss: 0.02383405\n",
      "Epoch: [ 4] [   5/  20] time: 36.9416, loss: 0.02419679\n",
      "Epoch: [ 4] [   6/  20] time: 37.3997, loss: 0.01082362\n",
      "Epoch: [ 4] [   7/  20] time: 37.8469, loss: 0.04301245\n",
      "Epoch: [ 4] [   8/  20] time: 38.2963, loss: 0.01641856\n",
      "Epoch: [ 4] [   9/  20] time: 38.7443, loss: 0.01094930\n",
      "Epoch: [ 4] [  10/  20] time: 39.1951, loss: 0.03048228\n",
      "Epoch: [ 4] [  11/  20] time: 39.6521, loss: 0.00599293\n",
      "Epoch: [ 4] [  12/  20] time: 40.1039, loss: 0.06105175\n",
      "Epoch: [ 4] [  13/  20] time: 40.5621, loss: 0.00952464\n",
      "Epoch: [ 4] [  14/  20] time: 41.0082, loss: 0.02648878\n",
      "Epoch: [ 4] [  15/  20] time: 41.4645, loss: 0.01023206\n",
      "Epoch: [ 4] [  16/  20] time: 41.9102, loss: 0.03632772\n",
      "Epoch: [ 4] [  17/  20] time: 42.3647, loss: 0.06543253\n",
      "Epoch: [ 4] [  18/  20] time: 42.8055, loss: 0.01174016\n",
      "Epoch: [ 4] [  19/  20] time: 43.2606, loss: 0.04759781\n",
      "[4/80] - ptime: 9.9073 loss: 0.03316971 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 5] [   0/  20] time: 45.0433, loss: 0.03944788\n",
      "Epoch: [ 5] [   1/  20] time: 45.5012, loss: 0.02579175\n",
      "Epoch: [ 5] [   2/  20] time: 45.9458, loss: 0.02195690\n",
      "Epoch: [ 5] [   3/  20] time: 46.3912, loss: 0.01588973\n",
      "Epoch: [ 5] [   4/  20] time: 46.8492, loss: 0.01676592\n",
      "Epoch: [ 5] [   5/  20] time: 47.2964, loss: 0.01897648\n",
      "Epoch: [ 5] [   6/  20] time: 47.7523, loss: 0.01250899\n",
      "Epoch: [ 5] [   7/  20] time: 48.2056, loss: 0.00623384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 5] [   8/  20] time: 48.6693, loss: 0.00767415\n",
      "Epoch: [ 5] [   9/  20] time: 49.1230, loss: 0.02674006\n",
      "Epoch: [ 5] [  10/  20] time: 49.5887, loss: 0.08388700\n",
      "Epoch: [ 5] [  11/  20] time: 50.0600, loss: 0.01122781\n",
      "Epoch: [ 5] [  12/  20] time: 50.5426, loss: 0.02599703\n",
      "Epoch: [ 5] [  13/  20] time: 51.0020, loss: 0.01488030\n",
      "Epoch: [ 5] [  14/  20] time: 51.4533, loss: 0.02967080\n",
      "Epoch: [ 5] [  15/  20] time: 51.9054, loss: 0.02119436\n",
      "Epoch: [ 5] [  16/  20] time: 52.3562, loss: 0.04280825\n",
      "Epoch: [ 5] [  17/  20] time: 52.8200, loss: 0.02671346\n",
      "Epoch: [ 5] [  18/  20] time: 53.2744, loss: 0.00978928\n",
      "Epoch: [ 5] [  19/  20] time: 53.7454, loss: 0.02139311\n",
      "[5/80] - ptime: 10.0304 loss: 0.02397736 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 6] [   0/  20] time: 55.5534, loss: 0.00454256\n",
      "Epoch: [ 6] [   1/  20] time: 56.0084, loss: 0.01128612\n",
      "Epoch: [ 6] [   2/  20] time: 56.4549, loss: 0.02369104\n",
      "Epoch: [ 6] [   3/  20] time: 56.9182, loss: 0.00652893\n",
      "Epoch: [ 6] [   4/  20] time: 57.3791, loss: 0.02336161\n",
      "Epoch: [ 6] [   5/  20] time: 57.8522, loss: 0.04381765\n",
      "Epoch: [ 6] [   6/  20] time: 58.3025, loss: 0.00915292\n",
      "Epoch: [ 6] [   7/  20] time: 58.7793, loss: 0.00388978\n",
      "Epoch: [ 6] [   8/  20] time: 59.2412, loss: 0.00570222\n",
      "Epoch: [ 6] [   9/  20] time: 59.7066, loss: 0.03789594\n",
      "Epoch: [ 6] [  10/  20] time: 60.1540, loss: 0.01470182\n",
      "Epoch: [ 6] [  11/  20] time: 60.6015, loss: 0.02176946\n",
      "Epoch: [ 6] [  12/  20] time: 61.0654, loss: 0.01819492\n",
      "Epoch: [ 6] [  13/  20] time: 61.5233, loss: 0.02019172\n",
      "Epoch: [ 6] [  14/  20] time: 61.9979, loss: 0.03144044\n",
      "Epoch: [ 6] [  15/  20] time: 62.4575, loss: 0.01196577\n",
      "Epoch: [ 6] [  16/  20] time: 62.9132, loss: 0.00954123\n",
      "Epoch: [ 6] [  17/  20] time: 63.3600, loss: 0.02144901\n",
      "Epoch: [ 6] [  18/  20] time: 63.8185, loss: 0.00310779\n",
      "Epoch: [ 6] [  19/  20] time: 64.2806, loss: 0.12615003\n",
      "[6/80] - ptime: 9.9481 loss: 0.02241905 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 7] [   0/  20] time: 66.2765, loss: 0.00219424\n",
      "Epoch: [ 7] [   1/  20] time: 66.7236, loss: 0.04729274\n",
      "Epoch: [ 7] [   2/  20] time: 67.2017, loss: 0.01574894\n",
      "Epoch: [ 7] [   3/  20] time: 67.6639, loss: 0.01603043\n",
      "Epoch: [ 7] [   4/  20] time: 68.1330, loss: 0.02304637\n",
      "Epoch: [ 7] [   5/  20] time: 68.5917, loss: 0.02892400\n",
      "Epoch: [ 7] [   6/  20] time: 69.0760, loss: 0.01327042\n",
      "Epoch: [ 7] [   7/  20] time: 69.5219, loss: 0.03296394\n",
      "Epoch: [ 7] [   8/  20] time: 69.9757, loss: 0.03821708\n",
      "Epoch: [ 7] [   9/  20] time: 70.4255, loss: 0.05052952\n",
      "Epoch: [ 7] [  10/  20] time: 70.8943, loss: 0.06445052\n",
      "Epoch: [ 7] [  11/  20] time: 71.3571, loss: 0.00399943\n",
      "Epoch: [ 7] [  12/  20] time: 71.8083, loss: 0.10166722\n",
      "Epoch: [ 7] [  13/  20] time: 72.2669, loss: 0.00993757\n",
      "Epoch: [ 7] [  14/  20] time: 72.7140, loss: 0.04546126\n",
      "Epoch: [ 7] [  15/  20] time: 73.1859, loss: 0.01827702\n",
      "Epoch: [ 7] [  16/  20] time: 73.6439, loss: 0.08494054\n",
      "Epoch: [ 7] [  17/  20] time: 74.1178, loss: 0.00978237\n",
      "Epoch: [ 7] [  18/  20] time: 74.5690, loss: 0.00838397\n",
      "Epoch: [ 7] [  19/  20] time: 75.0408, loss: 0.02182922\n",
      "[7/80] - ptime: 10.1225 loss: 0.03184734 acc: 0.45000 lr: 0.00100000\n",
      "Epoch: [ 8] [   0/  20] time: 76.9259, loss: 0.00715854\n",
      "Epoch: [ 8] [   1/  20] time: 77.3918, loss: 0.04588099\n",
      "Epoch: [ 8] [   2/  20] time: 77.8439, loss: 0.05889081\n",
      "Epoch: [ 8] [   3/  20] time: 78.3059, loss: 0.01732513\n",
      "Epoch: [ 8] [   4/  20] time: 78.7551, loss: 0.00130948\n",
      "Epoch: [ 8] [   5/  20] time: 79.2077, loss: 0.02839670\n",
      "Epoch: [ 8] [   6/  20] time: 79.6540, loss: 0.02012569\n",
      "Epoch: [ 8] [   7/  20] time: 80.1094, loss: 0.01572436\n",
      "Epoch: [ 8] [   8/  20] time: 80.5644, loss: 0.03235344\n",
      "Epoch: [ 8] [   9/  20] time: 81.0162, loss: 0.00785716\n",
      "Epoch: [ 8] [  10/  20] time: 81.4773, loss: 0.02965494\n",
      "Epoch: [ 8] [  11/  20] time: 81.9246, loss: 0.02407750\n",
      "Epoch: [ 8] [  12/  20] time: 82.3937, loss: 0.01256458\n",
      "Epoch: [ 8] [  13/  20] time: 82.8365, loss: 0.01646368\n",
      "Epoch: [ 8] [  14/  20] time: 83.3057, loss: 0.02526062\n",
      "Epoch: [ 8] [  15/  20] time: 83.7544, loss: 0.01328768\n",
      "Epoch: [ 8] [  16/  20] time: 84.2028, loss: 0.00627657\n",
      "Epoch: [ 8] [  17/  20] time: 84.6474, loss: 0.00590552\n",
      "Epoch: [ 8] [  18/  20] time: 85.0958, loss: 0.01415226\n",
      "Epoch: [ 8] [  19/  20] time: 85.5570, loss: 0.02128890\n",
      "[8/80] - ptime: 9.9529 loss: 0.02019773 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [ 9] [   0/  20] time: 87.4203, loss: 0.01481109\n",
      "Epoch: [ 9] [   1/  20] time: 87.8691, loss: 0.00107014\n",
      "Epoch: [ 9] [   2/  20] time: 88.3226, loss: 0.02862727\n",
      "Epoch: [ 9] [   3/  20] time: 88.7692, loss: 0.01241718\n",
      "Epoch: [ 9] [   4/  20] time: 89.2309, loss: 0.00827852\n",
      "Epoch: [ 9] [   5/  20] time: 89.6818, loss: 0.02902872\n",
      "Epoch: [ 9] [   6/  20] time: 90.1266, loss: 0.00559838\n",
      "Epoch: [ 9] [   7/  20] time: 90.5890, loss: 0.03457038\n",
      "Epoch: [ 9] [   8/  20] time: 91.0345, loss: 0.02098968\n",
      "Epoch: [ 9] [   9/  20] time: 91.4948, loss: 0.01372003\n",
      "Epoch: [ 9] [  10/  20] time: 91.9433, loss: 0.00903149\n",
      "Epoch: [ 9] [  11/  20] time: 92.4103, loss: 0.01300683\n",
      "Epoch: [ 9] [  12/  20] time: 92.8574, loss: 0.01725468\n",
      "Epoch: [ 9] [  13/  20] time: 93.3169, loss: 0.01798383\n",
      "Epoch: [ 9] [  14/  20] time: 93.7732, loss: 0.00786490\n",
      "Epoch: [ 9] [  15/  20] time: 94.2269, loss: 0.00473607\n",
      "Epoch: [ 9] [  16/  20] time: 94.6955, loss: 0.01267077\n",
      "Epoch: [ 9] [  17/  20] time: 95.1433, loss: 0.00028023\n",
      "Epoch: [ 9] [  18/  20] time: 95.6094, loss: 0.01849158\n",
      "Epoch: [ 9] [  19/  20] time: 96.0707, loss: 0.29238945\n",
      "[9/80] - ptime: 9.9203 loss: 0.02814106 acc: 0.21000 lr: 0.00100000\n",
      "Epoch: [10] [   0/  20] time: 97.9858, loss: 0.02613292\n",
      "Epoch: [10] [   1/  20] time: 98.4526, loss: 0.01763429\n",
      "Epoch: [10] [   2/  20] time: 98.9086, loss: 0.04963409\n",
      "Epoch: [10] [   3/  20] time: 99.3593, loss: 0.15915991\n",
      "Epoch: [10] [   4/  20] time: 99.8210, loss: 0.17747621\n",
      "Epoch: [10] [   5/  20] time: 100.2767, loss: 0.03028632\n",
      "Epoch: [10] [   6/  20] time: 100.7340, loss: 0.05448655\n",
      "Epoch: [10] [   7/  20] time: 101.1940, loss: 0.02516569\n",
      "Epoch: [10] [   8/  20] time: 101.6501, loss: 0.04191020\n",
      "Epoch: [10] [   9/  20] time: 102.1028, loss: 0.02502230\n",
      "Epoch: [10] [  10/  20] time: 102.5522, loss: 0.03154795\n",
      "Epoch: [10] [  11/  20] time: 103.0028, loss: 0.01050213\n",
      "Epoch: [10] [  12/  20] time: 103.4539, loss: 0.02521937\n",
      "Epoch: [10] [  13/  20] time: 103.9342, loss: 0.01369459\n",
      "Epoch: [10] [  14/  20] time: 104.3918, loss: 0.01162256\n",
      "Epoch: [10] [  15/  20] time: 104.8556, loss: 0.03130833\n",
      "Epoch: [10] [  16/  20] time: 105.3156, loss: 0.01759917\n",
      "Epoch: [10] [  17/  20] time: 105.7788, loss: 0.01147521\n",
      "Epoch: [10] [  18/  20] time: 106.2281, loss: 0.03288421\n",
      "Epoch: [10] [  19/  20] time: 106.6792, loss: 0.06551166\n",
      "[10/80] - ptime: 10.0553 loss: 0.04291368 acc: 0.20000 lr: 0.00100000\n",
      "Epoch: [11] [   0/  20] time: 108.6034, loss: 0.00298831\n",
      "Epoch: [11] [   1/  20] time: 109.0616, loss: 0.02686039\n",
      "Epoch: [11] [   2/  20] time: 109.5133, loss: 0.00091229\n",
      "Epoch: [11] [   3/  20] time: 109.9897, loss: 0.02197166\n",
      "Epoch: [11] [   4/  20] time: 110.4488, loss: 0.02212650\n",
      "Epoch: [11] [   5/  20] time: 110.9310, loss: 0.00438948\n",
      "Epoch: [11] [   6/  20] time: 111.3986, loss: 0.02991709\n",
      "Epoch: [11] [   7/  20] time: 111.8846, loss: 0.11992373\n",
      "Epoch: [11] [   8/  20] time: 112.3599, loss: 0.03221232\n",
      "Epoch: [11] [   9/  20] time: 112.8389, loss: 0.02734588\n",
      "Epoch: [11] [  10/  20] time: 113.3191, loss: 0.01359254\n",
      "Epoch: [11] [  11/  20] time: 113.7725, loss: 0.01700530\n",
      "Epoch: [11] [  12/  20] time: 114.2372, loss: 0.01008530\n",
      "Epoch: [11] [  13/  20] time: 114.6901, loss: 0.01431215\n",
      "Epoch: [11] [  14/  20] time: 115.1520, loss: 0.01923944\n",
      "Epoch: [11] [  15/  20] time: 115.6033, loss: 0.02116329\n",
      "Epoch: [11] [  16/  20] time: 116.0683, loss: 0.01798222\n",
      "Epoch: [11] [  17/  20] time: 116.5175, loss: 0.00252793\n",
      "Epoch: [11] [  18/  20] time: 116.9739, loss: 0.00257759\n",
      "Epoch: [11] [  19/  20] time: 117.4254, loss: 0.01894758\n",
      "[11/80] - ptime: 10.1215 loss: 0.02130405 acc: 0.42000 lr: 0.00090000\n",
      "Epoch: [12] [   0/  20] time: 119.4460, loss: 0.00727751\n",
      "Epoch: [12] [   1/  20] time: 119.8992, loss: 0.01988100\n",
      "Epoch: [12] [   2/  20] time: 120.3646, loss: 0.01547880\n",
      "Epoch: [12] [   3/  20] time: 120.8177, loss: 0.01619706\n",
      "Epoch: [12] [   4/  20] time: 121.2789, loss: 0.00262839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [12] [   5/  20] time: 121.7333, loss: 0.01029557\n",
      "Epoch: [12] [   6/  20] time: 122.1967, loss: 0.00768825\n",
      "Epoch: [12] [   7/  20] time: 122.6453, loss: 0.02453582\n",
      "Epoch: [12] [   8/  20] time: 123.1025, loss: 0.00617231\n",
      "Epoch: [12] [   9/  20] time: 123.5567, loss: 0.01110442\n",
      "Epoch: [12] [  10/  20] time: 124.0093, loss: 0.01502557\n",
      "Epoch: [12] [  11/  20] time: 124.4633, loss: 0.00216306\n",
      "Epoch: [12] [  12/  20] time: 124.9167, loss: 0.00807695\n",
      "Epoch: [12] [  13/  20] time: 125.3789, loss: 0.03617557\n",
      "Epoch: [12] [  14/  20] time: 125.8328, loss: 0.00485286\n",
      "Epoch: [12] [  15/  20] time: 126.2905, loss: 0.01161657\n",
      "Epoch: [12] [  16/  20] time: 126.7456, loss: 0.02061384\n",
      "Epoch: [12] [  17/  20] time: 127.2043, loss: 0.00103490\n",
      "Epoch: [12] [  18/  20] time: 127.6529, loss: 0.02339260\n",
      "Epoch: [12] [  19/  20] time: 128.1071, loss: 0.08686573\n",
      "[12/80] - ptime: 10.0363 loss: 0.01655384 acc: 0.49000 lr: 0.00090000\n",
      "Epoch: [13] [   0/  20] time: 129.9271, loss: 0.01482668\n",
      "Epoch: [13] [   1/  20] time: 130.3920, loss: 0.01201778\n",
      "Epoch: [13] [   2/  20] time: 130.8450, loss: 0.01000731\n",
      "Epoch: [13] [   3/  20] time: 131.3143, loss: 0.00634905\n",
      "Epoch: [13] [   4/  20] time: 131.7657, loss: 0.07026073\n",
      "Epoch: [13] [   5/  20] time: 132.2185, loss: 0.01423891\n",
      "Epoch: [13] [   6/  20] time: 132.6765, loss: 0.01758751\n",
      "Epoch: [13] [   7/  20] time: 133.1330, loss: 0.00544134\n",
      "Epoch: [13] [   8/  20] time: 133.6028, loss: 0.00323450\n",
      "Epoch: [13] [   9/  20] time: 134.0539, loss: 0.00660660\n",
      "Epoch: [13] [  10/  20] time: 134.5135, loss: 0.00509921\n",
      "Epoch: [13] [  11/  20] time: 134.9686, loss: 0.01653110\n",
      "Epoch: [13] [  12/  20] time: 135.4290, loss: 0.02045330\n",
      "Epoch: [13] [  13/  20] time: 135.8784, loss: 0.00226118\n",
      "Epoch: [13] [  14/  20] time: 136.3433, loss: 0.01541719\n",
      "Epoch: [13] [  15/  20] time: 136.7956, loss: 0.00325164\n",
      "Epoch: [13] [  16/  20] time: 137.2543, loss: 0.00591807\n",
      "Epoch: [13] [  17/  20] time: 137.7038, loss: 0.01631327\n",
      "Epoch: [13] [  18/  20] time: 138.1583, loss: 0.01680022\n",
      "Epoch: [13] [  19/  20] time: 138.6113, loss: 0.04694043\n",
      "[13/80] - ptime: 10.0111 loss: 0.01547780 acc: 0.48000 lr: 0.00090000\n",
      "Epoch: [14] [   0/  20] time: 140.5511, loss: 0.01112034\n",
      "Epoch: [14] [   1/  20] time: 141.0071, loss: 0.01062972\n",
      "Epoch: [14] [   2/  20] time: 141.4756, loss: 0.00617976\n",
      "Epoch: [14] [   3/  20] time: 141.9284, loss: 0.00635972\n",
      "Epoch: [14] [   4/  20] time: 142.3943, loss: 0.00904890\n",
      "Epoch: [14] [   5/  20] time: 142.8465, loss: 0.00922813\n",
      "Epoch: [14] [   6/  20] time: 143.2978, loss: 0.02455134\n",
      "Epoch: [14] [   7/  20] time: 143.7606, loss: 0.00584779\n",
      "Epoch: [14] [   8/  20] time: 144.2146, loss: 0.00409072\n",
      "Epoch: [14] [   9/  20] time: 144.6750, loss: 0.00591112\n",
      "Epoch: [14] [  10/  20] time: 145.1291, loss: 0.00114822\n",
      "Epoch: [14] [  11/  20] time: 145.5896, loss: 0.00053598\n",
      "Epoch: [14] [  12/  20] time: 146.0514, loss: 0.00170524\n",
      "Epoch: [14] [  13/  20] time: 146.5231, loss: 0.02541685\n",
      "Epoch: [14] [  14/  20] time: 146.9767, loss: 0.00038434\n",
      "Epoch: [14] [  15/  20] time: 147.4354, loss: 0.00054231\n",
      "Epoch: [14] [  16/  20] time: 147.8970, loss: 0.02825242\n",
      "Epoch: [14] [  17/  20] time: 148.3480, loss: 0.02027613\n",
      "Epoch: [14] [  18/  20] time: 148.8058, loss: 0.00530853\n",
      "Epoch: [14] [  19/  20] time: 149.2564, loss: 0.00013498\n",
      "[14/80] - ptime: 10.0151 loss: 0.00883363 acc: 0.45000 lr: 0.00090000\n",
      "Epoch: [15] [   0/  20] time: 151.2400, loss: 0.00485803\n",
      "Epoch: [15] [   1/  20] time: 151.6840, loss: 0.00427416\n",
      "Epoch: [15] [   2/  20] time: 152.1534, loss: 0.00009229\n",
      "Epoch: [15] [   3/  20] time: 152.6061, loss: 0.02895538\n",
      "Epoch: [15] [   4/  20] time: 153.0673, loss: 0.01434209\n",
      "Epoch: [15] [   5/  20] time: 153.5229, loss: 0.02385969\n",
      "Epoch: [15] [   6/  20] time: 153.9826, loss: 0.00963467\n",
      "Epoch: [15] [   7/  20] time: 154.4344, loss: 0.00199497\n",
      "Epoch: [15] [   8/  20] time: 154.8976, loss: 0.01658247\n",
      "Epoch: [15] [   9/  20] time: 155.3567, loss: 0.00053857\n",
      "Epoch: [15] [  10/  20] time: 155.8111, loss: 0.00021362\n",
      "Epoch: [15] [  11/  20] time: 156.2694, loss: 0.00124396\n",
      "Epoch: [15] [  12/  20] time: 156.7228, loss: 0.00347197\n",
      "Epoch: [15] [  13/  20] time: 157.1912, loss: 0.01322253\n",
      "Epoch: [15] [  14/  20] time: 157.6468, loss: 0.01347510\n",
      "Epoch: [15] [  15/  20] time: 158.1094, loss: 0.00934225\n",
      "Epoch: [15] [  16/  20] time: 158.5655, loss: 0.00070204\n",
      "Epoch: [15] [  17/  20] time: 159.0267, loss: 0.00155753\n",
      "Epoch: [15] [  18/  20] time: 159.4803, loss: 0.00101999\n",
      "Epoch: [15] [  19/  20] time: 159.9396, loss: 0.00815379\n",
      "[15/80] - ptime: 10.0903 loss: 0.00787675 acc: 0.57000 lr: 0.00090000\n",
      "Epoch: [16] [   0/  20] time: 161.8965, loss: 0.00018325\n",
      "Epoch: [16] [   1/  20] time: 162.3633, loss: 0.03295237\n",
      "Epoch: [16] [   2/  20] time: 162.8164, loss: 0.05414245\n",
      "Epoch: [16] [   3/  20] time: 163.2827, loss: 0.00680216\n",
      "Epoch: [16] [   4/  20] time: 163.7355, loss: 0.00863934\n",
      "Epoch: [16] [   5/  20] time: 164.1959, loss: 0.00383488\n",
      "Epoch: [16] [   6/  20] time: 164.6512, loss: 0.01282263\n",
      "Epoch: [16] [   7/  20] time: 165.1134, loss: 0.01041813\n",
      "Epoch: [16] [   8/  20] time: 165.5622, loss: 0.00560465\n",
      "Epoch: [16] [   9/  20] time: 166.0003, loss: 0.00704452\n",
      "Epoch: [16] [  10/  20] time: 166.4569, loss: 0.01639957\n",
      "Epoch: [16] [  11/  20] time: 166.9085, loss: 0.00846237\n",
      "Epoch: [16] [  12/  20] time: 167.3724, loss: 0.00276632\n",
      "Epoch: [16] [  13/  20] time: 167.8227, loss: 0.01036269\n",
      "Epoch: [16] [  14/  20] time: 168.2758, loss: 0.01105453\n",
      "Epoch: [16] [  15/  20] time: 168.7275, loss: 0.00315436\n",
      "Epoch: [16] [  16/  20] time: 169.1888, loss: 0.00156624\n",
      "Epoch: [16] [  17/  20] time: 169.6416, loss: 0.00482007\n",
      "Epoch: [16] [  18/  20] time: 170.1091, loss: 0.01644334\n",
      "Epoch: [16] [  19/  20] time: 170.5647, loss: 0.00202912\n",
      "[16/80] - ptime: 9.9135 loss: 0.01097515 acc: 0.71000 lr: 0.00090000\n",
      "Epoch: [17] [   0/  20] time: 172.5456, loss: 0.01224505\n",
      "Epoch: [17] [   1/  20] time: 173.0012, loss: 0.00334732\n",
      "Epoch: [17] [   2/  20] time: 173.4644, loss: 0.00071711\n",
      "Epoch: [17] [   3/  20] time: 173.9209, loss: 0.00189923\n",
      "Epoch: [17] [   4/  20] time: 174.3806, loss: 0.00111419\n",
      "Epoch: [17] [   5/  20] time: 174.8318, loss: 0.00447225\n",
      "Epoch: [17] [   6/  20] time: 175.2982, loss: 0.00323424\n",
      "Epoch: [17] [   7/  20] time: 175.7494, loss: 0.00354045\n",
      "Epoch: [17] [   8/  20] time: 176.2033, loss: 0.00043545\n",
      "Epoch: [17] [   9/  20] time: 176.6561, loss: 0.00601414\n",
      "Epoch: [17] [  10/  20] time: 177.1156, loss: 0.00930998\n",
      "Epoch: [17] [  11/  20] time: 177.5856, loss: 0.00046388\n",
      "Epoch: [17] [  12/  20] time: 178.0402, loss: 0.01507251\n",
      "Epoch: [17] [  13/  20] time: 178.5033, loss: 0.00081837\n",
      "Epoch: [17] [  14/  20] time: 178.9579, loss: 0.00229192\n",
      "Epoch: [17] [  15/  20] time: 179.4164, loss: 0.00248556\n",
      "Epoch: [17] [  16/  20] time: 179.8664, loss: 0.00105396\n",
      "Epoch: [17] [  17/  20] time: 180.3316, loss: 0.00232967\n",
      "Epoch: [17] [  18/  20] time: 180.7826, loss: 0.00053288\n",
      "Epoch: [17] [  19/  20] time: 181.2371, loss: 0.00540063\n",
      "[17/80] - ptime: 10.0754 loss: 0.00383894 acc: 0.65000 lr: 0.00090000\n",
      "Epoch: [18] [   0/  20] time: 183.0378, loss: 0.00864164\n",
      "Epoch: [18] [   1/  20] time: 183.4996, loss: 0.00108335\n",
      "Epoch: [18] [   2/  20] time: 183.9502, loss: 0.02531428\n",
      "Epoch: [18] [   3/  20] time: 184.4070, loss: 0.00047204\n",
      "Epoch: [18] [   4/  20] time: 184.8551, loss: 0.00547498\n",
      "Epoch: [18] [   5/  20] time: 185.3100, loss: 0.07138710\n",
      "Epoch: [18] [   6/  20] time: 185.7648, loss: 0.00430896\n",
      "Epoch: [18] [   7/  20] time: 186.2126, loss: 0.00744789\n",
      "Epoch: [18] [   8/  20] time: 186.6768, loss: 0.00434536\n",
      "Epoch: [18] [   9/  20] time: 187.1295, loss: 0.00810308\n",
      "Epoch: [18] [  10/  20] time: 187.5857, loss: 0.01085994\n",
      "Epoch: [18] [  11/  20] time: 188.0394, loss: 0.00201368\n",
      "Epoch: [18] [  12/  20] time: 188.5055, loss: 0.00051457\n",
      "Epoch: [18] [  13/  20] time: 188.9546, loss: 0.00767111\n",
      "Epoch: [18] [  14/  20] time: 189.4010, loss: 0.00012814\n",
      "Epoch: [18] [  15/  20] time: 189.8466, loss: 0.00150906\n",
      "Epoch: [18] [  16/  20] time: 190.3019, loss: 0.00360041\n",
      "Epoch: [18] [  17/  20] time: 190.7671, loss: 0.00088901\n",
      "Epoch: [18] [  18/  20] time: 191.2192, loss: 0.00213832\n",
      "Epoch: [18] [  19/  20] time: 191.6821, loss: 0.00032812\n",
      "[18/80] - ptime: 9.9857 loss: 0.00831155 acc: 0.53000 lr: 0.00090000\n",
      "Epoch: [19] [   0/  20] time: 193.5398, loss: 0.01522441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19] [   1/  20] time: 193.9902, loss: 0.01196761\n",
      "Epoch: [19] [   2/  20] time: 194.4455, loss: 0.00318387\n",
      "Epoch: [19] [   3/  20] time: 194.8982, loss: 0.00164215\n",
      "Epoch: [19] [   4/  20] time: 195.3517, loss: 0.00269081\n",
      "Epoch: [19] [   5/  20] time: 195.8155, loss: 0.01961377\n",
      "Epoch: [19] [   6/  20] time: 196.2729, loss: 0.00421581\n",
      "Epoch: [19] [   7/  20] time: 196.7342, loss: 0.00134254\n",
      "Epoch: [19] [   8/  20] time: 197.1864, loss: 0.00902102\n",
      "Epoch: [19] [   9/  20] time: 197.6519, loss: 0.00381451\n",
      "Epoch: [19] [  10/  20] time: 198.1047, loss: 0.00539623\n",
      "Epoch: [19] [  11/  20] time: 198.5621, loss: 0.00322905\n",
      "Epoch: [19] [  12/  20] time: 199.0096, loss: 0.00144389\n",
      "Epoch: [19] [  13/  20] time: 199.4537, loss: 0.00466176\n",
      "Epoch: [19] [  14/  20] time: 199.9159, loss: 0.00306119\n",
      "Epoch: [19] [  15/  20] time: 200.3647, loss: 0.00119737\n",
      "Epoch: [19] [  16/  20] time: 200.8195, loss: 0.08885644\n",
      "Epoch: [19] [  17/  20] time: 201.2723, loss: 0.01403618\n",
      "Epoch: [19] [  18/  20] time: 201.7326, loss: 0.01956506\n",
      "Epoch: [19] [  19/  20] time: 202.1885, loss: 0.00235129\n",
      "[19/80] - ptime: 9.9020 loss: 0.01082575 acc: 0.64000 lr: 0.00090000\n",
      "Epoch: [20] [   0/  20] time: 204.1148, loss: 0.00964719\n",
      "Epoch: [20] [   1/  20] time: 204.5626, loss: 0.01286087\n",
      "Epoch: [20] [   2/  20] time: 205.0278, loss: 0.00515998\n",
      "Epoch: [20] [   3/  20] time: 205.4778, loss: 0.00052526\n",
      "Epoch: [20] [   4/  20] time: 205.9344, loss: 0.02293030\n",
      "Epoch: [20] [   5/  20] time: 206.3839, loss: 0.02665354\n",
      "Epoch: [20] [   6/  20] time: 206.8450, loss: 0.00007586\n",
      "Epoch: [20] [   7/  20] time: 207.3006, loss: 0.00716077\n",
      "Epoch: [20] [   8/  20] time: 207.7619, loss: 0.00275576\n",
      "Epoch: [20] [   9/  20] time: 208.2102, loss: 0.06590416\n",
      "Epoch: [20] [  10/  20] time: 208.6634, loss: 0.03571638\n",
      "Epoch: [20] [  11/  20] time: 209.1146, loss: 0.01446538\n",
      "Epoch: [20] [  12/  20] time: 209.5733, loss: 0.00527900\n",
      "Epoch: [20] [  13/  20] time: 210.0362, loss: 0.00042206\n",
      "Epoch: [20] [  14/  20] time: 210.4908, loss: 0.00534689\n",
      "Epoch: [20] [  15/  20] time: 210.9479, loss: 0.01794476\n",
      "Epoch: [20] [  16/  20] time: 211.3976, loss: 0.02344663\n",
      "Epoch: [20] [  17/  20] time: 211.8591, loss: 0.00267718\n",
      "Epoch: [20] [  18/  20] time: 212.3049, loss: 0.00464371\n",
      "Epoch: [20] [  19/  20] time: 212.7590, loss: 0.00806098\n",
      "[20/80] - ptime: 10.0045 loss: 0.01358383 acc: 0.76000 lr: 0.00090000\n",
      "Epoch: [21] [   0/  20] time: 214.5804, loss: 0.00129118\n",
      "Epoch: [21] [   1/  20] time: 215.0429, loss: 0.01095793\n",
      "Epoch: [21] [   2/  20] time: 215.4956, loss: 0.00046389\n",
      "Epoch: [21] [   3/  20] time: 215.9542, loss: 0.00400954\n",
      "Epoch: [21] [   4/  20] time: 216.4054, loss: 0.00085511\n",
      "Epoch: [21] [   5/  20] time: 216.8597, loss: 0.00271706\n",
      "Epoch: [21] [   6/  20] time: 217.3164, loss: 0.00404862\n",
      "Epoch: [21] [   7/  20] time: 217.7724, loss: 0.00384412\n",
      "Epoch: [21] [   8/  20] time: 218.2394, loss: 0.00424607\n",
      "Epoch: [21] [   9/  20] time: 218.6938, loss: 0.00018578\n",
      "Epoch: [21] [  10/  20] time: 219.1591, loss: 0.00089947\n",
      "Epoch: [21] [  11/  20] time: 219.6149, loss: 0.00064606\n",
      "Epoch: [21] [  12/  20] time: 220.0778, loss: 0.00546012\n",
      "Epoch: [21] [  13/  20] time: 220.5321, loss: 0.00131154\n",
      "Epoch: [21] [  14/  20] time: 220.9926, loss: 0.00365180\n",
      "Epoch: [21] [  15/  20] time: 221.4448, loss: 0.00056338\n",
      "Epoch: [21] [  16/  20] time: 221.8953, loss: 0.04564391\n",
      "Epoch: [21] [  17/  20] time: 222.3603, loss: 0.03082557\n",
      "Epoch: [21] [  18/  20] time: 222.8113, loss: 0.01966683\n",
      "Epoch: [21] [  19/  20] time: 223.2737, loss: 0.00386347\n",
      "[21/80] - ptime: 10.0258 loss: 0.00725757 acc: 0.57000 lr: 0.00081000\n",
      "Epoch: [22] [   0/  20] time: 225.1453, loss: 0.00045375\n",
      "Epoch: [22] [   1/  20] time: 225.5971, loss: 0.00747088\n",
      "Epoch: [22] [   2/  20] time: 226.0596, loss: 0.01146605\n",
      "Epoch: [22] [   3/  20] time: 226.5103, loss: 0.00207312\n",
      "Epoch: [22] [   4/  20] time: 226.9634, loss: 0.00737169\n",
      "Epoch: [22] [   5/  20] time: 227.4199, loss: 0.01160083\n",
      "Epoch: [22] [   6/  20] time: 227.8769, loss: 0.00268353\n",
      "Epoch: [22] [   7/  20] time: 228.3394, loss: 0.00921055\n",
      "Epoch: [22] [   8/  20] time: 228.7944, loss: 0.00217930\n",
      "Epoch: [22] [   9/  20] time: 229.2534, loss: 0.01625279\n",
      "Epoch: [22] [  10/  20] time: 229.7043, loss: 0.01185671\n",
      "Epoch: [22] [  11/  20] time: 230.1726, loss: 0.00016482\n",
      "Epoch: [22] [  12/  20] time: 230.6275, loss: 0.00920825\n",
      "Epoch: [22] [  13/  20] time: 231.0894, loss: 0.00056409\n",
      "Epoch: [22] [  14/  20] time: 231.5401, loss: 0.00078521\n",
      "Epoch: [22] [  15/  20] time: 231.9933, loss: 0.00171431\n",
      "Epoch: [22] [  16/  20] time: 232.4450, loss: 0.00253952\n",
      "Epoch: [22] [  17/  20] time: 232.9008, loss: 0.00036452\n",
      "Epoch: [22] [  18/  20] time: 233.3607, loss: 0.00043192\n",
      "Epoch: [22] [  19/  20] time: 233.8202, loss: 0.00006400\n",
      "[22/80] - ptime: 9.9618 loss: 0.00492279 acc: 0.58000 lr: 0.00081000\n",
      "Epoch: [23] [   0/  20] time: 235.7204, loss: 0.00065013\n",
      "Epoch: [23] [   1/  20] time: 236.1704, loss: 0.00021904\n",
      "Epoch: [23] [   2/  20] time: 236.6319, loss: 0.00034664\n",
      "Epoch: [23] [   3/  20] time: 237.0853, loss: 0.00250988\n",
      "Epoch: [23] [   4/  20] time: 237.5530, loss: 0.00039751\n",
      "Epoch: [23] [   5/  20] time: 238.0003, loss: 0.00163359\n",
      "Epoch: [23] [   6/  20] time: 238.4624, loss: 0.00014830\n",
      "Epoch: [23] [   7/  20] time: 238.9147, loss: 0.00077861\n",
      "Epoch: [23] [   8/  20] time: 239.3663, loss: 0.00023682\n",
      "Epoch: [23] [   9/  20] time: 239.8200, loss: 0.00065364\n",
      "Epoch: [23] [  10/  20] time: 240.2781, loss: 0.00097591\n",
      "Epoch: [23] [  11/  20] time: 240.7286, loss: 0.00000552\n",
      "Epoch: [23] [  12/  20] time: 241.1839, loss: 0.00047033\n",
      "Epoch: [23] [  13/  20] time: 241.6380, loss: 0.00256727\n",
      "Epoch: [23] [  14/  20] time: 242.0905, loss: 0.00076477\n",
      "Epoch: [23] [  15/  20] time: 242.5567, loss: 0.00130784\n",
      "Epoch: [23] [  16/  20] time: 243.0101, loss: 0.00162600\n",
      "Epoch: [23] [  17/  20] time: 243.4704, loss: 0.00041019\n",
      "Epoch: [23] [  18/  20] time: 243.9228, loss: 0.00021736\n",
      "Epoch: [23] [  19/  20] time: 244.3847, loss: 0.00133283\n",
      "[23/80] - ptime: 10.0171 loss: 0.00086261 acc: 0.58000 lr: 0.00081000\n",
      "Epoch: [24] [   0/  20] time: 246.2457, loss: 0.00066324\n",
      "Epoch: [24] [   1/  20] time: 246.7072, loss: 0.00021347\n",
      "Epoch: [24] [   2/  20] time: 247.1638, loss: 0.00021665\n",
      "Epoch: [24] [   3/  20] time: 247.6216, loss: 0.00332161\n",
      "Epoch: [24] [   4/  20] time: 248.0761, loss: 0.00042438\n",
      "Epoch: [24] [   5/  20] time: 248.5387, loss: 0.00021901\n",
      "Epoch: [24] [   6/  20] time: 248.9910, loss: 0.00177748\n",
      "Epoch: [24] [   7/  20] time: 249.4476, loss: 0.00009164\n",
      "Epoch: [24] [   8/  20] time: 249.8999, loss: 0.00013645\n",
      "Epoch: [24] [   9/  20] time: 250.3499, loss: 0.00048561\n",
      "Epoch: [24] [  10/  20] time: 250.8011, loss: 0.00139747\n",
      "Epoch: [24] [  11/  20] time: 251.2512, loss: 0.00001881\n",
      "Epoch: [24] [  12/  20] time: 251.7147, loss: 0.00053529\n",
      "Epoch: [24] [  13/  20] time: 252.1672, loss: 0.00008705\n",
      "Epoch: [24] [  14/  20] time: 252.6273, loss: 0.00127596\n",
      "Epoch: [24] [  15/  20] time: 253.0863, loss: 0.00019097\n",
      "Epoch: [24] [  16/  20] time: 253.5441, loss: 0.00015167\n",
      "Epoch: [24] [  17/  20] time: 253.9983, loss: 0.00150892\n",
      "Epoch: [24] [  18/  20] time: 254.4567, loss: 0.00003404\n",
      "Epoch: [24] [  19/  20] time: 254.9071, loss: 0.00015002\n",
      "[24/80] - ptime: 9.9712 loss: 0.00064499 acc: 0.58000 lr: 0.00081000\n",
      "Epoch: [25] [   0/  20] time: 256.8819, loss: 0.00030705\n",
      "Epoch: [25] [   1/  20] time: 257.3319, loss: 0.00001235\n",
      "Epoch: [25] [   2/  20] time: 257.8025, loss: 0.00042668\n",
      "Epoch: [25] [   3/  20] time: 258.2551, loss: 0.00016205\n",
      "Epoch: [25] [   4/  20] time: 258.7220, loss: 0.00001303\n",
      "Epoch: [25] [   5/  20] time: 259.1738, loss: 0.00025947\n",
      "Epoch: [25] [   6/  20] time: 259.6435, loss: 0.00088059\n",
      "Epoch: [25] [   7/  20] time: 260.0968, loss: 0.00033017\n",
      "Epoch: [25] [   8/  20] time: 260.5514, loss: 0.00003668\n",
      "Epoch: [25] [   9/  20] time: 261.0004, loss: 0.00010289\n",
      "Epoch: [25] [  10/  20] time: 261.4568, loss: 0.00002170\n",
      "Epoch: [25] [  11/  20] time: 261.9178, loss: 0.00123651\n",
      "Epoch: [25] [  12/  20] time: 262.3693, loss: 0.00002201\n",
      "Epoch: [25] [  13/  20] time: 262.8318, loss: 0.00000572\n",
      "Epoch: [25] [  14/  20] time: 263.2894, loss: 0.00014920\n",
      "Epoch: [25] [  15/  20] time: 263.7505, loss: 0.00022293\n",
      "Epoch: [25] [  16/  20] time: 264.2061, loss: 0.00126853\n",
      "Epoch: [25] [  17/  20] time: 264.6683, loss: 0.00011054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25] [  18/  20] time: 265.1252, loss: 0.00024564\n",
      "Epoch: [25] [  19/  20] time: 265.5786, loss: 0.00097133\n",
      "[25/80] - ptime: 10.0530 loss: 0.00033925 acc: 0.58000 lr: 0.00081000\n",
      "Epoch: [26] [   0/  20] time: 267.4203, loss: 0.00029303\n",
      "Epoch: [26] [   1/  20] time: 267.8835, loss: 0.00003664\n",
      "Epoch: [26] [   2/  20] time: 268.3362, loss: 0.00001343\n",
      "Epoch: [26] [   3/  20] time: 268.8020, loss: 0.00000302\n",
      "Epoch: [26] [   4/  20] time: 269.2587, loss: 0.00008021\n",
      "Epoch: [26] [   5/  20] time: 269.7136, loss: 0.00020175\n",
      "Epoch: [26] [   6/  20] time: 270.1688, loss: 0.00011083\n",
      "Epoch: [26] [   7/  20] time: 270.6198, loss: 0.00036555\n",
      "Epoch: [26] [   8/  20] time: 271.0825, loss: 0.00003301\n",
      "Epoch: [26] [   9/  20] time: 271.5326, loss: 0.00000757\n",
      "Epoch: [26] [  10/  20] time: 271.9964, loss: 0.00014551\n",
      "Epoch: [26] [  11/  20] time: 272.4521, loss: 0.00000289\n",
      "Epoch: [26] [  12/  20] time: 272.9155, loss: 0.00170044\n",
      "Epoch: [26] [  13/  20] time: 273.3681, loss: 0.00017934\n",
      "Epoch: [26] [  14/  20] time: 273.8191, loss: 0.00000822\n",
      "Epoch: [26] [  15/  20] time: 274.2693, loss: 0.00004282\n",
      "Epoch: [26] [  16/  20] time: 274.7246, loss: 0.00002301\n",
      "Epoch: [26] [  17/  20] time: 275.1840, loss: 0.00003260\n",
      "Epoch: [26] [  18/  20] time: 275.6349, loss: 0.00006123\n",
      "Epoch: [26] [  19/  20] time: 276.0968, loss: 0.00050462\n",
      "[26/80] - ptime: 10.0005 loss: 0.00019229 acc: 0.58000 lr: 0.00081000\n",
      "Epoch: [27] [   0/  20] time: 278.0550, loss: 0.00033900\n",
      "Epoch: [27] [   1/  20] time: 278.5105, loss: 0.00048957\n",
      "Epoch: [27] [   2/  20] time: 278.9625, loss: 0.00005410\n",
      "Epoch: [27] [   3/  20] time: 279.4157, loss: 0.00000380\n",
      "Epoch: [27] [   4/  20] time: 279.8828, loss: 0.00005965\n",
      "Epoch: [27] [   5/  20] time: 280.3388, loss: 0.00024850\n",
      "Epoch: [27] [   6/  20] time: 280.7902, loss: 0.00001285\n",
      "Epoch: [27] [   7/  20] time: 281.2462, loss: 0.00000326\n",
      "Epoch: [27] [   8/  20] time: 281.6998, loss: 0.00002088\n",
      "Epoch: [27] [   9/  20] time: 282.1639, loss: 0.00007657\n",
      "Epoch: [27] [  10/  20] time: 282.6167, loss: 0.00000401\n",
      "Epoch: [27] [  11/  20] time: 283.0776, loss: 0.00004004\n",
      "Epoch: [27] [  12/  20] time: 283.5239, loss: 0.00038953\n",
      "Epoch: [27] [  13/  20] time: 283.9832, loss: 0.00008759\n",
      "Epoch: [27] [  14/  20] time: 284.4310, loss: 0.00000285\n",
      "Epoch: [27] [  15/  20] time: 284.8818, loss: 0.00001603\n",
      "Epoch: [27] [  16/  20] time: 285.3333, loss: 0.00006993\n",
      "Epoch: [27] [  17/  20] time: 285.7776, loss: 0.00029865\n",
      "Epoch: [27] [  18/  20] time: 286.2362, loss: 0.00032421\n",
      "Epoch: [27] [  19/  20] time: 286.6907, loss: 0.00015141\n",
      "[27/80] - ptime: 9.9605 loss: 0.00013462 acc: 0.61000 lr: 0.00081000\n",
      "Epoch: [28] [   0/  20] time: 288.6445, loss: 0.00001043\n",
      "Epoch: [28] [   1/  20] time: 289.1055, loss: 0.00037178\n",
      "Epoch: [28] [   2/  20] time: 289.5559, loss: 0.00006527\n",
      "Epoch: [28] [   3/  20] time: 290.0092, loss: 0.00003735\n",
      "Epoch: [28] [   4/  20] time: 290.4726, loss: 0.00016405\n",
      "Epoch: [28] [   5/  20] time: 290.9322, loss: 0.00013325\n",
      "Epoch: [28] [   6/  20] time: 291.3951, loss: 0.00010402\n",
      "Epoch: [28] [   7/  20] time: 291.8478, loss: 0.00001975\n",
      "Epoch: [28] [   8/  20] time: 292.3082, loss: 0.00011560\n",
      "Epoch: [28] [   9/  20] time: 292.7661, loss: 0.00010459\n",
      "Epoch: [28] [  10/  20] time: 293.2261, loss: 0.00000596\n",
      "Epoch: [28] [  11/  20] time: 293.6795, loss: 0.00002311\n",
      "Epoch: [28] [  12/  20] time: 294.1413, loss: 0.00054110\n",
      "Epoch: [28] [  13/  20] time: 294.5903, loss: 0.00021631\n",
      "Epoch: [28] [  14/  20] time: 295.0447, loss: 0.00026851\n",
      "Epoch: [28] [  15/  20] time: 295.4938, loss: 0.00002417\n",
      "Epoch: [28] [  16/  20] time: 295.9466, loss: 0.00014948\n",
      "Epoch: [28] [  17/  20] time: 296.4040, loss: 0.00016467\n",
      "Epoch: [28] [  18/  20] time: 296.8595, loss: 0.00031823\n",
      "Epoch: [28] [  19/  20] time: 297.3198, loss: 0.00005907\n",
      "[28/80] - ptime: 10.0350 loss: 0.00014484 acc: 0.60000 lr: 0.00081000\n",
      "Epoch: [29] [   0/  20] time: 299.1171, loss: 0.00037444\n",
      "Epoch: [29] [   1/  20] time: 299.5714, loss: 0.00000395\n",
      "Epoch: [29] [   2/  20] time: 300.0257, loss: 0.00003371\n",
      "Epoch: [29] [   3/  20] time: 300.4928, loss: 0.00006923\n",
      "Epoch: [29] [   4/  20] time: 300.9446, loss: 0.00000166\n",
      "Epoch: [29] [   5/  20] time: 301.4108, loss: 0.00005212\n",
      "Epoch: [29] [   6/  20] time: 301.8634, loss: 0.00001165\n",
      "Epoch: [29] [   7/  20] time: 302.3194, loss: 0.00001166\n",
      "Epoch: [29] [   8/  20] time: 302.7737, loss: 0.00009785\n",
      "Epoch: [29] [   9/  20] time: 303.2316, loss: 0.00001210\n",
      "Epoch: [29] [  10/  20] time: 303.6841, loss: 0.00000241\n",
      "Epoch: [29] [  11/  20] time: 304.1375, loss: 0.00000174\n",
      "Epoch: [29] [  12/  20] time: 304.5943, loss: 0.00001549\n",
      "Epoch: [29] [  13/  20] time: 305.0493, loss: 0.00006547\n",
      "Epoch: [29] [  14/  20] time: 305.5071, loss: 0.00013681\n",
      "Epoch: [29] [  15/  20] time: 305.9624, loss: 0.00009139\n",
      "Epoch: [29] [  16/  20] time: 306.4250, loss: 0.00000351\n",
      "Epoch: [29] [  17/  20] time: 306.8790, loss: 0.00000224\n",
      "Epoch: [29] [  18/  20] time: 307.3387, loss: 0.00003770\n",
      "Epoch: [29] [  19/  20] time: 307.7906, loss: 0.00009600\n",
      "[29/80] - ptime: 9.8955 loss: 0.00005606 acc: 0.60000 lr: 0.00081000\n",
      "Epoch: [30] [   0/  20] time: 309.7386, loss: 0.00000777\n",
      "Epoch: [30] [   1/  20] time: 310.1959, loss: 0.00009921\n",
      "Epoch: [30] [   2/  20] time: 310.6602, loss: 0.00002510\n",
      "Epoch: [30] [   3/  20] time: 311.1149, loss: 0.00009317\n",
      "Epoch: [30] [   4/  20] time: 311.5785, loss: 0.00004619\n",
      "Epoch: [30] [   5/  20] time: 312.0311, loss: 0.00001446\n",
      "Epoch: [30] [   6/  20] time: 312.4886, loss: 0.00007077\n",
      "Epoch: [30] [   7/  20] time: 312.9367, loss: 0.00001488\n",
      "Epoch: [30] [   8/  20] time: 313.3856, loss: 0.00004352\n",
      "Epoch: [30] [   9/  20] time: 313.8388, loss: 0.00073210\n",
      "Epoch: [30] [  10/  20] time: 314.2902, loss: 0.00001698\n",
      "Epoch: [30] [  11/  20] time: 314.7513, loss: 0.00001672\n",
      "Epoch: [30] [  12/  20] time: 315.1979, loss: 0.00007588\n",
      "Epoch: [30] [  13/  20] time: 315.6565, loss: 0.00004702\n",
      "Epoch: [30] [  14/  20] time: 316.1087, loss: 0.00000027\n",
      "Epoch: [30] [  15/  20] time: 316.5638, loss: 0.00000360\n",
      "Epoch: [30] [  16/  20] time: 317.0181, loss: 0.00005881\n",
      "Epoch: [30] [  17/  20] time: 317.4650, loss: 0.00001695\n",
      "Epoch: [30] [  18/  20] time: 317.9158, loss: 0.00000822\n",
      "Epoch: [30] [  19/  20] time: 318.3690, loss: 0.00002997\n",
      "[30/80] - ptime: 10.0044 loss: 0.00007108 acc: 0.61000 lr: 0.00072900\n",
      "Epoch: [31] [   0/  20] time: 320.3900, loss: 0.00000132\n",
      "Epoch: [31] [   1/  20] time: 320.8505, loss: 0.00004485\n",
      "Epoch: [31] [   2/  20] time: 321.3082, loss: 0.00000833\n",
      "Epoch: [31] [   3/  20] time: 321.7725, loss: 0.00006392\n",
      "Epoch: [31] [   4/  20] time: 322.2285, loss: 0.00031630\n",
      "Epoch: [31] [   5/  20] time: 322.6882, loss: 0.00000066\n",
      "Epoch: [31] [   6/  20] time: 323.1408, loss: 0.00002522\n",
      "Epoch: [31] [   7/  20] time: 323.5952, loss: 0.00000411\n",
      "Epoch: [31] [   8/  20] time: 324.0586, loss: 0.00003727\n",
      "Epoch: [31] [   9/  20] time: 324.5093, loss: 0.00011039\n",
      "Epoch: [31] [  10/  20] time: 324.9764, loss: 0.00001710\n",
      "Epoch: [31] [  11/  20] time: 325.4267, loss: 0.00004486\n",
      "Epoch: [31] [  12/  20] time: 325.8904, loss: 0.00000449\n",
      "Epoch: [31] [  13/  20] time: 326.3410, loss: 0.00000347\n",
      "Epoch: [31] [  14/  20] time: 326.7979, loss: 0.00003824\n",
      "Epoch: [31] [  15/  20] time: 327.2470, loss: 0.00000879\n",
      "Epoch: [31] [  16/  20] time: 327.7062, loss: 0.00004032\n",
      "Epoch: [31] [  17/  20] time: 328.1572, loss: 0.00000663\n",
      "Epoch: [31] [  18/  20] time: 328.6152, loss: 0.00000307\n",
      "Epoch: [31] [  19/  20] time: 329.0661, loss: 0.00000756\n",
      "[31/80] - ptime: 9.9528 loss: 0.00003934 acc: 0.59000 lr: 0.00072900\n",
      "Epoch: [32] [   0/  20] time: 331.0044, loss: 0.00000190\n",
      "Epoch: [32] [   1/  20] time: 331.4532, loss: 0.00023391\n",
      "Epoch: [32] [   2/  20] time: 331.9175, loss: 0.00000063\n",
      "Epoch: [32] [   3/  20] time: 332.3676, loss: 0.00002156\n",
      "Epoch: [32] [   4/  20] time: 332.8303, loss: 0.00006216\n",
      "Epoch: [32] [   5/  20] time: 333.2852, loss: 0.00000676\n",
      "Epoch: [32] [   6/  20] time: 333.7409, loss: 0.00001624\n",
      "Epoch: [32] [   7/  20] time: 334.1916, loss: 0.00000794\n",
      "Epoch: [32] [   8/  20] time: 334.6436, loss: 0.00001313\n",
      "Epoch: [32] [   9/  20] time: 335.1105, loss: 0.00000568\n",
      "Epoch: [32] [  10/  20] time: 335.5625, loss: 0.00009760\n",
      "Epoch: [32] [  11/  20] time: 336.0185, loss: 0.00000979\n",
      "Epoch: [32] [  12/  20] time: 336.4689, loss: 0.00000435\n",
      "Epoch: [32] [  13/  20] time: 336.9321, loss: 0.00001096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [32] [  14/  20] time: 337.3797, loss: 0.00033754\n",
      "Epoch: [32] [  15/  20] time: 337.8355, loss: 0.00001417\n",
      "Epoch: [32] [  16/  20] time: 338.2944, loss: 0.00013717\n",
      "Epoch: [32] [  17/  20] time: 338.7498, loss: 0.00006409\n",
      "Epoch: [32] [  18/  20] time: 339.2014, loss: 0.00000125\n",
      "Epoch: [32] [  19/  20] time: 339.6520, loss: 0.00000091\n",
      "[32/80] - ptime: 9.9905 loss: 0.00005239 acc: 0.59000 lr: 0.00072900\n",
      "Epoch: [33] [   0/  20] time: 341.4845, loss: 0.00001678\n",
      "Epoch: [33] [   1/  20] time: 341.9522, loss: 0.00002519\n",
      "Epoch: [33] [   2/  20] time: 342.4050, loss: 0.00000277\n",
      "Epoch: [33] [   3/  20] time: 342.8587, loss: 0.00005699\n",
      "Epoch: [33] [   4/  20] time: 343.3262, loss: 0.00001414\n",
      "Epoch: [33] [   5/  20] time: 343.7794, loss: 0.00001210\n",
      "Epoch: [33] [   6/  20] time: 344.2429, loss: 0.00001938\n",
      "Epoch: [33] [   7/  20] time: 344.6929, loss: 0.00003981\n",
      "Epoch: [33] [   8/  20] time: 345.1620, loss: 0.00005187\n",
      "Epoch: [33] [   9/  20] time: 345.6144, loss: 0.00003614\n",
      "Epoch: [33] [  10/  20] time: 346.0805, loss: 0.00000998\n",
      "Epoch: [33] [  11/  20] time: 346.5307, loss: 0.00002673\n",
      "Epoch: [33] [  12/  20] time: 346.9876, loss: 0.00037444\n",
      "Epoch: [33] [  13/  20] time: 347.4391, loss: 0.00000204\n",
      "Epoch: [33] [  14/  20] time: 347.8975, loss: 0.00000238\n",
      "Epoch: [33] [  15/  20] time: 348.3568, loss: 0.00005536\n",
      "Epoch: [33] [  16/  20] time: 348.8142, loss: 0.00016126\n",
      "Epoch: [33] [  17/  20] time: 349.2819, loss: 0.00014106\n",
      "Epoch: [33] [  18/  20] time: 349.7371, loss: 0.00026077\n",
      "Epoch: [33] [  19/  20] time: 350.2005, loss: 0.00000578\n",
      "[33/80] - ptime: 10.0597 loss: 0.00006575 acc: 0.59000 lr: 0.00072900\n",
      "Epoch: [34] [   0/  20] time: 352.0219, loss: 0.00002750\n",
      "Epoch: [34] [   1/  20] time: 352.4776, loss: 0.00007131\n",
      "Epoch: [34] [   2/  20] time: 352.9298, loss: 0.00001326\n",
      "Epoch: [34] [   3/  20] time: 353.3938, loss: 0.00000618\n",
      "Epoch: [34] [   4/  20] time: 353.8479, loss: 0.00000203\n",
      "Epoch: [34] [   5/  20] time: 354.3224, loss: 0.00013896\n",
      "Epoch: [34] [   6/  20] time: 354.7792, loss: 0.00000598\n",
      "Epoch: [34] [   7/  20] time: 355.2383, loss: 0.00000625\n",
      "Epoch: [34] [   8/  20] time: 355.6914, loss: 0.00000086\n",
      "Epoch: [34] [   9/  20] time: 356.1567, loss: 0.00001618\n",
      "Epoch: [34] [  10/  20] time: 356.6076, loss: 0.00000558\n",
      "Epoch: [34] [  11/  20] time: 357.0629, loss: 0.00015259\n",
      "Epoch: [34] [  12/  20] time: 357.5210, loss: 0.00003385\n",
      "Epoch: [34] [  13/  20] time: 357.9775, loss: 0.00037266\n",
      "Epoch: [34] [  14/  20] time: 358.4382, loss: 0.00008770\n",
      "Epoch: [34] [  15/  20] time: 358.8916, loss: 0.00010129\n",
      "Epoch: [34] [  16/  20] time: 359.3514, loss: 0.00005614\n",
      "Epoch: [34] [  17/  20] time: 359.8065, loss: 0.00002386\n",
      "Epoch: [34] [  18/  20] time: 360.2638, loss: 0.00000934\n",
      "Epoch: [34] [  19/  20] time: 360.7158, loss: 0.00001721\n",
      "[34/80] - ptime: 9.9219 loss: 0.00005744 acc: 0.60000 lr: 0.00072900\n",
      "Epoch: [35] [   0/  20] time: 362.6319, loss: 0.00000911\n",
      "Epoch: [35] [   1/  20] time: 363.0883, loss: 0.00021639\n",
      "Epoch: [35] [   2/  20] time: 363.5621, loss: 0.00000792\n",
      "Epoch: [35] [   3/  20] time: 364.0191, loss: 0.00000118\n",
      "Epoch: [35] [   4/  20] time: 364.4732, loss: 0.00013525\n",
      "Epoch: [35] [   5/  20] time: 364.9312, loss: 0.00000373\n",
      "Epoch: [35] [   6/  20] time: 365.3905, loss: 0.00003648\n",
      "Epoch: [35] [   7/  20] time: 365.8405, loss: 0.00008352\n",
      "Epoch: [35] [   8/  20] time: 366.3001, loss: 0.00000095\n",
      "Epoch: [35] [   9/  20] time: 366.7516, loss: 0.00003883\n",
      "Epoch: [35] [  10/  20] time: 367.2048, loss: 0.00040644\n",
      "Epoch: [35] [  11/  20] time: 367.6602, loss: 0.00000269\n",
      "Epoch: [35] [  12/  20] time: 368.1165, loss: 0.00000318\n",
      "Epoch: [35] [  13/  20] time: 368.5807, loss: 0.00002605\n",
      "Epoch: [35] [  14/  20] time: 369.0347, loss: 0.00026476\n",
      "Epoch: [35] [  15/  20] time: 369.4946, loss: 0.00005228\n",
      "Epoch: [35] [  16/  20] time: 369.9513, loss: 0.00007092\n",
      "Epoch: [35] [  17/  20] time: 370.4157, loss: 0.00002228\n",
      "Epoch: [35] [  18/  20] time: 370.8661, loss: 0.00000389\n",
      "Epoch: [35] [  19/  20] time: 371.3268, loss: 0.00003719\n",
      "[35/80] - ptime: 10.0417 loss: 0.00007115 acc: 0.60000 lr: 0.00072900\n",
      "Epoch: [36] [   0/  20] time: 373.0884, loss: 0.00001079\n",
      "Epoch: [36] [   1/  20] time: 373.5473, loss: 0.00000397\n",
      "Epoch: [36] [   2/  20] time: 373.9917, loss: 0.00002168\n",
      "Epoch: [36] [   3/  20] time: 374.4504, loss: 0.00001192\n",
      "Epoch: [36] [   4/  20] time: 374.9015, loss: 0.00000359\n",
      "Epoch: [36] [   5/  20] time: 375.3557, loss: 0.00003247\n",
      "Epoch: [36] [   6/  20] time: 375.8106, loss: 0.00004009\n",
      "Epoch: [36] [   7/  20] time: 376.2667, loss: 0.00002543\n",
      "Epoch: [36] [   8/  20] time: 376.7317, loss: 0.00000080\n",
      "Epoch: [36] [   9/  20] time: 377.1858, loss: 0.00003203\n",
      "Epoch: [36] [  10/  20] time: 377.6459, loss: 0.00000292\n",
      "Epoch: [36] [  11/  20] time: 378.0995, loss: 0.00001815\n",
      "Epoch: [36] [  12/  20] time: 378.5607, loss: 0.00013320\n",
      "Epoch: [36] [  13/  20] time: 379.0169, loss: 0.00002491\n",
      "Epoch: [36] [  14/  20] time: 379.4796, loss: 0.00002136\n",
      "Epoch: [36] [  15/  20] time: 379.9298, loss: 0.00000856\n",
      "Epoch: [36] [  16/  20] time: 380.3777, loss: 0.00000499\n",
      "Epoch: [36] [  17/  20] time: 380.8327, loss: 0.00003928\n",
      "Epoch: [36] [  18/  20] time: 381.2830, loss: 0.00007998\n",
      "Epoch: [36] [  19/  20] time: 381.7467, loss: 0.00000685\n",
      "[36/80] - ptime: 9.9551 loss: 0.00002615 acc: 0.60000 lr: 0.00072900\n",
      "Epoch: [37] [   0/  20] time: 383.6741, loss: 0.00000083\n",
      "Epoch: [37] [   1/  20] time: 384.1305, loss: 0.00000141\n",
      "Epoch: [37] [   2/  20] time: 384.5879, loss: 0.00022069\n",
      "Epoch: [37] [   3/  20] time: 385.0402, loss: 0.00006204\n",
      "Epoch: [37] [   4/  20] time: 385.5016, loss: 0.00000198\n",
      "Epoch: [37] [   5/  20] time: 385.9535, loss: 0.00001432\n",
      "Epoch: [37] [   6/  20] time: 386.4099, loss: 0.00000389\n",
      "Epoch: [37] [   7/  20] time: 386.8727, loss: 0.00003705\n",
      "Epoch: [37] [   8/  20] time: 387.3185, loss: 0.00001957\n",
      "Epoch: [37] [   9/  20] time: 387.7775, loss: 0.00002268\n",
      "Epoch: [37] [  10/  20] time: 388.2313, loss: 0.00000502\n",
      "Epoch: [37] [  11/  20] time: 388.7024, loss: 0.00003787\n",
      "Epoch: [37] [  12/  20] time: 389.1620, loss: 0.00000457\n",
      "Epoch: [37] [  13/  20] time: 389.6209, loss: 0.00000859\n",
      "Epoch: [37] [  14/  20] time: 390.0708, loss: 0.00000136\n",
      "Epoch: [37] [  15/  20] time: 390.5235, loss: 0.00000232\n",
      "Epoch: [37] [  16/  20] time: 390.9780, loss: 0.00000020\n",
      "Epoch: [37] [  17/  20] time: 391.4300, loss: 0.00000679\n",
      "Epoch: [37] [  18/  20] time: 391.8954, loss: 0.00021852\n",
      "Epoch: [37] [  19/  20] time: 392.3454, loss: 0.00005036\n",
      "[37/80] - ptime: 9.9886 loss: 0.00003600 acc: 0.60000 lr: 0.00072900\n",
      "Epoch: [38] [   0/  20] time: 394.2026, loss: 0.00000513\n",
      "Epoch: [38] [   1/  20] time: 394.6566, loss: 0.00000450\n",
      "Epoch: [38] [   2/  20] time: 395.1100, loss: 0.00037639\n",
      "Epoch: [38] [   3/  20] time: 395.5631, loss: 0.00003524\n",
      "Epoch: [38] [   4/  20] time: 396.0250, loss: 0.00000439\n",
      "Epoch: [38] [   5/  20] time: 396.4793, loss: 0.00010036\n",
      "Epoch: [38] [   6/  20] time: 396.9534, loss: 0.00003916\n",
      "Epoch: [38] [   7/  20] time: 397.4007, loss: 0.00000990\n",
      "Epoch: [38] [   8/  20] time: 397.8622, loss: 0.00000679\n",
      "Epoch: [38] [   9/  20] time: 398.3124, loss: 0.00104169\n",
      "Epoch: [38] [  10/  20] time: 398.7679, loss: 0.00001045\n",
      "Epoch: [38] [  11/  20] time: 399.2209, loss: 0.00000796\n",
      "Epoch: [38] [  12/  20] time: 399.6746, loss: 0.00000836\n",
      "Epoch: [38] [  13/  20] time: 400.1265, loss: 0.00001361\n",
      "Epoch: [38] [  14/  20] time: 400.5752, loss: 0.00002877\n",
      "Epoch: [38] [  15/  20] time: 401.0356, loss: 0.00005408\n",
      "Epoch: [38] [  16/  20] time: 401.4851, loss: 0.00037409\n",
      "Epoch: [38] [  17/  20] time: 401.9436, loss: 0.00001986\n",
      "Epoch: [38] [  18/  20] time: 402.3934, loss: 0.00001466\n",
      "Epoch: [38] [  19/  20] time: 402.8554, loss: 0.00001825\n",
      "[38/80] - ptime: 10.0109 loss: 0.00010868 acc: 0.56000 lr: 0.00072900\n",
      "Epoch: [39] [   0/  20] time: 404.6215, loss: 0.00006894\n",
      "Epoch: [39] [   1/  20] time: 405.0815, loss: 0.00000898\n",
      "Epoch: [39] [   2/  20] time: 405.5316, loss: 0.00008282\n",
      "Epoch: [39] [   3/  20] time: 405.9925, loss: 0.00000351\n",
      "Epoch: [39] [   4/  20] time: 406.4478, loss: 0.00000082\n",
      "Epoch: [39] [   5/  20] time: 406.9131, loss: 0.00001082\n",
      "Epoch: [39] [   6/  20] time: 407.3674, loss: 0.00000773\n",
      "Epoch: [39] [   7/  20] time: 407.8238, loss: 0.00020726\n",
      "Epoch: [39] [   8/  20] time: 408.2741, loss: 0.00001537\n",
      "Epoch: [39] [   9/  20] time: 408.7300, loss: 0.00000402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [39] [  10/  20] time: 409.1860, loss: 0.00000948\n",
      "Epoch: [39] [  11/  20] time: 409.6426, loss: 0.00001836\n",
      "Epoch: [39] [  12/  20] time: 410.0996, loss: 0.00003942\n",
      "Epoch: [39] [  13/  20] time: 410.5497, loss: 0.00001415\n",
      "Epoch: [39] [  14/  20] time: 411.0129, loss: 0.00000271\n",
      "Epoch: [39] [  15/  20] time: 411.4668, loss: 0.00001254\n",
      "Epoch: [39] [  16/  20] time: 411.9297, loss: 0.00001532\n",
      "Epoch: [39] [  17/  20] time: 412.3797, loss: 0.00000347\n",
      "Epoch: [39] [  18/  20] time: 412.8399, loss: 0.00001048\n",
      "Epoch: [39] [  19/  20] time: 413.2952, loss: 0.00000872\n",
      "[39/80] - ptime: 9.8827 loss: 0.00002725 acc: 0.59000 lr: 0.00072900\n",
      "Epoch: [40] [   0/  20] time: 415.1857, loss: 0.00000247\n",
      "Epoch: [40] [   1/  20] time: 415.6387, loss: 0.00001866\n",
      "Epoch: [40] [   2/  20] time: 416.1051, loss: 0.00000593\n",
      "Epoch: [40] [   3/  20] time: 416.5609, loss: 0.00001015\n",
      "Epoch: [40] [   4/  20] time: 417.0217, loss: 0.00001765\n",
      "Epoch: [40] [   5/  20] time: 417.4734, loss: 0.00002122\n",
      "Epoch: [40] [   6/  20] time: 417.9335, loss: 0.00000047\n",
      "Epoch: [40] [   7/  20] time: 418.3823, loss: 0.00001423\n",
      "Epoch: [40] [   8/  20] time: 418.8540, loss: 0.00000668\n",
      "Epoch: [40] [   9/  20] time: 419.3048, loss: 0.00000161\n",
      "Epoch: [40] [  10/  20] time: 419.7659, loss: 0.00013755\n",
      "Epoch: [40] [  11/  20] time: 420.2181, loss: 0.00018631\n",
      "Epoch: [40] [  12/  20] time: 420.6695, loss: 0.00001163\n",
      "Epoch: [40] [  13/  20] time: 421.1236, loss: 0.00003298\n",
      "Epoch: [40] [  14/  20] time: 421.5715, loss: 0.00001909\n",
      "Epoch: [40] [  15/  20] time: 422.0488, loss: 0.00000586\n",
      "Epoch: [40] [  16/  20] time: 422.4991, loss: 0.00003177\n",
      "Epoch: [40] [  17/  20] time: 422.9627, loss: 0.00000450\n",
      "Epoch: [40] [  18/  20] time: 423.4130, loss: 0.00007770\n",
      "Epoch: [40] [  19/  20] time: 423.8732, loss: 0.00002366\n",
      "[40/80] - ptime: 10.0386 loss: 0.00003151 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [41] [   0/  20] time: 425.6584, loss: 0.00000667\n",
      "Epoch: [41] [   1/  20] time: 426.1262, loss: 0.00000262\n",
      "Epoch: [41] [   2/  20] time: 426.5736, loss: 0.00002154\n",
      "Epoch: [41] [   3/  20] time: 427.0404, loss: 0.00000377\n",
      "Epoch: [41] [   4/  20] time: 427.4935, loss: 0.00005867\n",
      "Epoch: [41] [   5/  20] time: 427.9518, loss: 0.00000967\n",
      "Epoch: [41] [   6/  20] time: 428.4015, loss: 0.00022901\n",
      "Epoch: [41] [   7/  20] time: 428.8622, loss: 0.00000704\n",
      "Epoch: [41] [   8/  20] time: 429.3087, loss: 0.00000281\n",
      "Epoch: [41] [   9/  20] time: 429.7641, loss: 0.00000338\n",
      "Epoch: [41] [  10/  20] time: 430.2172, loss: 0.00027371\n",
      "Epoch: [41] [  11/  20] time: 430.6671, loss: 0.00024319\n",
      "Epoch: [41] [  12/  20] time: 431.1335, loss: 0.00001769\n",
      "Epoch: [41] [  13/  20] time: 431.5865, loss: 0.00000436\n",
      "Epoch: [41] [  14/  20] time: 432.0539, loss: 0.00019072\n",
      "Epoch: [41] [  15/  20] time: 432.5078, loss: 0.00002049\n",
      "Epoch: [41] [  16/  20] time: 432.9642, loss: 0.00000156\n",
      "Epoch: [41] [  17/  20] time: 433.4164, loss: 0.00000583\n",
      "Epoch: [41] [  18/  20] time: 433.8824, loss: 0.00001653\n",
      "Epoch: [41] [  19/  20] time: 434.3268, loss: 0.00006449\n",
      "[41/80] - ptime: 9.9043 loss: 0.00005919 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [42] [   0/  20] time: 436.3433, loss: 0.00004708\n",
      "Epoch: [42] [   1/  20] time: 436.7956, loss: 0.00002258\n",
      "Epoch: [42] [   2/  20] time: 437.2545, loss: 0.00000666\n",
      "Epoch: [42] [   3/  20] time: 437.7049, loss: 0.00000451\n",
      "Epoch: [42] [   4/  20] time: 438.1701, loss: 0.00000722\n",
      "Epoch: [42] [   5/  20] time: 438.6246, loss: 0.00000504\n",
      "Epoch: [42] [   6/  20] time: 439.0875, loss: 0.00000242\n",
      "Epoch: [42] [   7/  20] time: 439.5381, loss: 0.00003458\n",
      "Epoch: [42] [   8/  20] time: 439.9975, loss: 0.00003767\n",
      "Epoch: [42] [   9/  20] time: 440.4481, loss: 0.00000719\n",
      "Epoch: [42] [  10/  20] time: 440.9018, loss: 0.00001259\n",
      "Epoch: [42] [  11/  20] time: 441.3525, loss: 0.00001239\n",
      "Epoch: [42] [  12/  20] time: 441.8001, loss: 0.00003315\n",
      "Epoch: [42] [  13/  20] time: 442.2688, loss: 0.00001983\n",
      "Epoch: [42] [  14/  20] time: 442.7190, loss: 0.00001003\n",
      "Epoch: [42] [  15/  20] time: 443.1808, loss: 0.00000706\n",
      "Epoch: [42] [  16/  20] time: 443.6303, loss: 0.00001382\n",
      "Epoch: [42] [  17/  20] time: 444.0914, loss: 0.00008590\n",
      "Epoch: [42] [  18/  20] time: 444.5411, loss: 0.00001019\n",
      "Epoch: [42] [  19/  20] time: 445.0039, loss: 0.00001061\n",
      "[42/80] - ptime: 10.0340 loss: 0.00001953 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [43] [   0/  20] time: 446.7773, loss: 0.00002495\n",
      "Epoch: [43] [   1/  20] time: 447.2359, loss: 0.00006299\n",
      "Epoch: [43] [   2/  20] time: 447.6855, loss: 0.00007624\n",
      "Epoch: [43] [   3/  20] time: 448.1472, loss: 0.00005332\n",
      "Epoch: [43] [   4/  20] time: 448.6000, loss: 0.00000567\n",
      "Epoch: [43] [   5/  20] time: 449.0529, loss: 0.00000147\n",
      "Epoch: [43] [   6/  20] time: 449.4975, loss: 0.00004109\n",
      "Epoch: [43] [   7/  20] time: 449.9495, loss: 0.00000471\n",
      "Epoch: [43] [   8/  20] time: 450.4066, loss: 0.00005095\n",
      "Epoch: [43] [   9/  20] time: 450.8589, loss: 0.00002214\n",
      "Epoch: [43] [  10/  20] time: 451.3272, loss: 0.00032729\n",
      "Epoch: [43] [  11/  20] time: 451.7796, loss: 0.00014613\n",
      "Epoch: [43] [  12/  20] time: 452.2423, loss: 0.00000249\n",
      "Epoch: [43] [  13/  20] time: 452.6927, loss: 0.00001283\n",
      "Epoch: [43] [  14/  20] time: 453.1509, loss: 0.00000123\n",
      "Epoch: [43] [  15/  20] time: 453.6025, loss: 0.00000766\n",
      "Epoch: [43] [  16/  20] time: 454.0539, loss: 0.00000302\n",
      "Epoch: [43] [  17/  20] time: 454.5029, loss: 0.00012711\n",
      "Epoch: [43] [  18/  20] time: 454.9547, loss: 0.00001834\n",
      "Epoch: [43] [  19/  20] time: 455.4187, loss: 0.00000368\n",
      "[43/80] - ptime: 9.9274 loss: 0.00004967 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [44] [   0/  20] time: 457.3703, loss: 0.00000855\n",
      "Epoch: [44] [   1/  20] time: 457.8246, loss: 0.00001721\n",
      "Epoch: [44] [   2/  20] time: 458.2884, loss: 0.00003489\n",
      "Epoch: [44] [   3/  20] time: 458.7424, loss: 0.00006026\n",
      "Epoch: [44] [   4/  20] time: 459.2031, loss: 0.00000224\n",
      "Epoch: [44] [   5/  20] time: 459.6500, loss: 0.00000572\n",
      "Epoch: [44] [   6/  20] time: 460.1048, loss: 0.00001181\n",
      "Epoch: [44] [   7/  20] time: 460.5669, loss: 0.00000875\n",
      "Epoch: [44] [   8/  20] time: 461.0189, loss: 0.00000140\n",
      "Epoch: [44] [   9/  20] time: 461.4748, loss: 0.00000894\n",
      "Epoch: [44] [  10/  20] time: 461.9263, loss: 0.00000198\n",
      "Epoch: [44] [  11/  20] time: 462.3877, loss: 0.00000376\n",
      "Epoch: [44] [  12/  20] time: 462.8422, loss: 0.00005199\n",
      "Epoch: [44] [  13/  20] time: 463.3012, loss: 0.00000812\n",
      "Epoch: [44] [  14/  20] time: 463.7488, loss: 0.00000029\n",
      "Epoch: [44] [  15/  20] time: 464.2052, loss: 0.00000049\n",
      "Epoch: [44] [  16/  20] time: 464.6559, loss: 0.00001699\n",
      "Epoch: [44] [  17/  20] time: 465.1115, loss: 0.00006755\n",
      "Epoch: [44] [  18/  20] time: 465.5692, loss: 0.00000217\n",
      "Epoch: [44] [  19/  20] time: 466.0234, loss: 0.00004670\n",
      "[44/80] - ptime: 9.9789 loss: 0.00001799 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [45] [   0/  20] time: 467.9266, loss: 0.00001693\n",
      "Epoch: [45] [   1/  20] time: 468.3876, loss: 0.00001053\n",
      "Epoch: [45] [   2/  20] time: 468.8430, loss: 0.00004460\n",
      "Epoch: [45] [   3/  20] time: 469.3002, loss: 0.00000174\n",
      "Epoch: [45] [   4/  20] time: 469.7491, loss: 0.00000436\n",
      "Epoch: [45] [   5/  20] time: 470.2016, loss: 0.00000456\n",
      "Epoch: [45] [   6/  20] time: 470.6646, loss: 0.00001037\n",
      "Epoch: [45] [   7/  20] time: 471.1171, loss: 0.00000818\n",
      "Epoch: [45] [   8/  20] time: 471.5794, loss: 0.00000878\n",
      "Epoch: [45] [   9/  20] time: 472.0324, loss: 0.00003535\n",
      "Epoch: [45] [  10/  20] time: 472.4938, loss: 0.00000122\n",
      "Epoch: [45] [  11/  20] time: 472.9444, loss: 0.00000114\n",
      "Epoch: [45] [  12/  20] time: 473.4108, loss: 0.00003355\n",
      "Epoch: [45] [  13/  20] time: 473.8610, loss: 0.00010653\n",
      "Epoch: [45] [  14/  20] time: 474.3184, loss: 0.00003568\n",
      "Epoch: [45] [  15/  20] time: 474.7676, loss: 0.00001412\n",
      "Epoch: [45] [  16/  20] time: 475.2210, loss: 0.00000399\n",
      "Epoch: [45] [  17/  20] time: 475.6760, loss: 0.00009213\n",
      "Epoch: [45] [  18/  20] time: 476.1268, loss: 0.00000137\n",
      "Epoch: [45] [  19/  20] time: 476.5883, loss: 0.00003076\n",
      "[45/80] - ptime: 10.0831 loss: 0.00002329 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [46] [   0/  20] time: 478.4896, loss: 0.00000215\n",
      "Epoch: [46] [   1/  20] time: 478.9381, loss: 0.00000143\n",
      "Epoch: [46] [   2/  20] time: 479.3954, loss: 0.00000058\n",
      "Epoch: [46] [   3/  20] time: 479.8476, loss: 0.00000167\n",
      "Epoch: [46] [   4/  20] time: 480.3009, loss: 0.00006433\n",
      "Epoch: [46] [   5/  20] time: 480.7568, loss: 0.00001100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46] [   6/  20] time: 481.2081, loss: 0.00000247\n",
      "Epoch: [46] [   7/  20] time: 481.6725, loss: 0.00005049\n",
      "Epoch: [46] [   8/  20] time: 482.1236, loss: 0.00000225\n",
      "Epoch: [46] [   9/  20] time: 482.5800, loss: 0.00007150\n",
      "Epoch: [46] [  10/  20] time: 483.0261, loss: 0.00000956\n",
      "Epoch: [46] [  11/  20] time: 483.4861, loss: 0.00000136\n",
      "Epoch: [46] [  12/  20] time: 483.9350, loss: 0.00000154\n",
      "Epoch: [46] [  13/  20] time: 484.3836, loss: 0.00000289\n",
      "Epoch: [46] [  14/  20] time: 484.8336, loss: 0.00002924\n",
      "Epoch: [46] [  15/  20] time: 485.2856, loss: 0.00000894\n",
      "Epoch: [46] [  16/  20] time: 485.7512, loss: 0.00000087\n",
      "Epoch: [46] [  17/  20] time: 486.2079, loss: 0.00001364\n",
      "Epoch: [46] [  18/  20] time: 486.6715, loss: 0.00000163\n",
      "Epoch: [46] [  19/  20] time: 487.1246, loss: 0.00002619\n",
      "[46/80] - ptime: 9.9042 loss: 0.00001519 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [47] [   0/  20] time: 489.0131, loss: 0.00000019\n",
      "Epoch: [47] [   1/  20] time: 489.4641, loss: 0.00000074\n",
      "Epoch: [47] [   2/  20] time: 489.9190, loss: 0.00001386\n",
      "Epoch: [47] [   3/  20] time: 490.3725, loss: 0.00004363\n",
      "Epoch: [47] [   4/  20] time: 490.8298, loss: 0.00002272\n",
      "Epoch: [47] [   5/  20] time: 491.2835, loss: 0.00000087\n",
      "Epoch: [47] [   6/  20] time: 491.7458, loss: 0.00004629\n",
      "Epoch: [47] [   7/  20] time: 492.1974, loss: 0.00000039\n",
      "Epoch: [47] [   8/  20] time: 492.6559, loss: 0.00002344\n",
      "Epoch: [47] [   9/  20] time: 493.1109, loss: 0.00000135\n",
      "Epoch: [47] [  10/  20] time: 493.5677, loss: 0.00006835\n",
      "Epoch: [47] [  11/  20] time: 494.0210, loss: 0.00000044\n",
      "Epoch: [47] [  12/  20] time: 494.4735, loss: 0.00001085\n",
      "Epoch: [47] [  13/  20] time: 494.9304, loss: 0.00000680\n",
      "Epoch: [47] [  14/  20] time: 495.3838, loss: 0.00001322\n",
      "Epoch: [47] [  15/  20] time: 495.8490, loss: 0.00001896\n",
      "Epoch: [47] [  16/  20] time: 496.3034, loss: 0.00000468\n",
      "Epoch: [47] [  17/  20] time: 496.7640, loss: 0.00003212\n",
      "Epoch: [47] [  18/  20] time: 497.2167, loss: 0.00000314\n",
      "Epoch: [47] [  19/  20] time: 497.6768, loss: 0.00000817\n",
      "[47/80] - ptime: 10.0100 loss: 0.00001601 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [48] [   0/  20] time: 499.7796, loss: 0.00000402\n",
      "Epoch: [48] [   1/  20] time: 500.2300, loss: 0.00000385\n",
      "Epoch: [48] [   2/  20] time: 500.6807, loss: 0.00000519\n",
      "Epoch: [48] [   3/  20] time: 501.1345, loss: 0.00000173\n",
      "Epoch: [48] [   4/  20] time: 501.5904, loss: 0.00000801\n",
      "Epoch: [48] [   5/  20] time: 502.0499, loss: 0.00000786\n",
      "Epoch: [48] [   6/  20] time: 502.5037, loss: 0.00000224\n",
      "Epoch: [48] [   7/  20] time: 502.9658, loss: 0.00000053\n",
      "Epoch: [48] [   8/  20] time: 503.4168, loss: 0.00001064\n",
      "Epoch: [48] [   9/  20] time: 503.8804, loss: 0.00002014\n",
      "Epoch: [48] [  10/  20] time: 504.3314, loss: 0.00000064\n",
      "Epoch: [48] [  11/  20] time: 504.7938, loss: 0.00005660\n",
      "Epoch: [48] [  12/  20] time: 505.2413, loss: 0.00007096\n",
      "Epoch: [48] [  13/  20] time: 505.6936, loss: 0.00001003\n",
      "Epoch: [48] [  14/  20] time: 506.1535, loss: 0.00005561\n",
      "Epoch: [48] [  15/  20] time: 506.6042, loss: 0.00001147\n",
      "Epoch: [48] [  16/  20] time: 507.0664, loss: 0.00000095\n",
      "Epoch: [48] [  17/  20] time: 507.5210, loss: 0.00000895\n",
      "Epoch: [48] [  18/  20] time: 507.9849, loss: 0.00000260\n",
      "Epoch: [48] [  19/  20] time: 508.4363, loss: 0.00005550\n",
      "[48/80] - ptime: 9.9244 loss: 0.00001688 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [49] [   0/  20] time: 510.4212, loss: 0.00000012\n",
      "Epoch: [49] [   1/  20] time: 510.8824, loss: 0.00000191\n",
      "Epoch: [49] [   2/  20] time: 511.3340, loss: 0.00000118\n",
      "Epoch: [49] [   3/  20] time: 511.7852, loss: 0.00000098\n",
      "Epoch: [49] [   4/  20] time: 512.2351, loss: 0.00002233\n",
      "Epoch: [49] [   5/  20] time: 512.6865, loss: 0.00003833\n",
      "Epoch: [49] [   6/  20] time: 513.1524, loss: 0.00000698\n",
      "Epoch: [49] [   7/  20] time: 513.5963, loss: 0.00000238\n",
      "Epoch: [49] [   8/  20] time: 514.0582, loss: 0.00003536\n",
      "Epoch: [49] [   9/  20] time: 514.5098, loss: 0.00000820\n",
      "Epoch: [49] [  10/  20] time: 514.9745, loss: 0.00000023\n",
      "Epoch: [49] [  11/  20] time: 515.4298, loss: 0.00001007\n",
      "Epoch: [49] [  12/  20] time: 515.8912, loss: 0.00001097\n",
      "Epoch: [49] [  13/  20] time: 516.3431, loss: 0.00000155\n",
      "Epoch: [49] [  14/  20] time: 516.7927, loss: 0.00000069\n",
      "Epoch: [49] [  15/  20] time: 517.2475, loss: 0.00001268\n",
      "Epoch: [49] [  16/  20] time: 517.6979, loss: 0.00003862\n",
      "Epoch: [49] [  17/  20] time: 518.1576, loss: 0.00006763\n",
      "Epoch: [49] [  18/  20] time: 518.6102, loss: 0.00000934\n",
      "Epoch: [49] [  19/  20] time: 519.0740, loss: 0.00002192\n",
      "[49/80] - ptime: 10.0906 loss: 0.00001457 acc: 0.60000 lr: 0.00065610\n",
      "Epoch: [50] [   0/  20] time: 520.8664, loss: 0.00000729\n",
      "Epoch: [50] [   1/  20] time: 521.3236, loss: 0.00000245\n",
      "Epoch: [50] [   2/  20] time: 521.7754, loss: 0.00000983\n",
      "Epoch: [50] [   3/  20] time: 522.2412, loss: 0.00000224\n",
      "Epoch: [50] [   4/  20] time: 522.6980, loss: 0.00000557\n",
      "Epoch: [50] [   5/  20] time: 523.1568, loss: 0.00000492\n",
      "Epoch: [50] [   6/  20] time: 523.6118, loss: 0.00001000\n",
      "Epoch: [50] [   7/  20] time: 524.0786, loss: 0.00000549\n",
      "Epoch: [50] [   8/  20] time: 524.5353, loss: 0.00000831\n",
      "Epoch: [50] [   9/  20] time: 524.9959, loss: 0.00001121\n",
      "Epoch: [50] [  10/  20] time: 525.4498, loss: 0.00000264\n",
      "Epoch: [50] [  11/  20] time: 525.9019, loss: 0.00000624\n",
      "Epoch: [50] [  12/  20] time: 526.3591, loss: 0.00002741\n",
      "Epoch: [50] [  13/  20] time: 526.8084, loss: 0.00000477\n",
      "Epoch: [50] [  14/  20] time: 527.2825, loss: 0.00000881\n",
      "Epoch: [50] [  15/  20] time: 527.7336, loss: 0.00001496\n",
      "Epoch: [50] [  16/  20] time: 528.1921, loss: 0.00000034\n",
      "Epoch: [50] [  17/  20] time: 528.6490, loss: 0.00000060\n",
      "Epoch: [50] [  18/  20] time: 529.1113, loss: 0.00002495\n",
      "Epoch: [50] [  19/  20] time: 529.5612, loss: 0.00000025\n",
      "[50/80] - ptime: 9.9209 loss: 0.00000791 acc: 0.60000 lr: 0.00059049\n",
      "Epoch: [51] [   0/  20] time: 531.5123, loss: 0.00001511\n",
      "Epoch: [51] [   1/  20] time: 531.9665, loss: 0.00000625\n",
      "Epoch: [51] [   2/  20] time: 532.4327, loss: 0.00000724\n",
      "Epoch: [51] [   3/  20] time: 532.8841, loss: 0.00000115\n",
      "Epoch: [51] [   4/  20] time: 533.3500, loss: 0.00000891\n",
      "Epoch: [51] [   5/  20] time: 533.8021, loss: 0.00000112\n",
      "Epoch: [51] [   6/  20] time: 534.2611, loss: 0.00000041\n",
      "Epoch: [51] [   7/  20] time: 534.7123, loss: 0.00000634\n",
      "Epoch: [51] [   8/  20] time: 535.1714, loss: 0.00001523\n",
      "Epoch: [51] [   9/  20] time: 535.6254, loss: 0.00001095\n",
      "Epoch: [51] [  10/  20] time: 536.0839, loss: 0.00005158\n",
      "Epoch: [51] [  11/  20] time: 536.5406, loss: 0.00000598\n",
      "Epoch: [51] [  12/  20] time: 536.9984, loss: 0.00000278\n",
      "Epoch: [51] [  13/  20] time: 537.4571, loss: 0.00000472\n",
      "Epoch: [51] [  14/  20] time: 537.9090, loss: 0.00000080\n",
      "Epoch: [51] [  15/  20] time: 538.3718, loss: 0.00000367\n",
      "Epoch: [51] [  16/  20] time: 538.8331, loss: 0.00000499\n",
      "Epoch: [51] [  17/  20] time: 539.2938, loss: 0.00000702\n",
      "Epoch: [51] [  18/  20] time: 539.7429, loss: 0.00000330\n",
      "Epoch: [51] [  19/  20] time: 540.2023, loss: 0.00002734\n",
      "[51/80] - ptime: 10.0423 loss: 0.00000924 acc: 0.60000 lr: 0.00059049\n",
      "Epoch: [52] [   0/  20] time: 541.9939, loss: 0.00001249\n",
      "Epoch: [52] [   1/  20] time: 542.4566, loss: 0.00002072\n",
      "Epoch: [52] [   2/  20] time: 542.9103, loss: 0.00001482\n",
      "Epoch: [52] [   3/  20] time: 543.3746, loss: 0.00000068\n",
      "Epoch: [52] [   4/  20] time: 543.8249, loss: 0.00001603\n",
      "Epoch: [52] [   5/  20] time: 544.2845, loss: 0.00000888\n",
      "Epoch: [52] [   6/  20] time: 544.7379, loss: 0.00000700\n",
      "Epoch: [52] [   7/  20] time: 545.1918, loss: 0.00000369\n",
      "Epoch: [52] [   8/  20] time: 545.6451, loss: 0.00000329\n",
      "Epoch: [52] [   9/  20] time: 546.1009, loss: 0.00000923\n",
      "Epoch: [52] [  10/  20] time: 546.5651, loss: 0.00000687\n",
      "Epoch: [52] [  11/  20] time: 547.0240, loss: 0.00001712\n",
      "Epoch: [52] [  12/  20] time: 547.4859, loss: 0.00001083\n",
      "Epoch: [52] [  13/  20] time: 547.9388, loss: 0.00000072\n",
      "Epoch: [52] [  14/  20] time: 548.4011, loss: 0.00000613\n",
      "Epoch: [52] [  15/  20] time: 548.8537, loss: 0.00015377\n",
      "Epoch: [52] [  16/  20] time: 549.3137, loss: 0.00000578\n",
      "Epoch: [52] [  17/  20] time: 549.7658, loss: 0.00000171\n",
      "Epoch: [52] [  18/  20] time: 550.2197, loss: 0.00000032\n",
      "Epoch: [52] [  19/  20] time: 550.6753, loss: 0.00000255\n",
      "[52/80] - ptime: 9.9713 loss: 0.00001513 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [53] [   0/  20] time: 552.6487, loss: 0.00017588\n",
      "Epoch: [53] [   1/  20] time: 553.1001, loss: 0.00004034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [53] [   2/  20] time: 553.5475, loss: 0.00000014\n",
      "Epoch: [53] [   3/  20] time: 554.0003, loss: 0.00002628\n",
      "Epoch: [53] [   4/  20] time: 554.4715, loss: 0.00003026\n",
      "Epoch: [53] [   5/  20] time: 554.9244, loss: 0.00000169\n",
      "Epoch: [53] [   6/  20] time: 555.3734, loss: 0.00000030\n",
      "Epoch: [53] [   7/  20] time: 555.8228, loss: 0.00000081\n",
      "Epoch: [53] [   8/  20] time: 556.2756, loss: 0.00000713\n",
      "Epoch: [53] [   9/  20] time: 556.7405, loss: 0.00019718\n",
      "Epoch: [53] [  10/  20] time: 557.1958, loss: 0.00005313\n",
      "Epoch: [53] [  11/  20] time: 557.6573, loss: 0.00000595\n",
      "Epoch: [53] [  12/  20] time: 558.1062, loss: 0.00000176\n",
      "Epoch: [53] [  13/  20] time: 558.5670, loss: 0.00003063\n",
      "Epoch: [53] [  14/  20] time: 559.0175, loss: 0.00000414\n",
      "Epoch: [53] [  15/  20] time: 559.4765, loss: 0.00000517\n",
      "Epoch: [53] [  16/  20] time: 559.9261, loss: 0.00000117\n",
      "Epoch: [53] [  17/  20] time: 560.3793, loss: 0.00002033\n",
      "Epoch: [53] [  18/  20] time: 560.8337, loss: 0.00000943\n",
      "Epoch: [53] [  19/  20] time: 561.2873, loss: 0.00000218\n",
      "[53/80] - ptime: 9.9977 loss: 0.00003070 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [54] [   0/  20] time: 563.1221, loss: 0.00000289\n",
      "Epoch: [54] [   1/  20] time: 563.5726, loss: 0.00000202\n",
      "Epoch: [54] [   2/  20] time: 564.0251, loss: 0.00001225\n",
      "Epoch: [54] [   3/  20] time: 564.4729, loss: 0.00000119\n",
      "Epoch: [54] [   4/  20] time: 564.9379, loss: 0.00002500\n",
      "Epoch: [54] [   5/  20] time: 565.3902, loss: 0.00001245\n",
      "Epoch: [54] [   6/  20] time: 565.8535, loss: 0.00000083\n",
      "Epoch: [54] [   7/  20] time: 566.3083, loss: 0.00000891\n",
      "Epoch: [54] [   8/  20] time: 566.7677, loss: 0.00002681\n",
      "Epoch: [54] [   9/  20] time: 567.2204, loss: 0.00000249\n",
      "Epoch: [54] [  10/  20] time: 567.6781, loss: 0.00000200\n",
      "Epoch: [54] [  11/  20] time: 568.1315, loss: 0.00000901\n",
      "Epoch: [54] [  12/  20] time: 568.5832, loss: 0.00000083\n",
      "Epoch: [54] [  13/  20] time: 569.0398, loss: 0.00000087\n",
      "Epoch: [54] [  14/  20] time: 569.4931, loss: 0.00006735\n",
      "Epoch: [54] [  15/  20] time: 569.9611, loss: 0.00001308\n",
      "Epoch: [54] [  16/  20] time: 570.4125, loss: 0.00000078\n",
      "Epoch: [54] [  17/  20] time: 570.8717, loss: 0.00000104\n",
      "Epoch: [54] [  18/  20] time: 571.3262, loss: 0.00003829\n",
      "Epoch: [54] [  19/  20] time: 571.7920, loss: 0.00001166\n",
      "[54/80] - ptime: 10.0136 loss: 0.00001199 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [55] [   0/  20] time: 573.5747, loss: 0.00001176\n",
      "Epoch: [55] [   1/  20] time: 574.0366, loss: 0.00000336\n",
      "Epoch: [55] [   2/  20] time: 574.4942, loss: 0.00001346\n",
      "Epoch: [55] [   3/  20] time: 574.9542, loss: 0.00000015\n",
      "Epoch: [55] [   4/  20] time: 575.4063, loss: 0.00000600\n",
      "Epoch: [55] [   5/  20] time: 575.8644, loss: 0.00039963\n",
      "Epoch: [55] [   6/  20] time: 576.3156, loss: 0.00000383\n",
      "Epoch: [55] [   7/  20] time: 576.7714, loss: 0.00001021\n",
      "Epoch: [55] [   8/  20] time: 577.2213, loss: 0.00000220\n",
      "Epoch: [55] [   9/  20] time: 577.6726, loss: 0.00000289\n",
      "Epoch: [55] [  10/  20] time: 578.1271, loss: 0.00002725\n",
      "Epoch: [55] [  11/  20] time: 578.5833, loss: 0.00000108\n",
      "Epoch: [55] [  12/  20] time: 579.0471, loss: 0.00000833\n",
      "Epoch: [55] [  13/  20] time: 579.4998, loss: 0.00000800\n",
      "Epoch: [55] [  14/  20] time: 579.9555, loss: 0.00004425\n",
      "Epoch: [55] [  15/  20] time: 580.4168, loss: 0.00001343\n",
      "Epoch: [55] [  16/  20] time: 580.8762, loss: 0.00000768\n",
      "Epoch: [55] [  17/  20] time: 581.3243, loss: 0.00000401\n",
      "Epoch: [55] [  18/  20] time: 581.7782, loss: 0.00003130\n",
      "Epoch: [55] [  19/  20] time: 582.2282, loss: 0.00000293\n",
      "[55/80] - ptime: 9.9096 loss: 0.00003009 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [56] [   0/  20] time: 584.2419, loss: 0.00000254\n",
      "Epoch: [56] [   1/  20] time: 584.6937, loss: 0.00000080\n",
      "Epoch: [56] [   2/  20] time: 585.1589, loss: 0.00000101\n",
      "Epoch: [56] [   3/  20] time: 585.6107, loss: 0.00004346\n",
      "Epoch: [56] [   4/  20] time: 586.0720, loss: 0.00000685\n",
      "Epoch: [56] [   5/  20] time: 586.5272, loss: 0.00000140\n",
      "Epoch: [56] [   6/  20] time: 586.9817, loss: 0.00000082\n",
      "Epoch: [56] [   7/  20] time: 587.4339, loss: 0.00000656\n",
      "Epoch: [56] [   8/  20] time: 587.8849, loss: 0.00000307\n",
      "Epoch: [56] [   9/  20] time: 588.3442, loss: 0.00001261\n",
      "Epoch: [56] [  10/  20] time: 588.7958, loss: 0.00000029\n",
      "Epoch: [56] [  11/  20] time: 589.2587, loss: 0.00006381\n",
      "Epoch: [56] [  12/  20] time: 589.7111, loss: 0.00000037\n",
      "Epoch: [56] [  13/  20] time: 590.1716, loss: 0.00000027\n",
      "Epoch: [56] [  14/  20] time: 590.6244, loss: 0.00001482\n",
      "Epoch: [56] [  15/  20] time: 591.0868, loss: 0.00000078\n",
      "Epoch: [56] [  16/  20] time: 591.5385, loss: 0.00000172\n",
      "Epoch: [56] [  17/  20] time: 591.9977, loss: 0.00000107\n",
      "Epoch: [56] [  18/  20] time: 592.4429, loss: 0.00000225\n",
      "Epoch: [56] [  19/  20] time: 592.8920, loss: 0.00001522\n",
      "[56/80] - ptime: 10.0066 loss: 0.00000899 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [57] [   0/  20] time: 594.8034, loss: 0.00000567\n",
      "Epoch: [57] [   1/  20] time: 595.2716, loss: 0.00000996\n",
      "Epoch: [57] [   2/  20] time: 595.7233, loss: 0.00000031\n",
      "Epoch: [57] [   3/  20] time: 596.1875, loss: 0.00000163\n",
      "Epoch: [57] [   4/  20] time: 596.6439, loss: 0.00000607\n",
      "Epoch: [57] [   5/  20] time: 597.1063, loss: 0.00002753\n",
      "Epoch: [57] [   6/  20] time: 597.5547, loss: 0.00000114\n",
      "Epoch: [57] [   7/  20] time: 598.0065, loss: 0.00002465\n",
      "Epoch: [57] [   8/  20] time: 598.4617, loss: 0.00000108\n",
      "Epoch: [57] [   9/  20] time: 598.9102, loss: 0.00000453\n",
      "Epoch: [57] [  10/  20] time: 599.3745, loss: 0.00000564\n",
      "Epoch: [57] [  11/  20] time: 599.8285, loss: 0.00000037\n",
      "Epoch: [57] [  12/  20] time: 600.2872, loss: 0.00000223\n",
      "Epoch: [57] [  13/  20] time: 600.7366, loss: 0.00003783\n",
      "Epoch: [57] [  14/  20] time: 601.1938, loss: 0.00000029\n",
      "Epoch: [57] [  15/  20] time: 601.6471, loss: 0.00001118\n",
      "Epoch: [57] [  16/  20] time: 602.1052, loss: 0.00002770\n",
      "Epoch: [57] [  17/  20] time: 602.5577, loss: 0.00000343\n",
      "Epoch: [57] [  18/  20] time: 603.0123, loss: 0.00000135\n",
      "Epoch: [57] [  19/  20] time: 603.4645, loss: 0.00000063\n",
      "[57/80] - ptime: 9.9512 loss: 0.00000866 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [58] [   0/  20] time: 605.3971, loss: 0.00001205\n",
      "Epoch: [58] [   1/  20] time: 605.8459, loss: 0.00000934\n",
      "Epoch: [58] [   2/  20] time: 606.3032, loss: 0.00000226\n",
      "Epoch: [58] [   3/  20] time: 606.7570, loss: 0.00002179\n",
      "Epoch: [58] [   4/  20] time: 607.2158, loss: 0.00002685\n",
      "Epoch: [58] [   5/  20] time: 607.6725, loss: 0.00000045\n",
      "Epoch: [58] [   6/  20] time: 608.1261, loss: 0.00001320\n",
      "Epoch: [58] [   7/  20] time: 608.5834, loss: 0.00002555\n",
      "Epoch: [58] [   8/  20] time: 609.0347, loss: 0.00000196\n",
      "Epoch: [58] [   9/  20] time: 609.4937, loss: 0.00000751\n",
      "Epoch: [58] [  10/  20] time: 609.9455, loss: 0.00001524\n",
      "Epoch: [58] [  11/  20] time: 610.4097, loss: 0.00000144\n",
      "Epoch: [58] [  12/  20] time: 610.8610, loss: 0.00000061\n",
      "Epoch: [58] [  13/  20] time: 611.3213, loss: 0.00002741\n",
      "Epoch: [58] [  14/  20] time: 611.7741, loss: 0.00000137\n",
      "Epoch: [58] [  15/  20] time: 612.2264, loss: 0.00000257\n",
      "Epoch: [58] [  16/  20] time: 612.6797, loss: 0.00001184\n",
      "Epoch: [58] [  17/  20] time: 613.1384, loss: 0.00000032\n",
      "Epoch: [58] [  18/  20] time: 613.5981, loss: 0.00000129\n",
      "Epoch: [58] [  19/  20] time: 614.0547, loss: 0.00000108\n",
      "[58/80] - ptime: 9.9955 loss: 0.00000921 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [59] [   0/  20] time: 615.8915, loss: 0.00000304\n",
      "Epoch: [59] [   1/  20] time: 616.3522, loss: 0.00000147\n",
      "Epoch: [59] [   2/  20] time: 616.8061, loss: 0.00002076\n",
      "Epoch: [59] [   3/  20] time: 617.2650, loss: 0.00001449\n",
      "Epoch: [59] [   4/  20] time: 617.7231, loss: 0.00000224\n",
      "Epoch: [59] [   5/  20] time: 618.1772, loss: 0.00000605\n",
      "Epoch: [59] [   6/  20] time: 618.6397, loss: 0.00000078\n",
      "Epoch: [59] [   7/  20] time: 619.0901, loss: 0.00000034\n",
      "Epoch: [59] [   8/  20] time: 619.5543, loss: 0.00000217\n",
      "Epoch: [59] [   9/  20] time: 620.0100, loss: 0.00001139\n",
      "Epoch: [59] [  10/  20] time: 620.4716, loss: 0.00000093\n",
      "Epoch: [59] [  11/  20] time: 620.9254, loss: 0.00000016\n",
      "Epoch: [59] [  12/  20] time: 621.3853, loss: 0.00000310\n",
      "Epoch: [59] [  13/  20] time: 621.8383, loss: 0.00000271\n",
      "Epoch: [59] [  14/  20] time: 622.2940, loss: 0.00006514\n",
      "Epoch: [59] [  15/  20] time: 622.7400, loss: 0.00000855\n",
      "Epoch: [59] [  16/  20] time: 623.1951, loss: 0.00001553\n",
      "Epoch: [59] [  17/  20] time: 623.6573, loss: 0.00000051\n",
      "Epoch: [59] [  18/  20] time: 624.1148, loss: 0.00002865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [59] [  19/  20] time: 624.5792, loss: 0.00001268\n",
      "[59/80] - ptime: 10.0321 loss: 0.00001004 acc: 0.61000 lr: 0.00059049\n",
      "Epoch: [60] [   0/  20] time: 626.3889, loss: 0.00000666\n",
      "Epoch: [60] [   1/  20] time: 626.8406, loss: 0.00000164\n",
      "Epoch: [60] [   2/  20] time: 627.2901, loss: 0.00000268\n",
      "Epoch: [60] [   3/  20] time: 627.7498, loss: 0.00000745\n",
      "Epoch: [60] [   4/  20] time: 628.2009, loss: 0.00000723\n",
      "Epoch: [60] [   5/  20] time: 628.6669, loss: 0.00000098\n",
      "Epoch: [60] [   6/  20] time: 629.1195, loss: 0.00000204\n",
      "Epoch: [60] [   7/  20] time: 629.5814, loss: 0.00006519\n",
      "Epoch: [60] [   8/  20] time: 630.0347, loss: 0.00000005\n",
      "Epoch: [60] [   9/  20] time: 630.4993, loss: 0.00000770\n",
      "Epoch: [60] [  10/  20] time: 630.9490, loss: 0.00001473\n",
      "Epoch: [60] [  11/  20] time: 631.4044, loss: 0.00000820\n",
      "Epoch: [60] [  12/  20] time: 631.8671, loss: 0.00000111\n",
      "Epoch: [60] [  13/  20] time: 632.3169, loss: 0.00000040\n",
      "Epoch: [60] [  14/  20] time: 632.7763, loss: 0.00000011\n",
      "Epoch: [60] [  15/  20] time: 633.2224, loss: 0.00000047\n",
      "Epoch: [60] [  16/  20] time: 633.6795, loss: 0.00000514\n",
      "Epoch: [60] [  17/  20] time: 634.1365, loss: 0.00001274\n",
      "Epoch: [60] [  18/  20] time: 634.6042, loss: 0.00009379\n",
      "Epoch: [60] [  19/  20] time: 635.0593, loss: 0.00000098\n",
      "[60/80] - ptime: 9.9059 loss: 0.00001196 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [61] [   0/  20] time: 637.0455, loss: 0.00000078\n",
      "Epoch: [61] [   1/  20] time: 637.4953, loss: 0.00000518\n",
      "Epoch: [61] [   2/  20] time: 637.9537, loss: 0.00000289\n",
      "Epoch: [61] [   3/  20] time: 638.4038, loss: 0.00001127\n",
      "Epoch: [61] [   4/  20] time: 638.8756, loss: 0.00000087\n",
      "Epoch: [61] [   5/  20] time: 639.3283, loss: 0.00000477\n",
      "Epoch: [61] [   6/  20] time: 639.7939, loss: 0.00003112\n",
      "Epoch: [61] [   7/  20] time: 640.2435, loss: 0.00000273\n",
      "Epoch: [61] [   8/  20] time: 640.7109, loss: 0.00001780\n",
      "Epoch: [61] [   9/  20] time: 641.1648, loss: 0.00000019\n",
      "Epoch: [61] [  10/  20] time: 641.6208, loss: 0.00000083\n",
      "Epoch: [61] [  11/  20] time: 642.0770, loss: 0.00002144\n",
      "Epoch: [61] [  12/  20] time: 642.5270, loss: 0.00000132\n",
      "Epoch: [61] [  13/  20] time: 642.9873, loss: 0.00010008\n",
      "Epoch: [61] [  14/  20] time: 643.4391, loss: 0.00000378\n",
      "Epoch: [61] [  15/  20] time: 643.9016, loss: 0.00009604\n",
      "Epoch: [61] [  16/  20] time: 644.3536, loss: 0.00002256\n",
      "Epoch: [61] [  17/  20] time: 644.8174, loss: 0.00000678\n",
      "Epoch: [61] [  18/  20] time: 645.2718, loss: 0.00000957\n",
      "Epoch: [61] [  19/  20] time: 645.7324, loss: 0.00000137\n",
      "[61/80] - ptime: 10.0563 loss: 0.00001707 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [62] [   0/  20] time: 647.5383, loss: 0.00000199\n",
      "Epoch: [62] [   1/  20] time: 647.9982, loss: 0.00000074\n",
      "Epoch: [62] [   2/  20] time: 648.4495, loss: 0.00000170\n",
      "Epoch: [62] [   3/  20] time: 648.9051, loss: 0.00000546\n",
      "Epoch: [62] [   4/  20] time: 649.3585, loss: 0.00001920\n",
      "Epoch: [62] [   5/  20] time: 649.8203, loss: 0.00004440\n",
      "Epoch: [62] [   6/  20] time: 650.2694, loss: 0.00000386\n",
      "Epoch: [62] [   7/  20] time: 650.7322, loss: 0.00000554\n",
      "Epoch: [62] [   8/  20] time: 651.1848, loss: 0.00000027\n",
      "Epoch: [62] [   9/  20] time: 651.6312, loss: 0.00000247\n",
      "Epoch: [62] [  10/  20] time: 652.0909, loss: 0.00000463\n",
      "Epoch: [62] [  11/  20] time: 652.5390, loss: 0.00000157\n",
      "Epoch: [62] [  12/  20] time: 652.9990, loss: 0.00001536\n",
      "Epoch: [62] [  13/  20] time: 653.4523, loss: 0.00000944\n",
      "Epoch: [62] [  14/  20] time: 653.9137, loss: 0.00000282\n",
      "Epoch: [62] [  15/  20] time: 654.3663, loss: 0.00000054\n",
      "Epoch: [62] [  16/  20] time: 654.8268, loss: 0.00000254\n",
      "Epoch: [62] [  17/  20] time: 655.2750, loss: 0.00000192\n",
      "Epoch: [62] [  18/  20] time: 655.7315, loss: 0.00000151\n",
      "Epoch: [62] [  19/  20] time: 656.1787, loss: 0.00000327\n",
      "[62/80] - ptime: 9.8934 loss: 0.00000646 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [63] [   0/  20] time: 658.1551, loss: 0.00000136\n",
      "Epoch: [63] [   1/  20] time: 658.6132, loss: 0.00000242\n",
      "Epoch: [63] [   2/  20] time: 659.0754, loss: 0.00000020\n",
      "Epoch: [63] [   3/  20] time: 659.5263, loss: 0.00000083\n",
      "Epoch: [63] [   4/  20] time: 659.9863, loss: 0.00000057\n",
      "Epoch: [63] [   5/  20] time: 660.4400, loss: 0.00000272\n",
      "Epoch: [63] [   6/  20] time: 660.9000, loss: 0.00000147\n",
      "Epoch: [63] [   7/  20] time: 661.3505, loss: 0.00005250\n",
      "Epoch: [63] [   8/  20] time: 661.8041, loss: 0.00006994\n",
      "Epoch: [63] [   9/  20] time: 662.2653, loss: 0.00000612\n",
      "Epoch: [63] [  10/  20] time: 662.7191, loss: 0.00002061\n",
      "Epoch: [63] [  11/  20] time: 663.1882, loss: 0.00000071\n",
      "Epoch: [63] [  12/  20] time: 663.6400, loss: 0.00000484\n",
      "Epoch: [63] [  13/  20] time: 664.1044, loss: 0.00003701\n",
      "Epoch: [63] [  14/  20] time: 664.5640, loss: 0.00000163\n",
      "Epoch: [63] [  15/  20] time: 665.0282, loss: 0.00000176\n",
      "Epoch: [63] [  16/  20] time: 665.4811, loss: 0.00000280\n",
      "Epoch: [63] [  17/  20] time: 665.9370, loss: 0.00000215\n",
      "Epoch: [63] [  18/  20] time: 666.3870, loss: 0.00000224\n",
      "Epoch: [63] [  19/  20] time: 666.8380, loss: 0.00000281\n",
      "[63/80] - ptime: 10.0391 loss: 0.00001073 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [64] [   0/  20] time: 668.6573, loss: 0.00003191\n",
      "Epoch: [64] [   1/  20] time: 669.1227, loss: 0.00000484\n",
      "Epoch: [64] [   2/  20] time: 669.5729, loss: 0.00005300\n",
      "Epoch: [64] [   3/  20] time: 670.0260, loss: 0.00000418\n",
      "Epoch: [64] [   4/  20] time: 670.4847, loss: 0.00000007\n",
      "Epoch: [64] [   5/  20] time: 670.9393, loss: 0.00003805\n",
      "Epoch: [64] [   6/  20] time: 671.4003, loss: 0.00000069\n",
      "Epoch: [64] [   7/  20] time: 671.8579, loss: 0.00000263\n",
      "Epoch: [64] [   8/  20] time: 672.3147, loss: 0.00001429\n",
      "Epoch: [64] [   9/  20] time: 672.7666, loss: 0.00000710\n",
      "Epoch: [64] [  10/  20] time: 673.2261, loss: 0.00002042\n",
      "Epoch: [64] [  11/  20] time: 673.6824, loss: 0.00004709\n",
      "Epoch: [64] [  12/  20] time: 674.1429, loss: 0.00000394\n",
      "Epoch: [64] [  13/  20] time: 674.5935, loss: 0.00000400\n",
      "Epoch: [64] [  14/  20] time: 675.0532, loss: 0.00002026\n",
      "Epoch: [64] [  15/  20] time: 675.4964, loss: 0.00000009\n",
      "Epoch: [64] [  16/  20] time: 675.9488, loss: 0.00000192\n",
      "Epoch: [64] [  17/  20] time: 676.4142, loss: 0.00000053\n",
      "Epoch: [64] [  18/  20] time: 676.8687, loss: 0.00000008\n",
      "Epoch: [64] [  19/  20] time: 677.3308, loss: 0.00000024\n",
      "[64/80] - ptime: 10.0044 loss: 0.00001277 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [65] [   0/  20] time: 679.1256, loss: 0.00000098\n",
      "Epoch: [65] [   1/  20] time: 679.5805, loss: 0.00000070\n",
      "Epoch: [65] [   2/  20] time: 680.0326, loss: 0.00000145\n",
      "Epoch: [65] [   3/  20] time: 680.4983, loss: 0.00000949\n",
      "Epoch: [65] [   4/  20] time: 680.9514, loss: 0.00000026\n",
      "Epoch: [65] [   5/  20] time: 681.4128, loss: 0.00000163\n",
      "Epoch: [65] [   6/  20] time: 681.8687, loss: 0.00000068\n",
      "Epoch: [65] [   7/  20] time: 682.3278, loss: 0.00000047\n",
      "Epoch: [65] [   8/  20] time: 682.7825, loss: 0.00000161\n",
      "Epoch: [65] [   9/  20] time: 683.2387, loss: 0.00000013\n",
      "Epoch: [65] [  10/  20] time: 683.6928, loss: 0.00000004\n",
      "Epoch: [65] [  11/  20] time: 684.1491, loss: 0.00000144\n",
      "Epoch: [65] [  12/  20] time: 684.6030, loss: 0.00000092\n",
      "Epoch: [65] [  13/  20] time: 685.0576, loss: 0.00000213\n",
      "Epoch: [65] [  14/  20] time: 685.5128, loss: 0.00001527\n",
      "Epoch: [65] [  15/  20] time: 685.9774, loss: 0.00000908\n",
      "Epoch: [65] [  16/  20] time: 686.4424, loss: 0.00000537\n",
      "Epoch: [65] [  17/  20] time: 686.8985, loss: 0.00000065\n",
      "Epoch: [65] [  18/  20] time: 687.3634, loss: 0.00000038\n",
      "Epoch: [65] [  19/  20] time: 687.8152, loss: 0.00012124\n",
      "[65/80] - ptime: 9.9060 loss: 0.00000870 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [66] [   0/  20] time: 689.7819, loss: 0.00000053\n",
      "Epoch: [66] [   1/  20] time: 690.2368, loss: 0.00000054\n",
      "Epoch: [66] [   2/  20] time: 690.7004, loss: 0.00000075\n",
      "Epoch: [66] [   3/  20] time: 691.1550, loss: 0.00000085\n",
      "Epoch: [66] [   4/  20] time: 691.6210, loss: 0.00000053\n",
      "Epoch: [66] [   5/  20] time: 692.0771, loss: 0.00000041\n",
      "Epoch: [66] [   6/  20] time: 692.5381, loss: 0.00000195\n",
      "Epoch: [66] [   7/  20] time: 692.9943, loss: 0.00000444\n",
      "Epoch: [66] [   8/  20] time: 693.4565, loss: 0.00000038\n",
      "Epoch: [66] [   9/  20] time: 693.9109, loss: 0.00000376\n",
      "Epoch: [66] [  10/  20] time: 694.3630, loss: 0.00000214\n",
      "Epoch: [66] [  11/  20] time: 694.8245, loss: 0.00001562\n",
      "Epoch: [66] [  12/  20] time: 695.2769, loss: 0.00001975\n",
      "Epoch: [66] [  13/  20] time: 695.7411, loss: 0.00000872\n",
      "Epoch: [66] [  14/  20] time: 696.1931, loss: 0.00001087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [66] [  15/  20] time: 696.6582, loss: 0.00000200\n",
      "Epoch: [66] [  16/  20] time: 697.1142, loss: 0.00000797\n",
      "Epoch: [66] [  17/  20] time: 697.5760, loss: 0.00001447\n",
      "Epoch: [66] [  18/  20] time: 698.0295, loss: 0.00002235\n",
      "Epoch: [66] [  19/  20] time: 698.5028, loss: 0.00000048\n",
      "[66/80] - ptime: 10.0924 loss: 0.00000592 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [67] [   0/  20] time: 700.3730, loss: 0.00000147\n",
      "Epoch: [67] [   1/  20] time: 700.8311, loss: 0.00001500\n",
      "Epoch: [67] [   2/  20] time: 701.2880, loss: 0.00001465\n",
      "Epoch: [67] [   3/  20] time: 701.7455, loss: 0.00000029\n",
      "Epoch: [67] [   4/  20] time: 702.1947, loss: 0.00000030\n",
      "Epoch: [67] [   5/  20] time: 702.6568, loss: 0.00001618\n",
      "Epoch: [67] [   6/  20] time: 703.1092, loss: 0.00000438\n",
      "Epoch: [67] [   7/  20] time: 703.5598, loss: 0.00000014\n",
      "Epoch: [67] [   8/  20] time: 704.0194, loss: 0.00000687\n",
      "Epoch: [67] [   9/  20] time: 704.4698, loss: 0.00000045\n",
      "Epoch: [67] [  10/  20] time: 704.9342, loss: 0.00000453\n",
      "Epoch: [67] [  11/  20] time: 705.3861, loss: 0.00000172\n",
      "Epoch: [67] [  12/  20] time: 705.8503, loss: 0.00000021\n",
      "Epoch: [67] [  13/  20] time: 706.3014, loss: 0.00002253\n",
      "Epoch: [67] [  14/  20] time: 706.7587, loss: 0.00000280\n",
      "Epoch: [67] [  15/  20] time: 707.2109, loss: 0.00000167\n",
      "Epoch: [67] [  16/  20] time: 707.6661, loss: 0.00000682\n",
      "Epoch: [67] [  17/  20] time: 708.1111, loss: 0.00001214\n",
      "Epoch: [67] [  18/  20] time: 708.5614, loss: 0.00000014\n",
      "Epoch: [67] [  19/  20] time: 709.0224, loss: 0.00000915\n",
      "[67/80] - ptime: 9.9829 loss: 0.00000607 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [68] [   0/  20] time: 710.8851, loss: 0.00000028\n",
      "Epoch: [68] [   1/  20] time: 711.3337, loss: 0.00000124\n",
      "Epoch: [68] [   2/  20] time: 711.7834, loss: 0.00000268\n",
      "Epoch: [68] [   3/  20] time: 712.2348, loss: 0.00000755\n",
      "Epoch: [68] [   4/  20] time: 712.6872, loss: 0.00000992\n",
      "Epoch: [68] [   5/  20] time: 713.1472, loss: 0.00000182\n",
      "Epoch: [68] [   6/  20] time: 713.6003, loss: 0.00001360\n",
      "Epoch: [68] [   7/  20] time: 714.0656, loss: 0.00002021\n",
      "Epoch: [68] [   8/  20] time: 714.5174, loss: 0.00000134\n",
      "Epoch: [68] [   9/  20] time: 714.9782, loss: 0.00000664\n",
      "Epoch: [68] [  10/  20] time: 715.4295, loss: 0.00000016\n",
      "Epoch: [68] [  11/  20] time: 715.8926, loss: 0.00010747\n",
      "Epoch: [68] [  12/  20] time: 716.3405, loss: 0.00000021\n",
      "Epoch: [68] [  13/  20] time: 716.7888, loss: 0.00000076\n",
      "Epoch: [68] [  14/  20] time: 717.2390, loss: 0.00000017\n",
      "Epoch: [68] [  15/  20] time: 717.6927, loss: 0.00000024\n",
      "Epoch: [68] [  16/  20] time: 718.1569, loss: 0.00001177\n",
      "Epoch: [68] [  17/  20] time: 718.6104, loss: 0.00000008\n",
      "Epoch: [68] [  18/  20] time: 719.0733, loss: 0.00000426\n",
      "Epoch: [68] [  19/  20] time: 719.5273, loss: 0.00000076\n",
      "[68/80] - ptime: 9.9259 loss: 0.00000956 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [69] [   0/  20] time: 721.6678, loss: 0.00000071\n",
      "Epoch: [69] [   1/  20] time: 722.1275, loss: 0.00000190\n",
      "Epoch: [69] [   2/  20] time: 722.5788, loss: 0.00000002\n",
      "Epoch: [69] [   3/  20] time: 723.0430, loss: 0.00000120\n",
      "Epoch: [69] [   4/  20] time: 723.4996, loss: 0.00000566\n",
      "Epoch: [69] [   5/  20] time: 723.9519, loss: 0.00000451\n",
      "Epoch: [69] [   6/  20] time: 724.4059, loss: 0.00000603\n",
      "Epoch: [69] [   7/  20] time: 724.8617, loss: 0.00003952\n",
      "Epoch: [69] [   8/  20] time: 725.3258, loss: 0.00000047\n",
      "Epoch: [69] [   9/  20] time: 725.7836, loss: 0.00000091\n",
      "Epoch: [69] [  10/  20] time: 726.2441, loss: 0.00000037\n",
      "Epoch: [69] [  11/  20] time: 726.6938, loss: 0.00000018\n",
      "Epoch: [69] [  12/  20] time: 727.1564, loss: 0.00002083\n",
      "Epoch: [69] [  13/  20] time: 727.6101, loss: 0.00000095\n",
      "Epoch: [69] [  14/  20] time: 728.0718, loss: 0.00001643\n",
      "Epoch: [69] [  15/  20] time: 728.5222, loss: 0.00000920\n",
      "Epoch: [69] [  16/  20] time: 728.9745, loss: 0.00003589\n",
      "Epoch: [69] [  17/  20] time: 729.4226, loss: 0.00000110\n",
      "Epoch: [69] [  18/  20] time: 729.8751, loss: 0.00000073\n",
      "Epoch: [69] [  19/  20] time: 730.3378, loss: 0.00000100\n",
      "[69/80] - ptime: 10.0048 loss: 0.00000738 acc: 0.61000 lr: 0.00053144\n",
      "Epoch: [70] [   0/  20] time: 732.1629, loss: 0.00000421\n",
      "Epoch: [70] [   1/  20] time: 732.6023, loss: 0.00000327\n",
      "Epoch: [70] [   2/  20] time: 733.0573, loss: 0.00001233\n",
      "Epoch: [70] [   3/  20] time: 733.5140, loss: 0.00000283\n",
      "Epoch: [70] [   4/  20] time: 733.9654, loss: 0.00000186\n",
      "Epoch: [70] [   5/  20] time: 734.4277, loss: 0.00001647\n",
      "Epoch: [70] [   6/  20] time: 734.8829, loss: 0.00000523\n",
      "Epoch: [70] [   7/  20] time: 735.3411, loss: 0.00000108\n",
      "Epoch: [70] [   8/  20] time: 735.7962, loss: 0.00000156\n",
      "Epoch: [70] [   9/  20] time: 736.2569, loss: 0.00000001\n",
      "Epoch: [70] [  10/  20] time: 736.7068, loss: 0.00002695\n",
      "Epoch: [70] [  11/  20] time: 737.1512, loss: 0.00000541\n",
      "Epoch: [70] [  12/  20] time: 737.6063, loss: 0.00000234\n",
      "Epoch: [70] [  13/  20] time: 738.0629, loss: 0.00001517\n",
      "Epoch: [70] [  14/  20] time: 738.5269, loss: 0.00000155\n",
      "Epoch: [70] [  15/  20] time: 738.9814, loss: 0.00000041\n",
      "Epoch: [70] [  16/  20] time: 739.4414, loss: 0.00000397\n",
      "Epoch: [70] [  17/  20] time: 739.8943, loss: 0.00000121\n",
      "Epoch: [70] [  18/  20] time: 740.3527, loss: 0.00000027\n",
      "Epoch: [70] [  19/  20] time: 740.8053, loss: 0.00000038\n",
      "[70/80] - ptime: 9.8828 loss: 0.00000533 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [71] [   0/  20] time: 742.7425, loss: 0.00000329\n",
      "Epoch: [71] [   1/  20] time: 743.1921, loss: 0.00000405\n",
      "Epoch: [71] [   2/  20] time: 743.6536, loss: 0.00003046\n",
      "Epoch: [71] [   3/  20] time: 744.1048, loss: 0.00000170\n",
      "Epoch: [71] [   4/  20] time: 744.5692, loss: 0.00000363\n",
      "Epoch: [71] [   5/  20] time: 745.0262, loss: 0.00000376\n",
      "Epoch: [71] [   6/  20] time: 745.4856, loss: 0.00001027\n",
      "Epoch: [71] [   7/  20] time: 745.9401, loss: 0.00000722\n",
      "Epoch: [71] [   8/  20] time: 746.4003, loss: 0.00000180\n",
      "Epoch: [71] [   9/  20] time: 746.8484, loss: 0.00000021\n",
      "Epoch: [71] [  10/  20] time: 747.2964, loss: 0.00000327\n",
      "Epoch: [71] [  11/  20] time: 747.7504, loss: 0.00000183\n",
      "Epoch: [71] [  12/  20] time: 748.2002, loss: 0.00001030\n",
      "Epoch: [71] [  13/  20] time: 748.6664, loss: 0.00000015\n",
      "Epoch: [71] [  14/  20] time: 749.1185, loss: 0.00000131\n",
      "Epoch: [71] [  15/  20] time: 749.5768, loss: 0.00000005\n",
      "Epoch: [71] [  16/  20] time: 750.0287, loss: 0.00005309\n",
      "Epoch: [71] [  17/  20] time: 750.4882, loss: 0.00000530\n",
      "Epoch: [71] [  18/  20] time: 750.9413, loss: 0.00000025\n",
      "Epoch: [71] [  19/  20] time: 751.4009, loss: 0.00000507\n",
      "[71/80] - ptime: 10.0154 loss: 0.00000735 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [72] [   0/  20] time: 753.2083, loss: 0.00000683\n",
      "Epoch: [72] [   1/  20] time: 753.6689, loss: 0.00000029\n",
      "Epoch: [72] [   2/  20] time: 754.1229, loss: 0.00001842\n",
      "Epoch: [72] [   3/  20] time: 754.5839, loss: 0.00000013\n",
      "Epoch: [72] [   4/  20] time: 755.0371, loss: 0.00000191\n",
      "Epoch: [72] [   5/  20] time: 755.4971, loss: 0.00000612\n",
      "Epoch: [72] [   6/  20] time: 755.9489, loss: 0.00000070\n",
      "Epoch: [72] [   7/  20] time: 756.4054, loss: 0.00000122\n",
      "Epoch: [72] [   8/  20] time: 756.8617, loss: 0.00000047\n",
      "Epoch: [72] [   9/  20] time: 757.3131, loss: 0.00000287\n",
      "Epoch: [72] [  10/  20] time: 757.7747, loss: 0.00000173\n",
      "Epoch: [72] [  11/  20] time: 758.2275, loss: 0.00000079\n",
      "Epoch: [72] [  12/  20] time: 758.6861, loss: 0.00000047\n",
      "Epoch: [72] [  13/  20] time: 759.1416, loss: 0.00000080\n",
      "Epoch: [72] [  14/  20] time: 759.5995, loss: 0.00005657\n",
      "Epoch: [72] [  15/  20] time: 760.0512, loss: 0.00000013\n",
      "Epoch: [72] [  16/  20] time: 760.4996, loss: 0.00000785\n",
      "Epoch: [72] [  17/  20] time: 760.9589, loss: 0.00000307\n",
      "Epoch: [72] [  18/  20] time: 761.4104, loss: 0.00000009\n",
      "Epoch: [72] [  19/  20] time: 761.8738, loss: 0.00000355\n",
      "[72/80] - ptime: 9.9882 loss: 0.00000570 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [73] [   0/  20] time: 763.7879, loss: 0.00000539\n",
      "Epoch: [73] [   1/  20] time: 764.2379, loss: 0.00000384\n",
      "Epoch: [73] [   2/  20] time: 764.6932, loss: 0.00000032\n",
      "Epoch: [73] [   3/  20] time: 765.1506, loss: 0.00000022\n",
      "Epoch: [73] [   4/  20] time: 765.6045, loss: 0.00004067\n",
      "Epoch: [73] [   5/  20] time: 766.0574, loss: 0.00000184\n",
      "Epoch: [73] [   6/  20] time: 766.5097, loss: 0.00001437\n",
      "Epoch: [73] [   7/  20] time: 766.9806, loss: 0.00000162\n",
      "Epoch: [73] [   8/  20] time: 767.4341, loss: 0.00000495\n",
      "Epoch: [73] [   9/  20] time: 767.8962, loss: 0.00000030\n",
      "Epoch: [73] [  10/  20] time: 768.3473, loss: 0.00001870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [73] [  11/  20] time: 768.8083, loss: 0.00002828\n",
      "Epoch: [73] [  12/  20] time: 769.2597, loss: 0.00000083\n",
      "Epoch: [73] [  13/  20] time: 769.7197, loss: 0.00000209\n",
      "Epoch: [73] [  14/  20] time: 770.1709, loss: 0.00000272\n",
      "Epoch: [73] [  15/  20] time: 770.6219, loss: 0.00001259\n",
      "Epoch: [73] [  16/  20] time: 771.0798, loss: 0.00000118\n",
      "Epoch: [73] [  17/  20] time: 771.5316, loss: 0.00000293\n",
      "Epoch: [73] [  18/  20] time: 771.9905, loss: 0.00000136\n",
      "Epoch: [73] [  19/  20] time: 772.4431, loss: 0.00000103\n",
      "[73/80] - ptime: 9.9615 loss: 0.00000726 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [74] [   0/  20] time: 774.3156, loss: 0.00000013\n",
      "Epoch: [74] [   1/  20] time: 774.7732, loss: 0.00000381\n",
      "Epoch: [74] [   2/  20] time: 775.2281, loss: 0.00001358\n",
      "Epoch: [74] [   3/  20] time: 775.6797, loss: 0.00000139\n",
      "Epoch: [74] [   4/  20] time: 776.1520, loss: 0.00000081\n",
      "Epoch: [74] [   5/  20] time: 776.5940, loss: 0.00000020\n",
      "Epoch: [74] [   6/  20] time: 777.0611, loss: 0.00046914\n",
      "Epoch: [74] [   7/  20] time: 777.5147, loss: 0.00000174\n",
      "Epoch: [74] [   8/  20] time: 777.9800, loss: 0.00000614\n",
      "Epoch: [74] [   9/  20] time: 778.4312, loss: 0.00000529\n",
      "Epoch: [74] [  10/  20] time: 778.9006, loss: 0.00000054\n",
      "Epoch: [74] [  11/  20] time: 779.3492, loss: 0.00000050\n",
      "Epoch: [74] [  12/  20] time: 779.8034, loss: 0.00004428\n",
      "Epoch: [74] [  13/  20] time: 780.2563, loss: 0.00000049\n",
      "Epoch: [74] [  14/  20] time: 780.7085, loss: 0.00000346\n",
      "Epoch: [74] [  15/  20] time: 781.1766, loss: 0.00000167\n",
      "Epoch: [74] [  16/  20] time: 781.6279, loss: 0.00000024\n",
      "Epoch: [74] [  17/  20] time: 782.0946, loss: 0.00000009\n",
      "Epoch: [74] [  18/  20] time: 782.5431, loss: 0.00000988\n",
      "Epoch: [74] [  19/  20] time: 783.0059, loss: 0.00000068\n",
      "[74/80] - ptime: 10.0312 loss: 0.00002820 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [75] [   0/  20] time: 784.8040, loss: 0.00000532\n",
      "Epoch: [75] [   1/  20] time: 785.2681, loss: 0.00009402\n",
      "Epoch: [75] [   2/  20] time: 785.7205, loss: 0.00000455\n",
      "Epoch: [75] [   3/  20] time: 786.1801, loss: 0.00002308\n",
      "Epoch: [75] [   4/  20] time: 786.6317, loss: 0.00000040\n",
      "Epoch: [75] [   5/  20] time: 787.0968, loss: 0.00002557\n",
      "Epoch: [75] [   6/  20] time: 787.5461, loss: 0.00000008\n",
      "Epoch: [75] [   7/  20] time: 787.9958, loss: 0.00000052\n",
      "Epoch: [75] [   8/  20] time: 788.4569, loss: 0.00000066\n",
      "Epoch: [75] [   9/  20] time: 788.9071, loss: 0.00000145\n",
      "Epoch: [75] [  10/  20] time: 789.3690, loss: 0.00000007\n",
      "Epoch: [75] [  11/  20] time: 789.8233, loss: 0.00001112\n",
      "Epoch: [75] [  12/  20] time: 790.2829, loss: 0.00002003\n",
      "Epoch: [75] [  13/  20] time: 790.7343, loss: 0.00000025\n",
      "Epoch: [75] [  14/  20] time: 791.2019, loss: 0.00000544\n",
      "Epoch: [75] [  15/  20] time: 791.6487, loss: 0.00000184\n",
      "Epoch: [75] [  16/  20] time: 792.1045, loss: 0.00000312\n",
      "Epoch: [75] [  17/  20] time: 792.5621, loss: 0.00000562\n",
      "Epoch: [75] [  18/  20] time: 793.0149, loss: 0.00001066\n",
      "Epoch: [75] [  19/  20] time: 793.4667, loss: 0.00000041\n",
      "[75/80] - ptime: 9.9767 loss: 0.00001071 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [76] [   0/  20] time: 795.4048, loss: 0.00000120\n",
      "Epoch: [76] [   1/  20] time: 795.8591, loss: 0.00000096\n",
      "Epoch: [76] [   2/  20] time: 796.3127, loss: 0.00000472\n",
      "Epoch: [76] [   3/  20] time: 796.7641, loss: 0.00000060\n",
      "Epoch: [76] [   4/  20] time: 797.2216, loss: 0.00001485\n",
      "Epoch: [76] [   5/  20] time: 797.6733, loss: 0.00002900\n",
      "Epoch: [76] [   6/  20] time: 798.1320, loss: 0.00000006\n",
      "Epoch: [76] [   7/  20] time: 798.5980, loss: 0.00001074\n",
      "Epoch: [76] [   8/  20] time: 799.0551, loss: 0.00000962\n",
      "Epoch: [76] [   9/  20] time: 799.5122, loss: 0.00000027\n",
      "Epoch: [76] [  10/  20] time: 799.9621, loss: 0.00003630\n",
      "Epoch: [76] [  11/  20] time: 800.4215, loss: 0.00000035\n",
      "Epoch: [76] [  12/  20] time: 800.8727, loss: 0.00001106\n",
      "Epoch: [76] [  13/  20] time: 801.3266, loss: 0.00000058\n",
      "Epoch: [76] [  14/  20] time: 801.7775, loss: 0.00000030\n",
      "Epoch: [76] [  15/  20] time: 802.2331, loss: 0.00000032\n",
      "Epoch: [76] [  16/  20] time: 802.6931, loss: 0.00000453\n",
      "Epoch: [76] [  17/  20] time: 803.1492, loss: 0.00000420\n",
      "Epoch: [76] [  18/  20] time: 803.6095, loss: 0.00000211\n",
      "Epoch: [76] [  19/  20] time: 804.0622, loss: 0.00000102\n",
      "[76/80] - ptime: 9.9813 loss: 0.00000664 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [77] [   0/  20] time: 805.9270, loss: 0.00000660\n",
      "Epoch: [77] [   1/  20] time: 806.3774, loss: 0.00009705\n",
      "Epoch: [77] [   2/  20] time: 806.8338, loss: 0.00000211\n",
      "Epoch: [77] [   3/  20] time: 807.2854, loss: 0.00004794\n",
      "Epoch: [77] [   4/  20] time: 807.7440, loss: 0.00000101\n",
      "Epoch: [77] [   5/  20] time: 808.1981, loss: 0.00000337\n",
      "Epoch: [77] [   6/  20] time: 808.6704, loss: 0.00000295\n",
      "Epoch: [77] [   7/  20] time: 809.1239, loss: 0.00000017\n",
      "Epoch: [77] [   8/  20] time: 809.5777, loss: 0.00000071\n",
      "Epoch: [77] [   9/  20] time: 810.0279, loss: 0.00000272\n",
      "Epoch: [77] [  10/  20] time: 810.4824, loss: 0.00000252\n",
      "Epoch: [77] [  11/  20] time: 810.9320, loss: 0.00000087\n",
      "Epoch: [77] [  12/  20] time: 811.3843, loss: 0.00000996\n",
      "Epoch: [77] [  13/  20] time: 811.8511, loss: 0.00000244\n",
      "Epoch: [77] [  14/  20] time: 812.3023, loss: 0.00000172\n",
      "Epoch: [77] [  15/  20] time: 812.7621, loss: 0.00000010\n",
      "Epoch: [77] [  16/  20] time: 813.2140, loss: 0.00000587\n",
      "Epoch: [77] [  17/  20] time: 813.6695, loss: 0.00000069\n",
      "Epoch: [77] [  18/  20] time: 814.1231, loss: 0.00000111\n",
      "Epoch: [77] [  19/  20] time: 814.5839, loss: 0.00000008\n",
      "[77/80] - ptime: 10.0105 loss: 0.00000950 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [78] [   0/  20] time: 816.4177, loss: 0.00000021\n",
      "Epoch: [78] [   1/  20] time: 816.8768, loss: 0.00000042\n",
      "Epoch: [78] [   2/  20] time: 817.3287, loss: 0.00000062\n",
      "Epoch: [78] [   3/  20] time: 817.7868, loss: 0.00000168\n",
      "Epoch: [78] [   4/  20] time: 818.2412, loss: 0.00000214\n",
      "Epoch: [78] [   5/  20] time: 818.7046, loss: 0.00000738\n",
      "Epoch: [78] [   6/  20] time: 819.1576, loss: 0.00000165\n",
      "Epoch: [78] [   7/  20] time: 819.6065, loss: 0.00000026\n",
      "Epoch: [78] [   8/  20] time: 820.0608, loss: 0.00000137\n",
      "Epoch: [78] [   9/  20] time: 820.5198, loss: 0.00000283\n",
      "Epoch: [78] [  10/  20] time: 820.9874, loss: 0.00000318\n",
      "Epoch: [78] [  11/  20] time: 821.4398, loss: 0.00000006\n",
      "Epoch: [78] [  12/  20] time: 821.9012, loss: 0.00000588\n",
      "Epoch: [78] [  13/  20] time: 822.3569, loss: 0.00000012\n",
      "Epoch: [78] [  14/  20] time: 822.8172, loss: 0.00000091\n",
      "Epoch: [78] [  15/  20] time: 823.2736, loss: 0.00000015\n",
      "Epoch: [78] [  16/  20] time: 823.7319, loss: 0.00000075\n",
      "Epoch: [78] [  17/  20] time: 824.1816, loss: 0.00000059\n",
      "Epoch: [78] [  18/  20] time: 824.6330, loss: 0.00000167\n",
      "Epoch: [78] [  19/  20] time: 825.0892, loss: 0.00000039\n",
      "[78/80] - ptime: 9.9485 loss: 0.00000161 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [79] [   0/  20] time: 826.9578, loss: 0.00000015\n",
      "Epoch: [79] [   1/  20] time: 827.4121, loss: 0.00000281\n",
      "Epoch: [79] [   2/  20] time: 827.8686, loss: 0.00001757\n",
      "Epoch: [79] [   3/  20] time: 828.3193, loss: 0.00000315\n",
      "Epoch: [79] [   4/  20] time: 828.7711, loss: 0.00000223\n",
      "Epoch: [79] [   5/  20] time: 829.2266, loss: 0.00006516\n",
      "Epoch: [79] [   6/  20] time: 829.6769, loss: 0.00002219\n",
      "Epoch: [79] [   7/  20] time: 830.1473, loss: 0.00000005\n",
      "Epoch: [79] [   8/  20] time: 830.6014, loss: 0.00000016\n",
      "Epoch: [79] [   9/  20] time: 831.0673, loss: 0.00000008\n",
      "Epoch: [79] [  10/  20] time: 831.5223, loss: 0.00000121\n",
      "Epoch: [79] [  11/  20] time: 831.9843, loss: 0.00000587\n",
      "Epoch: [79] [  12/  20] time: 832.4353, loss: 0.00000052\n",
      "Epoch: [79] [  13/  20] time: 832.8902, loss: 0.00000141\n",
      "Epoch: [79] [  14/  20] time: 833.3488, loss: 0.00000094\n",
      "Epoch: [79] [  15/  20] time: 833.7983, loss: 0.00000337\n",
      "Epoch: [79] [  16/  20] time: 834.2631, loss: 0.00000023\n",
      "Epoch: [79] [  17/  20] time: 834.7181, loss: 0.00000056\n",
      "Epoch: [79] [  18/  20] time: 835.1830, loss: 0.00000321\n",
      "Epoch: [79] [  19/  20] time: 835.6298, loss: 0.00000430\n",
      "[79/80] - ptime: 9.9721 loss: 0.00000676 acc: 0.61000 lr: 0.00047830\n",
      "Epoch: [80] [   0/  20] time: 837.5474, loss: 0.00000031\n",
      "Epoch: [80] [   1/  20] time: 838.0025, loss: 0.00000021\n",
      "Epoch: [80] [   2/  20] time: 838.4525, loss: 0.00000313\n",
      "Epoch: [80] [   3/  20] time: 838.9099, loss: 0.00000443\n",
      "Epoch: [80] [   4/  20] time: 839.3744, loss: 0.00001968\n",
      "Epoch: [80] [   5/  20] time: 839.8242, loss: 0.00000530\n",
      "Epoch: [80] [   6/  20] time: 840.2797, loss: 0.00000205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [80] [   7/  20] time: 840.7290, loss: 0.00000088\n",
      "Epoch: [80] [   8/  20] time: 841.1931, loss: 0.00000080\n",
      "Epoch: [80] [   9/  20] time: 841.6454, loss: 0.00000040\n",
      "Epoch: [80] [  10/  20] time: 842.0989, loss: 0.00006491\n",
      "Epoch: [80] [  11/  20] time: 842.5536, loss: 0.00000319\n",
      "Epoch: [80] [  12/  20] time: 843.0058, loss: 0.00000108\n",
      "Epoch: [80] [  13/  20] time: 843.4735, loss: 0.00000293\n",
      "Epoch: [80] [  14/  20] time: 843.9222, loss: 0.00052794\n",
      "Epoch: [80] [  15/  20] time: 844.3834, loss: 0.00000034\n",
      "Epoch: [80] [  16/  20] time: 844.8333, loss: 0.00000040\n",
      "Epoch: [80] [  17/  20] time: 845.2968, loss: 0.00001051\n",
      "Epoch: [80] [  18/  20] time: 845.7475, loss: 0.00000159\n",
      "Epoch: [80] [  19/  20] time: 846.2060, loss: 0.00002755\n",
      "[80/80] - ptime: 10.0123 loss: 0.00003388 acc: 0.61000 lr: 0.00043047\n",
      "Avg per epoch ptime: 10.01, total 80 epochs ptime: 846.76\n",
      " [*] Training finished!\n",
      " [*] Best Epoch:  20 , Accuracy:  0.7599999308586121\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay-20\n",
      " [*] Finished testing Best Epoch: 20 , accuracy:  0.7599999308586121 !\n"
     ]
    }
   ],
   "source": [
    "dataset = '4_Flowers_1s'\n",
    "epoch = 80\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "log_dir = 'logs'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --log_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    CNN = CNN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                log_dir=log_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    CNN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    CNN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    CNN.train()\n",
    "    \n",
    "#     CNN.test(epoch)\n",
    "        \n",
    "sess.close()\n",
    "        \n",
    "# lrdecay\n",
    "# Avg per epoch ptime: 10.01, total 80 epochs ptime: 846.76\n",
    "#  [*] Training finished!\n",
    "#  [*] Best Epoch:  20 , Accuracy:  0.7599999308586121\n",
    "# INFO:tensorflow:Restoring parameters from checkpoint/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay/CNN_Canny&Pyramid_L_C5_D1_Kernel(3,3)_128_lrdecay-20\n",
    "#  [*] Finished testing Best Epoch: 20 , accuracy:  0.7599999308586121 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "file='/home/huiqy/Music/CloudMusic/All_Time_Low.mp3' #文件名是完整路径名\n",
    "pygame.mixer.init() #初始化音频\n",
    "track = pygame.mixer.music.load(file)#载入音乐文件\n",
    "pygame.mixer.music.play()#开始播放\n",
    "time.sleep(60)#播放10秒\n",
    "pygame.mixer.music.stop()#停止播放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
