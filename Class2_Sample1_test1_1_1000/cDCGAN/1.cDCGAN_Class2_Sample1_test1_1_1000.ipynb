{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "def load_flower_data():\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] handling images...\")\n",
    "    TRAIN_ORIGINAL_DIR = '../train/'\n",
    "    TRAIN_SUB_DIR = '../subsample/'\n",
    "    TEST_DIR = '../test/'\n",
    "\n",
    "    # use this for full dataset\n",
    "    train_images_original = [TRAIN_ORIGINAL_DIR + i for i in os.listdir(TRAIN_ORIGINAL_DIR)]\n",
    "    train_images_sub = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "\n",
    "    train_images = train_images_original + train_images_sub\n",
    "\n",
    "    #print (train_images)\n",
    "    train_images.sort(key=natural_keys)\n",
    "    print (len(train_images))\n",
    "\n",
    "    # initialize the features matrix and labels list\n",
    "    trainImage = []\n",
    "    trainLabels = []\n",
    "\n",
    "    # loop over the input images\n",
    "    for (i, imagePath) in enumerate(train_images):\n",
    "        # extract the class label\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # read and resize image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        trainImage.append(img)\n",
    "        trainLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "#         if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "#             print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "\n",
    "    trainImage = np.array(trainImage,dtype = float32)\n",
    "    trainLabels = np.array(trainLabels)\n",
    "    print (trainImage.shape)\n",
    "    trainImage = trainImage.astype(np.float32) / 255\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainLabels)\n",
    "    list(le.classes_)\n",
    "    trainLabels = le.transform(trainLabels) \n",
    "    \n",
    "    return trainImage, trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "2002\n",
      "(2002, 128, 128, 3)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "[INFO] trainImage matrix: 384.38MB\n",
      "[INFO] trainLabels matrix: 0.0313MB\n"
     ]
    }
   ],
   "source": [
    "trainImage,trainLabels = load_flower_data()\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "print (trainLabels)\n",
    "np.save('./trainImage.npy', trainImage)\n",
    "np.save('./trainLabels.npy', trainLabels)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu( X, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * X + f2 * tf.abs(X)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, result_dir, log_dir, \n",
    "                 test_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = \"cDCGAN\"     # name for checkpoint\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.output_height = 128\n",
    "        self.output_width = 128\n",
    "\n",
    "        self.z_dim = 100         # dimension of noise-vector\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay( 0.0002,\n",
    "                                             global_step=self.global_step,\n",
    "                                             decay_steps=20,\n",
    "                                             decay_rate=0.9,\n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # test\n",
    "        #visual results\n",
    "        self.onehot = np.eye(self.nb_class)\n",
    "        self.sample_num = 100  # number of generated images to be saved\n",
    "        self.visual_team = self.batch_size // self.nb_class  # number of generated images to be saved\n",
    "\n",
    "        #load_flower_data\n",
    "        self.data_x = np.load('./trainImage.npy')\n",
    "        self.data_y= np.load('./trainLabels.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches = len(self.data_x) // self.batch_size\n",
    "\n",
    "    def discriminator(self, x, y_fill, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"D:x\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            print(\"D:y_fill\",y_fill.get_shape())\n",
    "            # concat layer\n",
    "            \n",
    "            #卷积核为4*4 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(x, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            \n",
    "            print(\"D:\",net1_1.get_shape())\n",
    "            \n",
    "            net1_2 = tf.layers.conv2d(y_fill, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                         kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"D:\",net1_2.get_shape())\n",
    "    \n",
    "            #把数据和标签进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为128        \n",
    "            net = tf.layers.conv2d(net, 64, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "    \n",
    "            #卷积核为4*4 输出维度为128 \n",
    "            net = tf.layers.conv2d(net, 128, [4, 4], strides=(2, 2), padding='same', \n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为256\n",
    "            net = tf.layers.conv2d(net, 256, [4, 4], strides=(2, 2), padding='same', \n",
    "                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为512\n",
    "            net = tf.layers.conv2d(net, 512, [4, 4], strides=(2, 2), padding='same', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #output\n",
    "            out_logit = tf.layers.conv2d(net, 1, [4, 4], strides=(1, 1), padding='valid', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            print(\"D:out_logit\",out_logit.get_shape())\n",
    "            \n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:out\",out.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out, out_logit, net\n",
    "\n",
    "    def generator(self, z, y_label, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "            \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "            \n",
    "            print(\"G:z\",z.get_shape())\n",
    "            print(\"G:y_label\",y_label.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_1 = tf.layers.conv2d_transpose(z, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            print(\"G:\",net1_1.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_2 = tf.layers.conv2d_transpose(y_label, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"G:\",net1_2.get_shape())\n",
    "            \n",
    "            #把数据和标签进行连接\n",
    "            # concat layer\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度512\n",
    "            net = tf.layers.conv2d_transpose(net, 512, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度128\n",
    "            net = tf.layers.conv2d_transpose(net, 128, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度64\n",
    "            net = tf.layers.conv2d_transpose(net, 64, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度32\n",
    "            net = tf.layers.conv2d_transpose(net, 32, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度3\n",
    "            net = tf.layers.conv2d_transpose(net, 3, [4, 4], strides=(2, 2), padding='same',\n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            out = tf.nn.tanh(net)\n",
    "            print(\"G:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "            return out\n",
    "\n",
    "    def build_model(self):\n",
    "        #parameters\n",
    "        image_dims = [self.input_height, self.input_width, self.c_dim]\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=(self.batch_size,self.input_height, self.input_width, self.c_dim), \n",
    "                                name='real_images')\n",
    "\n",
    "        # noises\n",
    "        self.z = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.z_dim), name='z')\n",
    "        \n",
    "        self.y_label = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.nb_class), name='y_label')\n",
    "        self.y_fill = tf.placeholder(tf.float32, shape=(self.batch_size, self.output_width, \n",
    "                                                        self.output_height, self.nb_class), name='y_fill')\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of D for real images\n",
    "        D_real, D_real_logits, _ = self.discriminator(self.x, self.y_fill, is_training=True, reuse=False)\n",
    "            \n",
    "        #networks : generator\n",
    "        G = self.generator(self.z, self.y_label, is_training=True, reuse=False)\n",
    "\n",
    "        # output of D for fake images\n",
    "        D_fake, D_fake_logits, _ = self.discriminator(G, self.y_fill, is_training=True, reuse=True)\n",
    "\n",
    "        # get loss for discriminator\n",
    "        self.d_loss_real = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n",
    "        self.d_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n",
    "\n",
    "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
    "        \n",
    "        # get loss for generator\n",
    "        self.g_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # divide trainable variables into a group for D and a group for G\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        d_vars = [var for var in tf_vars if var.name.startswith('discriminator')]\n",
    "        g_vars = [var for var in tf_vars if var.name.startswith('generator')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)\n",
    "        \n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        self.fake_images = self.generator(self.z, self.y_label, is_training=False, reuse=True)\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", self.d_loss_real)\n",
    "        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", self.d_loss_fake)\n",
    "        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n",
    "\n",
    "        # final summary operations\n",
    "        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n",
    "        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # graph inputs for visualize training results\n",
    "        self.sample_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "\n",
    "        self.test_images = self.data_x[0:self.batch_size]\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep= self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            G_losses = []\n",
    "            D_losses = []\n",
    "    \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.data_x.shape[0]), self.data_x.shape[0])\n",
    "            shuffled_set = self.data_x[shuffle_idxs]\n",
    "            shuffled_label = self.data_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y_label = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill = batch_y_label * np.ones([self.batch_size, self.output_height, self.output_width, self.nb_class])\n",
    "                batch_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.z: batch_z,\n",
    "                                                          self.y_fill: batch_y_fill,\n",
    "                                                          self.y_label: batch_y_label}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                # update G network\n",
    "                batch_y = np.random.randint(0, self.nb_class, (self.batch_size, 1)) # <=  <\n",
    "                batch_y_label = self.onehot[batch_y.astype(np.int32)].reshape([self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill  = batch_y_label * np.ones([self.batch_size, self.input_height, self.input_width, self.nb_class])\n",
    "\n",
    "                # update G once\n",
    "                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss],\n",
    "                                                          feed_dict={self.x: batch_x,\n",
    "                                                                     self.z: batch_z, \n",
    "                                                                     self.y_fill: batch_y_fill,\n",
    "                                                                     self.y_label: batch_y_label})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                \n",
    "                D_losses.append(d_loss)\n",
    "                G_losses.append(g_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" % (epoch_loop, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss_d: %.8f, loss_g: %.8f, lf:  %.8f' % (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                        np.mean(D_losses), np.mean(G_losses), rate))\n",
    "            self.train_hist['D_losses'].append(np.mean(D_losses))\n",
    "            self.train_hist['G_losses'].append(np.mean(G_losses))\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "\n",
    "            # show temporal results\n",
    "            self.visualize_epoch_results(epoch_loop)\n",
    "            \n",
    "            # save trainhist for the initial train\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            \n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' + 'train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "    def visualize_img_to_gif(self, path, size, fps = 5):\n",
    "        print(\" [*] Generation Animation GIF start!\")\n",
    "        path_images = [path + '/'+ i for i in os.listdir(path)]\n",
    "        path_images.sort(key=natural_keys)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images start!\")\n",
    "        images = []\n",
    "        for p in tqdm(path_images):\n",
    "            img = imageio.imread(p)\n",
    "            img = cv2.resize(img, size)\n",
    "            images.append(img)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images finished!\")\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF start! FPS=\", fps)\n",
    "        path_gif = path + '/' + self.model_name + '_epoch%03d' % self.epoch + '_' + self.dataset_name + 'generation_animation.gif'\n",
    "        imageio.mimsave(path_gif, images, fps = fps)\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF finished! FPS=\", fps)\n",
    "\n",
    "    def visualize_test_image(self, epoch, num, times):\n",
    "        tot_num_samples = num #  100\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_dir + '/' + self.model_name + '/'+ self.model_name +'.model-'+ str(epoch)\n",
    "        \n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "            \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "        for j in range(times):\n",
    "            noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "            fixed_noise = noise \n",
    "            fixed_label = np.zeros((self.visual_team , 1))\n",
    "            #用于显示25组图像\n",
    "            for i in range(self.nb_class - 1):\n",
    "                fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "                temp_label = np.ones((self.visual_team, 1)) + i\n",
    "                fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "            fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "            samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "            self.save_cv2_img(samples[:tot_num_samples, :, :, :], tot_num_samples, epoch , j) \n",
    "        print(\" [*] Finished generating Epoch:\", epoch, \",\",times*num,\"new images!\")\n",
    "        \n",
    "                                    \n",
    "    def save_cv2_img(self, images, num, epoch, times):\n",
    "    # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(num):\n",
    "            classname = self.classname[idx // self.visual_team]\n",
    "            img_save = images[idx:idx+1, :, :, :][0, ...]*255\n",
    "            path = self.test_dir + '/' + classname + '_epoch%03d' % epoch + '_t%02d' % times+ '_%03d' % idx + '.png'\n",
    "            cv2.imwrite( path, img_save)\n",
    "              \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "        \n",
    "    def save_matplot_img(self, images, size, image_path):\n",
    "        # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(100):\n",
    "            vMin = np.amin(images[idx])\n",
    "            vMax = np.amax(images[idx])\n",
    "            img_arr = images[idx].reshape(128*128*3,1) # flatten\n",
    "            for i, v in enumerate(img_arr):\n",
    "                img_arr[i] = (v-vMin)/(vMax-vMin)\n",
    "            img_arr = img_arr.reshape(128,128,3) # M*N*3\n",
    "\n",
    "            # matplot display\n",
    "            plt.subplot(10,10,idx+1),plt.imshow(cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB), interpolation='nearest')\n",
    "            #plt.title(\"pred.:{}\".format(np.argmax(self.data_y[0]),fontsize=10))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.savefig(image_path, dpi = 400)\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}_{}\".format(\n",
    "            self.dataset_name, self.batch_size,\n",
    "            self.output_height, self.output_width)\n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['D_losses'])+1)\n",
    "\n",
    "        y1 = hist['D_losses']\n",
    "        y2 = hist['G_losses']\n",
    "\n",
    "        plt.plot(x, y1, label='D_loss')\n",
    "        plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.legend(loc=4)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "    def visualize_epoch_results(self, epoch):\n",
    "        tot_num_samples = min(self.sample_num, self.batch_size) # 100\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples))) # 10\n",
    "        \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "            \n",
    "        noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "        fixed_noise = noise \n",
    "        fixed_label = np.zeros((self.visual_team , 1))\n",
    "        \n",
    "        #用于显示25组图像\n",
    "        for i in range(self.nb_class - 1):\n",
    "            fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "            temp_label = np.ones((self.visual_team, 1)) + i\n",
    "            fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "        fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "    \n",
    "        samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "\n",
    "        self.save_matplot_img(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                    self.result_dir + '/' + self.model_name + '_epoch%03d' % epoch + '_' + self.dataset_name +'.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 2)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 2)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 2)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 2)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "discriminator/conv2d/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "discriminator/conv2d/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_1/kernel:0 (float32_ref 4x4x2x32) [1024, bytes: 4096]\n",
      "discriminator/conv2d_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_2/kernel:0 (float32_ref 4x4x64x64) [65536, bytes: 262144]\n",
      "discriminator/conv2d_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/conv2d_3/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "discriminator/conv2d_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/conv2d_4/kernel:0 (float32_ref 4x4x128x256) [524288, bytes: 2097152]\n",
      "discriminator/conv2d_4/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/conv2d_5/kernel:0 (float32_ref 4x4x256x512) [2097152, bytes: 8388608]\n",
      "discriminator/conv2d_5/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/conv2d_6/kernel:0 (float32_ref 4x4x512x1) [8192, bytes: 32768]\n",
      "discriminator/conv2d_6/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/conv2d_transpose/kernel:0 (float32_ref 4x4x256x100) [409600, bytes: 1638400]\n",
      "generator/conv2d_transpose/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_1/kernel:0 (float32_ref 4x4x256x2) [8192, bytes: 32768]\n",
      "generator/conv2d_transpose_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_2/kernel:0 (float32_ref 4x4x512x512) [4194304, bytes: 16777216]\n",
      "generator/conv2d_transpose_2/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/conv2d_transpose_3/kernel:0 (float32_ref 4x4x128x512) [1048576, bytes: 4194304]\n",
      "generator/conv2d_transpose_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/conv2d_transpose_4/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "generator/conv2d_transpose_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/conv2d_transpose_5/kernel:0 (float32_ref 4x4x32x64) [32768, bytes: 131072]\n",
      "generator/conv2d_transpose_5/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/conv2d_transpose_6/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "generator/conv2d_transpose_6/bias:0 (float32_ref 3) [3, bytes: 12]\n",
      "Total size of variables: 8660516\n",
      "Total bytes of variables: 34642064\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-190\n",
      " [*] Success to read [cDCGAN.model-190], epoch [190]\n",
      " [*] Load SUCCESS\n",
      " [!] START_EPOCH is  191\n",
      "Epoch: [191] [   0/  20] time: 1.7815, d_loss: 0.10762396, g_loss: 3.63959527\n",
      "Epoch: [191] [   1/  20] time: 2.2764, d_loss: 0.09976791, g_loss: 4.02277040\n",
      "Epoch: [191] [   2/  20] time: 2.7740, d_loss: 0.07299372, g_loss: 4.31051207\n",
      "Epoch: [191] [   3/  20] time: 3.2469, d_loss: 0.08774310, g_loss: 3.61209941\n",
      "Epoch: [191] [   4/  20] time: 3.7093, d_loss: 0.07981887, g_loss: 3.83873177\n",
      "Epoch: [191] [   5/  20] time: 4.1879, d_loss: 0.12368675, g_loss: 3.58317494\n",
      "Epoch: [191] [   6/  20] time: 4.6641, d_loss: 0.08454989, g_loss: 3.98015571\n",
      "Epoch: [191] [   7/  20] time: 5.1465, d_loss: 0.13763130, g_loss: 3.75763702\n",
      "Epoch: [191] [   8/  20] time: 5.6123, d_loss: 0.06707527, g_loss: 4.15228176\n",
      "Epoch: [191] [   9/  20] time: 6.0825, d_loss: 0.09254909, g_loss: 3.62016010\n",
      "Epoch: [191] [  10/  20] time: 6.5495, d_loss: 0.11543597, g_loss: 3.74632072\n",
      "Epoch: [191] [  11/  20] time: 7.0220, d_loss: 0.10172588, g_loss: 3.66188359\n",
      "Epoch: [191] [  12/  20] time: 7.5105, d_loss: 0.10409138, g_loss: 3.70444822\n",
      "Epoch: [191] [  13/  20] time: 8.0034, d_loss: 0.12266545, g_loss: 3.20026159\n",
      "Epoch: [191] [  14/  20] time: 8.4879, d_loss: 0.13857314, g_loss: 4.22610140\n",
      "Epoch: [191] [  15/  20] time: 8.9717, d_loss: 0.13556449, g_loss: 3.53561783\n",
      "Epoch: [191] [  16/  20] time: 9.4668, d_loss: 0.09167967, g_loss: 3.34482455\n",
      "Epoch: [191] [  17/  20] time: 9.9608, d_loss: 0.09744611, g_loss: 4.11533117\n",
      "Epoch: [191] [  18/  20] time: 10.4495, d_loss: 0.14435863, g_loss: 2.99940920\n",
      "Epoch: [191] [  19/  20] time: 10.9281, d_loss: 0.08286628, g_loss: 3.29253268\n",
      "[191/200] - ptime: 10.9497 loss_d: 0.10439233, loss_g: 3.71719289, lf:  0.00007748\n",
      "Epoch: [192] [   0/  20] time: 26.6215, d_loss: 0.15078786, g_loss: 5.18751907\n",
      "Epoch: [192] [   1/  20] time: 27.1098, d_loss: 0.11020757, g_loss: 4.16831923\n",
      "Epoch: [192] [   2/  20] time: 27.5807, d_loss: 0.06815802, g_loss: 3.83837557\n",
      "Epoch: [192] [   3/  20] time: 28.0845, d_loss: 0.11123189, g_loss: 3.55000710\n",
      "Epoch: [192] [   4/  20] time: 28.5537, d_loss: 0.15698558, g_loss: 4.61847639\n",
      "Epoch: [192] [   5/  20] time: 29.0141, d_loss: 0.14096862, g_loss: 3.27013588\n",
      "Epoch: [192] [   6/  20] time: 29.5061, d_loss: 0.07804070, g_loss: 3.51371384\n",
      "Epoch: [192] [   7/  20] time: 29.9981, d_loss: 0.08070071, g_loss: 3.86940122\n",
      "Epoch: [192] [   8/  20] time: 30.4704, d_loss: 0.11023407, g_loss: 3.79341006\n",
      "Epoch: [192] [   9/  20] time: 30.9462, d_loss: 0.10047870, g_loss: 4.81617737\n",
      "Epoch: [192] [  10/  20] time: 31.4346, d_loss: 0.17236063, g_loss: 2.75676799\n",
      "Epoch: [192] [  11/  20] time: 31.9016, d_loss: 0.11088715, g_loss: 3.54915452\n",
      "Epoch: [192] [  12/  20] time: 32.3697, d_loss: 0.13608097, g_loss: 5.09039116\n",
      "Epoch: [192] [  13/  20] time: 32.8322, d_loss: 0.19999550, g_loss: 2.86052990\n",
      "Epoch: [192] [  14/  20] time: 33.2999, d_loss: 0.21301301, g_loss: 4.48068047\n",
      "Epoch: [192] [  15/  20] time: 33.7678, d_loss: 0.17254557, g_loss: 3.41199350\n",
      "Epoch: [192] [  16/  20] time: 34.2359, d_loss: 0.08673026, g_loss: 3.57544518\n",
      "Epoch: [192] [  17/  20] time: 34.6974, d_loss: 0.14918390, g_loss: 3.41647482\n",
      "Epoch: [192] [  18/  20] time: 35.1638, d_loss: 0.11943759, g_loss: 4.30025673\n",
      "Epoch: [192] [  19/  20] time: 35.6304, d_loss: 0.08845327, g_loss: 3.97767162\n",
      "[192/200] - ptime: 9.6374 loss_d: 0.12782410, loss_g: 3.90224504, lf:  0.00007748\n",
      "Epoch: [193] [   0/  20] time: 51.7879, d_loss: 0.08416789, g_loss: 4.18288088\n",
      "Epoch: [193] [   1/  20] time: 52.2728, d_loss: 0.07492278, g_loss: 4.12395668\n",
      "Epoch: [193] [   2/  20] time: 52.7697, d_loss: 0.12871692, g_loss: 3.42787480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [193] [   3/  20] time: 53.2455, d_loss: 0.15125179, g_loss: 4.40341663\n",
      "Epoch: [193] [   4/  20] time: 53.7190, d_loss: 0.13831598, g_loss: 3.21561694\n",
      "Epoch: [193] [   5/  20] time: 54.2174, d_loss: 0.07806432, g_loss: 3.42737150\n",
      "Epoch: [193] [   6/  20] time: 54.6966, d_loss: 0.11525726, g_loss: 4.02499151\n",
      "Epoch: [193] [   7/  20] time: 55.1835, d_loss: 0.07602951, g_loss: 4.03896189\n",
      "Epoch: [193] [   8/  20] time: 55.6650, d_loss: 0.08597717, g_loss: 3.88558483\n",
      "Epoch: [193] [   9/  20] time: 56.1552, d_loss: 0.10427490, g_loss: 3.61598706\n",
      "Epoch: [193] [  10/  20] time: 56.6566, d_loss: 0.11826041, g_loss: 3.66373324\n",
      "Epoch: [193] [  11/  20] time: 57.1524, d_loss: 0.10792067, g_loss: 3.75782728\n",
      "Epoch: [193] [  12/  20] time: 57.6174, d_loss: 0.11621810, g_loss: 3.16845083\n",
      "Epoch: [193] [  13/  20] time: 58.1189, d_loss: 0.11068827, g_loss: 4.83276463\n",
      "Epoch: [193] [  14/  20] time: 58.6083, d_loss: 0.23637965, g_loss: 1.80512583\n",
      "Epoch: [193] [  15/  20] time: 59.0812, d_loss: 0.31709269, g_loss: 5.78744888\n",
      "Epoch: [193] [  16/  20] time: 59.5433, d_loss: 0.20948459, g_loss: 3.68268108\n",
      "Epoch: [193] [  17/  20] time: 60.0113, d_loss: 0.11289195, g_loss: 3.74724817\n",
      "Epoch: [193] [  18/  20] time: 60.4810, d_loss: 0.17822175, g_loss: 4.35720778\n",
      "Epoch: [193] [  19/  20] time: 60.9546, d_loss: 0.31431881, g_loss: 2.12057090\n",
      "[193/200] - ptime: 9.7852 loss_d: 0.14292276, loss_g: 3.76348448, lf:  0.00007748\n",
      "Epoch: [194] [   0/  20] time: 76.7459, d_loss: 0.57861549, g_loss: 7.12362194\n",
      "Epoch: [194] [   1/  20] time: 77.2383, d_loss: 1.42342877, g_loss: 1.41081905\n",
      "Epoch: [194] [   2/  20] time: 77.7383, d_loss: 1.14817834, g_loss: 9.11437988\n",
      "Epoch: [194] [   3/  20] time: 78.2306, d_loss: 4.06799078, g_loss: 0.41250256\n",
      "Epoch: [194] [   4/  20] time: 78.7192, d_loss: 3.38655829, g_loss: 7.81295252\n",
      "Epoch: [194] [   5/  20] time: 79.2070, d_loss: 2.76415348, g_loss: 0.43019411\n",
      "Epoch: [194] [   6/  20] time: 79.7140, d_loss: 3.67559862, g_loss: 6.80700874\n",
      "Epoch: [194] [   7/  20] time: 80.2024, d_loss: 1.88992465, g_loss: 1.90313554\n",
      "Epoch: [194] [   8/  20] time: 80.7306, d_loss: 1.25229907, g_loss: 4.70558119\n",
      "Epoch: [194] [   9/  20] time: 81.2436, d_loss: 1.80305374, g_loss: 0.60964191\n",
      "Epoch: [194] [  10/  20] time: 81.7461, d_loss: 2.48638415, g_loss: 7.68373394\n",
      "Epoch: [194] [  11/  20] time: 82.2275, d_loss: 2.07638931, g_loss: 1.79930580\n",
      "Epoch: [194] [  12/  20] time: 82.6962, d_loss: 0.87111270, g_loss: 2.77968979\n",
      "Epoch: [194] [  13/  20] time: 83.1800, d_loss: 0.81664413, g_loss: 4.13049650\n",
      "Epoch: [194] [  14/  20] time: 83.6800, d_loss: 0.57311726, g_loss: 2.28447008\n",
      "Epoch: [194] [  15/  20] time: 84.1784, d_loss: 0.70983702, g_loss: 3.92898846\n",
      "Epoch: [194] [  16/  20] time: 84.6697, d_loss: 0.58437902, g_loss: 2.32470679\n",
      "Epoch: [194] [  17/  20] time: 85.1467, d_loss: 0.65042430, g_loss: 3.87716198\n",
      "Epoch: [194] [  18/  20] time: 85.6384, d_loss: 0.41107982, g_loss: 4.08013201\n",
      "Epoch: [194] [  19/  20] time: 86.1430, d_loss: 0.46521598, g_loss: 2.76712584\n",
      "[194/200] - ptime: 10.0346 loss_d: 1.58171916, loss_g: 3.79928255, lf:  0.00007748\n",
      "Epoch: [195] [   0/  20] time: 102.0507, d_loss: 0.24927759, g_loss: 3.15923429\n",
      "Epoch: [195] [   1/  20] time: 102.5527, d_loss: 0.27077508, g_loss: 3.66342926\n",
      "Epoch: [195] [   2/  20] time: 103.0352, d_loss: 0.30821756, g_loss: 3.06559300\n",
      "Epoch: [195] [   3/  20] time: 103.5112, d_loss: 0.35077983, g_loss: 3.35710335\n",
      "Epoch: [195] [   4/  20] time: 104.0120, d_loss: 0.40618238, g_loss: 2.43615746\n",
      "Epoch: [195] [   5/  20] time: 104.5138, d_loss: 0.29055259, g_loss: 3.67584562\n",
      "Epoch: [195] [   6/  20] time: 105.0041, d_loss: 0.19847181, g_loss: 4.21932983\n",
      "Epoch: [195] [   7/  20] time: 105.4732, d_loss: 0.25250143, g_loss: 2.83187985\n",
      "Epoch: [195] [   8/  20] time: 105.9536, d_loss: 0.27290183, g_loss: 2.74044919\n",
      "Epoch: [195] [   9/  20] time: 106.4229, d_loss: 0.23099497, g_loss: 3.30699849\n",
      "Epoch: [195] [  10/  20] time: 106.8919, d_loss: 0.17414211, g_loss: 3.44062328\n",
      "Epoch: [195] [  11/  20] time: 107.3604, d_loss: 0.15906456, g_loss: 3.76747060\n",
      "Epoch: [195] [  12/  20] time: 107.8487, d_loss: 0.15092729, g_loss: 3.30520105\n",
      "Epoch: [195] [  13/  20] time: 108.3161, d_loss: 0.19569841, g_loss: 2.85943055\n",
      "Epoch: [195] [  14/  20] time: 108.7954, d_loss: 0.16805717, g_loss: 3.28390694\n",
      "Epoch: [195] [  15/  20] time: 109.2646, d_loss: 0.18127875, g_loss: 3.43130612\n",
      "Epoch: [195] [  16/  20] time: 109.7467, d_loss: 0.16788146, g_loss: 2.96333194\n",
      "Epoch: [195] [  17/  20] time: 110.2219, d_loss: 0.20694923, g_loss: 3.94143438\n",
      "Epoch: [195] [  18/  20] time: 110.6925, d_loss: 0.23388444, g_loss: 2.92463565\n",
      "Epoch: [195] [  19/  20] time: 111.1655, d_loss: 0.21247618, g_loss: 2.80784607\n",
      "[195/200] - ptime: 9.7683 loss_d: 0.23405072, loss_g: 3.25906038, lf:  0.00007748\n",
      "Epoch: [196] [   0/  20] time: 127.3461, d_loss: 0.23069291, g_loss: 4.53546762\n",
      "Epoch: [196] [   1/  20] time: 127.8164, d_loss: 0.34304202, g_loss: 2.74716759\n",
      "Epoch: [196] [   2/  20] time: 128.2916, d_loss: 0.23923841, g_loss: 3.09153056\n",
      "Epoch: [196] [   3/  20] time: 128.7551, d_loss: 0.15011415, g_loss: 3.54051828\n",
      "Epoch: [196] [   4/  20] time: 129.2242, d_loss: 0.15922037, g_loss: 3.89042521\n",
      "Epoch: [196] [   5/  20] time: 129.7029, d_loss: 0.19009796, g_loss: 3.40773535\n",
      "Epoch: [196] [   6/  20] time: 130.1811, d_loss: 0.13631602, g_loss: 3.13361192\n",
      "Epoch: [196] [   7/  20] time: 130.6755, d_loss: 0.15988460, g_loss: 3.07397389\n",
      "Epoch: [196] [   8/  20] time: 131.1497, d_loss: 0.15784772, g_loss: 3.16359591\n",
      "Epoch: [196] [   9/  20] time: 131.6195, d_loss: 0.15510190, g_loss: 3.22448373\n",
      "Epoch: [196] [  10/  20] time: 132.1111, d_loss: 0.12601194, g_loss: 3.37609720\n",
      "Epoch: [196] [  11/  20] time: 132.5969, d_loss: 0.18202773, g_loss: 4.11541080\n",
      "Epoch: [196] [  12/  20] time: 133.0928, d_loss: 0.20245177, g_loss: 3.01593709\n",
      "Epoch: [196] [  13/  20] time: 133.5934, d_loss: 0.11184333, g_loss: 3.23134780\n",
      "Epoch: [196] [  14/  20] time: 134.0940, d_loss: 0.14156121, g_loss: 3.21724415\n",
      "Epoch: [196] [  15/  20] time: 134.6028, d_loss: 0.12938793, g_loss: 3.56794786\n",
      "Epoch: [196] [  16/  20] time: 135.0969, d_loss: 0.16061735, g_loss: 3.53624797\n",
      "Epoch: [196] [  17/  20] time: 135.5793, d_loss: 0.14725807, g_loss: 3.33367014\n",
      "Epoch: [196] [  18/  20] time: 136.0719, d_loss: 0.11054509, g_loss: 3.16511035\n",
      "Epoch: [196] [  19/  20] time: 136.5502, d_loss: 0.11702955, g_loss: 3.52920127\n",
      "[196/200] - ptime: 9.8165 loss_d: 0.16751449, loss_g: 3.39483595, lf:  0.00007748\n",
      "Epoch: [197] [   0/  20] time: 152.8948, d_loss: 0.10322325, g_loss: 3.83009768\n",
      "Epoch: [197] [   1/  20] time: 153.3970, d_loss: 0.18260475, g_loss: 3.42226577\n",
      "Epoch: [197] [   2/  20] time: 153.8995, d_loss: 0.14609349, g_loss: 3.48642516\n",
      "Epoch: [197] [   3/  20] time: 154.3716, d_loss: 0.13094741, g_loss: 3.28387713\n",
      "Epoch: [197] [   4/  20] time: 154.8622, d_loss: 0.13444711, g_loss: 3.75916386\n",
      "Epoch: [197] [   5/  20] time: 155.3332, d_loss: 0.15750919, g_loss: 2.94783688\n",
      "Epoch: [197] [   6/  20] time: 155.8356, d_loss: 0.12421444, g_loss: 3.36384225\n",
      "Epoch: [197] [   7/  20] time: 156.3199, d_loss: 0.09903353, g_loss: 3.83882189\n",
      "Epoch: [197] [   8/  20] time: 156.8426, d_loss: 0.15351734, g_loss: 3.30067968\n",
      "Epoch: [197] [   9/  20] time: 157.3290, d_loss: 0.14927141, g_loss: 3.48838735\n",
      "Epoch: [197] [  10/  20] time: 157.8214, d_loss: 0.10577344, g_loss: 3.33896160\n",
      "Epoch: [197] [  11/  20] time: 158.3017, d_loss: 0.12951666, g_loss: 3.33250618\n",
      "Epoch: [197] [  12/  20] time: 158.7876, d_loss: 0.12120570, g_loss: 3.63611746\n",
      "Epoch: [197] [  13/  20] time: 159.2640, d_loss: 0.13670114, g_loss: 3.43685722\n",
      "Epoch: [197] [  14/  20] time: 159.7424, d_loss: 0.12307258, g_loss: 3.30779290\n",
      "Epoch: [197] [  15/  20] time: 160.2490, d_loss: 0.08128126, g_loss: 3.72697496\n",
      "Epoch: [197] [  16/  20] time: 160.7243, d_loss: 0.11273159, g_loss: 3.76769066\n",
      "Epoch: [197] [  17/  20] time: 161.2009, d_loss: 0.12207095, g_loss: 3.57610250\n",
      "Epoch: [197] [  18/  20] time: 161.6716, d_loss: 0.13682485, g_loss: 3.30545378\n",
      "Epoch: [197] [  19/  20] time: 162.1422, d_loss: 0.11246071, g_loss: 3.59085250\n",
      "[197/200] - ptime: 9.8829 loss_d: 0.12812504, loss_g: 3.48703527, lf:  0.00007748\n",
      "Epoch: [198] [   0/  20] time: 178.0433, d_loss: 0.10837530, g_loss: 3.91708899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [198] [   1/  20] time: 178.5441, d_loss: 0.13633618, g_loss: 3.43660259\n",
      "Epoch: [198] [   2/  20] time: 179.0719, d_loss: 0.10035962, g_loss: 3.19329309\n",
      "Epoch: [198] [   3/  20] time: 179.5885, d_loss: 0.10620913, g_loss: 3.69285059\n",
      "Epoch: [198] [   4/  20] time: 180.0922, d_loss: 0.09932896, g_loss: 3.73386598\n",
      "Epoch: [198] [   5/  20] time: 180.5906, d_loss: 0.14573434, g_loss: 3.22782421\n",
      "Epoch: [198] [   6/  20] time: 181.0737, d_loss: 0.19139746, g_loss: 3.53449225\n",
      "Epoch: [198] [   7/  20] time: 181.5626, d_loss: 0.08474525, g_loss: 4.28076172\n",
      "Epoch: [198] [   8/  20] time: 182.0415, d_loss: 0.10746295, g_loss: 3.74169850\n",
      "Epoch: [198] [   9/  20] time: 182.5191, d_loss: 0.10269394, g_loss: 3.16688800\n",
      "Epoch: [198] [  10/  20] time: 183.0323, d_loss: 0.11954165, g_loss: 3.37635803\n",
      "Epoch: [198] [  11/  20] time: 183.5232, d_loss: 0.09452444, g_loss: 4.20082808\n",
      "Epoch: [198] [  12/  20] time: 184.0172, d_loss: 0.11220875, g_loss: 3.12910461\n",
      "Epoch: [198] [  13/  20] time: 184.5111, d_loss: 0.11046225, g_loss: 3.22750711\n",
      "Epoch: [198] [  14/  20] time: 184.9970, d_loss: 0.13348663, g_loss: 3.84498072\n",
      "Epoch: [198] [  15/  20] time: 185.4930, d_loss: 0.08404341, g_loss: 3.77329564\n",
      "Epoch: [198] [  16/  20] time: 185.9744, d_loss: 0.17990869, g_loss: 3.76261473\n",
      "Epoch: [198] [  17/  20] time: 186.4490, d_loss: 0.11250297, g_loss: 3.28972340\n",
      "Epoch: [198] [  18/  20] time: 186.9341, d_loss: 0.14871575, g_loss: 3.29448962\n",
      "Epoch: [198] [  19/  20] time: 187.4165, d_loss: 0.12018512, g_loss: 3.77990150\n",
      "[198/200] - ptime: 10.0287 loss_d: 0.11991115, loss_g: 3.58020830, lf:  0.00007748\n",
      "Epoch: [199] [   0/  20] time: 203.6795, d_loss: 0.08907168, g_loss: 3.69154692\n",
      "Epoch: [199] [   1/  20] time: 204.1706, d_loss: 0.10115440, g_loss: 3.81836987\n",
      "Epoch: [199] [   2/  20] time: 204.6660, d_loss: 0.12911592, g_loss: 3.41352153\n",
      "Epoch: [199] [   3/  20] time: 205.1698, d_loss: 0.14788158, g_loss: 3.60392380\n",
      "Epoch: [199] [   4/  20] time: 205.6646, d_loss: 0.09610382, g_loss: 3.96770930\n",
      "Epoch: [199] [   5/  20] time: 206.1591, d_loss: 0.12224165, g_loss: 3.09929943\n",
      "Epoch: [199] [   6/  20] time: 206.6515, d_loss: 0.10608004, g_loss: 3.56180406\n",
      "Epoch: [199] [   7/  20] time: 207.1258, d_loss: 0.10637241, g_loss: 4.23601294\n",
      "Epoch: [199] [   8/  20] time: 207.6321, d_loss: 0.09180290, g_loss: 4.13453770\n",
      "Epoch: [199] [   9/  20] time: 208.1265, d_loss: 0.09617496, g_loss: 3.26995087\n",
      "Epoch: [199] [  10/  20] time: 208.6318, d_loss: 0.16814631, g_loss: 2.51103950\n",
      "Epoch: [199] [  11/  20] time: 209.1425, d_loss: 0.15462844, g_loss: 3.31389546\n",
      "Epoch: [199] [  12/  20] time: 209.6428, d_loss: 0.12239114, g_loss: 4.13886452\n",
      "Epoch: [199] [  13/  20] time: 210.1387, d_loss: 0.15330118, g_loss: 4.57535362\n",
      "Epoch: [199] [  14/  20] time: 210.6351, d_loss: 0.11658917, g_loss: 3.48207474\n",
      "Epoch: [199] [  15/  20] time: 211.1019, d_loss: 0.10922724, g_loss: 3.28487134\n",
      "Epoch: [199] [  16/  20] time: 211.5695, d_loss: 0.11508641, g_loss: 3.87840867\n",
      "Epoch: [199] [  17/  20] time: 212.0372, d_loss: 0.11282268, g_loss: 3.96898580\n",
      "Epoch: [199] [  18/  20] time: 212.5063, d_loss: 0.13374336, g_loss: 3.66940045\n",
      "Epoch: [199] [  19/  20] time: 212.9845, d_loss: 0.09081574, g_loss: 3.50750780\n",
      "[199/200] - ptime: 9.9281 loss_d: 0.11813755, loss_g: 3.65635419, lf:  0.00007748\n",
      "Epoch: [200] [   0/  20] time: 228.7216, d_loss: 0.10570662, g_loss: 3.53864622\n",
      "Epoch: [200] [   1/  20] time: 229.2042, d_loss: 0.07958388, g_loss: 3.88187289\n",
      "Epoch: [200] [   2/  20] time: 229.6901, d_loss: 0.08269067, g_loss: 3.83116126\n",
      "Epoch: [200] [   3/  20] time: 230.1627, d_loss: 0.07869325, g_loss: 3.83759594\n",
      "Epoch: [200] [   4/  20] time: 230.6449, d_loss: 0.11528818, g_loss: 3.06084371\n",
      "Epoch: [200] [   5/  20] time: 231.1320, d_loss: 0.08208948, g_loss: 3.78356409\n",
      "Epoch: [200] [   6/  20] time: 231.6019, d_loss: 0.12516385, g_loss: 3.70794511\n",
      "Epoch: [200] [   7/  20] time: 232.1037, d_loss: 0.08535031, g_loss: 4.09073877\n",
      "Epoch: [200] [   8/  20] time: 232.5853, d_loss: 0.12534145, g_loss: 3.67947698\n",
      "Epoch: [200] [   9/  20] time: 233.0580, d_loss: 0.10734171, g_loss: 3.32240844\n",
      "Epoch: [200] [  10/  20] time: 233.5316, d_loss: 0.10362367, g_loss: 3.40743995\n",
      "Epoch: [200] [  11/  20] time: 234.0161, d_loss: 0.09526183, g_loss: 3.41537547\n",
      "Epoch: [200] [  12/  20] time: 234.5039, d_loss: 0.09437057, g_loss: 3.83439398\n",
      "Epoch: [200] [  13/  20] time: 234.9892, d_loss: 0.09584039, g_loss: 3.87096596\n",
      "Epoch: [200] [  14/  20] time: 235.4874, d_loss: 0.12525417, g_loss: 3.39708400\n",
      "Epoch: [200] [  15/  20] time: 235.9756, d_loss: 0.09946971, g_loss: 3.50455165\n",
      "Epoch: [200] [  16/  20] time: 236.4616, d_loss: 0.12055621, g_loss: 3.63554859\n",
      "Epoch: [200] [  17/  20] time: 236.9625, d_loss: 0.09006292, g_loss: 3.37694168\n",
      "Epoch: [200] [  18/  20] time: 237.4582, d_loss: 0.10196508, g_loss: 3.74040127\n",
      "Epoch: [200] [  19/  20] time: 237.9390, d_loss: 0.11902430, g_loss: 3.51869297\n",
      "[200/200] - ptime: 9.8475 loss_d: 0.10163392, loss_g: 3.62178278, lf:  0.00006974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/198 [00:00<00:21,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg per epoch ptime: 9.81, total 200 epochs ptime: 253.17\n",
      " [*] Training finished!\n",
      " [*] Generation Animation GIF start!\n",
      " [*] Reading 198 (900, 600) images start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:18<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading 198 (900, 600) images finished!\n",
      " [*] Generation Animation (900, 600) GIF start! FPS= 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Generation Animation (900, 600) GIF finished! FPS= 5\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 1/20 [00:04<01:25,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 116 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:08<01:15,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 131 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:13<01:17,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 153 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:18<01:12,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 137 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:23<01:10,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 159 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:27<01:05,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 103 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:32<01:00,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 130 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:38<00:57,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 126 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:43<00:52,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 114 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [00:48<00:48,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 157 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [00:53<00:43,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 143 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [00:59<00:39,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 113 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [01:04<00:34,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 154 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [01:10<00:30,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 148 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [01:15<00:25,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 118 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [01:22<00:20,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 163 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [01:28<00:15,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 150 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [01:34<00:10,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 117 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [01:39<00:05,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 169 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample1_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [01:45<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 123 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'cDCGAN'\n",
    "dataset = 'Class2_Sample1_test1_1_1000'\n",
    "epoch = 200\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "result_dir = 'results'\n",
    "log_dir = 'logs'\n",
    "test_dir = 'image_gan'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --test_dir\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    cDCGAN = cDCGAN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                    result_dir=result_dir, log_dir=log_dir, test_dir=test_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    cDCGAN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    cDCGAN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    cDCGAN.train()\n",
    "    \n",
    "    #visualize_img_to_gif\n",
    "    cDCGAN.visualize_img_to_gif(path=result_dir, size=(900,600), fps=5)\n",
    "\n",
    "    vepoch = random.sample(range(100,170), 20)\n",
    "\n",
    "    for e in tqdm(vepoch):\n",
    "        cDCGAN.visualize_test_image( e, 100, 1)\n",
    "        \n",
    "sess.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
