{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#灰度共生矩阵\n",
    "#定义最大灰度级数\n",
    "gray_level = 16\n",
    "\n",
    "def maxGrayLevel(img):\n",
    "    max_gray_level=0\n",
    "    (height,width)=img.shape\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if img[y][x] > max_gray_level:\n",
    "                max_gray_level = img[y][x]\n",
    "    return max_gray_level+1\n",
    "\n",
    "def getGlcm(img,d_x,d_y):\n",
    "    srcdata=img.copy()\n",
    "    ret=[[0.0 for i in range(gray_level)] for j in range(gray_level)]\n",
    "    (height,width) = img.shape\n",
    "\n",
    "    max_gray_level=maxGrayLevel(img)\n",
    "\n",
    "    #若灰度级数大于gray_level，则将图像的灰度级缩小至gray_level，减小灰度共生矩阵的大小\n",
    "    if max_gray_level > gray_level:\n",
    "        for j in range(height):\n",
    "            for i in range(width):\n",
    "                srcdata[j][i] = srcdata[j][i]*gray_level / max_gray_level\n",
    "\n",
    "    for j in range(height-d_y):\n",
    "        for i in range(width-d_x):\n",
    "            rows = srcdata[j][i]\n",
    "            cols = srcdata[j + d_y][i+d_x]\n",
    "            ret[rows][cols]+=1.0\n",
    "\n",
    "    for i in range(gray_level):\n",
    "        for j in range(gray_level):\n",
    "            ret[i][j]/=float(height*width)\n",
    "\n",
    "    return np.array(ret)\n",
    "    \n",
    "def feature_computer(p):\n",
    "    Con=0.0\n",
    "    Eng=0.0\n",
    "    Asm=0.0\n",
    "    Idm=0.0\n",
    "    for i in range(gray_level):\n",
    "        for j in range(gray_level):\n",
    "            Con+=(i-j)*(i-j)*p[i][j]\n",
    "            Asm+=p[i][j]*p[i][j]\n",
    "            Idm+=p[i][j]/(1+(i-j)*(i-j))\n",
    "            if p[i][j]>0.0:\n",
    "                Eng+=p[i][j]*math.log(p[i][j])\n",
    "    return Asm,Con,-Eng,Idm\n",
    "\n",
    "def batch_GLCM(images):\n",
    "    greycomatrix_list = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "        gray=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        glcm_0=getGlcm(gray, 1,0)\n",
    "        asm0,con0,eng0,idm0 = feature_computer(glcm_0)\n",
    "        \n",
    "        glcm_1=getGlcm(gray, 0,1)\n",
    "        asm1,con1,eng1,idm1 = feature_computer(glcm_1)\n",
    "        \n",
    "        glcm_2=getGlcm(gray, 1,1)\n",
    "        asm2,con2,eng2,idm2 = feature_computer(glcm_2)\n",
    "\n",
    "        greycomatrix_list.append([asm0,con0,eng0,idm0,\n",
    "                                  asm1,con1,eng1,idm1,\n",
    "                                  asm2,con2,eng2,idm2])\n",
    "        \n",
    "    greycomatrix_list=np.array(greycomatrix_list,dtype = float32)\n",
    "    \n",
    "    print (greycomatrix_list.shape)\n",
    "    return greycomatrix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_canny_rgb(images):\n",
    "    canny_list = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "        img = cv2.resize(img, (32,32))\n",
    "        canny_superposition = np.zeros(shape=(img.shape[0],img.shape[1]),dtype=np.uint16)\n",
    "        for channel in range(3):\n",
    "            img_ch = img[:,:,channel]\n",
    "            canny_ch = cv2.Canny(img_ch, 60, 150)\n",
    "            canny_superposition =  canny_superposition + (canny_ch).astype(np.uint16)\n",
    "        canny_superposition = cv2.normalize(canny_superposition, canny_superposition,0,255,cv2.NORM_MINMAX)\n",
    "        canny_list.append(np.array((canny_superposition).astype(np.uint8)).flatten())\n",
    "    canny_list = np.array(canny_list,dtype = float32)\n",
    "    \n",
    "    print (canny_list.shape)\n",
    "    return canny_list\n",
    "\n",
    "def batch_canny_gray(images):\n",
    "    canny_list = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "        img = cv2.resize(img, (32,32))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        canny = cv2.Canny(gray, 60, 150)\n",
    "        canny = cv2.normalize(canny, canny,0,255,cv2.NORM_MINMAX)\n",
    "        canny_list.append(np.array((canny).astype(np.uint8)).flatten())\n",
    "    canny_list = np.array(canny_list,dtype = float32)\n",
    "    \n",
    "    print (canny_list.shape)\n",
    "    return canny_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pyramid\n",
    "def batch_pyramid(images):\n",
    "    pyramid_list = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        img = (images.astype(np.float32)* 255)[i, :, :, :].astype(np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        G = img.copy()\n",
    "        gp = [G]\n",
    "        for i in range(4):\n",
    "            G = cv2.pyrDown(G)\n",
    "            gp.append(G)\n",
    "        lp = [gp[4]]\n",
    "        for i in range(4,0,-1):\n",
    "            GE = cv2.pyrUp(gp[i])\n",
    "            (x,y) = gp[i-1].shape\n",
    "            L = cv2.subtract(gp[i-1],GE[:x,:y])\n",
    "            lp.append(L)\n",
    "        lp_1 = cv2.normalize(lp[1], lp[1],0,255,cv2.NORM_MINMAX)\n",
    "        lp_2 = cv2.normalize(lp[2], lp[2],0,255,cv2.NORM_MINMAX)\n",
    "        v_1 = np.array((lp_1).astype(np.uint8)).flatten() \n",
    "        v_2 = np.array((lp_2).astype(np.uint8)).flatten() \n",
    "        v_1_2 = np.hstack((v_1,v_2))\n",
    "        pyramid_list.append(np.array((v_1_2).astype(np.uint8)).flatten())\n",
    "    pyramid_list = np.array(pyramid_list,dtype = float32)\n",
    "    \n",
    "    print (pyramid_list.shape)\n",
    "    return pyramid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "def load_flower_data():\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] handling images...\")\n",
    "    TRAIN_ORIGINAL_DIR = '../train/'\n",
    "    TRAIN_SUB_DIR = '../subsample/'\n",
    "    TRAIN_GAN = '../image_gan/'\n",
    "    TEST_DIR = '../test/'\n",
    "\n",
    "    # use this for full dataset\n",
    "    train_images = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "    test_images = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "    \n",
    "    train_images.sort(key=natural_keys)\n",
    "    test_images.sort(key=natural_keys)\n",
    "\n",
    "    # initialize the features matrix and labels list\n",
    "    trainImage = []\n",
    "    trainLabels = []\n",
    "    testImage = []\n",
    "    testLabels = []\n",
    "\n",
    "    # loop over the input images\n",
    "    for (i, imagePath) in enumerate(train_images):\n",
    "        # extract the class label\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # read and resize image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        trainImage.append(img)\n",
    "        trainLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "            \n",
    "      # loop over the input images\n",
    "    for (i, imagePath) in enumerate(test_images):\n",
    "        # extract the class label\n",
    "        # our images were named as labels.image_number.format\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # extract CNN features in the image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        testImage.append(img)\n",
    "        testLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "        if i > 0 and ((i + 1) % 1000 == 0 or i == len(test_images) - 1):\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(test_images)))\n",
    "\n",
    "\n",
    "    trainImage = np.array(trainImage,dtype = float32)\n",
    "    trainLabels = np.array(trainLabels)\n",
    "    testImage = np.array(testImage,dtype = float32)\n",
    "    testLabels = np.array(testLabels)\n",
    "    print (trainImage.shape)\n",
    "    \n",
    "    trainImage = trainImage.astype(np.float32) / 255\n",
    "    testImage = testImage.astype(np.float32) / 255\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainLabels)\n",
    "    list(le.classes_)\n",
    "    trainLabels = le.transform(trainLabels) \n",
    "    testLabels = le.transform(testLabels) \n",
    "    \n",
    "    return trainImage, trainLabels, testImage, testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "[INFO] processed 1000/2000\n",
      "[INFO] processed 2000/2000\n",
      "[INFO] processed 158/158\n",
      "(2000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "trainImage, trainLabels, testImage, testLabels = load_flower_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "(2,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1]\n",
      "(158,)\n",
      "[INFO] trainLabels matrix: 0.0000MB\n",
      "[INFO] testLabels matrix: 0.0012MB\n"
     ]
    }
   ],
   "source": [
    "np.save('./trainLabels.npy', trainLabels)\n",
    "np.save('./testLabels.npy', testLabels)\n",
    "\n",
    "print (trainLabels)\n",
    "print (trainLabels.shape)\n",
    "print (testLabels)\n",
    "print (testLabels.shape)\n",
    "\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testLabels matrix: {:.4f}MB\".format(\n",
    "    (testLabels.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "(2, 2)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "(158, 2)\n",
      "[INFO] trainLabels_onehot matrix: 0.0000MB\n",
      "[INFO] testLabels_onehot matrix: 0.0025MB\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "nb_classes = 2\n",
    "trainLabels_onehot = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "testLabels_onehot = keras.utils.to_categorical(testLabels, nb_classes)\n",
    "\n",
    "np.save('./trainLabels_onehot.npy', trainLabels_onehot)\n",
    "np.save('./testLabels_onehot.npy', testLabels_onehot)\n",
    "\n",
    "print (trainLabels_onehot)\n",
    "print (trainLabels_onehot.shape)\n",
    "print (testLabels_onehot)\n",
    "print (testLabels_onehot.shape)\n",
    "\n",
    "print(\"[INFO] trainLabels_onehot matrix: {:.4f}MB\".format(\n",
    "    (trainLabels_onehot.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testLabels_onehot matrix: {:.4f}MB\".format(\n",
    "    (testLabels_onehot.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1755.67it/s]\n",
      "  0%|          | 0/158 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 114.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 1024)\n",
      "[INFO] trainImage_canny matrix: 0.01MB\n",
      "[INFO] testImage_canny matrix: 0.6320MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainImage_canny = batch_canny_rgb(trainImage)\n",
    "testImage_canny = batch_canny_rgb(testImage)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(trainImage_canny)\n",
    "trainImage_canny = scaler.transform(trainImage_canny)\n",
    "testImage_canny = scaler.transform(testImage_canny)\n",
    "\n",
    "np.save('./trainImage_canny.npy', trainImage_canny)\n",
    "np.save('./testImage_canny.npy', testImage_canny)\n",
    "\n",
    "print(\"[INFO] trainImage_canny matrix: {:.2f}MB\".format(\n",
    "    (trainImage_canny.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_canny matrix: {:.4f}MB\".format(\n",
    "    (testImage_canny.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainImage_canny\n",
    "del testImage_canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [06:44<00:00,  4.94it/s]\n",
      "  7%|▋         | 11/158 [00:00<00:01, 104.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 125.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 1024)\n",
      "[INFO] trainImage_canny_gray matrix: 8.00MB\n",
      "[INFO] testImage_canny_gray matrix: 0.6320MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainImage_canny_gray = batch_canny_gray(trainImage)\n",
    "testImage_canny_gray = batch_canny_gray(testImage)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(trainImage_canny_gray)\n",
    "trainImage_canny_gray = scaler.transform(trainImage_canny_gray)\n",
    "testImage_canny_gray = scaler.transform(testImage_canny_gray)\n",
    "\n",
    "np.save('./trainImage_canny_gray.npy', trainImage_canny_gray)\n",
    "np.save('./testImage_canny_gray.npy', testImage_canny_gray)\n",
    "\n",
    "print(\"[INFO] trainImage_canny_gray matrix: {:.2f}MB\".format(\n",
    "    (trainImage_canny_gray.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_canny_gray matrix: {:.4f}MB\".format(\n",
    "    (testImage_canny_gray.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainImage_canny_gray\n",
    "del testImage_canny_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.57it/s]\n",
      "  1%|          | 1/158 [00:00<00:22,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:22<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 12)\n",
      "[INFO] trainImage_GLCM matrix: 0.00MB\n",
      "[INFO] testImage_GLCM matrix: 0.0074MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainImage_GLCM = batch_GLCM(trainImage)\n",
    "testImage_GLCM = batch_GLCM(testImage)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(trainImage_GLCM)\n",
    "trainImage_GLCM = scaler.transform(trainImage_GLCM)\n",
    "testImage_GLCM = scaler.transform(testImage_GLCM)\n",
    "\n",
    "np.save('./trainImage_GLCM.npy', trainImage_GLCM)\n",
    "np.save('./testImage_GLCM.npy', testImage_GLCM)\n",
    "\n",
    "print(\"[INFO] trainImage_GLCM matrix: {:.2f}MB\".format(\n",
    "    (trainImage_GLCM.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_GLCM matrix: {:.4f}MB\".format(\n",
    "    (testImage_GLCM.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainImage_GLCM\n",
    "del testImage_GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [07:41<00:00,  4.33it/s]\n",
      "  8%|▊         | 13/158 [00:00<00:01, 129.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 121.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 1280)\n",
      "[INFO] trainImage_pyramid matrix: 10.00MB\n",
      "[INFO] testImage_cpyramid matrix: 0.7900MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainImage_pyramid = batch_pyramid(trainImage)\n",
    "testImage_pyramid = batch_pyramid(testImage)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(trainImage_pyramid)\n",
    "trainImage_pyramid = scaler.transform(trainImage_pyramid)\n",
    "testImage_pyramid = scaler.transform(testImage_pyramid)\n",
    "\n",
    "np.save('./trainImage_pyramid.npy', trainImage_pyramid)\n",
    "np.save('./testImage_pyramid.npy', testImage_pyramid)\n",
    "\n",
    "print(\"[INFO] trainImage_pyramid matrix: {:.2f}MB\".format(\n",
    "    (trainImage_pyramid.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_cpyramid matrix: {:.4f}MB\".format(\n",
    "    (testImage_pyramid.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainImage_pyramid\n",
    "del testImage_pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] trainImage matrix: 0.38MB\n",
      "[INFO] testImage matrix: 30.34MB\n"
     ]
    }
   ],
   "source": [
    "# scaler = sklearn.preprocessing.StandardScaler().fit(trainImage)\n",
    "# trainImage = scaler.transform(trainImage)\n",
    "# testImage = scaler.transform(testImage)\n",
    "\n",
    "np.save('./trainImage.npy', trainImage)\n",
    "np.save('./testImage.npy', testImage)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage matrix: {:.2f}MB\".format(\n",
    "    (testImage.nbytes) / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] trainImage_canny_GLCM matrix: 0.01MB\n",
      "[INFO] testImage_canny_GLCM matrix: 0.64MB\n"
     ]
    }
   ],
   "source": [
    "trainImage_canny = np.load('./trainImage_canny.npy')\n",
    "testImage_canny = np.load('./testImage_canny.npy')\n",
    "trainImage_GLCM = np.load('./trainImage_GLCM.npy')\n",
    "testImage_GLCM = np.load('./testImage_GLCM.npy')\n",
    "\n",
    "trainImage_canny_GLCM = np.hstack((trainImage_canny,trainImage_GLCM))\n",
    "testImage_canny_GLCM = np.hstack((testImage_canny,testImage_GLCM))\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(trainImage_canny_GLCM)\n",
    "trainImage_canny_GLCM = scaler.transform(trainImage_canny_GLCM)\n",
    "testImage_canny_GLCM = scaler.transform(testImage_canny_GLCM)\n",
    "\n",
    "np.save('./trainImage_canny_GLCM.npy', trainImage_canny_GLCM)\n",
    "np.save('./testImage_canny_GLCM.npy', testImage_canny_GLCM)\n",
    "\n",
    "print(\"[INFO] trainImage_canny_GLCM matrix: {:.2f}MB\".format(\n",
    "    (trainImage_canny_GLCM.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] testImage_canny_GLCM matrix: {:.2f}MB\".format(\n",
    "    (testImage_canny_GLCM.nbytes) / (1024 * 1000.0)))\n",
    "\n",
    "del trainImage_canny\n",
    "del testImage_canny\n",
    "del trainImage_GLCM\n",
    "del testImage_GLCM\n",
    "del trainImage_canny_GLCM\n",
    "del testImage_canny_GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "[INFO] processed 2/2\n",
      "[INFO] processed 100/158\n",
      "[INFO] processed 158/158\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16,preprocess_input\n",
    "#from keras.applications.vgg19 import VGG19,preprocess_input\n",
    "#from keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# grab the list of images that we'll be describing\n",
    "print(\"[INFO] handling images...\")\n",
    "TRAIN_ORIGINAL_DIR = '../train/'\n",
    "TRAIN_SUB_DIR = '../subsample/'\n",
    "TRAIN_GAN = '../image_gan/'\n",
    "TEST_DIR = '../test/'\n",
    "\n",
    "# use this for full dataset\n",
    "train_images = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "test_images = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "train_images.sort(key=natural_keys)\n",
    "test_images.sort(key=natural_keys)\n",
    "\n",
    "# initialize the features matrix and labels list\n",
    "trainImage_CNN = []\n",
    "testImage_CNN  = []\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "#model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# loop over the input images\n",
    "for (i, imagePath) in enumerate(train_images):\n",
    "\n",
    "    # extract CNN features in the image\n",
    "    img = image.load_img(imagePath, target_size=(224,224)) #VGG16\n",
    "    #img = image.load_img(imagePath, target_size=(299,299))#InceptionV3\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)[0, ...].flatten()\n",
    "\n",
    "    # add the messages we got to features and labels matricies\n",
    "    trainImage_CNN.append(features)\n",
    "\n",
    "#     # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1) % 200 == 0 or i == len(train_images) - 1):\n",
    "        print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "\n",
    "\n",
    "# loop over the test images\n",
    "for (i, imagePath) in enumerate(test_images):\n",
    "   \n",
    "    # extract CNN features in the image\n",
    "    img = image.load_img(imagePath, target_size=(224,224)) #VGG16\n",
    "    #img = image.load_img(imagePath, target_size=(299,299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    features = model.predict(x)[0, ...].flatten()\n",
    "\n",
    "    # add the messages we got to features and labels matricies\n",
    "    testImage_CNN.append(features)\n",
    "\n",
    "#     # show an update every 200 images until the last image\n",
    "    if i > 0 and ((i + 1) % 100 == 0 or i == len(test_images) - 1):\n",
    "        print(\"[INFO] processed {}/{}\".format(i + 1, len(test_images)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] CNN Feature matrix: 15.68MB\n"
     ]
    }
   ],
   "source": [
    "trainImage_CNN = np.array(trainImage_CNN,dtype = float32)\n",
    "testImage_CNN = np.array(testImage_CNN,dtype = float32)\n",
    "\n",
    "scaler = sklearn.preprocessing.StandardScaler().fit(trainImage_CNN)\n",
    "trainImage_CNN = scaler.transform(trainImage_CNN)\n",
    "testImage_CNN = scaler.transform(testImage_CNN)\n",
    "\n",
    "print(\"[INFO] CNN Feature matrix: {:.2f}MB\".format(\n",
    "    (trainImage_CNN.nbytes + testImage_CNN.nbytes) / (1024 * 1000.0)))\n",
    "\n",
    "#save matrix\n",
    "np.save('./trainImage_CNN.npy', trainImage_CNN)\n",
    "np.save('./testImage_CNN.npy', testImage_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
