{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huiqy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from imutils import paths\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import argparse\n",
    "import imutils,sklearn\n",
    "import os, cv2, re, random, shutil, imageio, pickle\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "def load_flower_data():\n",
    "    # grab the list of images that we'll be describing\n",
    "    print(\"[INFO] handling images...\")\n",
    "    TRAIN_ORIGINAL_DIR = '../train/'\n",
    "    TRAIN_SUB_DIR = '../subsample/'\n",
    "    TEST_DIR = '../test/'\n",
    "\n",
    "    # use this for full dataset\n",
    "    train_images_original = [TRAIN_ORIGINAL_DIR + i for i in os.listdir(TRAIN_ORIGINAL_DIR)]\n",
    "    train_images_sub = [TRAIN_SUB_DIR + i for i in os.listdir(TRAIN_SUB_DIR)]\n",
    "\n",
    "    train_images = train_images_original + train_images_sub\n",
    "\n",
    "    #print (train_images)\n",
    "    train_images.sort(key=natural_keys)\n",
    "    print (len(train_images))\n",
    "\n",
    "    # initialize the features matrix and labels list\n",
    "    trainImage = []\n",
    "    trainLabels = []\n",
    "\n",
    "    # loop over the input images\n",
    "    for (i, imagePath) in enumerate(train_images):\n",
    "        # extract the class label\n",
    "        # get the labels from the name of the images by extract the string before \"_\"\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\"_\")[0]\n",
    "\n",
    "        # read and resize image\n",
    "        img = cv2.imread(imagePath)\n",
    "        img = cv2.resize(img, (128,128))\n",
    "\n",
    "        # add the messages we got to features and labels matricies\n",
    "        trainImage.append(img)\n",
    "        trainLabels.append(label)\n",
    "\n",
    "        # show an update every 100 images until the last image\n",
    "#         if i > 0 and ((i + 1) % 1000 == 0 or i == len(train_images) - 1):\n",
    "#             print(\"[INFO] processed {}/{}\".format(i + 1, len(train_images)))\n",
    "\n",
    "    trainImage = np.array(trainImage,dtype = float32)\n",
    "    trainLabels = np.array(trainLabels)\n",
    "    print (trainImage.shape)\n",
    "    trainImage = trainImage.astype(np.float32) / 255\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainLabels)\n",
    "    list(le.classes_)\n",
    "    trainLabels = le.transform(trainLabels) \n",
    "    \n",
    "    return trainImage, trainLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] handling images...\n",
      "6006\n",
      "(6006, 128, 128, 3)\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[INFO] trainImage matrix: 1153.15MB\n",
      "[INFO] trainLabels matrix: 0.0938MB\n"
     ]
    }
   ],
   "source": [
    "trainImage,trainLabels = load_flower_data()\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "trainLabels = keras.utils.to_categorical(trainLabels, nb_classes)\n",
    "print (trainLabels)\n",
    "np.save('./trainImage.npy', trainImage)\n",
    "np.save('./trainLabels.npy', trainLabels)\n",
    "\n",
    "print(\"[INFO] trainImage matrix: {:.2f}MB\".format(\n",
    "    (trainImage.nbytes) / (1024 * 1000.0)))\n",
    "print(\"[INFO] trainLabels matrix: {:.4f}MB\".format(\n",
    "    (trainLabels.nbytes) / (1024 * 1000.0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu( X, leak=0.2):\n",
    "    f1 = 0.5 * (1 + leak)\n",
    "    f2 = 0.5 * (1 - leak)\n",
    "    return f1 * X + f2 * tf.abs(X)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cDCGAN(object):\n",
    "    def __init__(self, sess, epoch, batch_size, dataset_name, checkpoint_dir, result_dir, log_dir, \n",
    "                 test_dir, trainhist_dir):\n",
    "        self.sess = sess\n",
    "        self.dataset_name = dataset_name\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.result_dir = result_dir\n",
    "        self.log_dir = log_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.trainhist_dir = trainhist_dir\n",
    "        self.epoch = epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = \"cDCGAN\"     # name for checkpoint\n",
    "        \n",
    "        self.classname = ['Iris', 'Pansy']\n",
    "\n",
    "        # parameters\n",
    "        self.input_height = 128\n",
    "        self.input_width = 128\n",
    "        self.output_height = 128\n",
    "        self.output_width = 128\n",
    "\n",
    "        self.z_dim = 100         # dimension of noise-vector\n",
    "        self.c_dim = 3  # color dimension\n",
    "        self.nb_class = 2\n",
    "\n",
    "        # train\n",
    "        #设置一个全局的计数器\n",
    "        self.global_step = tf.Variable(0, trainable=False)\n",
    "        self.lr = tf.train.exponential_decay( 0.0002,\n",
    "                                             global_step=self.global_step,\n",
    "                                             decay_steps=20,\n",
    "                                             decay_rate=0.9,\n",
    "                                             staircase=True)\n",
    "        self.beta1 = 0.5\n",
    "        #max model to keep saving\n",
    "        self.max_to_keep = 300\n",
    "\n",
    "        # test\n",
    "        #visual results\n",
    "        self.onehot = np.eye(self.nb_class)\n",
    "        self.sample_num = 100  # number of generated images to be saved\n",
    "        self.visual_team = self.batch_size // self.nb_class  # number of generated images to be saved\n",
    "\n",
    "        #load_flower_data\n",
    "        self.data_x = np.load('./trainImage.npy')\n",
    "        self.data_y= np.load('./trainLabels.npy')\n",
    "        \n",
    "        #记录\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_losses'] = []\n",
    "        self.train_hist['G_losses'] = []\n",
    "        self.train_hist['learning_rate'] = []\n",
    "        self.train_hist['per_epoch_ptimes'] = []\n",
    "        self.train_hist['total_ptime'] = []\n",
    "        \n",
    "        # get number of batches for a single epoch\n",
    "        self.num_batches = len(self.data_x) // self.batch_size\n",
    "\n",
    "    def discriminator(self, x, y_fill, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "             \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "        \n",
    "            print(\"D:x\",x.get_shape()) # 32, 32, 3 = 3072\n",
    "            print(\"D:y_fill\",y_fill.get_shape())\n",
    "            # concat layer\n",
    "            \n",
    "            #卷积核为4*4 输出维度为32\n",
    "            net1_1 = tf.layers.conv2d(x, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            \n",
    "            print(\"D:\",net1_1.get_shape())\n",
    "            \n",
    "            net1_2 = tf.layers.conv2d(y_fill, 32, [4, 4], strides=(2, 2), padding='same', \n",
    "                         kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"D:\",net1_2.get_shape())\n",
    "    \n",
    "            #把数据和标签进行连接\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为128        \n",
    "            net = tf.layers.conv2d(net, 64, [4, 4], strides=(2, 2), padding='same', \n",
    "                                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "    \n",
    "            #卷积核为4*4 输出维度为128 \n",
    "            net = tf.layers.conv2d(net, 128, [4, 4], strides=(2, 2), padding='same', \n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为256\n",
    "            net = tf.layers.conv2d(net, 256, [4, 4], strides=(2, 2), padding='same', \n",
    "                     kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #卷积核为4*4 输出维度为512\n",
    "            net = tf.layers.conv2d(net, 512, [4, 4], strides=(2, 2), padding='same', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"D:\",net.get_shape())\n",
    "            \n",
    "            #output\n",
    "            out_logit = tf.layers.conv2d(net, 1, [4, 4], strides=(1, 1), padding='valid', \n",
    "                 kernel_initializer=W, bias_initializer=b)\n",
    "            print(\"D:out_logit\",out_logit.get_shape())\n",
    "            \n",
    "            out = tf.nn.sigmoid(out_logit)\n",
    "            print(\"D:out\",out.get_shape())\n",
    "            print(\"------------------------\")    \n",
    "\n",
    "            return out, out_logit, net\n",
    "\n",
    "    def generator(self, z, y_label, is_training=True, reuse=False):\n",
    "        with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "            \n",
    "            #初始化参数\n",
    "            W = tf.truncated_normal_initializer(mean=0.0, stddev=0.02)\n",
    "            b = tf.constant_initializer(0.0)\n",
    "            \n",
    "            print(\"G:z\",z.get_shape())\n",
    "            print(\"G:y_label\",y_label.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_1 = tf.layers.conv2d_transpose(z, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_1 = leaky_relu(net1_1, 0.2)\n",
    "            print(\"G:\",net1_1.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度256\n",
    "            net1_2 = tf.layers.conv2d_transpose(y_label, 256, [4, 4], strides=(1, 1), padding='valid',\n",
    "                                               kernel_initializer=W, bias_initializer=b)\n",
    "            net1_2 = leaky_relu(net1_2, 0.2)\n",
    "            print(\"G:\",net1_2.get_shape())\n",
    "            \n",
    "            #把数据和标签进行连接\n",
    "            # concat layer\n",
    "            net = tf.concat([net1_1, net1_2], 3)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度512\n",
    "            net = tf.layers.conv2d_transpose(net, 512, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度128\n",
    "            net = tf.layers.conv2d_transpose(net, 128, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度64\n",
    "            net = tf.layers.conv2d_transpose(net, 64, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度32\n",
    "            net = tf.layers.conv2d_transpose(net, 32, [4, 4], strides=(2, 2), padding='same',\n",
    "                                             kernel_initializer=W, bias_initializer=b)\n",
    "            net = tf.layers.batch_normalization(net, training=is_training)#batch norm\n",
    "            net = leaky_relu(net, 0.2)\n",
    "            print(\"G:\",net.get_shape())\n",
    "            \n",
    "            #反卷积,卷积核大小为4*4，输出维度3\n",
    "            net = tf.layers.conv2d_transpose(net, 3, [4, 4], strides=(2, 2), padding='same',\n",
    "                                 kernel_initializer=W, bias_initializer=b)\n",
    "            out = tf.nn.tanh(net)\n",
    "            print(\"G:\",out.get_shape())\n",
    "            print(\"------------------------\")\n",
    "\n",
    "            return out\n",
    "\n",
    "    def build_model(self):\n",
    "        #parameters\n",
    "        image_dims = [self.input_height, self.input_width, self.c_dim]\n",
    "\n",
    "        \"\"\" Graph Input \"\"\"\n",
    "        # images\n",
    "        self.x = tf.placeholder(tf.float32, shape=(self.batch_size,self.input_height, self.input_width, self.c_dim), \n",
    "                                name='real_images')\n",
    "\n",
    "        # noises\n",
    "        self.z = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.z_dim), name='z')\n",
    "        \n",
    "        self.y_label = tf.placeholder(tf.float32, shape=(self.batch_size, 1, 1, self.nb_class), name='y_label')\n",
    "        self.y_fill = tf.placeholder(tf.float32, shape=(self.batch_size, self.output_width, \n",
    "                                                        self.output_height, self.nb_class), name='y_fill')\n",
    "        \n",
    "        self.add_global = self.global_step.assign_add(1)\n",
    "\n",
    "        \"\"\" Loss Function \"\"\"\n",
    "\n",
    "        # output of D for real images\n",
    "        D_real, D_real_logits, _ = self.discriminator(self.x, self.y_fill, is_training=True, reuse=False)\n",
    "            \n",
    "        #networks : generator\n",
    "        G = self.generator(self.z, self.y_label, is_training=True, reuse=False)\n",
    "\n",
    "        # output of D for fake images\n",
    "        D_fake, D_fake_logits, _ = self.discriminator(G, self.y_fill, is_training=True, reuse=True)\n",
    "\n",
    "        # get loss for discriminator\n",
    "        self.d_loss_real = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real_logits, labels=tf.ones_like(D_real)))\n",
    "        self.d_loss_fake = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.zeros_like(D_fake)))\n",
    "\n",
    "        self.d_loss = self.d_loss_real + self.d_loss_fake\n",
    "        \n",
    "        # get loss for generator\n",
    "        self.g_loss = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(logits=D_fake_logits, labels=tf.ones_like(D_fake)))\n",
    "        \n",
    "        \"\"\" Training \"\"\"\n",
    "        # divide trainable variables into a group for D and a group for G\n",
    "        tf_vars = tf.trainable_variables()\n",
    "        d_vars = [var for var in tf_vars if var.name.startswith('discriminator')]\n",
    "        g_vars = [var for var in tf_vars if var.name.startswith('generator')]\n",
    "\n",
    "        # optimizers\n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            self.d_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.d_loss, var_list=d_vars)\n",
    "            self.g_optim = tf.train.AdamOptimizer(self.lr, beta1=self.beta1).minimize(self.g_loss, var_list=g_vars)\n",
    "        \n",
    "        \"\"\"\" Testing \"\"\"\n",
    "        # for test\n",
    "        self.fake_images = self.generator(self.z, self.y_label, is_training=False, reuse=True)\n",
    "\n",
    "        \"\"\" Summary \"\"\"\n",
    "        d_loss_real_sum = tf.summary.scalar(\"d_loss_real\", self.d_loss_real)\n",
    "        d_loss_fake_sum = tf.summary.scalar(\"d_loss_fake\", self.d_loss_fake)\n",
    "        d_loss_sum = tf.summary.scalar(\"d_loss\", self.d_loss)\n",
    "        g_loss_sum = tf.summary.scalar(\"g_loss\", self.g_loss)\n",
    "\n",
    "        # final summary operations\n",
    "        self.g_sum = tf.summary.merge([d_loss_fake_sum, g_loss_sum])\n",
    "        self.d_sum = tf.summary.merge([d_loss_real_sum, d_loss_sum])\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        # graph inputs for visualize training results\n",
    "        self.sample_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "\n",
    "        self.test_images = self.data_x[0:self.batch_size]\n",
    "\n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver(max_to_keep= self.max_to_keep)\n",
    "\n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_name, self.sess.graph)\n",
    "\n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_epoch = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_epoch) + 1\n",
    "            counter = 1\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'rb') \n",
    "            self.train_hist = pickle.load(f)\n",
    "            f.close()\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "            print(\" [!] START_EPOCH is \", start_epoch)\n",
    "        else:\n",
    "            start_epoch = 1\n",
    "            counter = 1\n",
    "            print(\" [!] Load failed...\")\n",
    "\n",
    "        # loop for epoch\n",
    "        start_time = time.time()\n",
    "        for epoch_loop in range(start_epoch, self.epoch + 1):\n",
    "\n",
    "            G_losses = []\n",
    "            D_losses = []\n",
    "    \n",
    "            epoch_start_time = time.time()\n",
    "            shuffle_idxs = random.sample(range(0, self.data_x.shape[0]), self.data_x.shape[0])\n",
    "            shuffled_set = self.data_x[shuffle_idxs]\n",
    "            shuffled_label = self.data_y[shuffle_idxs]\n",
    "    \n",
    "            # get batch data\n",
    "            for idx in range(self.num_batches):\n",
    "                batch_x = shuffled_set[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "                batch_y_label = shuffled_label[idx*self.batch_size:(idx+1)*self.batch_size].reshape(\n",
    "                                        [self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill = batch_y_label * np.ones([self.batch_size, self.output_height, self.output_width, self.nb_class])\n",
    "                batch_z = np.random.normal(0, 1, (self.batch_size, 1, 1, 100)).astype(np.float32)\n",
    "                \n",
    "\n",
    "                # update D network\n",
    "                _, summary_str, d_loss = self.sess.run([self.d_optim, self.d_sum, self.d_loss],\n",
    "                                               feed_dict={self.x: batch_x,\n",
    "                                                          self.z: batch_z,\n",
    "                                                          self.y_fill: batch_y_fill,\n",
    "                                                          self.y_label: batch_y_label}\n",
    "                                                      )\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "\n",
    "                # update G network\n",
    "                batch_y = np.random.randint(0, self.nb_class, (self.batch_size, 1)) # <=  <\n",
    "                batch_y_label = self.onehot[batch_y.astype(np.int32)].reshape([self.batch_size, 1, 1, self.nb_class])\n",
    "                batch_y_fill  = batch_y_label * np.ones([self.batch_size, self.input_height, self.input_width, self.nb_class])\n",
    "\n",
    "                # update G once\n",
    "                _, summary_str, g_loss = self.sess.run([self.g_optim, self.g_sum, self.g_loss],\n",
    "                                                          feed_dict={self.x: batch_x,\n",
    "                                                                     self.z: batch_z, \n",
    "                                                                     self.y_fill: batch_y_fill,\n",
    "                                                                     self.y_label: batch_y_label})\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "                \n",
    "                D_losses.append(d_loss)\n",
    "                G_losses.append(g_loss)\n",
    "\n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" % (epoch_loop, idx, self.num_batches, time.time() - start_time, d_loss, g_loss))\n",
    "\n",
    "            # After an epoch\n",
    "            #update learning rate\n",
    "            _, rate = sess.run([self.add_global, self.lr])\n",
    "            epoch_end_time = time.time()\n",
    "            per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "            \n",
    "            print('[%d/%d] - ptime: %.4f loss_d: %.8f, loss_g: %.8f, lf:  %.8f' % (epoch_loop, self.epoch, per_epoch_ptime, \n",
    "                                                                        np.mean(D_losses), np.mean(G_losses), rate))\n",
    "            self.train_hist['D_losses'].append(np.mean(D_losses))\n",
    "            self.train_hist['G_losses'].append(np.mean(G_losses))\n",
    "            self.train_hist['learning_rate'].append(rate)\n",
    "            self.train_hist['per_epoch_ptimes'].append(per_epoch_ptime)\n",
    "            \n",
    "            # save model\n",
    "            self.save(self.checkpoint_dir, epoch_loop)\n",
    "\n",
    "            # show temporal results\n",
    "            self.visualize_epoch_results(epoch_loop)\n",
    "            \n",
    "            # save trainhist for the initial train\n",
    "            f = open(self.trainhist_dir + '/' + 'train_hist.pkl', 'wb') \n",
    "            pickle.dump(self.train_hist, f)\n",
    "            f.close()\n",
    "            \n",
    "            self.show_train_hist(self.train_hist, save=True, path= self.trainhist_dir + '/' + 'train_hist.png')\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_ptime = end_time - start_time\n",
    "        self.train_hist['total_ptime'].append(total_ptime)\n",
    "        print('Avg per epoch ptime: %.2f, total %d epochs ptime: %.2f' % (np.mean(self.train_hist['per_epoch_ptimes']), \n",
    "                                                                          self.epoch, total_ptime))\n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "    def visualize_img_to_gif(self, path, size, fps = 5):\n",
    "        print(\" [*] Generation Animation GIF start!\")\n",
    "        path_images = [path + '/'+ i for i in os.listdir(path)]\n",
    "        path_images.sort(key=natural_keys)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images start!\")\n",
    "        images = []\n",
    "        for p in tqdm(path_images):\n",
    "            img = imageio.imread(p)\n",
    "            img = cv2.resize(img, size)\n",
    "            images.append(img)\n",
    "        print(\" [*] Reading \" + str(len(path_images)) + \" \" +  str(size) + \" images finished!\")\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF start! FPS=\", fps)\n",
    "        path_gif = path + '/' + self.model_name + '_epoch%03d' % self.epoch + '_' + self.dataset_name + 'generation_animation.gif'\n",
    "        imageio.mimsave(path_gif, images, fps = fps)\n",
    "        print(\" [*] Generation Animation \"+ str(size) + \" GIF finished! FPS=\", fps)\n",
    "\n",
    "    def visualize_test_image(self, epoch, num, times):\n",
    "        tot_num_samples = num #  100\n",
    "        path_model = self.checkpoint_dir + '/' + self.model_dir + '/' + self.model_name + '/'+ self.model_name +'.model-'+ str(epoch)\n",
    "        \n",
    "        \"\"\" restore epoch \"\"\"\n",
    "        new_saver = tf.train.import_meta_graph(path_model + '.meta' )\n",
    "        new_saver.restore(self.sess,path_model)\n",
    "            \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "        for j in range(times):\n",
    "            noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "            fixed_noise = noise \n",
    "            fixed_label = np.zeros((self.visual_team , 1))\n",
    "            #用于显示25组图像\n",
    "            for i in range(self.nb_class - 1):\n",
    "                fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "                temp_label = np.ones((self.visual_team, 1)) + i\n",
    "                fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "            fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "            samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "            self.save_cv2_img(samples[:tot_num_samples, :, :, :], tot_num_samples, epoch , j) \n",
    "        print(\" [*] Finished generating Epoch:\", epoch, \",\",times*num,\"new images!\")\n",
    "        \n",
    "                                    \n",
    "    def save_cv2_img(self, images, num, epoch, times):\n",
    "    # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(num):\n",
    "            classname = self.classname[idx // self.visual_team]\n",
    "            img_save = images[idx:idx+1, :, :, :][0, ...]*255\n",
    "            path = self.test_dir + '/' + classname + '_epoch%03d' % epoch + '_t%02d' % times+ '_%03d' % idx + '.png'\n",
    "            cv2.imwrite( path, img_save)\n",
    "              \n",
    "    def show_all_variables(self):\n",
    "        model_vars = tf.trainable_variables()\n",
    "        tf.contrib.slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "        \n",
    "    def save_matplot_img(self, images, size, image_path):\n",
    "        # revice image data // M*N*3 // RGB float32 : value must set between 0. with 1.\n",
    "        for idx in range(100):\n",
    "            vMin = np.amin(images[idx])\n",
    "            vMax = np.amax(images[idx])\n",
    "            img_arr = images[idx].reshape(128*128*3,1) # flatten\n",
    "            for i, v in enumerate(img_arr):\n",
    "                img_arr[i] = (v-vMin)/(vMax-vMin)\n",
    "            img_arr = img_arr.reshape(128,128,3) # M*N*3\n",
    "\n",
    "            # matplot display\n",
    "            plt.subplot(10,10,idx+1),plt.imshow(cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB), interpolation='nearest')\n",
    "            #plt.title(\"pred.:{}\".format(np.argmax(self.data_y[0]),fontsize=10))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.savefig(image_path, dpi = 400)\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}_{}\".format(\n",
    "            self.dataset_name, self.batch_size,\n",
    "            self.output_height, self.output_width)\n",
    "\n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess,os.path.join(checkpoint_dir, self.model_name+'.model'), global_step=step)\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir, self.model_name)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            epoch = int(next(re.finditer(\"(\\d+)(?!.*\\d)\",ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read [{}], epoch [{}]\".format(ckpt_name,epoch))\n",
    "            return True, epoch\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "    def show_train_hist(self, hist, show = False, save = False, path = 'Train_hist.png'):\n",
    "        x = range(1, len(hist['D_losses'])+1)\n",
    "\n",
    "        y1 = hist['D_losses']\n",
    "        y2 = hist['G_losses']\n",
    "\n",
    "        plt.plot(x, y1, label='D_loss')\n",
    "        plt.plot(x, y2, label='G_loss')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "\n",
    "        plt.legend(loc=4)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(path, dpi = 400)\n",
    "\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "    def visualize_epoch_results(self, epoch):\n",
    "        tot_num_samples = min(self.sample_num, self.batch_size) # 100\n",
    "        image_frame_dim = int(np.floor(np.sqrt(tot_num_samples))) # 10\n",
    "        \n",
    "        \"\"\" random condition, random noise \"\"\"\n",
    "            \n",
    "        noise = np.random.normal(0, 1, (self.visual_team, 1, 1, self.z_dim))\n",
    "        fixed_noise = noise \n",
    "        fixed_label = np.zeros((self.visual_team , 1))\n",
    "        \n",
    "        #用于显示25组图像\n",
    "        for i in range(self.nb_class - 1):\n",
    "            fixed_noise = np.concatenate([fixed_noise, noise], 0)\n",
    "            temp_label = np.ones((self.visual_team, 1)) + i\n",
    "            fixed_label = np.concatenate([fixed_label, temp_label], 0)\n",
    "        fixed_label = self.onehot[fixed_label.astype(np.int32)].reshape((self.batch_size, 1, 1, self.nb_class))\n",
    "    \n",
    "        samples = self.sess.run(self.fake_images, feed_dict={self.z: fixed_noise, self.y_label: fixed_label})\n",
    "\n",
    "        self.save_matplot_img(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
    "                    self.result_dir + '/' + self.model_name + '_epoch%03d' % epoch + '_' + self.dataset_name +'.png')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 2)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 2)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "D:x (100, 128, 128, 3)\n",
      "D:y_fill (100, 128, 128, 2)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 32)\n",
      "D: (100, 64, 64, 64)\n",
      "D: (100, 32, 32, 64)\n",
      "D: (100, 16, 16, 128)\n",
      "D: (100, 8, 8, 256)\n",
      "D: (100, 4, 4, 512)\n",
      "D:out_logit (100, 1, 1, 1)\n",
      "D:out (100, 1, 1, 1)\n",
      "------------------------\n",
      "G:z (100, 1, 1, 100)\n",
      "G:y_label (100, 1, 1, 2)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 256)\n",
      "G: (100, 4, 4, 512)\n",
      "G: (100, 8, 8, 512)\n",
      "G: (100, 16, 16, 128)\n",
      "G: (100, 32, 32, 64)\n",
      "G: (100, 64, 64, 32)\n",
      "G: (100, 128, 128, 3)\n",
      "------------------------\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "discriminator/conv2d/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "discriminator/conv2d/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_1/kernel:0 (float32_ref 4x4x2x32) [1024, bytes: 4096]\n",
      "discriminator/conv2d_1/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "discriminator/conv2d_2/kernel:0 (float32_ref 4x4x64x64) [65536, bytes: 262144]\n",
      "discriminator/conv2d_2/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/batch_normalization/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "discriminator/conv2d_3/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "discriminator/conv2d_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "discriminator/conv2d_4/kernel:0 (float32_ref 4x4x128x256) [524288, bytes: 2097152]\n",
      "discriminator/conv2d_4/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/batch_normalization_2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "discriminator/conv2d_5/kernel:0 (float32_ref 4x4x256x512) [2097152, bytes: 8388608]\n",
      "discriminator/conv2d_5/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/batch_normalization_3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "discriminator/conv2d_6/kernel:0 (float32_ref 4x4x512x1) [8192, bytes: 32768]\n",
      "discriminator/conv2d_6/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "generator/conv2d_transpose/kernel:0 (float32_ref 4x4x256x100) [409600, bytes: 1638400]\n",
      "generator/conv2d_transpose/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_1/kernel:0 (float32_ref 4x4x256x2) [8192, bytes: 32768]\n",
      "generator/conv2d_transpose_1/bias:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/conv2d_transpose_2/kernel:0 (float32_ref 4x4x512x512) [4194304, bytes: 16777216]\n",
      "generator/conv2d_transpose_2/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/batch_normalization/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/conv2d_transpose_3/kernel:0 (float32_ref 4x4x128x512) [1048576, bytes: 4194304]\n",
      "generator/conv2d_transpose_3/bias:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/batch_normalization_1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/conv2d_transpose_4/kernel:0 (float32_ref 4x4x64x128) [131072, bytes: 524288]\n",
      "generator/conv2d_transpose_4/bias:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/batch_normalization_2/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/conv2d_transpose_5/kernel:0 (float32_ref 4x4x32x64) [32768, bytes: 131072]\n",
      "generator/conv2d_transpose_5/bias:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/beta:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/batch_normalization_3/gamma:0 (float32_ref 32) [32, bytes: 128]\n",
      "generator/conv2d_transpose_6/kernel:0 (float32_ref 4x4x3x32) [1536, bytes: 6144]\n",
      "generator/conv2d_transpose_6/bias:0 (float32_ref 3) [3, bytes: 12]\n",
      "Total size of variables: 8660516\n",
      "Total bytes of variables: 34642064\n",
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-193\n",
      " [*] Success to read [cDCGAN.model-193], epoch [193]\n",
      " [*] Load SUCCESS\n",
      " [!] START_EPOCH is  194\n",
      "Epoch: [194] [   0/  60] time: 3.5162, d_loss: 0.04288389, g_loss: 4.81597757\n",
      "Epoch: [194] [   1/  60] time: 3.9899, d_loss: 0.06247490, g_loss: 4.73321676\n",
      "Epoch: [194] [   2/  60] time: 4.4550, d_loss: 0.05558294, g_loss: 4.47990274\n",
      "Epoch: [194] [   3/  60] time: 4.9373, d_loss: 0.05852796, g_loss: 3.77061558\n",
      "Epoch: [194] [   4/  60] time: 5.4297, d_loss: 0.04658155, g_loss: 3.96582389\n",
      "Epoch: [194] [   5/  60] time: 5.9020, d_loss: 0.03409193, g_loss: 4.70624161\n",
      "Epoch: [194] [   6/  60] time: 6.3868, d_loss: 0.06500069, g_loss: 4.94696665\n",
      "Epoch: [194] [   7/  60] time: 6.8666, d_loss: 0.05941139, g_loss: 4.61221170\n",
      "Epoch: [194] [   8/  60] time: 7.3267, d_loss: 0.04575770, g_loss: 5.47759295\n",
      "Epoch: [194] [   9/  60] time: 7.7858, d_loss: 0.03894072, g_loss: 4.52111149\n",
      "Epoch: [194] [  10/  60] time: 8.2442, d_loss: 0.07605755, g_loss: 4.37304926\n",
      "Epoch: [194] [  11/  60] time: 8.7044, d_loss: 0.09761155, g_loss: 4.35470581\n",
      "Epoch: [194] [  12/  60] time: 9.1633, d_loss: 0.04075095, g_loss: 4.42598343\n",
      "Epoch: [194] [  13/  60] time: 9.6438, d_loss: 0.06654149, g_loss: 4.40871334\n",
      "Epoch: [194] [  14/  60] time: 10.1209, d_loss: 0.04136315, g_loss: 4.98457861\n",
      "Epoch: [194] [  15/  60] time: 10.5781, d_loss: 0.04005969, g_loss: 5.35714674\n",
      "Epoch: [194] [  16/  60] time: 11.0545, d_loss: 0.04809467, g_loss: 4.85510254\n",
      "Epoch: [194] [  17/  60] time: 11.5155, d_loss: 0.08294837, g_loss: 4.17266083\n",
      "Epoch: [194] [  18/  60] time: 11.9806, d_loss: 0.05977860, g_loss: 4.15355968\n",
      "Epoch: [194] [  19/  60] time: 12.4465, d_loss: 0.08364330, g_loss: 4.52558565\n",
      "Epoch: [194] [  20/  60] time: 12.9213, d_loss: 0.08607059, g_loss: 4.97853136\n",
      "Epoch: [194] [  21/  60] time: 13.3993, d_loss: 0.05020712, g_loss: 5.28651142\n",
      "Epoch: [194] [  22/  60] time: 13.8625, d_loss: 0.03773248, g_loss: 4.43740416\n",
      "Epoch: [194] [  23/  60] time: 14.3242, d_loss: 0.05832680, g_loss: 3.87768722\n",
      "Epoch: [194] [  24/  60] time: 14.7885, d_loss: 0.07646795, g_loss: 3.66027832\n",
      "Epoch: [194] [  25/  60] time: 15.2571, d_loss: 0.06852771, g_loss: 4.81696606\n",
      "Epoch: [194] [  26/  60] time: 15.7173, d_loss: 0.05864226, g_loss: 4.87488174\n",
      "Epoch: [194] [  27/  60] time: 16.1786, d_loss: 0.04768174, g_loss: 4.47776699\n",
      "Epoch: [194] [  28/  60] time: 16.6447, d_loss: 0.05394980, g_loss: 4.00623322\n",
      "Epoch: [194] [  29/  60] time: 17.1079, d_loss: 0.06113096, g_loss: 4.79253292\n",
      "Epoch: [194] [  30/  60] time: 17.5664, d_loss: 0.08193299, g_loss: 4.91301250\n",
      "Epoch: [194] [  31/  60] time: 18.0221, d_loss: 0.06771068, g_loss: 4.47674131\n",
      "Epoch: [194] [  32/  60] time: 18.4817, d_loss: 0.03766578, g_loss: 4.43565750\n",
      "Epoch: [194] [  33/  60] time: 18.9474, d_loss: 0.05576633, g_loss: 4.01721954\n",
      "Epoch: [194] [  34/  60] time: 19.4124, d_loss: 0.03967894, g_loss: 5.36831808\n",
      "Epoch: [194] [  35/  60] time: 19.8712, d_loss: 0.06871596, g_loss: 3.94476438\n",
      "Epoch: [194] [  36/  60] time: 20.3335, d_loss: 0.08862446, g_loss: 4.32453346\n",
      "Epoch: [194] [  37/  60] time: 20.7905, d_loss: 0.06774295, g_loss: 5.18507528\n",
      "Epoch: [194] [  38/  60] time: 21.2490, d_loss: 0.06095885, g_loss: 5.04045963\n",
      "Epoch: [194] [  39/  60] time: 21.7070, d_loss: 0.04979464, g_loss: 4.98526907\n",
      "Epoch: [194] [  40/  60] time: 22.1665, d_loss: 0.04807419, g_loss: 3.87551188\n",
      "Epoch: [194] [  41/  60] time: 22.6283, d_loss: 0.07715760, g_loss: 3.80649614\n",
      "Epoch: [194] [  42/  60] time: 23.0871, d_loss: 0.03398971, g_loss: 4.39190960\n",
      "Epoch: [194] [  43/  60] time: 23.5443, d_loss: 0.03660966, g_loss: 4.91447210\n",
      "Epoch: [194] [  44/  60] time: 24.0076, d_loss: 0.04712950, g_loss: 4.71831703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [194] [  45/  60] time: 24.4717, d_loss: 0.06856532, g_loss: 4.84311485\n",
      "Epoch: [194] [  46/  60] time: 24.9368, d_loss: 0.08855126, g_loss: 4.02815771\n",
      "Epoch: [194] [  47/  60] time: 25.4012, d_loss: 0.04519202, g_loss: 3.46830058\n",
      "Epoch: [194] [  48/  60] time: 25.8613, d_loss: 0.12589398, g_loss: 5.03662682\n",
      "Epoch: [194] [  49/  60] time: 26.3328, d_loss: 0.06118522, g_loss: 5.06762123\n",
      "Epoch: [194] [  50/  60] time: 26.8081, d_loss: 0.04918308, g_loss: 5.49938679\n",
      "Epoch: [194] [  51/  60] time: 27.2729, d_loss: 0.05498641, g_loss: 4.17603493\n",
      "Epoch: [194] [  52/  60] time: 27.7489, d_loss: 0.06353293, g_loss: 4.38031006\n",
      "Epoch: [194] [  53/  60] time: 28.2118, d_loss: 0.03952925, g_loss: 4.56011581\n",
      "Epoch: [194] [  54/  60] time: 28.6892, d_loss: 0.05028833, g_loss: 5.20901918\n",
      "Epoch: [194] [  55/  60] time: 29.1570, d_loss: 0.03678952, g_loss: 4.57510710\n",
      "Epoch: [194] [  56/  60] time: 29.6213, d_loss: 0.05215177, g_loss: 4.83979177\n",
      "Epoch: [194] [  57/  60] time: 30.0884, d_loss: 0.03826317, g_loss: 4.16320038\n",
      "Epoch: [194] [  58/  60] time: 30.5727, d_loss: 0.09462275, g_loss: 5.17245626\n",
      "Epoch: [194] [  59/  60] time: 31.0513, d_loss: 0.09434325, g_loss: 4.15108204\n",
      "[194/200] - ptime: 31.0739 loss_d: 0.05949118, loss_g: 4.57362700, lf:  0.00007748\n",
      "Epoch: [195] [   0/  60] time: 47.6955, d_loss: 0.04451334, g_loss: 4.27281380\n",
      "Epoch: [195] [   1/  60] time: 48.1588, d_loss: 0.04649774, g_loss: 4.16756678\n",
      "Epoch: [195] [   2/  60] time: 48.6223, d_loss: 0.05673325, g_loss: 4.23972225\n",
      "Epoch: [195] [   3/  60] time: 49.0870, d_loss: 0.05138064, g_loss: 4.92279482\n",
      "Epoch: [195] [   4/  60] time: 49.5463, d_loss: 0.01773305, g_loss: 4.92314291\n",
      "Epoch: [195] [   5/  60] time: 50.0039, d_loss: 0.05555793, g_loss: 4.39249802\n",
      "Epoch: [195] [   6/  60] time: 50.4691, d_loss: 0.03233606, g_loss: 4.50808811\n",
      "Epoch: [195] [   7/  60] time: 50.9300, d_loss: 0.04630929, g_loss: 4.58992004\n",
      "Epoch: [195] [   8/  60] time: 51.3978, d_loss: 0.05527315, g_loss: 4.94256735\n",
      "Epoch: [195] [   9/  60] time: 51.8564, d_loss: 0.03281754, g_loss: 4.67740774\n",
      "Epoch: [195] [  10/  60] time: 52.3213, d_loss: 0.04479783, g_loss: 4.20278645\n",
      "Epoch: [195] [  11/  60] time: 52.7840, d_loss: 0.05992453, g_loss: 4.44579077\n",
      "Epoch: [195] [  12/  60] time: 53.2572, d_loss: 0.04388626, g_loss: 5.24420738\n",
      "Epoch: [195] [  13/  60] time: 53.7239, d_loss: 0.05551407, g_loss: 4.46047878\n",
      "Epoch: [195] [  14/  60] time: 54.2023, d_loss: 0.08172148, g_loss: 3.90462041\n",
      "Epoch: [195] [  15/  60] time: 54.6700, d_loss: 0.06438280, g_loss: 3.92496109\n",
      "Epoch: [195] [  16/  60] time: 55.1373, d_loss: 0.07342719, g_loss: 4.38670969\n",
      "Epoch: [195] [  17/  60] time: 55.5990, d_loss: 0.06964422, g_loss: 4.55669546\n",
      "Epoch: [195] [  18/  60] time: 56.0622, d_loss: 0.03020654, g_loss: 5.19474888\n",
      "Epoch: [195] [  19/  60] time: 56.5271, d_loss: 0.08202457, g_loss: 5.13025665\n",
      "Epoch: [195] [  20/  60] time: 57.0154, d_loss: 0.09299681, g_loss: 3.25332212\n",
      "Epoch: [195] [  21/  60] time: 57.4999, d_loss: 0.11747518, g_loss: 3.89956856\n",
      "Epoch: [195] [  22/  60] time: 57.9878, d_loss: 0.07462355, g_loss: 4.94524670\n",
      "Epoch: [195] [  23/  60] time: 58.4827, d_loss: 0.05006632, g_loss: 5.01760292\n",
      "Epoch: [195] [  24/  60] time: 58.9468, d_loss: 0.13799006, g_loss: 3.65855527\n",
      "Epoch: [195] [  25/  60] time: 59.4331, d_loss: 0.04673402, g_loss: 4.11730576\n",
      "Epoch: [195] [  26/  60] time: 59.9171, d_loss: 0.14763854, g_loss: 4.93849325\n",
      "Epoch: [195] [  27/  60] time: 60.4021, d_loss: 0.04944523, g_loss: 5.90622091\n",
      "Epoch: [195] [  28/  60] time: 60.8795, d_loss: 0.14554672, g_loss: 3.59358740\n",
      "Epoch: [195] [  29/  60] time: 61.3422, d_loss: 0.10312292, g_loss: 3.90212440\n",
      "Epoch: [195] [  30/  60] time: 61.8161, d_loss: 0.12228700, g_loss: 5.85344887\n",
      "Epoch: [195] [  31/  60] time: 62.2766, d_loss: 0.18096973, g_loss: 3.31493187\n",
      "Epoch: [195] [  32/  60] time: 62.7439, d_loss: 0.10502246, g_loss: 3.87498045\n",
      "Epoch: [195] [  33/  60] time: 63.2248, d_loss: 0.11404639, g_loss: 5.66148567\n",
      "Epoch: [195] [  34/  60] time: 63.7062, d_loss: 0.06751217, g_loss: 5.46773434\n",
      "Epoch: [195] [  35/  60] time: 64.1689, d_loss: 0.19172268, g_loss: 2.68293095\n",
      "Epoch: [195] [  36/  60] time: 64.6347, d_loss: 0.15225670, g_loss: 4.40959406\n",
      "Epoch: [195] [  37/  60] time: 65.1259, d_loss: 0.10197838, g_loss: 5.07562160\n",
      "Epoch: [195] [  38/  60] time: 65.6015, d_loss: 0.05447328, g_loss: 5.50986576\n",
      "Epoch: [195] [  39/  60] time: 66.0813, d_loss: 0.06981771, g_loss: 4.62510872\n",
      "Epoch: [195] [  40/  60] time: 66.5580, d_loss: 0.03621335, g_loss: 4.68972635\n",
      "Epoch: [195] [  41/  60] time: 67.0282, d_loss: 0.03402035, g_loss: 4.25938416\n",
      "Epoch: [195] [  42/  60] time: 67.4903, d_loss: 0.05138343, g_loss: 4.51071739\n",
      "Epoch: [195] [  43/  60] time: 67.9582, d_loss: 0.03340803, g_loss: 5.28324032\n",
      "Epoch: [195] [  44/  60] time: 68.4250, d_loss: 0.03617894, g_loss: 4.53454733\n",
      "Epoch: [195] [  45/  60] time: 68.9049, d_loss: 0.04035703, g_loss: 4.54043770\n",
      "Epoch: [195] [  46/  60] time: 69.3795, d_loss: 0.03446334, g_loss: 4.82011318\n",
      "Epoch: [195] [  47/  60] time: 69.8481, d_loss: 0.05489141, g_loss: 4.84773588\n",
      "Epoch: [195] [  48/  60] time: 70.3322, d_loss: 0.04974235, g_loss: 4.82278585\n",
      "Epoch: [195] [  49/  60] time: 70.8037, d_loss: 0.04486762, g_loss: 5.26170731\n",
      "Epoch: [195] [  50/  60] time: 71.2663, d_loss: 0.05132177, g_loss: 4.71658230\n",
      "Epoch: [195] [  51/  60] time: 71.7267, d_loss: 0.04816754, g_loss: 4.66813469\n",
      "Epoch: [195] [  52/  60] time: 72.1873, d_loss: 0.06017081, g_loss: 4.48205948\n",
      "Epoch: [195] [  53/  60] time: 72.6745, d_loss: 0.05627345, g_loss: 4.57214832\n",
      "Epoch: [195] [  54/  60] time: 73.1558, d_loss: 0.10227369, g_loss: 4.40392017\n",
      "Epoch: [195] [  55/  60] time: 73.6359, d_loss: 0.06469185, g_loss: 4.56868553\n",
      "Epoch: [195] [  56/  60] time: 74.1010, d_loss: 0.04074839, g_loss: 4.56143093\n",
      "Epoch: [195] [  57/  60] time: 74.5626, d_loss: 0.06041059, g_loss: 4.26765490\n",
      "Epoch: [195] [  58/  60] time: 75.0420, d_loss: 0.02985825, g_loss: 4.50069189\n",
      "Epoch: [195] [  59/  60] time: 75.5272, d_loss: 0.04915681, g_loss: 4.85141802\n",
      "[195/200] - ptime: 28.7202 loss_d: 0.06915010, loss_g: 4.56597757, lf:  0.00007748\n",
      "Epoch: [196] [   0/  60] time: 91.8053, d_loss: 0.03634430, g_loss: 4.85571909\n",
      "Epoch: [196] [   1/  60] time: 92.2688, d_loss: 0.04717417, g_loss: 5.55505753\n",
      "Epoch: [196] [   2/  60] time: 92.7293, d_loss: 0.04746499, g_loss: 4.93067694\n",
      "Epoch: [196] [   3/  60] time: 93.1912, d_loss: 0.02457949, g_loss: 4.75091600\n",
      "Epoch: [196] [   4/  60] time: 93.6564, d_loss: 0.03091717, g_loss: 4.55159950\n",
      "Epoch: [196] [   5/  60] time: 94.1148, d_loss: 0.06594487, g_loss: 5.38473892\n",
      "Epoch: [196] [   6/  60] time: 94.5753, d_loss: 0.05182022, g_loss: 4.82827997\n",
      "Epoch: [196] [   7/  60] time: 95.0323, d_loss: 0.05060505, g_loss: 4.57520962\n",
      "Epoch: [196] [   8/  60] time: 95.4943, d_loss: 0.05153269, g_loss: 4.02654505\n",
      "Epoch: [196] [   9/  60] time: 95.9626, d_loss: 0.04559105, g_loss: 4.52112103\n",
      "Epoch: [196] [  10/  60] time: 96.4210, d_loss: 0.05442648, g_loss: 4.41107941\n",
      "Epoch: [196] [  11/  60] time: 96.8773, d_loss: 0.06547106, g_loss: 4.62473345\n",
      "Epoch: [196] [  12/  60] time: 97.3384, d_loss: 0.03497421, g_loss: 5.32916498\n",
      "Epoch: [196] [  13/  60] time: 97.8040, d_loss: 0.04508997, g_loss: 4.63231564\n",
      "Epoch: [196] [  14/  60] time: 98.2672, d_loss: 0.05256934, g_loss: 4.52594471\n",
      "Epoch: [196] [  15/  60] time: 98.7440, d_loss: 0.06293083, g_loss: 4.51571512\n",
      "Epoch: [196] [  16/  60] time: 99.2079, d_loss: 0.03447130, g_loss: 4.77092934\n",
      "Epoch: [196] [  17/  60] time: 99.6702, d_loss: 0.06172235, g_loss: 4.90411377\n",
      "Epoch: [196] [  18/  60] time: 100.1288, d_loss: 0.03518544, g_loss: 4.94751453\n",
      "Epoch: [196] [  19/  60] time: 100.5955, d_loss: 0.04069171, g_loss: 5.54632092\n",
      "Epoch: [196] [  20/  60] time: 101.0588, d_loss: 0.08080751, g_loss: 3.91058707\n",
      "Epoch: [196] [  21/  60] time: 101.5237, d_loss: 0.02948576, g_loss: 4.57477760\n",
      "Epoch: [196] [  22/  60] time: 101.9830, d_loss: 0.05977264, g_loss: 4.97518444\n",
      "Epoch: [196] [  23/  60] time: 102.4438, d_loss: 0.03096668, g_loss: 4.38718987\n",
      "Epoch: [196] [  24/  60] time: 102.9054, d_loss: 0.06116274, g_loss: 5.14248896\n",
      "Epoch: [196] [  25/  60] time: 103.3718, d_loss: 0.03685988, g_loss: 4.21973324\n",
      "Epoch: [196] [  26/  60] time: 103.8317, d_loss: 0.06369683, g_loss: 4.40160799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [196] [  27/  60] time: 104.2935, d_loss: 0.04975280, g_loss: 4.45365429\n",
      "Epoch: [196] [  28/  60] time: 104.7542, d_loss: 0.07150847, g_loss: 5.02605724\n",
      "Epoch: [196] [  29/  60] time: 105.2366, d_loss: 0.04799389, g_loss: 5.33975697\n",
      "Epoch: [196] [  30/  60] time: 105.7016, d_loss: 0.05783553, g_loss: 4.20861197\n",
      "Epoch: [196] [  31/  60] time: 106.1661, d_loss: 0.03800731, g_loss: 4.07607841\n",
      "Epoch: [196] [  32/  60] time: 106.6291, d_loss: 0.05017956, g_loss: 4.39074898\n",
      "Epoch: [196] [  33/  60] time: 107.0973, d_loss: 0.09258578, g_loss: 5.07843113\n",
      "Epoch: [196] [  34/  60] time: 107.5854, d_loss: 0.08011502, g_loss: 5.35803032\n",
      "Epoch: [196] [  35/  60] time: 108.0509, d_loss: 0.02707359, g_loss: 4.37766504\n",
      "Epoch: [196] [  36/  60] time: 108.5152, d_loss: 0.05904130, g_loss: 4.59938622\n",
      "Epoch: [196] [  37/  60] time: 108.9808, d_loss: 0.03780190, g_loss: 4.90116072\n",
      "Epoch: [196] [  38/  60] time: 109.4431, d_loss: 0.05969931, g_loss: 4.93968439\n",
      "Epoch: [196] [  39/  60] time: 109.9135, d_loss: 0.05173504, g_loss: 4.19319487\n",
      "Epoch: [196] [  40/  60] time: 110.3945, d_loss: 0.04992601, g_loss: 4.10934162\n",
      "Epoch: [196] [  41/  60] time: 110.8615, d_loss: 0.04974501, g_loss: 4.85271549\n",
      "Epoch: [196] [  42/  60] time: 111.3277, d_loss: 0.03507270, g_loss: 5.55248165\n",
      "Epoch: [196] [  43/  60] time: 111.7912, d_loss: 0.02322997, g_loss: 5.15095139\n",
      "Epoch: [196] [  44/  60] time: 112.2553, d_loss: 0.05640274, g_loss: 4.41663027\n",
      "Epoch: [196] [  45/  60] time: 112.7169, d_loss: 0.05692282, g_loss: 4.78796244\n",
      "Epoch: [196] [  46/  60] time: 113.1829, d_loss: 0.07878338, g_loss: 4.25876760\n",
      "Epoch: [196] [  47/  60] time: 113.6433, d_loss: 0.03940257, g_loss: 3.94635272\n",
      "Epoch: [196] [  48/  60] time: 114.1030, d_loss: 0.03336557, g_loss: 4.81696224\n",
      "Epoch: [196] [  49/  60] time: 114.5612, d_loss: 0.04523487, g_loss: 5.04103470\n",
      "Epoch: [196] [  50/  60] time: 115.0247, d_loss: 0.03339230, g_loss: 5.48559618\n",
      "Epoch: [196] [  51/  60] time: 115.4888, d_loss: 0.04307314, g_loss: 4.75066710\n",
      "Epoch: [196] [  52/  60] time: 115.9486, d_loss: 0.08523561, g_loss: 4.09516144\n",
      "Epoch: [196] [  53/  60] time: 116.4123, d_loss: 0.05177981, g_loss: 4.41103840\n",
      "Epoch: [196] [  54/  60] time: 116.8727, d_loss: 0.03815169, g_loss: 4.86257648\n",
      "Epoch: [196] [  55/  60] time: 117.3360, d_loss: 0.04365619, g_loss: 4.83285713\n",
      "Epoch: [196] [  56/  60] time: 117.8010, d_loss: 0.04739023, g_loss: 4.81278515\n",
      "Epoch: [196] [  57/  60] time: 118.2676, d_loss: 0.04864623, g_loss: 4.76582909\n",
      "Epoch: [196] [  58/  60] time: 118.7289, d_loss: 0.03533655, g_loss: 4.67756605\n",
      "Epoch: [196] [  59/  60] time: 119.1897, d_loss: 0.03632554, g_loss: 4.93905830\n",
      "[196/200] - ptime: 28.2566 loss_d: 0.04927769, loss_g: 4.72180080, lf:  0.00007748\n",
      "Epoch: [197] [   0/  60] time: 135.3100, d_loss: 0.03295462, g_loss: 5.22362709\n",
      "Epoch: [197] [   1/  60] time: 135.7710, d_loss: 0.05372915, g_loss: 4.32947397\n",
      "Epoch: [197] [   2/  60] time: 136.2340, d_loss: 0.07868613, g_loss: 4.97205353\n",
      "Epoch: [197] [   3/  60] time: 136.6983, d_loss: 0.09264423, g_loss: 3.58339930\n",
      "Epoch: [197] [   4/  60] time: 137.1712, d_loss: 0.05952515, g_loss: 3.69944119\n",
      "Epoch: [197] [   5/  60] time: 137.6617, d_loss: 0.05820532, g_loss: 4.77458096\n",
      "Epoch: [197] [   6/  60] time: 138.1399, d_loss: 0.03975166, g_loss: 5.10085440\n",
      "Epoch: [197] [   7/  60] time: 138.6208, d_loss: 0.05447558, g_loss: 5.85995007\n",
      "Epoch: [197] [   8/  60] time: 139.0911, d_loss: 0.05062827, g_loss: 4.94510365\n",
      "Epoch: [197] [   9/  60] time: 139.5565, d_loss: 0.04809063, g_loss: 4.28510427\n",
      "Epoch: [197] [  10/  60] time: 140.0505, d_loss: 0.04812721, g_loss: 3.86036444\n",
      "Epoch: [197] [  11/  60] time: 140.5351, d_loss: 0.05216579, g_loss: 4.51658821\n",
      "Epoch: [197] [  12/  60] time: 141.0074, d_loss: 0.04326854, g_loss: 4.73345375\n",
      "Epoch: [197] [  13/  60] time: 141.5018, d_loss: 0.05089327, g_loss: 4.60670853\n",
      "Epoch: [197] [  14/  60] time: 141.9792, d_loss: 0.05677275, g_loss: 4.40887117\n",
      "Epoch: [197] [  15/  60] time: 142.4556, d_loss: 0.02991442, g_loss: 4.01456022\n",
      "Epoch: [197] [  16/  60] time: 142.9318, d_loss: 0.08970544, g_loss: 5.17120123\n",
      "Epoch: [197] [  17/  60] time: 143.3935, d_loss: 0.04258268, g_loss: 6.07102060\n",
      "Epoch: [197] [  18/  60] time: 143.8559, d_loss: 0.04685900, g_loss: 4.53277302\n",
      "Epoch: [197] [  19/  60] time: 144.3173, d_loss: 0.04672258, g_loss: 4.59172964\n",
      "Epoch: [197] [  20/  60] time: 144.7852, d_loss: 0.03237361, g_loss: 4.63921070\n",
      "Epoch: [197] [  21/  60] time: 145.2540, d_loss: 0.06541637, g_loss: 4.94033432\n",
      "Epoch: [197] [  22/  60] time: 145.7233, d_loss: 0.04287765, g_loss: 5.02748394\n",
      "Epoch: [197] [  23/  60] time: 146.1876, d_loss: 0.03930626, g_loss: 4.81054640\n",
      "Epoch: [197] [  24/  60] time: 146.6494, d_loss: 0.04375602, g_loss: 4.50136137\n",
      "Epoch: [197] [  25/  60] time: 147.1142, d_loss: 0.03033873, g_loss: 4.41134977\n",
      "Epoch: [197] [  26/  60] time: 147.5739, d_loss: 0.06641692, g_loss: 4.84771776\n",
      "Epoch: [197] [  27/  60] time: 148.0411, d_loss: 0.02556605, g_loss: 4.88117599\n",
      "Epoch: [197] [  28/  60] time: 148.5078, d_loss: 0.04394562, g_loss: 5.01423979\n",
      "Epoch: [197] [  29/  60] time: 148.9802, d_loss: 0.04603478, g_loss: 5.12379360\n",
      "Epoch: [197] [  30/  60] time: 149.4451, d_loss: 0.06150119, g_loss: 4.14623880\n",
      "Epoch: [197] [  31/  60] time: 149.9107, d_loss: 0.07271770, g_loss: 4.30296993\n",
      "Epoch: [197] [  32/  60] time: 150.3740, d_loss: 0.04448290, g_loss: 5.27278280\n",
      "Epoch: [197] [  33/  60] time: 150.8389, d_loss: 0.05049666, g_loss: 5.03873253\n",
      "Epoch: [197] [  34/  60] time: 151.3064, d_loss: 0.03795265, g_loss: 4.30701303\n",
      "Epoch: [197] [  35/  60] time: 151.7718, d_loss: 0.05289230, g_loss: 4.75389767\n",
      "Epoch: [197] [  36/  60] time: 152.2342, d_loss: 0.05205473, g_loss: 4.91973257\n",
      "Epoch: [197] [  37/  60] time: 152.7019, d_loss: 0.03783897, g_loss: 4.93564987\n",
      "Epoch: [197] [  38/  60] time: 153.1679, d_loss: 0.05088577, g_loss: 4.25716686\n",
      "Epoch: [197] [  39/  60] time: 153.6331, d_loss: 0.02554420, g_loss: 5.43427181\n",
      "Epoch: [197] [  40/  60] time: 154.0997, d_loss: 0.03717643, g_loss: 4.01984119\n",
      "Epoch: [197] [  41/  60] time: 154.5616, d_loss: 0.05374302, g_loss: 3.91222143\n",
      "Epoch: [197] [  42/  60] time: 155.0388, d_loss: 0.05534191, g_loss: 4.32252359\n",
      "Epoch: [197] [  43/  60] time: 155.5268, d_loss: 0.03769976, g_loss: 4.67843008\n",
      "Epoch: [197] [  44/  60] time: 156.0137, d_loss: 0.04344139, g_loss: 4.10836411\n",
      "Epoch: [197] [  45/  60] time: 156.4953, d_loss: 0.07974188, g_loss: 3.61692524\n",
      "Epoch: [197] [  46/  60] time: 156.9637, d_loss: 0.07757748, g_loss: 5.22182846\n",
      "Epoch: [197] [  47/  60] time: 157.4286, d_loss: 0.04600457, g_loss: 5.19751549\n",
      "Epoch: [197] [  48/  60] time: 157.9122, d_loss: 0.03457140, g_loss: 4.85084724\n",
      "Epoch: [197] [  49/  60] time: 158.4049, d_loss: 0.05686374, g_loss: 4.83211040\n",
      "Epoch: [197] [  50/  60] time: 158.8865, d_loss: 0.03298345, g_loss: 4.05282402\n",
      "Epoch: [197] [  51/  60] time: 159.3555, d_loss: 0.09235871, g_loss: 6.12077665\n",
      "Epoch: [197] [  52/  60] time: 159.8351, d_loss: 0.04651672, g_loss: 5.39957619\n",
      "Epoch: [197] [  53/  60] time: 160.3143, d_loss: 0.05246123, g_loss: 5.40144253\n",
      "Epoch: [197] [  54/  60] time: 160.7996, d_loss: 0.04464629, g_loss: 4.71372461\n",
      "Epoch: [197] [  55/  60] time: 161.2684, d_loss: 0.04336876, g_loss: 3.95450926\n",
      "Epoch: [197] [  56/  60] time: 161.7464, d_loss: 0.03789587, g_loss: 5.22500849\n",
      "Epoch: [197] [  57/  60] time: 162.2127, d_loss: 0.05099770, g_loss: 3.81469464\n",
      "Epoch: [197] [  58/  60] time: 162.6787, d_loss: 0.03382495, g_loss: 4.41998148\n",
      "Epoch: [197] [  59/  60] time: 163.1418, d_loss: 0.06012478, g_loss: 4.20798779\n",
      "[197/200] - ptime: 28.7378 loss_d: 0.05025736, loss_g: 4.68196106, lf:  0.00007748\n",
      "Epoch: [198] [   0/  60] time: 179.4942, d_loss: 0.07990049, g_loss: 4.01923418\n",
      "Epoch: [198] [   1/  60] time: 179.9611, d_loss: 0.04479977, g_loss: 4.35633802\n",
      "Epoch: [198] [   2/  60] time: 180.4301, d_loss: 0.05528153, g_loss: 4.97889853\n",
      "Epoch: [198] [   3/  60] time: 180.9175, d_loss: 0.13284722, g_loss: 3.15773106\n",
      "Epoch: [198] [   4/  60] time: 181.3859, d_loss: 0.15929550, g_loss: 5.44358540\n",
      "Epoch: [198] [   5/  60] time: 181.8641, d_loss: 0.06240390, g_loss: 5.66206169\n",
      "Epoch: [198] [   6/  60] time: 182.3356, d_loss: 0.12719567, g_loss: 3.81322002\n",
      "Epoch: [198] [   7/  60] time: 182.8046, d_loss: 0.09165207, g_loss: 3.61923957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [198] [   8/  60] time: 183.2754, d_loss: 0.08473474, g_loss: 4.84861565\n",
      "Epoch: [198] [   9/  60] time: 183.7528, d_loss: 0.03684603, g_loss: 5.32169962\n",
      "Epoch: [198] [  10/  60] time: 184.2203, d_loss: 0.05784702, g_loss: 4.72110176\n",
      "Epoch: [198] [  11/  60] time: 184.6942, d_loss: 0.03909322, g_loss: 4.32872009\n",
      "Epoch: [198] [  12/  60] time: 185.1612, d_loss: 0.08225904, g_loss: 3.91064715\n",
      "Epoch: [198] [  13/  60] time: 185.6243, d_loss: 0.05837026, g_loss: 4.37937450\n",
      "Epoch: [198] [  14/  60] time: 186.0938, d_loss: 0.05259188, g_loss: 4.91894484\n",
      "Epoch: [198] [  15/  60] time: 186.5607, d_loss: 0.03655646, g_loss: 4.60840893\n",
      "Epoch: [198] [  16/  60] time: 187.0316, d_loss: 0.06903021, g_loss: 5.56140900\n",
      "Epoch: [198] [  17/  60] time: 187.4984, d_loss: 0.05134577, g_loss: 4.52007341\n",
      "Epoch: [198] [  18/  60] time: 187.9721, d_loss: 0.06101703, g_loss: 3.85306072\n",
      "Epoch: [198] [  19/  60] time: 188.4598, d_loss: 0.04353867, g_loss: 4.42543030\n",
      "Epoch: [198] [  20/  60] time: 188.9311, d_loss: 0.04675476, g_loss: 4.53670740\n",
      "Epoch: [198] [  21/  60] time: 189.4049, d_loss: 0.03566545, g_loss: 5.14513111\n",
      "Epoch: [198] [  22/  60] time: 189.8712, d_loss: 0.04661014, g_loss: 5.43520260\n",
      "Epoch: [198] [  23/  60] time: 190.3604, d_loss: 0.03193429, g_loss: 5.04819250\n",
      "Epoch: [198] [  24/  60] time: 190.8456, d_loss: 0.07535052, g_loss: 3.57410407\n",
      "Epoch: [198] [  25/  60] time: 191.3230, d_loss: 0.05305236, g_loss: 4.44469690\n",
      "Epoch: [198] [  26/  60] time: 191.7863, d_loss: 0.04288144, g_loss: 5.06088686\n",
      "Epoch: [198] [  27/  60] time: 192.2742, d_loss: 0.03068202, g_loss: 4.13765621\n",
      "Epoch: [198] [  28/  60] time: 192.7440, d_loss: 0.03014721, g_loss: 4.51351404\n",
      "Epoch: [198] [  29/  60] time: 193.2080, d_loss: 0.08298407, g_loss: 4.16919947\n",
      "Epoch: [198] [  30/  60] time: 193.6770, d_loss: 0.04879094, g_loss: 4.64700699\n",
      "Epoch: [198] [  31/  60] time: 194.1759, d_loss: 0.04405761, g_loss: 4.85197210\n",
      "Epoch: [198] [  32/  60] time: 194.6641, d_loss: 0.04118413, g_loss: 4.49518347\n",
      "Epoch: [198] [  33/  60] time: 195.1380, d_loss: 0.03844083, g_loss: 5.04815483\n",
      "Epoch: [198] [  34/  60] time: 195.6344, d_loss: 0.03544934, g_loss: 5.19625235\n",
      "Epoch: [198] [  35/  60] time: 196.1064, d_loss: 0.03717088, g_loss: 4.79668140\n",
      "Epoch: [198] [  36/  60] time: 196.5720, d_loss: 0.08152672, g_loss: 3.77396607\n",
      "Epoch: [198] [  37/  60] time: 197.0583, d_loss: 0.03267132, g_loss: 4.36459208\n",
      "Epoch: [198] [  38/  60] time: 197.5198, d_loss: 0.05516179, g_loss: 4.70277309\n",
      "Epoch: [198] [  39/  60] time: 197.9871, d_loss: 0.07392744, g_loss: 4.34834051\n",
      "Epoch: [198] [  40/  60] time: 198.4518, d_loss: 0.03153928, g_loss: 5.06838799\n",
      "Epoch: [198] [  41/  60] time: 198.9193, d_loss: 0.04643517, g_loss: 4.69557667\n",
      "Epoch: [198] [  42/  60] time: 199.3843, d_loss: 0.04158719, g_loss: 4.75894260\n",
      "Epoch: [198] [  43/  60] time: 199.8565, d_loss: 0.04826708, g_loss: 4.46153736\n",
      "Epoch: [198] [  44/  60] time: 200.3218, d_loss: 0.04867163, g_loss: 4.76480675\n",
      "Epoch: [198] [  45/  60] time: 200.7907, d_loss: 0.04376017, g_loss: 5.37027168\n",
      "Epoch: [198] [  46/  60] time: 201.2552, d_loss: 0.03398243, g_loss: 5.30637932\n",
      "Epoch: [198] [  47/  60] time: 201.7170, d_loss: 0.02984384, g_loss: 5.20730639\n",
      "Epoch: [198] [  48/  60] time: 202.1870, d_loss: 0.04589785, g_loss: 4.80620527\n",
      "Epoch: [198] [  49/  60] time: 202.6520, d_loss: 0.04656355, g_loss: 4.61259747\n",
      "Epoch: [198] [  50/  60] time: 203.1166, d_loss: 0.05005949, g_loss: 4.88818026\n",
      "Epoch: [198] [  51/  60] time: 203.5767, d_loss: 0.05023813, g_loss: 4.43820095\n",
      "Epoch: [198] [  52/  60] time: 204.0417, d_loss: 0.06127539, g_loss: 5.17790031\n",
      "Epoch: [198] [  53/  60] time: 204.5139, d_loss: 0.03305344, g_loss: 5.21946335\n",
      "Epoch: [198] [  54/  60] time: 204.9801, d_loss: 0.04623346, g_loss: 5.47084904\n",
      "Epoch: [198] [  55/  60] time: 205.4407, d_loss: 0.08390692, g_loss: 4.13022900\n",
      "Epoch: [198] [  56/  60] time: 205.9066, d_loss: 0.02629234, g_loss: 4.80242538\n",
      "Epoch: [198] [  57/  60] time: 206.3671, d_loss: 0.05328949, g_loss: 5.47116852\n",
      "Epoch: [198] [  58/  60] time: 206.8328, d_loss: 0.03335377, g_loss: 5.57142830\n",
      "Epoch: [198] [  59/  60] time: 207.2935, d_loss: 0.03504616, g_loss: 4.87383556\n",
      "[198/200] - ptime: 28.6712 loss_d: 0.05467244, loss_g: 4.69722843, lf:  0.00007748\n",
      "Epoch: [199] [   0/  60] time: 223.6913, d_loss: 0.05484629, g_loss: 4.71024132\n",
      "Epoch: [199] [   1/  60] time: 224.1572, d_loss: 0.02948731, g_loss: 4.17976236\n",
      "Epoch: [199] [   2/  60] time: 224.6273, d_loss: 0.05969352, g_loss: 4.42527103\n",
      "Epoch: [199] [   3/  60] time: 225.0954, d_loss: 0.04197084, g_loss: 4.26631451\n",
      "Epoch: [199] [   4/  60] time: 225.5620, d_loss: 0.03024102, g_loss: 4.80726957\n",
      "Epoch: [199] [   5/  60] time: 226.0322, d_loss: 0.05174456, g_loss: 4.81135607\n",
      "Epoch: [199] [   6/  60] time: 226.5053, d_loss: 0.03324162, g_loss: 4.85836220\n",
      "Epoch: [199] [   7/  60] time: 226.9996, d_loss: 0.04717522, g_loss: 4.32751799\n",
      "Epoch: [199] [   8/  60] time: 227.4958, d_loss: 0.03844481, g_loss: 4.92684603\n",
      "Epoch: [199] [   9/  60] time: 227.9641, d_loss: 0.05125705, g_loss: 4.23700714\n",
      "Epoch: [199] [  10/  60] time: 228.4363, d_loss: 0.05906245, g_loss: 4.19167757\n",
      "Epoch: [199] [  11/  60] time: 228.9230, d_loss: 0.05734411, g_loss: 5.01068258\n",
      "Epoch: [199] [  12/  60] time: 229.4004, d_loss: 0.04743792, g_loss: 5.52349663\n",
      "Epoch: [199] [  13/  60] time: 229.8734, d_loss: 0.03928923, g_loss: 4.94497395\n",
      "Epoch: [199] [  14/  60] time: 230.3433, d_loss: 0.03289209, g_loss: 4.59985447\n",
      "Epoch: [199] [  15/  60] time: 230.8136, d_loss: 0.07876693, g_loss: 4.05823231\n",
      "Epoch: [199] [  16/  60] time: 231.2800, d_loss: 0.02863702, g_loss: 4.62854624\n",
      "Epoch: [199] [  17/  60] time: 231.7440, d_loss: 0.02850219, g_loss: 5.17507267\n",
      "Epoch: [199] [  18/  60] time: 232.2283, d_loss: 0.06280559, g_loss: 5.22301674\n",
      "Epoch: [199] [  19/  60] time: 232.7279, d_loss: 0.02964652, g_loss: 3.70777535\n",
      "Epoch: [199] [  20/  60] time: 233.2223, d_loss: 0.04303868, g_loss: 4.61416340\n",
      "Epoch: [199] [  21/  60] time: 233.7061, d_loss: 0.08157758, g_loss: 4.70361567\n",
      "Epoch: [199] [  22/  60] time: 234.1952, d_loss: 0.03586518, g_loss: 4.64608574\n",
      "Epoch: [199] [  23/  60] time: 234.6749, d_loss: 0.03912669, g_loss: 4.59762812\n",
      "Epoch: [199] [  24/  60] time: 235.1491, d_loss: 0.02986034, g_loss: 5.22821474\n",
      "Epoch: [199] [  25/  60] time: 235.6335, d_loss: 0.03311583, g_loss: 5.21855736\n",
      "Epoch: [199] [  26/  60] time: 236.1354, d_loss: 0.05559160, g_loss: 4.28815079\n",
      "Epoch: [199] [  27/  60] time: 236.6199, d_loss: 0.05063714, g_loss: 4.97175455\n",
      "Epoch: [199] [  28/  60] time: 237.1108, d_loss: 0.02856046, g_loss: 5.29548359\n",
      "Epoch: [199] [  29/  60] time: 237.5895, d_loss: 0.04092466, g_loss: 4.92979527\n",
      "Epoch: [199] [  30/  60] time: 238.0682, d_loss: 0.03652635, g_loss: 5.07371140\n",
      "Epoch: [199] [  31/  60] time: 238.5612, d_loss: 0.03237533, g_loss: 4.42751598\n",
      "Epoch: [199] [  32/  60] time: 239.0513, d_loss: 0.02434035, g_loss: 5.05863428\n",
      "Epoch: [199] [  33/  60] time: 239.5481, d_loss: 0.06884772, g_loss: 4.73408842\n",
      "Epoch: [199] [  34/  60] time: 240.0422, d_loss: 0.03153630, g_loss: 4.90053654\n",
      "Epoch: [199] [  35/  60] time: 240.5362, d_loss: 0.04628841, g_loss: 5.17805862\n",
      "Epoch: [199] [  36/  60] time: 241.0081, d_loss: 0.04528211, g_loss: 4.07123995\n",
      "Epoch: [199] [  37/  60] time: 241.4755, d_loss: 0.06236718, g_loss: 5.13697577\n",
      "Epoch: [199] [  38/  60] time: 241.9573, d_loss: 0.03140743, g_loss: 5.18430328\n",
      "Epoch: [199] [  39/  60] time: 242.4650, d_loss: 0.03817119, g_loss: 4.77244473\n",
      "Epoch: [199] [  40/  60] time: 242.9587, d_loss: 0.03195023, g_loss: 5.44189882\n",
      "Epoch: [199] [  41/  60] time: 243.4371, d_loss: 0.03464144, g_loss: 5.03437471\n",
      "Epoch: [199] [  42/  60] time: 243.9394, d_loss: 0.05689228, g_loss: 4.51048851\n",
      "Epoch: [199] [  43/  60] time: 244.4247, d_loss: 0.05758631, g_loss: 4.00807905\n",
      "Epoch: [199] [  44/  60] time: 244.9322, d_loss: 0.08032084, g_loss: 5.25987816\n",
      "Epoch: [199] [  45/  60] time: 245.4310, d_loss: 0.07556002, g_loss: 5.03616714\n",
      "Epoch: [199] [  46/  60] time: 245.9396, d_loss: 0.04513156, g_loss: 3.97865558\n",
      "Epoch: [199] [  47/  60] time: 246.4417, d_loss: 0.04232474, g_loss: 4.94291401\n",
      "Epoch: [199] [  48/  60] time: 246.9474, d_loss: 0.04667595, g_loss: 5.74533081\n",
      "Epoch: [199] [  49/  60] time: 247.4545, d_loss: 0.07415071, g_loss: 3.91161537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [199] [  50/  60] time: 247.9545, d_loss: 0.05602770, g_loss: 4.51212358\n",
      "Epoch: [199] [  51/  60] time: 248.4579, d_loss: 0.04786793, g_loss: 4.58382750\n",
      "Epoch: [199] [  52/  60] time: 248.9502, d_loss: 0.03434230, g_loss: 4.98009157\n",
      "Epoch: [199] [  53/  60] time: 249.4519, d_loss: 0.06957927, g_loss: 4.45877218\n",
      "Epoch: [199] [  54/  60] time: 249.9351, d_loss: 0.04185715, g_loss: 4.13032198\n",
      "Epoch: [199] [  55/  60] time: 250.4200, d_loss: 0.04979715, g_loss: 5.15470648\n",
      "Epoch: [199] [  56/  60] time: 250.9211, d_loss: 0.07891736, g_loss: 3.84598017\n",
      "Epoch: [199] [  57/  60] time: 251.4152, d_loss: 0.04727333, g_loss: 4.55680847\n",
      "Epoch: [199] [  58/  60] time: 251.9054, d_loss: 0.02132474, g_loss: 5.51441240\n",
      "Epoch: [199] [  59/  60] time: 252.3839, d_loss: 0.03054039, g_loss: 5.26648092\n",
      "[199/200] - ptime: 29.5673 loss_d: 0.04634481, loss_g: 4.74195242, lf:  0.00007748\n",
      "Epoch: [200] [   0/  60] time: 270.1188, d_loss: 0.04388659, g_loss: 3.65519643\n",
      "Epoch: [200] [   1/  60] time: 270.6515, d_loss: 0.05544708, g_loss: 4.21458530\n",
      "Epoch: [200] [   2/  60] time: 271.1867, d_loss: 0.08953504, g_loss: 5.73376656\n",
      "Epoch: [200] [   3/  60] time: 271.7524, d_loss: 0.08754146, g_loss: 4.29448652\n",
      "Epoch: [200] [   4/  60] time: 272.3138, d_loss: 0.07733754, g_loss: 3.69977546\n",
      "Epoch: [200] [   5/  60] time: 272.8688, d_loss: 0.04303760, g_loss: 4.28072405\n",
      "Epoch: [200] [   6/  60] time: 273.4200, d_loss: 0.06575274, g_loss: 5.21035624\n",
      "Epoch: [200] [   7/  60] time: 273.9864, d_loss: 0.08423239, g_loss: 4.44450283\n",
      "Epoch: [200] [   8/  60] time: 274.4931, d_loss: 0.06825206, g_loss: 4.75822115\n",
      "Epoch: [200] [   9/  60] time: 275.0158, d_loss: 0.03401644, g_loss: 5.35167885\n",
      "Epoch: [200] [  10/  60] time: 275.5458, d_loss: 0.03176496, g_loss: 5.43544674\n",
      "Epoch: [200] [  11/  60] time: 276.0620, d_loss: 0.02984483, g_loss: 4.83943796\n",
      "Epoch: [200] [  12/  60] time: 276.5885, d_loss: 0.02541540, g_loss: 4.90426826\n",
      "Epoch: [200] [  13/  60] time: 277.0933, d_loss: 0.03177324, g_loss: 4.83539724\n",
      "Epoch: [200] [  14/  60] time: 277.6004, d_loss: 0.04300322, g_loss: 4.15979862\n",
      "Epoch: [200] [  15/  60] time: 278.1050, d_loss: 0.08861808, g_loss: 5.79732990\n",
      "Epoch: [200] [  16/  60] time: 278.6338, d_loss: 0.08075032, g_loss: 4.75249624\n",
      "Epoch: [200] [  17/  60] time: 279.1384, d_loss: 0.05388206, g_loss: 4.73803282\n",
      "Epoch: [200] [  18/  60] time: 279.6450, d_loss: 0.05141788, g_loss: 4.78493023\n",
      "Epoch: [200] [  19/  60] time: 280.1535, d_loss: 0.04204395, g_loss: 5.50795746\n",
      "Epoch: [200] [  20/  60] time: 280.6656, d_loss: 0.03964143, g_loss: 4.82270050\n",
      "Epoch: [200] [  21/  60] time: 281.1658, d_loss: 0.02988489, g_loss: 5.12438345\n",
      "Epoch: [200] [  22/  60] time: 281.6718, d_loss: 0.03665631, g_loss: 4.08810711\n",
      "Epoch: [200] [  23/  60] time: 282.1749, d_loss: 0.02735354, g_loss: 4.70279312\n",
      "Epoch: [200] [  24/  60] time: 282.6807, d_loss: 0.05994581, g_loss: 4.51019716\n",
      "Epoch: [200] [  25/  60] time: 283.1765, d_loss: 0.04211995, g_loss: 5.20075798\n",
      "Epoch: [200] [  26/  60] time: 283.6854, d_loss: 0.05415922, g_loss: 4.59491014\n",
      "Epoch: [200] [  27/  60] time: 284.1969, d_loss: 0.05146360, g_loss: 4.63819695\n",
      "Epoch: [200] [  28/  60] time: 284.6972, d_loss: 0.03638077, g_loss: 4.06108189\n",
      "Epoch: [200] [  29/  60] time: 285.1925, d_loss: 0.03117251, g_loss: 4.93418503\n",
      "Epoch: [200] [  30/  60] time: 285.6977, d_loss: 0.02288572, g_loss: 5.39197302\n",
      "Epoch: [200] [  31/  60] time: 286.2040, d_loss: 0.04292376, g_loss: 5.36795521\n",
      "Epoch: [200] [  32/  60] time: 286.6953, d_loss: 0.04885405, g_loss: 4.43526125\n",
      "Epoch: [200] [  33/  60] time: 287.1855, d_loss: 0.03861335, g_loss: 4.37506437\n",
      "Epoch: [200] [  34/  60] time: 287.6817, d_loss: 0.04318371, g_loss: 4.06366158\n",
      "Epoch: [200] [  35/  60] time: 288.1802, d_loss: 0.04481521, g_loss: 4.61829376\n",
      "Epoch: [200] [  36/  60] time: 288.7235, d_loss: 0.04198052, g_loss: 4.92959309\n",
      "Epoch: [200] [  37/  60] time: 289.2317, d_loss: 0.06089718, g_loss: 4.75238705\n",
      "Epoch: [200] [  38/  60] time: 289.7579, d_loss: 0.04877761, g_loss: 4.76593018\n",
      "Epoch: [200] [  39/  60] time: 290.2929, d_loss: 0.03249146, g_loss: 4.82678986\n",
      "Epoch: [200] [  40/  60] time: 290.8162, d_loss: 0.03037746, g_loss: 4.69935894\n",
      "Epoch: [200] [  41/  60] time: 291.3393, d_loss: 0.05664989, g_loss: 4.85072422\n",
      "Epoch: [200] [  42/  60] time: 291.8340, d_loss: 0.07805417, g_loss: 3.44030929\n",
      "Epoch: [200] [  43/  60] time: 292.3546, d_loss: 0.06855381, g_loss: 4.50387335\n",
      "Epoch: [200] [  44/  60] time: 292.9022, d_loss: 0.03217379, g_loss: 5.25281239\n",
      "Epoch: [200] [  45/  60] time: 293.4232, d_loss: 0.06428398, g_loss: 4.14532375\n",
      "Epoch: [200] [  46/  60] time: 293.9520, d_loss: 0.06211013, g_loss: 3.85469317\n",
      "Epoch: [200] [  47/  60] time: 294.4461, d_loss: 0.10612313, g_loss: 5.82983780\n",
      "Epoch: [200] [  48/  60] time: 294.9437, d_loss: 0.09307017, g_loss: 4.78777599\n",
      "Epoch: [200] [  49/  60] time: 295.4357, d_loss: 0.05141177, g_loss: 3.92978334\n",
      "Epoch: [200] [  50/  60] time: 295.9356, d_loss: 0.05613111, g_loss: 4.76186275\n",
      "Epoch: [200] [  51/  60] time: 296.4232, d_loss: 0.08037058, g_loss: 4.34564161\n",
      "Epoch: [200] [  52/  60] time: 296.9195, d_loss: 0.04186706, g_loss: 5.02988720\n",
      "Epoch: [200] [  53/  60] time: 297.4133, d_loss: 0.06902777, g_loss: 4.25330400\n",
      "Epoch: [200] [  54/  60] time: 297.9159, d_loss: 0.08504481, g_loss: 4.89109612\n",
      "Epoch: [200] [  55/  60] time: 298.4106, d_loss: 0.04238211, g_loss: 4.80879068\n",
      "Epoch: [200] [  56/  60] time: 298.9119, d_loss: 0.03074711, g_loss: 4.54512405\n",
      "Epoch: [200] [  57/  60] time: 299.4097, d_loss: 0.04089944, g_loss: 4.77453852\n",
      "Epoch: [200] [  58/  60] time: 299.9128, d_loss: 0.04898271, g_loss: 4.68915939\n",
      "Epoch: [200] [  59/  60] time: 300.4069, d_loss: 0.05188303, g_loss: 4.68855858\n",
      "[200/200] - ptime: 31.5319 loss_d: 0.05253163, loss_g: 4.69475079, lf:  0.00006974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:00<00:35,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg per epoch ptime: 29.53, total 200 epochs ptime: 317.22\n",
      " [*] Training finished!\n",
      " [*] Generation Animation GIF start!\n",
      " [*] Reading 200 (900, 600) images start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:26<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading 200 (900, 600) images finished!\n",
      " [*] Generation Animation (900, 600) GIF start! FPS= 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Generation Animation (900, 600) GIF finished! FPS= 5\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/60 [00:04<04:22,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 152 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/60 [00:09<04:49,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 136 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 3/60 [00:16<05:10,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 155 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 4/60 [00:26<06:14,  6.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 134 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 5/60 [00:33<06:04,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 110 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 6/60 [00:44<06:38,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 151 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 7/60 [00:50<06:23,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 168 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 8/60 [00:58<06:22,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 137 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 9/60 [01:06<06:19,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 127 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 10/60 [01:13<06:07,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 122 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 11/60 [01:21<06:04,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 145 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 12/60 [01:30<06:01,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 153 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 13/60 [01:41<06:07,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 148 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 14/60 [01:49<05:59,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 102 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 15/60 [01:58<05:56,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 150 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 16/60 [02:08<05:52,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 114 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 17/60 [02:14<05:41,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 116 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 18/60 [02:23<05:35,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 158 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 19/60 [02:31<05:26,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 111 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 20/60 [02:38<05:17,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 131 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 21/60 [02:46<05:09,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 121 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 22/60 [02:57<05:05,  8.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 113 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 23/60 [03:05<04:58,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 154 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 24/60 [03:13<04:50,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 120 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 25/60 [03:22<04:42,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 123 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 26/60 [03:30<04:35,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 140 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 27/60 [03:39<04:28,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 139 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 28/60 [03:51<04:24,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 144 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 29/60 [04:00<04:17,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 118 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 30/60 [04:09<04:09,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 147 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 31/60 [04:18<04:02,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 167 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 32/60 [04:28<03:54,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 165 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 33/60 [04:37<03:47,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 108 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 34/60 [04:47<03:40,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 104 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 35/60 [04:57<03:32,  8.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 160 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 36/60 [05:11<03:27,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 112 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 37/60 [05:22<03:20,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 107 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 38/60 [05:32<03:12,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 128 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 39/60 [05:43<03:04,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 132 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 40/60 [05:53<02:56,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 162 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████▊   | 41/60 [06:05<02:49,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 149 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 42/60 [06:16<02:41,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 135 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 43/60 [06:27<02:33,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 117 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 44/60 [06:39<02:25,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 164 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 45/60 [06:51<02:17,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 115 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 46/60 [07:02<02:08,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 109 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 47/60 [07:19<02:01,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 129 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 48/60 [07:31<01:52,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 100 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|████████▏ | 49/60 [07:43<01:44,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 166 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 50/60 [07:56<01:35,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 156 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 51/60 [08:09<01:26,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 133 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 52/60 [08:21<01:17,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 163 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 53/60 [08:34<01:07,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 142 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 54/60 [08:45<00:58,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 124 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 55/60 [08:54<00:48,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 101 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 56/60 [09:04<00:38,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 119 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 57/60 [09:14<00:29,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 141 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 58/60 [09:24<00:19,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 106 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 59/60 [09:37<00:09,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 125 , 100 new images!\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/Class2_Sample3_test1_1_1000_100_128_128/cDCGAN/cDCGAN.model-143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 60/60 [09:47<00:00,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Finished generating Epoch: 143 , 100 new images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gan_type = 'cDCGAN'\n",
    "dataset = 'Class2_Sample3_test1_1_1000'\n",
    "epoch = 200\n",
    "batch_size = 100\n",
    "checkpoint_dir = 'checkpoint'\n",
    "result_dir = 'results'\n",
    "log_dir = 'logs'\n",
    "test_dir = 'image_gan'\n",
    "trainhist_dir = 'trainhist'\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "# --result_dir\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    \n",
    "# --test_dir\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "# --trainhist_dir\n",
    "if not os.path.exists(trainhist_dir):\n",
    "    os.makedirs(trainhist_dir)\n",
    "\n",
    "# open session\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    \n",
    "    # declare instance for GAN\n",
    "    cDCGAN = cDCGAN(sess, epoch=epoch, batch_size=batch_size, dataset_name=dataset, checkpoint_dir=checkpoint_dir, \n",
    "                    result_dir=result_dir, log_dir=log_dir, test_dir=test_dir, trainhist_dir=trainhist_dir)\n",
    "\n",
    "    # build graph\n",
    "    cDCGAN.build_model()\n",
    "\n",
    "    # show network architecture\n",
    "    cDCGAN.show_all_variables()\n",
    "\n",
    "    # launch the graph in a session\n",
    "    cDCGAN.train()\n",
    "    \n",
    "    #visualize_img_to_gif\n",
    "    cDCGAN.visualize_img_to_gif(path=result_dir, size=(900,600), fps=5)\n",
    "\n",
    "    vepoch = random.sample(range(100,170), 60)\n",
    "\n",
    "    for e in tqdm(vepoch):\n",
    "        cDCGAN.visualize_test_image( e, 100, 1)\n",
    "        \n",
    "sess.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
